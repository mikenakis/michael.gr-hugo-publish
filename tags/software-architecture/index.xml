<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Software-Architecture on Michael&#39;s Blog</title>
        <link>//localhost:1313/tags/software-architecture/</link>
        <description>Recent content in Software-Architecture on Michael&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <copyright>Michael Belivanakis (a.k.a. Mike Nakis)</copyright>
        <lastBuildDate>Fri, 24 Oct 2025 10:19:02 +0200</lastBuildDate><atom:link href="//localhost:1313/tags/software-architecture/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>The perils of whiteboards</title>
        <link>//localhost:1313/post/2025-08-the-perils-of-whiteboards/</link>
        <pubDate>Thu, 28 Aug 2025 08:46:25 +0000</pubDate>
        
        <guid>//localhost:1313/post/2025-08-the-perils-of-whiteboards/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2025-08-the-perils-of-whiteboards/images/chimera.png&#34;
	width=&#34;1600&#34;
	height=&#34;952&#34;
	srcset=&#34;//localhost:1313/post/2025-08-the-perils-of-whiteboards/images/chimera_hu_6dff92ff1a9c9a17.png 480w, //localhost:1313/post/2025-08-the-perils-of-whiteboards/images/chimera_hu_7a9d1598158e4bb7.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;168&#34;
		data-flex-basis=&#34;403px&#34;
	
&gt;
&lt;/p&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;p&gt;Building upon the realization that conventional means of software design today amount to nothing more than fancy whiteboards, we examine the pitfalls, disadvantages, and consequences of designing software using such tools.&lt;/p&gt;
&lt;p&gt;This post is support material for  &lt;a 
   href=&#34;//localhost:1313/post/2023-12-09-authoritative-technical-design/&#34;
   &gt;Towards Authoritative Software Design&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id=&#34;the-means&#34;&gt;The means
&lt;/h3&gt;&lt;p&gt;The conventional means of software design today are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pen and paper&lt;/li&gt;
&lt;li&gt;Whiteboard&lt;/li&gt;
&lt;li&gt;General-purpose shape-drawing tools (e.g. Microsoft Word or PowerPoint drawings)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;or, in the best case,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Box-and-arrow drawing applications that are smart enough to keep the arrows connected as we drag the boxes around the canvas. (e.g. Microsoft Visio)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unfortunately, even the box-and-arrow apps have no notion of what the boxes and the arrows stand for; thus, they cannot be used for anything other than modelling, which makes them nothing more than fancy whiteboards.&lt;/p&gt;
&lt;p&gt;Over the years, various tools and techniques have been proposed to better aid the software design process, including UML, but none of them amounts to anything more than a fancy whiteboard. For details, see &lt;a 
   href=&#34;//localhost:1313/post/2025-08-the-state-of-affairs-in-computer-aided/&#34;
   &gt;The state of affairs in computer-aided software design&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;the-drawbacks&#34;&gt;The drawbacks
&lt;/h3&gt;&lt;p&gt;One of the immediately noticeable consequences of having nothing but whiteboards at our disposal is the lack of a standardized notation: every architect is free to express concepts in any way they like, and anyone attempting to make sense out of their design has to undergo initiation rituals. (UML attempted to standardize notation, but it is a failure, see &lt;a 
   href=&#34;//localhost:1313/post/2022-08-uml/&#34;
   &gt;On UML&lt;/a&gt;.) As a result, software design as conventionally practiced is not easy to communicate. This is, however, the least of our problems.&lt;/p&gt;
&lt;p&gt;Here  is a list of much more serious consequences of using whiteboards for technical software design:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Designs often include elements that are not well-defined in engineering terms.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You see this with designs containing supposedly technical but actually quite nebulous entities such as a &lt;em&gt;Persistent Data Store&lt;/em&gt; here, a &lt;em&gt;Messaging Backbone&lt;/em&gt; there, or a &lt;em&gt;Remote Server&lt;/em&gt; over there. Such entities are not sufficiently well-defined to be suitable for inclusion in a technical design.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Designs often include elements that are completely outside the realm of engineering.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You see this with designs containing human figures representing users, pictures of money representing payments, etc. The presence of such items in a software design usually indicates a confusion between what is a technical design and what is a functional specification.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Designs often include elements from wrong levels of abstraction.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You see this with designs that mix software components with flowcharts, state diagrams, etc. Notwithstanding the fact that these are also boxes connected with arrows, they represent decision-making logic, which is an implementation detail of the component that contains that logic; as such, they have no place in a design.&lt;/p&gt;
&lt;p&gt;You also see this with designs that confuse interfaces with other kinds of relationships between components, such as ownership, containment, inheritance, data flow, etc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Designs are not informed with what elements are available for      incorporation.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The medium on which software designs are conventionally expressed provides no technical means of establishing, or enforcing, a correspondence between a box as it appears in the design, and the actual provisionable, instantiatable, and  runnable software module that it represents. This can be okay in the case of modules that have not been developed yet, but more often than not, a design intends to incorporate existing modules. In the absence of any technical means for informing the design about existing modules, the design inescapably represents hypotheses, assumptions, and approximations rather than fact.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Designs often prescribe invalid combinations of elements.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The ways in which conventional designs intend to interconnect components do not necessarily match the ways in which the components can actually be interconnected.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A conventional design may assume that a certain component exposes or invokes a particular interface while in fact the component does not have  such an interface.&lt;/li&gt;
&lt;li&gt;A conventional design may prescribe a connection between two components on a particular interface, while in fact the interface exposed by one component is not a valid match for the interface invoked by the other component.&lt;/li&gt;
&lt;li&gt;A conventional design may fancy a connection that goes from one component to another component which is inside a different container. In reality, such crossing of containment boundaries is impossible; especially if it involves different execution environments or different levels of scale, it is complete nonsense.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Designs are often expressed at an unworkably high level of abstraction.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The level of abstraction necessary in order to guarantee the feasibility of a technical software design is that of the component diagram, which shows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The individual components that make up the system.&lt;/li&gt;
&lt;li&gt;The interfaces implemented and/or invoked by each component.&lt;/li&gt;
&lt;li&gt;Connections from interface invocations to interface implementations.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unfortunately, since conventional means of software design are not informed about existing components and their interfaces, they do not have enough factual information at their disposal to delve into the level of detail necessary for a component diagram.&lt;/p&gt;
&lt;p&gt;For this reason, the level of abstraction most commonly used by software architects is that of a block diagram, which might be suitable for abstract architectural work, but it is not detailed enough to give any guarantees about the feasibility of the proposed design.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Designs fail to capture dynamic aspects of software systems.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Conventional means of software design lack the ability to accurately express dynamic constructs such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Plurality: Multiple instantiation of a certain component, where the number  of instances is decided at runtime.&lt;/li&gt;
&lt;li&gt;Polymorphism: Fulfilling a certain role by instantiating one of several different component types capable of fulfilling that role, where the choice of which type to instantiate is made at runtime.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Designs are often incomplete.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A design may incorporate a component which needs to invoke a certain interface in order to get its job done, but omit incorporating a component implementing that interface. In such cases, the software system cannot be deployed as
designed, and yet the architects are free to proclaim the design as complete.&lt;/p&gt;
&lt;p&gt;The above long list of problems stems from the lack of technical means of informing the design with what is available, and restricting it to what is possible. This means that whiteboard designs allow the concoction of any &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Chimera_%28mythology%29&#34; target=&#34;_blank&#34;
   &gt;chimera&lt;/a&gt; imaginable.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For further reading, please see &lt;a 
   href=&#34;//localhost:1313/post/2023-12-09-authoritative-technical-design/&#34;
   &gt;Towards Authoritative Software Design&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: &lt;a class=&#34;external&#34; 
   href=&#34;https://commons.wikimedia.org/wiki/File:Coa_Illustration_Elements_Chimera.svg&#34; target=&#34;_blank&#34;
   &gt;Illustration of a chimera by Christie L. Ward, from Wikimedia Commons&lt;/a&gt;, used under &lt;a class=&#34;external&#34; 
   href=&#34;https://creativecommons.org/licenses/by-sa/3.0/deed.en&#34; target=&#34;_blank&#34;
   &gt;CC BY-SA 3.0&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>The confusion about the term Unit Testing</title>
        <link>//localhost:1313/post/2025-04-the-confusion-about-term-unit-testing/</link>
        <pubDate>Fri, 04 Apr 2025 14:53:02 +0000</pubDate>
        
        <guid>//localhost:1313/post/2025-04-the-confusion-about-term-unit-testing/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2025-04-the-confusion-about-term-unit-testing/images/crash-test-dummy-penseur.jpg&#34;
	width=&#34;2560&#34;
	height=&#34;1600&#34;
	srcset=&#34;//localhost:1313/post/2025-04-the-confusion-about-term-unit-testing/images/crash-test-dummy-penseur_hu_bcad233453122025.jpg 480w, //localhost:1313/post/2025-04-the-confusion-about-term-unit-testing/images/crash-test-dummy-penseur_hu_81009ce0ef2f8adf.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;Virtually everyone claims to be doing Unit Testing, but there is a surprising amount of disagreement as to how unit testing is defined. Let us see what the authorities on the subject have to say about it. What follows is mainly quotations from reputable sources, with some minimal commentary by me.&lt;/p&gt;
&lt;h3 id=&#34;wikipedia&#34;&gt;Wikipedia
&lt;/h3&gt;&lt;p&gt;Let us begin by checking &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Unit_testing&#34; target=&#34;_blank&#34;
   &gt;the Wikipedia entry for Unit Testing&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Unit testing, a.k.a. component or module testing, is a form of software testing by which isolated source code is tested to validate expected
behavior. Unit testing describes tests that are run at the unit-level to contrast testing at the integration or system level.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Further down in the history section, Wikipedia lists some of the earliest known efforts of what we would today call unit testing, where the common theme is testing separately smaller parts of large software systems before integrating them together.&lt;/p&gt;
&lt;p&gt;I am in full agreement with Wikipedia&amp;rsquo;s definition, but Wikipedia is everyone&amp;rsquo;s favorite source to cite if it agrees with their preconceptions, or proclaim untrustworthy if it does not, so can we find any other definition that corroborates the above?&lt;/p&gt;
&lt;h3 id=&#34;ieee&#34;&gt;IEEE
&lt;/h3&gt;&lt;p&gt;In the &lt;em&gt;&lt;strong&gt;Definitions&lt;/strong&gt;&lt;/em&gt; section of &lt;a class=&#34;external&#34; 
   href=&#34;https://ieeexplore.ieee.org/document/27763&#34; target=&#34;_blank&#34;
   &gt;IEEE 1008-1987 Standard for Software Unit Testing&lt;/a&gt; we read:&lt;/p&gt;
&lt;p&gt;[Warning! wooden language ahead!]&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;test unit3:&lt;/strong&gt; A set of one or more computer program modules together with associated control data, (for example, tables), usage procedures, and operating procedures that satisfy the following conditions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;All modules are from a single computer program&lt;/li&gt;
&lt;li&gt;At least one of the new or changed modules in the set has not completed the unit test&lt;sup&gt;4&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;The set of modules together with its associated data and procedures are the sole object of a testing process&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;p&gt;And the footnotes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;sup&gt;3&lt;/sup&gt; A test unit may occur at any level of the design hierarchy from a single module to a complete program. Therefore, a test unit may be a module, a few modules, or a complete computer program along with associated data and procedures.&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;4&lt;/sup&gt; A test unit may contain one or more modules that have already been unit tested.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;As we can see, IEEE&amp;rsquo;s definition says nothing about isolation; instead, it considers an entire set of modules, of which only one might need testing, as a unit.&lt;/p&gt;
&lt;p&gt;So, we have found a source that contradicts Wikipedia. It is a tie. Now we need to find a third opinion, to form a majority.&lt;/p&gt;
&lt;h3 id=&#34;kent-beck&#34;&gt;Kent Beck
&lt;/h3&gt;&lt;p&gt;Surely, Kent Beck, the inventor of Test-Driven Development and author of JUnit must have defined the term, right? Well, as it turns out, no.&lt;/p&gt;
&lt;p&gt;In his original &lt;a class=&#34;external&#34; 
   href=&#34;https://web.archive.org/web/20150315073817/http://www.xprogramming.com/testfram.htm&#34; target=&#34;_blank&#34;
   &gt;&amp;ldquo;Simple Smalltalk Testing: With Patterns&amp;rdquo; paper&lt;/a&gt; the closest he gets to providing a definition is this sentence:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I recommend that developers write their own unit tests, one per class.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Can &amp;ldquo;one test per class&amp;rdquo; be regarded as a definition of the term? I do not think so. I do not think it even makes sense as a statement, with modern programming languages and tooling.&lt;/p&gt;
&lt;p&gt;In &lt;em&gt;Test Driven Development by Example&lt;/em&gt; (2002) the closest that Kent Beck gets to providing a definition is this sentence:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The problem with driving development with small scale tests (I call them &amp;ldquo;unit tests&amp;rdquo;, but they don&amp;rsquo;t match the accepted definition of unit tests very well) is that you run the risk [&amp;hellip;]&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;So, Kent Beck seems to regard unit tests as small-scale tests, which is not really a definition, and he acknowledges that there exists some other, accepted definition, but he does not say what that definition is. Perhaps Kent Beck thinks of a unit test as &lt;em&gt;a unit of testing&lt;/em&gt;, as in &lt;em&gt;a unit of information&lt;/em&gt; or &lt;em&gt;a unit of improvement&lt;/em&gt;, but we cannot be sure.&lt;/p&gt;
&lt;p&gt;Although Kent Beck makes no other attempt to define the term, in the same book he does mention a couple of times that a unit test should be concerned with the externally visible behavior of a unit, not with its implementation.&lt;/p&gt;
&lt;p&gt;As a result, it should come as no surprise to hear that Kent Beck does not use mocks. In the video &lt;em&gt;Thoughtworks Hangouts: Is TDD dead?&lt;/em&gt; (&lt;a class=&#34;external&#34; 
   href=&#34;https://www.youtube.com/watch?v=z9quxZsLcfo&#34; target=&#34;_blank&#34;
   &gt;youtube&lt;/a&gt;, &lt;a class=&#34;external&#34; 
   href=&#34;https://martinfowler.com/articles/is-tdd-dead/&#34; target=&#34;_blank&#34;
   &gt;text digest&lt;/a&gt;) at 21&amp;rsquo;:10&amp;rsquo;&amp;rsquo; Kent Beck states:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;My personal practice is I mock almost nothing.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;martin-fowler&#34;&gt;Martin Fowler
&lt;/h3&gt;&lt;p&gt;One often-cited author who is known for defining terms and elucidating concepts is Martin Fowler. So, what does he have to say about unit testing?&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;external&#34; 
   href=&#34;https://martinfowler.com/bliki/UnitTest.html&#34; target=&#34;_blank&#34;
   &gt;Martin Fowler&amp;rsquo;s page on &lt;em&gt;&lt;strong&gt;Unit Test&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt; begins by acknowledging that it is an ill-defined term, and that the only characteristics of unit testing that people seem to agree on are that they are supposed to be a) small-scale, b) written by the programmers themselves, and c) fast. Then, Martin Fowler proceeds to talk about two schools of thought that understand the term differently:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &amp;ldquo;classicist&amp;rdquo; school of thought, which favors &amp;ldquo;sociable&amp;rdquo; unit tests, places emphasis on testing the behavior of a component, allowing the component to interact with its collaborators and assuming that the collaborators are working correctly. Martin Fowler places himself in this school of thought.&lt;/li&gt;
&lt;li&gt;The &amp;ldquo;mockist&amp;rdquo; school of thought, which favors &amp;ldquo;solitary&amp;rdquo; unit tests, insists on testing each component in isolation from its collaborators, and therefore requires that every collaborator must be replaced with a &amp;ldquo;test double&amp;rdquo; for the purpose of testing. Martin Fowler states that he respects this school of thought, but he does not belong to it.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Okay, so this did not lead us to a single definition of unit testing, but at least it helped us further define two competing definitions.&lt;/p&gt;
&lt;p&gt;It is also worth noting that Martin Fowler does not use mocks, either. In the video &lt;em&gt;Thoughtworks Hangouts: Is TDD dead?&lt;/em&gt; (&lt;a class=&#34;external&#34; 
   href=&#34;https://www.youtube.com/watch?v=z9quxZsLcfo&#34; target=&#34;_blank&#34;
   &gt;youtube&lt;/a&gt;, &lt;a class=&#34;external&#34; 
   href=&#34;https://martinfowler.com/articles/is-tdd-dead/&#34; target=&#34;_blank&#34;
   &gt;text digest&lt;/a&gt;) at 23&amp;rsquo;:56&amp;rsquo;&amp;rsquo; Martin Fowler adds:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I&amp;rsquo;m with Kent, I hardly ever use mocks.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;robert-c-martin-uncle-bob&#34;&gt;Robert C. Martin (Uncle Bob)
&lt;/h3&gt;&lt;p&gt;Among industry speakers, one of the most recognizable names is Robert C. Martin, a.k.a. Uncle Bob, author of the highly acclaimed book &lt;em&gt;&lt;strong&gt;Clean Code&lt;/strong&gt;&lt;/em&gt;. In his blog, under &lt;a class=&#34;external&#34; 
   href=&#34;https://blog.cleancoder.com/uncle-bob/2017/05/05/TestDefinitions.html&#34; target=&#34;_blank&#34;
   &gt;First-Class Tests&lt;/a&gt; he writes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Unit Test: A test written by a programmer for the purpose of ensuring that the production code does what the programmer expects it to do.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This is not very useful. According to this definition, a unit test could be virtually anything.&lt;/p&gt;
&lt;p&gt;Further down Uncle Bob gives a separate definition for integration tests, so maybe he regards the two as different, which would imply that he regards unit tests as testing units in isolation, but we cannot really be sure.&lt;/p&gt;
&lt;p&gt;To confuse things, further down he mentions mocks only in the context of what he calls functional tests, so maybe he thinks of mocks as not belonging to unit tests, (which then begs the question how the unit tests can achieve isolation,) but we cannot be sure about that, either.&lt;/p&gt;
&lt;p&gt;One thing we can be sure of is that Uncle Bob is also not particularly in favor of mocks. On that same page we read:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I, for example, seldom use a mocking tool. When I need a mock (or, rather, a Test Double) I write it myself.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Note that Uncle Bob finds it important enough to state his preference for a test double rather than a mock. That is probably because what he writes himself is fakes, not mocks. (Both fakes and mocks are different kinds of test doubles, see &lt;a class=&#34;external&#34; 
   href=&#34;https://martinfowler.com/bliki/TestDouble.html&#34; target=&#34;_blank&#34;
   &gt;Martin Fowler: Test Double&lt;/a&gt; and &lt;a class=&#34;external&#34; 
   href=&#34;https://martinfowler.com/articles/mocksArentStubs.html&#34; target=&#34;_blank&#34;
   &gt;Martin Fowler: Mocks Aren&amp;rsquo;t Stubs&lt;/a&gt;.)&lt;/p&gt;
&lt;h3 id=&#34;ian-cooper&#34;&gt;Ian Cooper
&lt;/h3&gt;&lt;p&gt;An interestingly conflicting opinion comes from Ian Cooper, an outspoken TDD advocate.&lt;/p&gt;
&lt;p&gt;In &lt;em&gt;&lt;a class=&#34;external&#34; 
   href=&#34;https://www.infoq.com/presentations/tdd-original/&#34; target=&#34;_blank&#34;
   &gt;TDD, Where Did It All Go Wrong? (&lt;/a&gt;&lt;a class=&#34;external&#34; 
   href=&#34;https://www.infoq.com/presentations/tdd-original/&#34; target=&#34;_blank&#34;
   &gt;InfoQ&lt;/a&gt;&lt;a class=&#34;external&#34; 
   href=&#34;https://www.infoq.com/presentations/tdd-original/&#34; target=&#34;_blank&#34;
   &gt;2017)&lt;/a&gt;&lt;/em&gt; Ian Cooper states that in TDD a unit test is defined as a test that runs in isolation from other tests, not a test that isolates the unit under test from other units. In other words, the unit of isolation is the test, not the unit under test.&lt;/p&gt;
&lt;p&gt;Ian Cooper obviously acknowledges that the prevailing understanding of unit tests is that they isolate the unit under test from other units, and he introduces a dissenting understanding, as if TDD is so radical that it justifies redefining long established terms. This is at best a refreshingly different take on the subject, and at worst a completely unfounded mental acrobatic.&lt;/p&gt;
&lt;p&gt;The notion that the term &amp;ldquo;unit&amp;rdquo; in unit testing refers to the test rather than the component-under-test is inadmissible at the very least because it does not rhyme with integration testing and end-to-end testing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Integration testing is about running our tests on integrations of system components, not about running tests somehow integrated with each other;&lt;/li&gt;
&lt;li&gt;End-to-end testing is about running our tests on our entire system as a whole, not about somehow stringing all of our tests together.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;therefore:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Unit testing is about running our tests on individual components of our system, not about running the tests individually. (Although I grant you that having isolation between individual tests is also a good idea, when possible.)&lt;/p&gt;
&lt;p&gt;It is worth noting that Ian Cooper also belongs to the ranks of those who do  not approve of mocks. In the same talk, at 49&amp;rsquo;:45&amp;rsquo;&amp;rsquo; he says:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;I argue quite heavily against mocks because they are over-specified.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;glenford-myers&#34;&gt;Glenford Myers
&lt;/h3&gt;&lt;p&gt;So far we have had only a moderate amount of luck in finding a majority opinion to define unit testing. Let us try to locate the original source of the term, shall we?&lt;/p&gt;
&lt;p&gt;I do not know for sure that the first recorded use of the term is in the 1979 classic &lt;em&gt;The Art of Software Testing&lt;/em&gt; by Glenford Myers, but the book is so old that it seems reasonable to suppose so.&lt;/p&gt;
&lt;p&gt;The original 1979 edition (ISBN 9780471043287, 0471043281)  is not easy to obtain, so I cannot ascertain this, but I strongly suspect that the term &amp;ldquo;unit&amp;rdquo; did not appear in it; instead, it was likely added in the 2nd edition, revised by other authors and published in 2004. Nonetheless, I think it is safe to assume that when back in 1979 Glenford Myers was writing of &amp;ldquo;module testing&amp;rdquo; what he meant was precisely that which we now call unit testing.&lt;/p&gt;
&lt;p&gt;In chapter 5 &amp;ldquo;Module (Unit) Testing&amp;rdquo; of the 2nd edition we read:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Module testing (or unit testing) is a process of testing the individual subprograms, subroutines, or procedures in a program. That is, rather than initially testing the program as a whole, testing is first focused on the smaller building blocks of the program.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Later in the same chapter the author acknowledges this form of testing to be white-box testing:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Module testing is largely white-box oriented.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Further down, he even lays down the foundations of what later came to be known as mocks:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[&amp;hellip;] since module B calls module E, something must be present to receive control when B calls E. A stub module, a special module given the name &amp;ldquo;E&amp;rdquo; that must be coded to simulate the function of module E, accomplishes this.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;So, this definition is in line with Wikipedia&amp;rsquo;s definition; we finally have a majority.&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;Although not unanimous, the prevailing opinion seems to be that the term unit refers to the component under test, and it is specifically called a unit because it is supposed to be tested in isolation from its collaborators, in contrast to integration testing and end-to-end testing where components are allowed to interact with their collaborators.&lt;/p&gt;
&lt;p&gt;This prevailing opinion comes from:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wikipedia&lt;/li&gt;
&lt;li&gt;Glenford Myers&lt;/li&gt;
&lt;li&gt;the mockist school of thought mentioned by Martin Fowler&lt;/li&gt;
&lt;li&gt;hints about a popular understanding of unit testing outside of TDD, which Ian Cooper tries to redefine in the context of TDD.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A lot of the confusion seems to stem from the fact that testing a component in isolation requires mocking its collaborators, but almost all of the people cited in this research realize that the use of mocks is misguided, so they either refrain from accurately defining the term, or try to give alternative definitions of the term, or speak of different schools of thought, in an attempt to legitimize violations of the requirement for isolation, so that they can still call what they do unit testing, even though it really is not.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: Created by michael.gr using ChatGPT, and then retouched to remove imperfections. The prompt used was: &amp;ldquo;Please give me an image of a crash test dummy in the style of The Thinker, by Auguste Rodin.&amp;rdquo;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Artificial Code Coverage</title>
        <link>//localhost:1313/post/2024-03-codecoverage/</link>
        <pubDate>Tue, 26 Mar 2024 15:01:55 +0000</pubDate>
        
        <guid>//localhost:1313/post/2024-03-codecoverage/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2024-03-codecoverage/images/patrick-robert-doyle-UrHNIeIjoE4-unsplash.jpg&#34;
	width=&#34;3258&#34;
	height=&#34;1890&#34;
	srcset=&#34;//localhost:1313/post/2024-03-codecoverage/images/patrick-robert-doyle-UrHNIeIjoE4-unsplash_hu_d19487727715a135.jpg 480w, //localhost:1313/post/2024-03-codecoverage/images/patrick-robert-doyle-UrHNIeIjoE4-unsplash_hu_15abe3b3c0c4821e.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;172&#34;
		data-flex-basis=&#34;413px&#34;
	
&gt;
&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract
&lt;/h3&gt;&lt;p&gt;In this paper I put forth the proposition that contrary to popular belief, 100% code coverage can be a very advantageous thing to have, and I discuss a technique for achieving it without excessive effort.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id=&#34;the-problem&#34;&gt;The problem
&lt;/h3&gt;&lt;p&gt;Conventional wisdom says that 100% code coverage is unnecessary, or even undesirable, because achieving it requires an exceedingly large amount of effort &lt;em&gt;&lt;strong&gt;not&lt;/strong&gt;&lt;/em&gt; for the purpose of asserting correctness, but instead for the sole purpose of achieving coverage. In other words, it is often said that 100% code coverage has no business value.&lt;/p&gt;
&lt;p&gt;Let me tell you why this is wrong, and why 100% code coverage can indeed be a very good thing to have.&lt;/p&gt;
&lt;p&gt;If you don&amp;rsquo;t have 100% code coverage, then by definition, you have some lower percentage, like 87.2%, or 94.5%. The remaining 12.8%, or 5.5% is uncovered. I call this &lt;em&gt;&lt;strong&gt;the worrisome percentage.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;As you keep working on your code base, the worrisome percentage fluctuates:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;one day you might add a test for some code that was previously uncovered, so the worrisome percentage decreases;&lt;/li&gt;
&lt;li&gt;another day you may add some code with no tests, so the percentage increases;&lt;/li&gt;
&lt;li&gt;yet another day you may add some more code along with tests, so even though the number of uncovered lines has not changed, it now represents a smaller percentage;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&amp;hellip; and it goes on like that.&lt;/p&gt;
&lt;p&gt;If the worrisome percentage is high, then you know for sure that you are doing a bad job, but if it is low, it does not mean that you are doing a good job, because some very important functionality may be left uncovered, and you just do not know. To make matters worse, modern programming languages offer constructs that achieve great terseness of code, meaning that a few uncovered lines may represent a considerable amount of uncovered functionality.&lt;/p&gt;
&lt;p&gt;So, each time you look at the worrisome percentage, you have to wonder what is in there: are all the important lines covered? are the uncovered lines okay to be left uncovered?&lt;/p&gt;
&lt;p&gt;In order to answer this question, you have to go over every single line of code in the worrisome percentage, and examine it to determine whether it is okay that it is being left uncovered. What you find is, more often than not, the usual suspects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Some &lt;code&gt;ToString()&lt;/code&gt; function which is only used for diagnostics;&lt;/li&gt;
&lt;li&gt;Some &lt;code&gt;Equals()&lt;/code&gt; and &lt;code&gt;HashCode()&lt;/code&gt; functions of some value type which does not currently happen to be used as a key in a hash-map;&lt;/li&gt;
&lt;li&gt;Some &lt;code&gt;default&lt;/code&gt; &lt;code&gt;switch&lt;/code&gt; clause which can never be reached, and if it was to ever be reached it would throw;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&amp;hellip; etc.&lt;/p&gt;
&lt;p&gt;So, your curiosity is satisfied, your worries are allayed, and you go back to your usual software development tasks.&lt;/p&gt;
&lt;p&gt;A couple of weeks later, the worrisome percentage has changed again, prompting the same question: what is being left uncovered now?&lt;/p&gt;
&lt;p&gt;Each time you need to have this question answered, you have to re-examine every single line of code in the worrisome percentage. As you do this, you discover that in the vast majority of cases, the lines that you are examining now are the exact same lines that you were examining the previous time you were going through this exercise. After a while, this starts getting tedious. Eventually, you quit looking. Sooner or later, everyone in the shop quits looking.&lt;/p&gt;
&lt;p&gt;The worrisome percentage has now become &lt;em&gt;&lt;strong&gt;terra incognita&lt;/strong&gt;&lt;/em&gt;: literally anything could be in there; nobody knows, and nobody wants to know, because finding out is such a dreary chore.&lt;/p&gt;
&lt;p&gt;That is not a particularly nice situation to be in.&lt;/p&gt;
&lt;h3 id=&#34;the-solution&#34;&gt;The solution
&lt;/h3&gt;&lt;p&gt;So, here is a radical proposition: If you always keep your code coverage at 100%, then the worrisome percentage is always zero, so there is nothing to worry about!&lt;/p&gt;
&lt;p&gt;When the worrisome percentage is never zero, then no matter how it fluctuates, it never represents an appreciable change in the situation: it always goes from some non-zero number to some other non-zero number, meaning that we used to have some code uncovered, and we still have some code uncovered. No matter what happens, there is no actionable item.&lt;/p&gt;
&lt;p&gt;On the other hand, if the worrisome percentage is normally zero, then each time it rises above zero it represents a definite change in the situation: you used to have everything covered, and now you have something uncovered. This signifies a clear call to action: the code that is now being left uncovered needs to be examined, and dealt with.&lt;/p&gt;
&lt;p&gt;By dealing with uncovered code as soon as it gets introduced, you bring the worrisome percentage back to zero, thus achieving two things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You ensure that next time the worrisome percentage becomes non-zero, it will represent a new call to action.&lt;/li&gt;
&lt;li&gt;You never find yourself in the unpleasant situation of re-examining code that has been examined before; so, the examination does not feel like a dreary chore.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The conventional understanding of how to deal with uncovered code is to write a test for it, and that is why achieving 100% code coverage is regarded as onerous; however, there exist alternatives that are much easier. For any given piece of uncovered code, you have three options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Option #1: Write a test for the code.&lt;/p&gt;
&lt;p&gt;This is of course the highest quality option, but it does not always represent the best value for money, and it is not even always possible. You only need to do it if the code is important enough to warrant testing, and you can only do it if the code is in fact testable. If you write a test, you can still minimize the effort of doing so, by utilizing certain techniques that I talk about in other posts, such as &lt;a 
   href=&#34;//localhost:1313/post/2024-04-audit-testing/&#34;
   &gt;Audit Testing&lt;/a&gt;, &lt;a 
   href=&#34;//localhost:1313/post/2022-10-testing-with-fakes/&#34;
   &gt;Testing with Fakes instead of Mocks&lt;/a&gt;, and &lt;a 
   href=&#34;//localhost:1313/post/2022-10-incremental-integration-testing/&#34;
   &gt;Incremental Integration Testing&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Option #2: Exclude the code from code coverage.&lt;/p&gt;
&lt;p&gt;Code that is not testable, or not important enough to warrant testing, can be moved into a separate module which does not participate in coverage analysis. Alternatively, if your code coverage analysis tool supports it, you may be able to exclude individual methods without having to move them to another module. In the DotNet world, this can be accomplished by marking a method with &lt;a class=&#34;external&#34; 
   href=&#34;https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.codeanalysis.excludefromcodecoverageattribute&#34; target=&#34;_blank&#34;
   &gt;the &lt;code&gt;ExcludeFromCodeCoverage&lt;/code&gt; attribute&lt;/a&gt;, found in the &lt;code&gt;System.Diagnostics.CodeAnalysis&lt;/code&gt; namespace. In the Java world, IntelliJ IDEA offers a setting for specifying what annotation we want to use for marking methods to be excluded from code coverage, so you can use any annotation you like. (See &lt;a 
   href=&#34;//localhost:1313/post/2022-12-intellij-idea-can-now-exclude-methods/&#34;
   &gt;IntelliJ IDEA can now exclude methods from code coverage&lt;/a&gt;.) Various different code coverage analyzers support additional ways of excluding code from coverage.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Option #3: Artificially cover the code.&lt;/p&gt;
&lt;p&gt;With the previous two options you should be able to bring the worrisome percentage down to a very small number, like 1 or 2 percent. What remains is code which should really be excluded from coverage, but it cannot, due to limitations in available tooling: although code coverage analyzers generally allow excluding entire functions from coverage analysis, they generally do not offer any means of excluding individual lines of code, such as the unreachable &lt;code&gt;default&lt;/code&gt; clause of some &lt;code&gt;switch&lt;/code&gt; statement. You can try moving that line into a separate function, and excluding that function, but you cannot exclude the call to that function, so the problem remains.&lt;/p&gt;
&lt;p&gt;The solution in these cases is to cause the uncovered code to be invoked during testing, &lt;em&gt;&lt;strong&gt;not&lt;/strong&gt;&lt;/em&gt; in order to test it, but simply in order to have it covered. This might sound like cheating, but it is not, because the stated objective was not to test the code, it was to exclude it from coverage. You would have excluded that line from coverage if the tooling supported doing so, but since it does not, the next best thing, (and the only option you are left with,) is to artificially include it in the code coverage.&lt;/p&gt;
&lt;p&gt;Here is a (hopefully exhaustive) list of all the different reasons due to which code might be left uncovered, and what to do in each case:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The code should really be covered, but you forgot to write tests for it, or you have plans to write tests in the future.&lt;/p&gt;
&lt;p&gt;Go with Option #1: write tests for it. Not in the future, &lt;em&gt;&lt;strong&gt;now&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The code is not used and there is no plan to use it.&lt;/p&gt;
&lt;p&gt;This is presumably code which exists for historical reasons, or for reference, or because it took some effort to write it and you do not want to admit that the effort was a waste by throwing away the code.&lt;/p&gt;
&lt;p&gt;Go with Option #2 and exclude it from coverage.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The code is only used for diagnostics.&lt;/p&gt;
&lt;p&gt;The prime example of this is &lt;code&gt;ToString()&lt;/code&gt; methods that are not normally invoked in a production environment, but give informative
descriptions of our objects while debugging.&lt;/p&gt;
&lt;p&gt;Go with Option #2: Exclude such methods from coverage.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The code is not normally reachable, but it is there in case something unexpected happens.&lt;/p&gt;
&lt;p&gt;The prime example of this is C# &lt;code&gt;switch&lt;/code&gt; statements that cover all possible cases and yet also contain a &lt;code&gt;default&lt;/code&gt; clause just in case an unexpected value somehow manages to creep in.&lt;/p&gt;
&lt;p&gt;Go with Option #3: Artificially cover such code. This may require a bit of refactoring to make it easier to cause the problematic &lt;code&gt;switch&lt;/code&gt; statement to be invoked with an invalid value. The code most likely throws, so catch the exception and swallow it. You can also assert that the expected exception was thrown, in which case it becomes more like Option #1: a test.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The code is reachable but not currently being reached.&lt;/p&gt;
&lt;p&gt;This is code which is necessary for completeness, and it just so happens that it is not currently being used, but nothing prevents it from being used at any moment. A prime example of this is the &lt;code&gt;Equals()&lt;/code&gt; and &lt;code&gt;HashCode()&lt;/code&gt; functions of value types: without those functions, a value type is incomplete; however, if the value type does not currently happen to be used as a key in a hash-map, then those functions are almost certainly unused.&lt;/p&gt;
&lt;p&gt;In this case, you can go with any of the three options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You can go with Option #1 and write a proper test.&lt;/li&gt;
&lt;li&gt;You can go with Option #2 and exclude the code.&lt;/li&gt;
&lt;li&gt;You can go with Option #3 and artificially cover the code.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The code is not important enough to have a test for it.&lt;/p&gt;
&lt;p&gt;Say you have a function which takes a tree data structure and converts it to text using &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Box-drawing_character&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;box-drawing characters&lt;/em&gt;&lt;/a&gt; so as to be able to print it nicely as a tree on the console. Since the function receives text and emits text, it is certainly testable, but is it really worth testing? If it ever draws something wrongly, you will probably notice, and if you do not notice, then maybe it did not matter anyway.&lt;/p&gt;
&lt;p&gt;In this case you can go either with Option #2 and exclude such functions, or Option #3 and artificially cover them.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The code is literally or practically untestable.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If your application has a Graphical User Interface (GUI), you can write automated tests for all of your application logic, but the only practical way to ascertain the correctness of the GUI is to have human eyes staring at the screen. (There exist tools for testing GUIs, but I assess them as &lt;em&gt;woefully impractical and acutely ineffective&lt;/em&gt;.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If your application controls some hardware, you may have a hardware abstraction layer with two implementations, one which emulates the hardware, and one which interacts with the actual hardware. The emulator will enable you to test all of your application logic without having the actual hardware in place; however, the implementation which interacts with the actual hardware is practically untestable by software alone.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you have a piece of code that queries the endianness of the hardware architecture and operates slightly differently depending on it, the only path you can truly cover is the one for the endianness of the hardware architecture you are actually using. (You can fake the endianness query, and pretend that your hardware has the opposite endianness, but you still have no guarantees as to whether the bit-juggling that you do in that path is right for the opposite endianness.)&lt;/p&gt;
&lt;p&gt;In all of the above cases, and in all similar cases, we have no option but #2: exclude the code from coverage.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h4&gt;&lt;p&gt;If testing has business value, then 100% code coverage has business value, too.&lt;/p&gt;
&lt;p&gt;A code coverage percentage of 100% is very useful, not for bragging, but for maintaining certainty that everything that ought to be tested is in fact being tested.&lt;/p&gt;
&lt;p&gt;Achieving a code coverage percentage of 100% does require some effort, but with techniques such as Artificial Coverage the effort can be reduced to manageable levels.&lt;/p&gt;
&lt;p&gt;Ideally, Artificial Coverage should never be necessary, but it is a practical workaround for the inability of coverage tools to exclude individual lines of code from analysis.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image by &lt;a class=&#34;external&#34; 
   href=&#34;https://unsplash.com/@teapowered&#34; target=&#34;_blank&#34;
   &gt;Patrick Robert Doyle from Unsplash&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Types of dependencies</title>
        <link>//localhost:1313/post/2024-01-types-of-dependencies/</link>
        <pubDate>Thu, 11 Jan 2024 17:33:42 +0000</pubDate>
        
        <guid>//localhost:1313/post/2024-01-types-of-dependencies/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2024-01-types-of-dependencies/images/dependency0.png&#34;
	width=&#34;1861&#34;
	height=&#34;1046&#34;
	srcset=&#34;//localhost:1313/post/2024-01-types-of-dependencies/images/dependency0_hu_616f75dcb058bc68.png 480w, //localhost:1313/post/2024-01-types-of-dependencies/images/dependency0_hu_55cc59d1b7857d37.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;The term &amp;ldquo;dependency&amp;rdquo; is used very often in software engineering, but depending on context, it may mean slightly different things. To avoid confusion, here are the different meanings of the term, and their explanations.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Compile-time (static) dependency:&lt;/strong&gt; When module &lt;strong&gt;A&lt;/strong&gt; makes use of a symbol which is defined in module &lt;strong&gt;B&lt;/strong&gt;, we say that &lt;strong&gt;A&lt;/strong&gt; has a compile-time dependency on &lt;strong&gt;B&lt;/strong&gt;. (Or that &lt;strong&gt;B is a compile-time dependency of A.&lt;/strong&gt;) This happens not only when module &lt;strong&gt;A&lt;/strong&gt; contains a hard-coded invocation to module &lt;strong&gt;B&lt;/strong&gt;, but also when &lt;strong&gt;A&lt;/strong&gt; makes use of some definition from &lt;strong&gt;B&lt;/strong&gt;, such as referring to a constant, implementing an interface, or instantiating a type defined in &lt;strong&gt;B&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Runtime (dynamic) dependency:&lt;/strong&gt; When module &lt;strong&gt;A&lt;/strong&gt; is given, at runtime, a reference to invoke module &lt;strong&gt;B&lt;/strong&gt;, then we have a runtime dependency between &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt;. Runtime dependencies can be further divided in two sub-categories:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Assembly-time (semi-dynamic) dependency:&lt;/strong&gt; This is a runtime dependency which is realized during system assembly, and remains unchanged throughout the lifetime of the system.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Post-assembly-time (fully dynamic) dependency:&lt;/strong&gt; This is a runtime dependency which may be realized or changed at any moment, by having one module programmatically pass a callback to another module.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we are to take the &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Dependency_inversion_principle&#34; target=&#34;_blank&#34;
   &gt;Dependency Inversion Principle (DIP)&lt;/a&gt; for granted in software architecture, (and we should,) then software architecture is not concerned with static dependencies. This is because the DIP states that concrete modules should never statically depend on other concrete modules; instead, concrete modules may statically depend only on abstractions. Thus, the DIP is advising us to build our concrete modules so that they have no knowledge of each other. Instead, they should be making outgoing invocations to interfaces, and these invocations should be wired to concrete modules implementing those interfaces. Interfaces are abstractions, so it is okay for a concrete module to have compile-time dependencies on modules defining such abstractions.&lt;/p&gt;
&lt;p&gt;Assembly-time dependencies are what software architecture is mostly concerned with. The architecture of a software system specifies how to wire interface invocations between components. The wiring prescribed by the design is normally performed during system assembly, which is part of system deployment. Thus, the wires constitute assembly-time dependencies, and the graph of these dependencies is essentially the call graph of the system as defined by the architecture.&lt;/p&gt;
&lt;p&gt;Post-assembly-time dependencies do not affect the topology of a design, because every post-assembly time dependency requires an existing assembly-time dependency through which the callback can be communicated. Thus, post-assembly-time dependencies constitute implementation details of the modules that supply and invoke callbacks. As such, they are of only limited interest in software architecture.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Call Graph Acyclicity</title>
        <link>//localhost:1313/post/2023-12-27-call-graph-acyclicity/</link>
        <pubDate>Wed, 27 Dec 2023 12:08:24 +0000</pubDate>
        
        <guid>//localhost:1313/post/2023-12-27-call-graph-acyclicity/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic0.png&#34;
	width=&#34;1860&#34;
	height=&#34;1122&#34;
	srcset=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic0_hu_5c4a1077d5a1af0.png 480w, //localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic0_hu_bc6ab53ae2d39e03.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;165&#34;
		data-flex-basis=&#34;397px&#34;
	
&gt;
&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract
&lt;/h3&gt;&lt;p&gt;In technical design of software systems as conventionally practiced, call graphs often contain cycles. We show that cyclic call graphs are highly problematic for a number of reasons, the most important being that they require careful handling on a case-by-case basis by custom-written code, thus preventing the standardization, and therefore the automation, of system assembly. We discuss refactoring strategies for systematically eliminating call cycles, including a universally applicable technique for trivially eliminating a certain common type of call cycle. We conclude that since call cycles can be avoided or eliminated, they can be comprehensively disallowed, thus paving the way for the automation of system assembly.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id=&#34;what-is-a-cycle-in-a-call-graph&#34;&gt;What is a cycle in a call graph
&lt;/h3&gt;&lt;p&gt;When component &lt;strong&gt;A&lt;/strong&gt; invokes component &lt;strong&gt;B&lt;/strong&gt;, and component &lt;strong&gt;B&lt;/strong&gt; also invokes component &lt;strong&gt;A&lt;/strong&gt;, we say that the call graph contains a &lt;em&gt;direct&lt;/em&gt; cycle. If &lt;strong&gt;A&lt;/strong&gt; invokes &lt;strong&gt;B&lt;/strong&gt;, which invokes &lt;strong&gt;C&lt;/strong&gt;, which in turn invokes &lt;strong&gt;A&lt;/strong&gt;, we say that the call graph contains an &lt;em&gt;indirect&lt;/em&gt; cycle. If &lt;strong&gt;A&lt;/strong&gt; invokes itself, we say that the call graph contains a self-loop, or a buckle, which is a special case of a cycle. In general, if a component diagram contains any path of invocations starting at a certain component and arriving back at the same component, the call graph contains a cycle.&lt;/p&gt;
&lt;p&gt;As an example, let us consider the simplest possible scenario, consisting of just two components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A temperature sensor component, whose job is to obtain a temperature value from some piece of hardware, and make that value available within the software system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A temperature indicator component, whose job is to display a temperature on the screen.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic1.png&#34;
	width=&#34;1860&#34;
	height=&#34;686&#34;
	srcset=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic1_hu_bb41670c7de8d3cb.png 480w, //localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic1_hu_2dad1d21c6ed7e3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;271&#34;
		data-flex-basis=&#34;650px&#34;
	
&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this diagram, each component has &lt;em&gt;&lt;strong&gt;inputs&lt;/strong&gt;&lt;/em&gt; and &lt;strong&gt;outputs&lt;/strong&gt;, collectively known as &lt;em&gt;&lt;strong&gt;pins&lt;/strong&gt;&lt;/em&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An input is an endpoint for receiving incoming interface invocations; it represents an interface exposed by a component for invocation by other components. It is signified by an arrow pointing into the component.&lt;/li&gt;
&lt;li&gt;An output is an endpoint through which a component places outgoing interface invocations; it represents an interface that a component wants to invoke. It is signified by an arrow pointing out of the component.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For those familiar with UML component diagrams, an input is a &lt;em&gt;&lt;strong&gt;provided&lt;/strong&gt;&lt;/em&gt; interface in UML, and an output is a &lt;em&gt;&lt;strong&gt;required&lt;/strong&gt;&lt;/em&gt; interface in UML. In this paper we use arrows to show the direction of invocations from output to input, instead of the socket-and-lollipop notation of UML.&lt;/p&gt;
&lt;p&gt;Each input and output has a name and a type. Obviously, an output can be connected to an input only if their types match.&lt;/p&gt;
&lt;p&gt;The temperature sensor:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Has an input called &lt;em&gt;&lt;strong&gt;Reading&lt;/strong&gt;&lt;/em&gt;, of type &lt;em&gt;&lt;strong&gt;ReadonlyFloat&lt;/strong&gt;&lt;/em&gt;, which can be invoked by some other component to obtain the current value of the temperature.&lt;/li&gt;
&lt;li&gt;Has an output called &lt;em&gt;&lt;strong&gt;Changed&lt;/strong&gt;&lt;/em&gt;, of type &lt;em&gt;&lt;strong&gt;Procedure0&lt;/strong&gt;&lt;/em&gt; (same thing as the &amp;ldquo;Runnable&amp;rdquo; of Java or the &amp;ldquo;Action&amp;rdquo; of C#) that it invokes in order to indicate that the value of the temperature has changed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The temperature indicator:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Has an output which is called &lt;em&gt;&lt;strong&gt;Reading&lt;/strong&gt;&lt;/em&gt;, of type &lt;em&gt;&lt;strong&gt;ReadonlyFloat&lt;/strong&gt;&lt;/em&gt;, that it invokes in order to obtain the current value of the temperature.&lt;/li&gt;
&lt;li&gt;Has an input called &lt;em&gt;&lt;strong&gt;Refresh&lt;/strong&gt;&lt;/em&gt;, of type &lt;em&gt;&lt;strong&gt;Procedure0&lt;/strong&gt;&lt;/em&gt;, which can be invoked to cause the indicator to re-display the current temperature value.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the diagram, the &lt;em&gt;&lt;strong&gt;Reading&lt;/strong&gt;&lt;/em&gt; output of the indicator has been connected to the &lt;em&gt;&lt;strong&gt;Reading&lt;/strong&gt;&lt;/em&gt; input of the sensor, and the &lt;em&gt;&lt;strong&gt;Changed&lt;/strong&gt;&lt;/em&gt; output of the sensor has been connected to the &lt;em&gt;&lt;strong&gt;Refresh&lt;/strong&gt;&lt;/em&gt; input of the indicator. Note that this design has a call cycle in it: The indicator invokes the sensor to obtain the current temperature, but the sensor also invokes the indicator to tell it that the current temperature has changed.&lt;/p&gt;
&lt;h3 id=&#34;dependencies&#34;&gt;Dependencies
&lt;/h3&gt;&lt;p&gt;In &lt;a 
   href=&#34;//localhost:1313/post/2024-01-types-of-dependencies/&#34;
   &gt;Types of dependencies&lt;/a&gt; I differentiate between &lt;strong&gt;compile-time (static)&lt;/strong&gt; dependencies, &lt;strong&gt;assembly-time (semi-dynamic)&lt;/strong&gt; dependencies, and &lt;strong&gt;post-assembly-time (fully dynamic)&lt;/strong&gt; dependencies.&lt;/p&gt;
&lt;p&gt;Compile-time dependencies have already been given a lot of consideration and the general consensus is that they better not be cyclic. Most build systems prohibit static dependency cycles between build modules; for example, in the Java world, Maven artifacts cannot circularly depend on each other; similarly, in the dotnet world, MSBuild projects cannot circularly depend on each other. However, programming languages usually allow compile-time dependency cycles within program code: if classes &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt; are defined within the same build module, it is usually possible to have &lt;strong&gt;A&lt;/strong&gt; contain a hard-coded invocation to a method of &lt;strong&gt;B&lt;/strong&gt;, and for &lt;strong&gt;B&lt;/strong&gt; to also contain a hard-coded invocation to a method of &lt;strong&gt;A&lt;/strong&gt;. Nonetheless, software architecture is not concerned with hard-coded invocations; therefore, in this paper the term &amp;ldquo;dependency&amp;rdquo; does &lt;em&gt;&lt;strong&gt;not&lt;/strong&gt;&lt;/em&gt; refer to compile-time (static) dependencies.&lt;/p&gt;
&lt;p&gt;Assembly-time dependencies are what software architecture is mostly concerned with, and as such, this is the sense in which the term &amp;ldquo;dependency&amp;rdquo; is used in this paper.&lt;/p&gt;
&lt;p&gt;Post-assembly-time dependencies are useful, as we will see, in certain techniques for eliminating call cycles; however, they do not affect the topology of a design, (they are implementation details which are not representable in a component diagram,) and as such these are not the kind of dependencies that we are referring to when we speak of dependencies in this paper.&lt;/p&gt;
&lt;h3 id=&#34;are-call-cycles-common&#34;&gt;Are call cycles common?
&lt;/h3&gt;&lt;p&gt;In software design as conventionally practiced, cycles in the call graph are a frequent phenomenon. Software architects often have no qualms about producing a design where &lt;strong&gt;A&lt;/strong&gt; calls &lt;strong&gt;B&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt; also calls &lt;strong&gt;A&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In the literature we find statements endorsing this practice. For example, in the seminal paper &lt;a class=&#34;external&#34; 
   href=&#34;https://c2.com/doc/oopsla89/paper.html&#34; target=&#34;_blank&#34;
   &gt;&amp;ldquo;A Laboratory For Teaching Object-Oriented Thinking&amp;rdquo;&lt;/a&gt;&lt;a class=&#34;external&#34; 
   href=&#34;https://c2.com/doc/oopsla89/paper.html&#34; target=&#34;_blank&#34;
   &gt;(1989)&lt;/a&gt; by &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Kent_Beck&#34; target=&#34;_blank&#34;
   &gt;Kent Beck&lt;/a&gt; and &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Ward_Cunningham&#34; target=&#34;_blank&#34;
   &gt;Ward Cunningham&lt;/a&gt;, the authors acknowledge that many components act as servers &amp;ldquo;with little regard or even awareness of [their] client&amp;rdquo;, but also find it perfectly normal for some components to be &amp;ldquo;near-equals&amp;rdquo; in a &amp;ldquo;symmetric relation&amp;rdquo;. That paper introduced the term &amp;ldquo;collaborator&amp;rdquo;, which became a staple term in the software engineering discipline, specifically in order to allow for bidirectional interaction between components, as opposed to the already-existing term &amp;ldquo;dependency&amp;rdquo;, which implies a one-way interaction. (For more on this, see &lt;a 
   href=&#34;//localhost:1313/post/2023-01-16-collaborator/&#34;
   &gt;Definition: Collaborator&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id=&#34;the-problem-with-cyclic-call-graphs&#34;&gt;The problem with cyclic call graphs
&lt;/h3&gt;&lt;p&gt;Cyclic call graphs constitute &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Tight_coupling?redirect=no&#34; target=&#34;_blank&#34;
   &gt;tight coupling&lt;/a&gt;. This in turn has a severe negative effect on the understandability and maintainability of software. Wikipedia &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Coupling_%28computer_programming%29&#34; target=&#34;_blank&#34;
   &gt;lists some specific disadvantages of tight coupling&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A change in one module usually forces a ripple effect of changes in other modules.&lt;/li&gt;
&lt;li&gt;Assembly of modules might require more effort and/or time due to the increased inter-module dependency.&lt;/li&gt;
&lt;li&gt;A particular module might be harder to reuse and/or test because dependent modules must be included.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The second point might be a bit vague, but it is very important, so it is worth examining it in more depth. The term &amp;ldquo;assembly of modules&amp;rdquo; refers to the process of instantiating each component that makes up the system, and wiring the components together so that the system can start running. In this paper, we call this process &lt;em&gt;&lt;strong&gt;system assembly&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The simplest approach to system assembly is to pass to each component all of its dependencies as constructor parameters when instantiating it, so that immediately upon construction the component is ready to start performing its duties. However, this approach is not viable if the call graph contains cycles, because circular dependencies introduce a chicken-and-egg problem: If each component requires all of its dependencies to be passed as constructor parameters, and if components &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt; depend on each other, then &lt;strong&gt;A&lt;/strong&gt; can only be constructed if &lt;strong&gt;B&lt;/strong&gt; has already been constructed, but &lt;strong&gt;B&lt;/strong&gt; cannot be constructed unless &lt;strong&gt;A&lt;/strong&gt; has been constructed first.&lt;/p&gt;
&lt;p&gt;This problem is pervasive, but it has not received much attention because we are resigned to software development being a largely unstandardized, labor-intensive process where copious amounts of custom-written code provide ad-hoc solutions to long-standing problems on a case by case basis. During system assembly, developers tend to wire as many components as they can during construction, and when a certain wire turns out to form a call cycle, they make a special case and refactor the components involved so as to postpone the wiring of that particular call until after construction. (This often leads to order-of-initialization bugs, which require painstaking effort to troubleshoot and fix.)&lt;/p&gt;
&lt;p&gt;As the system evolves, and wires between components are added or removed, developers try to keep components unchanged by re-arranging the order in which they are instantiated, and when this is not enough, they further refactor components, turning more construction-time wiring into post-construction-time wiring, and vice versa. (Invariably resulting in &lt;em&gt;more&lt;/em&gt; order-of-initialization bugs, and &lt;em&gt;more&lt;/em&gt; painstaking effort to troubleshoot and fix them.)&lt;/p&gt;
&lt;p&gt;Conventional software development practices often utilize &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Dependency_injection#Frameworks&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;&lt;strong&gt;dependency injection frameworks&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt; to handle the wiring of components. Such frameworks work as if by magic, which is by some schools of thought undesirable by definition; they also represent substantial runtime overhead, so they are unsuitable for certain classes of applications, e.g. for embedded systems. Some dependency injection frameworks do not solve the problem of circular dependencies, because they simply prohibit them, whereas others attempt to solve the problem by transparently creating proxy objects, which postpone wiring until some post-construction moment, and are therefore doubly magical. The problem with proxy objects is that they tend to fail if invoked from within a constructor, and when this happens it is extremely difficult to troubleshoot and fix. Most importantly, dependency injection frameworks tend to hide dependencies from view, while the goal of software architecture is precisely the opposite: to keep dependencies into view.&lt;/p&gt;
&lt;p&gt;The promise of authoritative technical software design, where the end-system is automatically generated from the design with no human intervention, requires us to stop writing custom code which wires components together in ad-hoc ways, and to replace it with a universally applicable, fully automated mechanism for assembling a system. In order for this mechanism to be fully automated, it must be fully standardized. If we were to try to standardize system assembly while allowing call cycles, we might for a moment imagine that we could accomplish our goal with a three-phase approach:&lt;/p&gt;
&lt;p&gt;(Note: I am not actually recommending this! It will not work!)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Construction:&lt;/strong&gt; All components are instantiated in an unconnected state.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wiring:&lt;/strong&gt; Now that all components exist, each component receives its dependencies.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Showtime:&lt;/strong&gt; A special event is broadcast to all components, letting them know that wiring is complete, so they can now perform their
initialization and start performing their duties.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This three-phase approach imposes a number of bureaucratic requirements on each component:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Each component must support some means of receiving references to its dependencies after construction. This constitutes incidental complexity.&lt;/li&gt;
&lt;li&gt;Each component must support some means of receiving the showtime event, so that it can perform the initialization that it would have otherwise performed in its constructor. This also constitutes incidental complexity.&lt;/li&gt;
&lt;li&gt;The requirement for components to be able to receive their dependencies after construction and to respond to the &amp;ldquo;showtime&amp;rdquo; event necessitates the introduction of some &lt;code&gt;IComponent&lt;/code&gt; interface, which must be implemented by all components. This ties all components to the framework which defines &lt;code&gt;IComponent&lt;/code&gt; and knows what to do with it.&lt;/li&gt;
&lt;li&gt;The member fields in which a component stores the references to its dependencies are initialized after construction, and therefore must be
declared as mutable, even though in principle they ought to be immutable. Similarly, the initialization performed during the showtime event often generates information that needs to be stored in member fields for later use. These member fields are also initialized after construction, so they must also be declared as mutable, even though in principle many of them ought to be immutable. Thus, any notion of immutability goes out the window.  Many components might still be &lt;em&gt;effectively immutable&lt;/em&gt;, but all of them  are very mutable as far as any code analysis tool can tell.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Most importantly, the three-phase approach does not solve the chicken-and-egg problem that we mentioned earlier, it only postpones it in time: When an event is triggered, the order in which event handlers are invoked is undefined. This means that during the processing of the showtime event a component may attempt to invoke another component which has not yet received the event, and therefore has not yet performed its initialization.&lt;/p&gt;
&lt;p&gt;Even if we were to further complicate things by introducing some additional mechanism that would give programmers control over the order in which components process the showtime event, the problem still remains: The presence of cycles in the call graph always leaves open the possibility that some components will be invoked before they have been initialized. It should by now be evident that cyclic call graphs are highly problematic, and that if they are to be allowed then there is no way to standardize system assembly. It remains to be shown whether call cycles can be systematically avoided or eliminated, and thus disallowed.&lt;/p&gt;
&lt;h3 id=&#34;solving-the-trivial-case&#34;&gt;Solving the trivial case
&lt;/h3&gt;&lt;p&gt;If our goal is to eliminate the cycle in the call graph of the earlier example with the temperature sensor and the temperature indicator, we can trivially accomplish it by applying the &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Observer_pattern&#34; target=&#34;_blank&#34;
   &gt;Observer Pattern&lt;/a&gt;, as shown in the following figure:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic2.png&#34;
	width=&#34;1861&#34;
	height=&#34;587&#34;
	srcset=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic2_hu_47aa25ae2d1ea891.png 480w, //localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic2_hu_1fd4268ef71dec79.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;317&#34;
		data-flex-basis=&#34;760px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;Note that the sensor does not invoke the indicator anymore; instead, the indicator invokes the sensor not only to read the current temperature but also to register an observer for temperature change notifications. The fact that the sensor will then be invoking that observer is an implementation detail which does not affect the topology of the design; thus, this design is free of cycles.&lt;/p&gt;
&lt;p&gt;Practically, the use of the observer pattern means that the sensor cannot invoke the indicator before the indicator has registered its observable, and this in turn means that the indicator can never be invoked before its initialization is complete.&lt;/p&gt;
&lt;p&gt;By eliminating the call cycle between the sensor and the indicator, we end up with a system that has a specific, computable order of initialization which is guaranteed to be free of problems: the sensor does not depend on the indicator anymore, so it can always be constructed first. The indicator, which depends on the sensor, can always be constructed after the sensor, so it can receive its dependencies as constructor parameters.&lt;/p&gt;
&lt;p&gt;As a result, each component can store all of its dependencies in immutable member variables. The only interface that needs to be stored in a mutable member variable is the callback that the observable receives from the observer, and this is in line with the nature of the observer pattern, where registration and de-registration of callbacks necessarily involves mutation.&lt;/p&gt;
&lt;p&gt;Pins of type &lt;code&gt;Observable&amp;amp;lt;T&amp;amp;gt;&lt;/code&gt; are bound to occur so often in software designs, that they warrant some special notation in order to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simplify their representation.&lt;/li&gt;
&lt;li&gt;Make them more conspicuous.&lt;/li&gt;
&lt;li&gt;Save space in the diagram.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following figure shows an example of what this notation could look like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic3.png&#34;
	width=&#34;1860&#34;
	height=&#34;590&#34;
	srcset=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic3_hu_720b9cdf7430d0df.png 480w, //localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic3_hu_3aca30d589c5dd57.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;315&#34;
		data-flex-basis=&#34;756px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;In the above diagram, the following changes have been made to pins of type &lt;code&gt;Observable&amp;amp;lt;T&amp;amp;gt;&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The generics notation (&lt;code&gt;Observable&amp;amp;lt;T&amp;amp;gt;&lt;/code&gt;) has been replaced with tilde notation (&lt;code&gt;~T&lt;/code&gt;). The tilde indicates that the type of the pin is not really of type &lt;code&gt;T&lt;/code&gt;, it is of type &lt;code&gt;Observable&amp;amp;lt;T&amp;amp;gt;&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The arrows of the observable pins have been replaced with slightly larger circles containing slightly smaller arrows pointing in the opposite direction.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The encircled arrows are not pointing from the output to the input as normal arrows do; instead, the encircled arrows are showing the direction of callback invocations, so they are pointing from the input to the output. Essentially, a circle signifies inversion of the direction of invocations, so an encircled arrow corresponds to a normal arrow of the opposite direction.&lt;/p&gt;
&lt;p&gt;If the callback interface does not contain any methods that return information, (as the case is with all notification interfaces,) the above design can be improved even more.&lt;/p&gt;
&lt;p&gt;First, note that the refactoring of an input-output pair to an observer-output-observable-input pair results in components that violate the &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Single_responsibility_principle&#34; target=&#34;_blank&#34;
   &gt;&lt;strong&gt;Single Responsibility Principle&lt;/strong&gt; (&lt;strong&gt;SRP&lt;/strong&gt;)&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Instead of simply exposing a &lt;em&gt;&lt;strong&gt;Changed&lt;/strong&gt;&lt;/em&gt; output, the sensor now has to implement the functionality of an event manager, so as to offer the same notification as an observable input.&lt;/li&gt;
&lt;li&gt;Similarly, instead of simply exposing a &lt;em&gt;&lt;strong&gt;Refresh&lt;/strong&gt;&lt;/em&gt; input, the indicator now has to contain a few more lines of code to register a callback in order to receive the same notification as an observer.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The above may not represent a lot of work, but it is nonetheless a refactoring which must be applied to the code in order to support the needs of the design; however, in a different design, the observer pattern might be unnecessary, so why should the components be hard-coded to support it?&lt;/p&gt;
&lt;p&gt;To solve this problem, let us revisit our first design, where we had a temperature sensor with a simple &lt;em&gt;&lt;strong&gt;Changed&lt;/strong&gt;&lt;/em&gt; output and a temperature indicator with a simple &lt;em&gt;&lt;strong&gt;Refresh&lt;/strong&gt;&lt;/em&gt; input, and hence a call cycle. Let us us now introduce two new components into the design, where one is a &lt;em&gt;&lt;strong&gt;General-Purpose Observable&lt;/strong&gt;&lt;/em&gt; and the other is a &lt;em&gt;&lt;strong&gt;General-Purpose Observer&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic4.png&#34;
	width=&#34;1860&#34;
	height=&#34;888&#34;
	srcset=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic4_hu_4b6ccb9e601811aa.png 480w, //localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic4_hu_3226eae63daffbb9.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;209&#34;
		data-flex-basis=&#34;502px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;The job of the observer is simply to register a callback via its &lt;em&gt;&lt;strong&gt;Registration&lt;/strong&gt;&lt;/em&gt; output during construction, and from that moment on to keep echoing each invocation of the callback to its &lt;em&gt;&lt;strong&gt;Trigger&lt;/strong&gt;&lt;/em&gt; output.&lt;/p&gt;
&lt;p&gt;The job of the observable is to receive an observer registration via its &lt;em&gt;&lt;strong&gt;Registration&lt;/strong&gt;&lt;/em&gt; input, and to keep echoing invocations coming into its &lt;em&gt;&lt;strong&gt;Trigger&lt;/strong&gt;&lt;/em&gt; input to the registered observer, if any.&lt;/p&gt;
&lt;p&gt;Note that with this arrangement, the call cycle is still eliminated, and at the same time we have managed to retain the sensor and indicator components in their original form, with no code refactoring necessary, since the refactoring has now been applied to the design. Also note that the SRP is being nicely upheld.&lt;/p&gt;
&lt;p&gt;I postulate that the combination of a general-purpose observer and a general-purpose observable will be occurring quite frequently, to the point where it might be worth simplifying their representation using some special notation. For this purpose, I propose an &lt;em&gt;&lt;strong&gt;air-gap pseudo-component&lt;/strong&gt;&lt;/em&gt;. With the use of an air-gap, the previous figure turns into the following:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic5.png&#34;
	width=&#34;1860&#34;
	height=&#34;835&#34;
	srcset=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic5_hu_684347aa7e465dfc.png 480w, //localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic5_hu_c30de23a51830a7c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;222&#34;
		data-flex-basis=&#34;534px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;Note that the symbol for the air-gap component has been borrowed from electronics, where it stands for a capacitor. An electronic capacitor is also, in a sense, an air gap; however, the similarity is superficial, and it is only meant to serve as a mnemonic: In software, an air-gap pseudo-component does not maintain any charge, nor does it act as some kind of high-pass filter, etc.; it just allows us to pick a wire that takes part in a call cycle, and trivially make that wire break the cycle.&lt;/p&gt;
&lt;p&gt;Also note that the air-gap is not a real component, it is a pseudo-component. This means that it is simply a notation, which represents an underlying pair of actual components: a general-purpose observer, and a general-purpose observable. This is necessary because these two components will invariably need to be constructed at different times during system assembly. In the sensor-indicator example, construction would take place in the following order:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The general-purpose observable is constructed first because it does not depend on anything else.&lt;/li&gt;
&lt;li&gt;Then, the sensor is constructed, which depends on the general-purpose observable.&lt;/li&gt;
&lt;li&gt;Then, the indicator is constructed, which depends on the sensor.&lt;/li&gt;
&lt;li&gt;Finally, the general-purpose observer is constructed, which depends on both the indicator and the general-purpose observable.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, during system assembly, each air-gap pseudo-component is decomposed into an observer and an observable, so that all components can be instantiated and wired in the order dictated by their dependency graph.&lt;/p&gt;
&lt;h3 id=&#34;solving-non-trivial-cases&#34;&gt;Solving non-trivial cases
&lt;/h3&gt;&lt;p&gt;The application of the observer pattern is a good first step in the direction of being able to express any software design acyclically; however, it does not cover all cases. Specifically, the observer pattern cannot be used under the following circumstances:&lt;/p&gt;
&lt;p&gt;The observable expects information to be returned back from the observer, and it is incapable of handling the case where no observer is registered, and therefore no results can be returned. (For example, the observable needs to invoke the observer and receive information back from the observer during the observable&amp;rsquo;s construction, at which point the observer cannot possibly have registered yet.)&lt;/p&gt;
&lt;p&gt;The simple &lt;em&gt;&lt;strong&gt;Changed&lt;/strong&gt;&lt;/em&gt; notification of the temperature-sensor-and-indicator example does not fall under these circumstances because it is in the nature of notifications that they never return any information; however, in other scenarios, these circumstances can arise. Thus, it remains to be shown how call cycles can be eliminated when the observer pattern is inapplicable.&lt;/p&gt;
&lt;h3 id=&#34;strategy-fusion&#34;&gt;Strategy: Fusion
&lt;/h3&gt;&lt;p&gt;The presence of a call cycle between components &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt; might indicate that perhaps they should not be separate components, and that we might be better off by fusing &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt; into a single component. In doing so, we remove the cycle from the topology of the design by turning it
into an implementation detail of the new component. The following figure illustrates this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic6.png&#34;
	width=&#34;1860&#34;
	height=&#34;426&#34;
	srcset=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic6_hu_b070ad42c31ba5da.png 480w, //localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic6_hu_b38442f141ba6f20.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;436&#34;
		data-flex-basis=&#34;1047px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;Clearly, the left diagram contains a cycle, whereas the right diagram does not.&lt;/p&gt;
&lt;p&gt;Needless to say, this strategy is only marginally useful, and it should not be considered unless all else fails, because the goal of software architecture is to distribute functionality into as many components as possible, so that each component can be as simple as possible, instead of conglomerating functionality into monolithic components. The fusion strategy is mentioned here only for the sake of completeness.&lt;/p&gt;
&lt;h3 id=&#34;strategy-plain-fission&#34;&gt;Strategy: Plain Fission
&lt;/h3&gt;&lt;p&gt;The presence of a call cycle between components &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt; might indicate that at least one of the two components violates the &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Single_responsibility_principle&#34; target=&#34;_blank&#34;
   &gt;&lt;strong&gt;Single Responsibility Principle&lt;/strong&gt; (&lt;strong&gt;SRP&lt;/strong&gt;)&lt;/a&gt;. In this case, one of the responsibilities can be extracted into a separate component which only exposes inputs, thus breaking the cycle, as the following figure illustrates:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic7.png&#34;
	width=&#34;1861&#34;
	height=&#34;722&#34;
	srcset=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic7_hu_f6ae600ec9ba0180.png 480w, //localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic7_hu_f26f68362306158c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;257&#34;
		data-flex-basis=&#34;618px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;In this diagram, component &lt;strong&gt;A&lt;/strong&gt; has been split into &lt;strong&gt;A1&lt;/strong&gt; and &lt;strong&gt;A2&lt;/strong&gt;. Both &lt;strong&gt;A1&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt; invoke &lt;strong&gt;A2&lt;/strong&gt;, but &lt;strong&gt;A2&lt;/strong&gt; does not invoke anything, so there is no cycle.&lt;/p&gt;
&lt;p&gt;This can happen, for example, if component &lt;strong&gt;A&lt;/strong&gt; contains both a data model and some logic acting upon the data model. If &lt;strong&gt;A&lt;/strong&gt; is incapable of fully encapsulating the data model, it may have to expose not only an output for interacting with the rest of the system, but also an input for the rest of the system to interact with the data model. With the fission refactoring, component &lt;strong&gt;A&lt;/strong&gt; has been split into one component for the logic (&lt;strong&gt;A1&lt;/strong&gt;) and a separate component for the data model (&lt;strong&gt;A2&lt;/strong&gt;).&lt;/p&gt;
&lt;h3 id=&#34;strategy-observable-fission&#34;&gt;Strategy: Observable Fission
&lt;/h3&gt;&lt;p&gt;The astute reader might notice that in the plain fission example, components &lt;strong&gt;A1&lt;/strong&gt; and &lt;strong&gt;A2&lt;/strong&gt; are not exactly equivalent to component &lt;strong&gt;A&lt;/strong&gt;: In the original diagram &lt;strong&gt;A&lt;/strong&gt; used to be able to take notice of incoming calls from &lt;strong&gt;B&lt;/strong&gt; intended for the data model, and could therefore take action in response to those calls, whereas in the refactored diagram &lt;strong&gt;A1&lt;/strong&gt; is oblivious to any calls that &lt;strong&gt;B&lt;/strong&gt; makes to &lt;strong&gt;A2&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;If &lt;strong&gt;A1&lt;/strong&gt; needs to be aware of such calls, this can be very easily accomplished by having &lt;strong&gt;A2&lt;/strong&gt; issue change notifications, and wiring these notifications back to &lt;strong&gt;A1&lt;/strong&gt;. This new wire does not introduce a call cycle, because as we have already shown when describing the trivial case, notifications can always be air-gapped.&lt;/p&gt;
&lt;p&gt;The following figure illustrates the application of the observable fission strategy:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic8.png&#34;
	width=&#34;1861&#34;
	height=&#34;722&#34;
	srcset=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic8_hu_c298426430891ac6.png 480w, //localhost:1313/post/2023-12-27-call-graph-acyclicity/images/acyclic8_hu_701e420d6dc70bd6.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;257&#34;
		data-flex-basis=&#34;618px&#34;
	
&gt;
&lt;/p&gt;
&lt;h4 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h4&gt;&lt;p&gt;We have shown that cyclic call graphs prevent the standardization, and therefore the automation, of system assembly.&lt;/p&gt;
&lt;p&gt;We have discussed refactoring strategies for systematically eliminating call cycles, including a universally applicable technique for trivially eliminating the most common call cycles.&lt;/p&gt;
&lt;p&gt;We conclude that since call cycles can be avoided or eliminated, they can be comprehensively disallowed, thus paving the way for the automation of system assembly.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;TO DO:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Change the cover image to make the cycle look nicer.&lt;/li&gt;
&lt;li&gt;Show a diagram where the observable and observer interfaces are fully spelled out before showing the diagram in which the notation has been simplified.&lt;/li&gt;
&lt;li&gt;Redo the placement and wiring of A1 and A2 to more clearly show that they used to be A.&lt;/li&gt;
&lt;li&gt;Mention that the air-gap pseudo-component does not need to incorporate an actual multicast observable component; a unicast observable will suffice.&lt;/li&gt;
&lt;li&gt;Provide a better example of a situation where an air-gap cannot be used.&lt;/li&gt;
&lt;li&gt;Most importantly: Introduce a distinction between &amp;ldquo;early&amp;rdquo; outputs, which may be invoked during construction, and &amp;ldquo;late&amp;rdquo; outputs, which may only be invoked after construction. Show that late  wires can be air-gapped too, even if they are two-way.&lt;/li&gt;
&lt;li&gt;Use a polarized capacitor symbol for one-way interface air-gaps and a non-polarized capacitor symbol for two-way interface air-gaps.&lt;/li&gt;
&lt;li&gt;Possibly introduce diode notation for one-way pins.&lt;/li&gt;
&lt;li&gt;Possibly introduce bar-plus-arrow notation for early pins.&lt;/li&gt;
&lt;li&gt;Possibly introduce not-gate notation for inverted pins.&lt;/li&gt;
&lt;li&gt;Possibly represent an observatory as a not-gate and an observer as the opposite (a triangle with a bubble on its flat side.)&lt;/li&gt;
&lt;li&gt;Note the following:
&lt;ul&gt;
&lt;li&gt;One-way interfaces: can always be inverted.&lt;/li&gt;
&lt;li&gt;Two-way interfaces: can only be inverted if late, and one-to-one.&lt;/li&gt;
&lt;li&gt;Normal two-way interfaces: multiple outputs can connect to one input.&lt;/li&gt;
&lt;li&gt;Normal one-way interfaces: multiple outputs can connect to multiple inputs. (With the help of a distributor.)&lt;/li&gt;
&lt;li&gt;Inverted one-way interfaces: one output can connect to multiple inputs.&lt;/li&gt;
&lt;li&gt;Inverted two-way interfaces: one output connects to one input. (And must be late.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Towards Authoritative Software Design</title>
        <link>//localhost:1313/post/2023-12-09-authoritative-technical-design/</link>
        <pubDate>Sat, 09 Dec 2023 19:16:05 +0000</pubDate>
        
        <guid>//localhost:1313/post/2023-12-09-authoritative-technical-design/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2023-12-09-authoritative-technical-design/media/blueprint.jpg&#34;
	width=&#34;5000&#34;
	height=&#34;2740&#34;
	srcset=&#34;//localhost:1313/post/2023-12-09-authoritative-technical-design/media/blueprint_hu_97e76780ef2663b9.jpg 480w, //localhost:1313/post/2023-12-09-authoritative-technical-design/media/blueprint_hu_44b86b65f3bab1f7.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;182&#34;
		data-flex-basis=&#34;437px&#34;
	
&gt;
&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract
&lt;/h3&gt;&lt;p&gt;This paper examines the long-standing need within the software engineering discipline for technical design that is &lt;em&gt;&lt;strong&gt;authoritative&lt;/strong&gt;&lt;/em&gt;. A design process is authoritative if there exist technical means of materializing the design document as a working product, thus guaranteeing that the end result is indeed as described by the design. We notice the scarcity and inadequacy of existing solutions for software design, we look at solutions in other engineering disciplines, and we conclude with realizations on what it would take to come up with a solution that works for software.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id=&#34;prior-art&#34;&gt;Prior art
&lt;/h3&gt;&lt;p&gt;Through the decades, plenty of tools and methodologies have been developed with the aim of aiding the software design process. A common pattern among them is that they try to make some aspect of development more visual rather than textual. They fall into one of the following categories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Visual Implementation tools (For example: &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Visual_programming_language&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;Visual Programming Languages&lt;/em&gt;&lt;/a&gt; like &lt;em&gt;Snap!&lt;/em&gt;, &lt;em&gt;Scratch&lt;/em&gt;, &lt;em&gt;EduBlocks&lt;/em&gt;, &lt;em&gt;Blockly&lt;/em&gt;, etc.,) - They are indeed visual, and they do indeed produce runnable software, but their structure and level of detail is identical to the structure and level of detail of program code in the form of text, so they express implementations rather than designs.&lt;/li&gt;
&lt;li&gt;Visualization tools (For example: class diagrams, dependency diagrams, call trees, etc.) - They are restricted to the visualization, exploration, and documentation, but not the editing of existing software, nor the design of new software. As such, they are reverse engineering tools, not design tools.&lt;/li&gt;
&lt;li&gt;Niche tools (For example: &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Web_Services_Description_Language&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;Web Services Description Language (WSDL)&lt;/em&gt;&lt;/a&gt;, &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Business_Process_Execution_Language&#34; target=&#34;_blank&#34;
   &gt;*Business Process Execution Language (BPEL)&lt;/a&gt;, etc.) - They are exclusively focused on specific domains such as web services, business processes, etc., and cannot be used for software design at large.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Look ma, no code&amp;rdquo; tools (For example: &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Rapid_application_development&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;Rapid Application Development (RAD) tools&lt;/em&gt;&lt;/a&gt;, &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/No-code_development_platform&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;No-Code Development Platforms (NCDPs)&lt;/em&gt;&lt;/a&gt;, and &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Low-code_development_platform&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;Low-Code Development Platforms (LCDPs)&lt;/em&gt;&lt;/a&gt;) - They impose limitations on what can be done; they impose the use of a massive vendor-specific platform; they do not scale; they are aimed at non-programmers, allowing easy creation of simple user-interface-centric applications to quickly (and usually haphazardly) meet specific narrow business needs.&lt;/li&gt;
&lt;li&gt;Modelling tools (For example: &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Microsoft_Visio&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;Microsoft Visio&lt;/em&gt;&lt;/a&gt;, &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Modeling_language&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;Modelling Languages&lt;/em&gt;&lt;/a&gt; such as &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Unified_Modeling_Language&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;Unified Modeling Language (UML)&lt;/em&gt;&lt;/a&gt;, The &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/C4_model&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;C4 model&lt;/em&gt;&lt;/a&gt;, etc.) - They are restricted to modelling, so they produce designs that bear no necessary relationship to reality. They aim to constrain what is supposed to be included in a design, but these constrains exist only in theory, because they are not enforced by any technical means.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For a more detailed look at prior art, see &lt;a 
   href=&#34;//localhost:1313/post/2025-08-the-state-of-affairs-in-computer-aided/&#34;
   &gt;The state of affairs in computer-aided software design&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Of all the technologies listed above, only modelling tools can legitimately be said to be of any potential usefulness in the software design process at large.&lt;/p&gt;
&lt;h3 id=&#34;the-unsuitability-of-modelling&#34;&gt;The unsuitability of modelling
&lt;/h3&gt;&lt;p&gt;Modelling tools allow designs that bear no relationship to reality: they are not informed via any technical means about the actual components available for incorporation in a design, nor about valid ways of interconnecting them. Consequently, modelling tools are nothing more than fancy whiteboards: they cannot guarantee, via any technical means, the feasibility of a design. (This is so by definition; otherwise, it would not be modelling, it would be engineering.)&lt;/p&gt;
&lt;p&gt;Essentially, modelling tools are &lt;em&gt;&lt;strong&gt;non-authoritative&lt;/strong&gt;&lt;/em&gt;: no matter how sophisticated the model is, the authoritative source of truth for the structure of the system remains the source code, not the model.&lt;/p&gt;
&lt;p&gt;The source code should ideally constitute a faithful implementation of the model, but there are no technological safeguards  to guarantee that it does, and as a matter of fact it usually cannot, because the model is almost never feasible as designed to begin with.&lt;/p&gt;
&lt;p&gt;For these reasons, modelling is of severely limited value, and programmers largely regard it as loathsome double book-keeping.&lt;/p&gt;
&lt;p&gt;For a list of ways in which modelling as a means of design fails the software engineering discipline, please see &lt;a 
   href=&#34;//localhost:1313/post/2025-08-the-perils-of-whiteboards/&#34;
   &gt;The perils of whiteboards&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;other-engineering-disciplines&#34;&gt;Other engineering disciplines
&lt;/h3&gt;&lt;p&gt;In long-established engineering disciplines such as mechanical, electrical, civil, etc., for several decades now, design work has been facilitated by &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Computer-aided_design&#34; target=&#34;_blank&#34;
   &gt;Computer-Aided Design (CAD)&lt;/a&gt; tools and &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Computer-aided_engineering&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;Computer-Aided Engineering (CAE)&lt;/em&gt;&lt;/a&gt; tools.&lt;/p&gt;
&lt;p&gt;Mechanical engineers use CAD tools to create documents describing complicated three-dimensional structures with detailed information about materials, dimensions, and tolerances. The tools perform various forms of analysis to verify the validity and feasibility of the design. Based on the results, the engineers can edit the design to optimize it, and repeat the analysis as necessary. Eventually, the design document is sent to a shop where &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Computer_numerical_control&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;CNC machining&lt;/em&gt;&lt;/a&gt; or &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/3D_printing&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;3D-printing&lt;/em&gt;&lt;/a&gt; is used to create the parts with minimal human intervention.&lt;/p&gt;
&lt;p&gt;In electronic engineering, which is the discipline from which most parallels can be drawn to software engineering, virtually all design work since the 1980s is being done using &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Electronic_design_automation&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;Electronic Design Automation (EDA) / Electronic Computer-Aided Design (ECAD) tools&lt;/em&gt;&lt;/a&gt;. These tools have revolutionized electronic design by using a standardized notation to not only describe, analyze, and optimize products, but also to manufacture them.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Electronic schematic diagrams use a standard notation which is understood by all electronic engineers. A new hire begins their first day at work by studying the schematics, and before the end of the day they are often able to pick up the soldering iron and start doing productive work. Contrast this with software engineering, where a new hire usually cannot be productive before spending weeks studying source code and documentation, and having numerous knowledge transfer meetings with senior engineers who know the system.&lt;/li&gt;
&lt;li&gt;Most importantly, ECAD tools bridge the gap from the physical world to the design, and from the design back to the physical world. The tools have libraries of electronic components available for inclusion in a design, and electronic manufacturing has long ago advanced to the point where an electronic design document can be turned into a functioning circuit board with nearly zero human intervention. Thus, electronic design documents today are &lt;em&gt;&lt;strong&gt;authoritative&lt;/strong&gt;&lt;/em&gt;: the end products are accurately described by their designs.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-problem-with-software&#34;&gt;The problem with software
&lt;/h3&gt;&lt;p&gt;Unfortunately, thus far, the software engineering discipline has been following a very different path from other engineering disciplines: technical software design documents are scarce, and &lt;em&gt;authoritative&lt;/em&gt; technical software design documents are completely non-existent.&lt;/p&gt;
&lt;p&gt;This situation has been allowed to go on for so long, partly because in software we already have a certain other kind of document which is authoritative, and this is the source code. However, source code is an implementation, or at best a detailed technical description, but not a technical design. To say that the technical design of a software system is a listing of the lines of source code that make up that software system is equivalent to saying that the technical design of the Great Wall of China is a list of all the bricks that make up the Great Wall of China.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;img src=&#34;//localhost:1313/post/2023-12-09-authoritative-technical-design/media/the-great-wall-by-hao-wei.jpg&#34;
	width=&#34;4606&#34;
	height=&#34;3071&#34;
	srcset=&#34;//localhost:1313/post/2023-12-09-authoritative-technical-design/media/the-great-wall-by-hao-wei_hu_d1eba4a46b4d1881.jpg 480w, //localhost:1313/post/2023-12-09-authoritative-technical-design/media/the-great-wall-by-hao-wei_hu_4d46a82415ff1bad.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;149&#34;
		data-flex-basis=&#34;359px&#34;
	
&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;(A tiny part of) the Great Wall of China &lt;a class=&#34;external&#34; 
   href=&#34;https://commons.wikimedia.org/w/index.php?curid=351725&#34; target=&#34;_blank&#34;
   &gt;by Hao Wei, CC BY 2.0&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;A technical design is supposed to list operative components, and to show how they are interconnected, but not to delve past the level of detail of the component. Unfortunately, we do not have that for software, at least not in an authoritative form.&lt;/p&gt;
&lt;p&gt;It is a great paradox of our times that the software engineering discipline is bereft of authoritative design tools, when such tools are the bread and butter of the long-established engineering disciplines.&lt;/p&gt;
&lt;p&gt;In lieu of authoritative tools, software design today is practiced using conventional, non-authoritative means, such as box-and-arrow drawing applications, which, as explained earlier, are only capable of modelling, and therefore amount to nothing more than fancy whiteboards.&lt;/p&gt;
&lt;p&gt;The end-result of all this is the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Software systems do not match their designs.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Even if the technical design happens to describe a software system that could actually be built as described, there are no technological safeguards to guarantee that it will: the software engineers and the operations engineers are free to build and deploy a system that deviates from the design, and neither the architects, nor the management, have any way of knowing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Software systems diverge from their designs over time.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Even if the deployed software system initially matches its design, the system is bound to evolve. The design should ideally evolve in tandem, but it rarely does, again because there are no technological safeguards to enforce this: the engineers are free to modify and redeploy the system without updating the design document, and in fact they usually do, because it saves them from double book-keeping. Thus, over time, the design bears less and less relationship to reality.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If, due to the above reasons, you suspect that your technical design document is counterfactual, and you would like to know exactly what it is that you have actually deployed and running out there, you have to begin by asking questions to the software engineers and the operations engineers.&lt;/p&gt;
&lt;p&gt;In order to answer your questions, the engineers will in turn have to examine source code, version control histories, build scripts, configuration files, server provisioning scripts, and launch scripts, because the truth is scattered in all those places. In some cases they might even have to try and remember specific commands that were once typed on a terminal to bring the system to life.&lt;/p&gt;
&lt;p&gt;If this sounds a bit like it is held together by shoestrings, it is because it is in fact held together by shoestrings.&lt;/p&gt;
&lt;p&gt;Thus, the information that you will receive will hardly be usable, and even if you manage to collect it all, make sense out of it, and update the design document with it, by the time you are done, the deployed system may have already changed, which means that your design document is already obsolete.&lt;/p&gt;
&lt;p&gt;As a result, it is generally impossible at any given moment to know the actual technical design of any non-trivial software system in existence.&lt;/p&gt;
&lt;p&gt;This is a very sorry state of affairs for the entire software industry to be in.&lt;/p&gt;
&lt;h3 id=&#34;towards-a-solution&#34;&gt;Towards a solution
&lt;/h3&gt;&lt;p&gt;If we consider all the previously listed problems that plague software design as conventionally practiced, and if we look at how the corresponding problems have been solved in long-established engineering disciplines, we inescapably arrive at the following realization:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;The technical design of a system can only be said to accurately describe that system if there exist technical means of having the system automatically created from the design.&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In order to automatically create a system from its design, the design must be semantically valid. This brings us to a second realization:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;The semantic validity of a technical design can only be guaranteed if there exist technical means of informing the design with components available for incorporation and restricting the design to only valid ways of  interconnecting them.&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The above statements define a design process as &lt;em&gt;&lt;strong&gt;authoritative&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;An authoritative software design document is an &lt;strong&gt;essential engineering instrument&lt;/strong&gt; instead of an abstract work of art:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The design document contains all the information necessary for provisioning target environments with software components, instantiating the components, and wiring them together; this information not only need not, but in fact must not be encoded anywhere else in the source code; this eliminates double book-keeping, which is considered by developers as another layer of red tape which is preventing them from getting things done, and is the complaint most often heard from developers about conventional software design.&lt;/li&gt;
&lt;li&gt;The design document is the only means through which the system can be re-deployed after making a change to either the code, or the design, or both; this guarantees that the deployed system will always be exactly as described by the design, so there is no possibility of the design ever becoming outdated, which is the complaint most often heard from architects about programmers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Any attempt to introduce authoritative design in the software engineering discipline would necessarily have to borrow concepts from the electronic engineering discipline. This means that the solution must lie within the realm of &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Component-based_software_engineering&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;Component-Based Software Engineering (CBSE)&lt;/em&gt;&lt;/a&gt;, where systems consist of well-defined components, connectable via specific interfaces, using well-defined connectivity rules.&lt;/p&gt;
&lt;p&gt;What we need is a toolset that implements such a paradigm for software. The toolset must have knowledge of available components, knowledge of the interfaces exposed by each component, and rules specifying valid ways of connecting those interfaces. The toolset must then be capable of materializing the design into a running software system.&lt;/p&gt;
&lt;p&gt;The toolset must not repeat the mistakes and suffer from the drawbacks of previous attempts at component-based software engineering. Thus, the toolset must meet the following goals:&lt;/p&gt;
&lt;h4 id=&#34;facilitate-any-programming-language&#34;&gt;Facilitate any programming language.
&lt;/h4&gt;&lt;p&gt;By this we do not mean that it should be possible to freely mix C++ components with Java components; what we mean is that it should be possible to express in one place a C++ subsystem containing C++ components interconnected via C++ interfaces, and in another place a Java subsystem containing Java components interconnected via Java interfaces, and at a higher scope to have each of these subsystems represented as an individual opaque component, where connections between the two components are made via language-agnostic interfaces (e.g. REST) or cross-language interfaces (e.g. JNI, JNA, etc.)&lt;/p&gt;
&lt;h4 id=&#34;facilitate-any-level-of-scale-from-embedded-systems-to-network-clouds&#34;&gt;Facilitate any level of scale, from embedded systems to network clouds.
&lt;/h4&gt;&lt;p&gt;This means that the nature of a component and the nature of an interface must not be restricted, so that they can be realized in different ways at different levels of scale. For example, at the embedded/C++ level of scale, a component might be defined as a C++ class exposing C++ interfaces, whereas at the internet level of scale a component is likely to be defined as a (physical or virtualized) network host exposing TCP interfaces.&lt;/p&gt;
&lt;h4 id=&#34;guarantee-type-safety-at-any-scale&#34;&gt;Guarantee type-safety at any scale.
&lt;/h4&gt;&lt;p&gt;Type safety can be carried across different levels of scale by means of parametric polymorphism (generic interfaces.) For example, a type-safe interface between a client and a server in a network can be described with a construct like Tcp&amp;lt;Rest&amp;lt;AcmeShopping&amp;gt;&amp;gt; which stands for a TCP connection through which we are exchanging REST transactions according to a schema which corresponds to some programmatic interface called &amp;ldquo;AcmeShopping&amp;rdquo;.&lt;/p&gt;
&lt;h4 id=&#34;require-minimal-extra-baggage&#34;&gt;Require minimal extra baggage.
&lt;/h4&gt;&lt;p&gt;Components should not be required to include a lot of extra overhead to facilitate their inclusion in a design. Especially at the embedded level, components should ideally include zero overhead.&lt;/p&gt;
&lt;p&gt;This means that a C++ class which accepts as constructor parameters interfaces to invoke and exposes interfaces for invocation by virtue of  simply implementing them should ideally be usable in s design as-is.&lt;/p&gt;
&lt;p&gt;The extra functionality necessary for representing the component during design-time, provisioning a target environment with it, instantiating it, and wiring it should be provided by a separate companion module, which acts as a plugin to the design toolset, and exists only during design-time and deployment-time, but not during run-time**.**&lt;/p&gt;
&lt;h4 id=&#34;support-automatic-deployment&#34;&gt;Support automatic deployment.
&lt;/h4&gt;&lt;p&gt;The toolset must be capable of deploying a software system of arbitrary complexity to a production environment of arbitrary complexity, and it must be capable of doing so with no human intervention other than the pressing of a &amp;ldquo;Deploy&amp;rdquo; button.  To this end, toolset must support components representing various different kinds of environments such as network hosts, isolated devices, operating systems, virtual machines, etc. and each of these components must be configurable with everything necessary in order to provision a certain environment with the corresponding part of the design.&lt;/p&gt;
&lt;h4 id=&#34;support-iterative-development&#34;&gt;Support iterative development.
&lt;/h4&gt;&lt;p&gt;Once a system has been designed, coded, and deployed, it is a fact of life that it will keep evolving. The design toolset must support re-deploying after modifying the code, or the design, or both.&lt;/p&gt;
&lt;h4 id=&#34;support-automatic-wiring&#34;&gt;Support automatic wiring.
&lt;/h4&gt;&lt;p&gt;Once an execution environment has been provisioned with software components, the components must be wired together in order to start running. Traditionally, the wiring of freshly instantiated components is done by carefully hand-crafted code, to account for circular dependency issues between components. If we are to have fully automated deployment, the wiring cannot be done by hand-crafted code anymore; it must be automated, therefore it must be standardized. This in turn means that certain connectivity rules are necessary in order to guarantee that software designs do not suffer from circular dependency issues that would require custom handling. For more on this, see &lt;a 
   href=&#34;//localhost:1313/post/2023-12-27-call-graph-acyclicity/&#34;
   &gt;Call Graph Acyclicity&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;facilitate-incremental-adoption&#34;&gt;Facilitate incremental adoption.
&lt;/h4&gt;&lt;p&gt;It should be possible to express, via an authoritative design document, the structure of a small subsystem within a larger system whose structure has not (yet) been expressed authoritatively.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In systems of medium scale and above, this may be handled by making the  core deployment and wiring engine of the toolset available on demand, during runtime, to quickly materialize a small subsystem within the larger system.&lt;/li&gt;
&lt;li&gt;In embedded-scale systems, it should be possible to utilize code generation to do the instantiation and the wiring, so as to avoid having the core engine present in the target environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;utilize-a-text-based-document-format&#34;&gt;Utilize a text-based document format.
&lt;/h4&gt;&lt;p&gt;In software we make heavy use of version control systems, which work best with text files, so the design documents must be text-based. The text format would essentially be a system description language, so it must be programmer-friendly in order to facilitate editing using a text editor or an IDE. A graphical design tool would read text of this language into data structures, allow the visual editing of such data structures, and save them back as text.&lt;/p&gt;
&lt;h4 id=&#34;facilitate-dynamic-software-systems&#34;&gt;Facilitate dynamic software systems.
&lt;/h4&gt;&lt;p&gt;Every non-trivial system has the ability to vary, at runtime, the number of instances of some components in response to changing computation needs, and to choose to instantiate different types of components to handle different needs. Therefore, a toolset aiming to be capable of expressing any kind of design must be capable of expressing, at a minimum, the following dynamic constructs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Plurality: Multiple instantiation of a certain component, where the number of instances is decided at runtime.&lt;/li&gt;
&lt;li&gt;Polymorphism: Fulfilling a certain role by instantiating one of several different types of components capable of fulfilling that role, where the choice of which component type to instantiate is made at runtime.&lt;/li&gt;
&lt;li&gt;Polymorphic plurality: A combination of the previous two: A runtime-variable array of components where each component can be of a     different, runtime-decidable type.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;facilitate-multiple-alternative-configurations-layers&#34;&gt;Facilitate multiple alternative configurations (layers).
&lt;/h4&gt;&lt;p&gt;In virtually every software development endeavor there is a core system design which is materialized in a number of variations to cover different needs. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Debug vs. release&lt;/li&gt;
&lt;li&gt;Testing vs. production&lt;/li&gt;
&lt;li&gt;With instrumentation or without&lt;/li&gt;
&lt;li&gt;With hardware emulation vs. a targeting the actual hardware&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The bulk of the components and the wires of the design exist in all configurations, but some configurations prescribe additional components and slightly different wiring.&lt;/p&gt;
&lt;p&gt;Therefore, the toolset must facilitate the expression of alternative configurations so that each configuration can be defined authoritatively.&lt;/p&gt;
&lt;p&gt;To facilitate this, the toolset must support design layers, similar to drawing layers found in drawing applications like Photoshop. Note that design layers are unrelated to the architectural layers found in layered architectures, although it is possible that people will figure out ways to represent architectural layers using design layers.&lt;/p&gt;
&lt;p&gt;The details of how layers are going to work in order to support configurations are to be decided, but one preliminary idea is to have one or   more base layers where the bulk of the components are laid out, and a few mutually exclusive configuration layers on top of them. A configuration layer combines with one or more base layers to form a complete system, and is deployable, whereas base layers do not describe complete systems and are therefore not deployable by themselves.&lt;/p&gt;
&lt;h4 id=&#34;be-extensible&#34;&gt;Be extensible.
&lt;/h4&gt;&lt;p&gt;The design document must support the inclusion of arbitrary metadata to be used by various tools, which can be either separate applications, or plugins to the graphical editor. Examples of metadata:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Keeping track of documentation of interest to different stakeholders, for example &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Architectural_decision&#34; target=&#34;_blank&#34;
   &gt;Architectural Decisions&lt;/a&gt; &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Keeping track of &lt;em&gt;Team Architecture&lt;/em&gt;, i.e. which development teams are responsible for building and/or maintaining different parts of the design. &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Recording various technical characteristics, such as data flow. (Every interface can be associated with a direction of data flow with respect to the direction of invocation: when invoked, some interfaces only pull data, some only push data, and some perform bi-directional transfer of data.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Recording, either manually or automatically, various metrics such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Technical debt estimations&lt;/li&gt;
&lt;li&gt;Threat modelling&lt;/li&gt;
&lt;li&gt;Compliance considerations and responsibilities&lt;/li&gt;
&lt;li&gt;Test code coverage results&lt;/li&gt;
&lt;li&gt;Performance statistics&lt;/li&gt;
&lt;li&gt;Frequency of change statistics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Using such metadata and plugins, the graphical editor may allow switching between views to visualize various aspects of the system overlaid on the component diagram, such as, for example, data flow instead of control flow, a heat map of technical debt, a heat map of test code coverage, a heat map of frequency of change, etc.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;be-accessible-and-attractive&#34;&gt;Be accessible and attractive.
&lt;/h4&gt;&lt;p&gt;The extent and speed by which a new software development technology is  adopted greatly depends on how accessible and attractive the technology is. To this end:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The core toolset must be free and open source software. (Profit may be made from additional, optional tools, such as a visual editor.) This also means that the toolset must be a cross-platform, installable software package rather than a cloud offering.&lt;/li&gt;
&lt;li&gt;A clear distance must be kept from unattractive technologies like UML, XML, etc.&lt;/li&gt;
&lt;li&gt;The literature around the toolset must avoid wooden language and alienating terms such as &amp;ldquo;enterprise architecture&amp;rdquo;, &amp;ldquo;standards committee&amp;rdquo;, &amp;ldquo;industry specifications consortium&amp;rdquo;, etc&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;efficiently-manage-complexity&#34;&gt;Efficiently manage complexity.
&lt;/h4&gt;&lt;p&gt;Software designs can become formidably complicated. One of the major goals of a design methodology is to manage complexity and to reduce clutter. Therefore, the toolset must support the following constructs:&lt;/p&gt;
&lt;p&gt;Containers&lt;/p&gt;
&lt;p&gt;Some systems are so large that expressing them in a single diagram may be inconvenient to the point of being unworkable. To address this, the
toolset must facilitate hierarchical system composition by means of container components. A container encapsulates an entire separately-editable diagram and exposes some of the interfaces of the contained components as interfaces of its own. Thus, containers can be used to abstract away entire sub-designs into opaque black-boxes within greater designs. Container components moust be boundlessly nestable.&lt;/p&gt;
&lt;p&gt;Vias&lt;/p&gt;
&lt;p&gt;Large numbers of wires traveling long distances within a diagram can have a detrimental effect on the intelligibility of the diagram. For this reason, the concept of the &amp;ldquo;via&amp;rdquo; will be borrowed from electronic design.  A via is a named circle into which a wire may terminate and thus vanish from view. All vias with the same name are implicitly connected without having to show the wires between them. This is especially useful for wires of interfaces representing cross-cutting concerns, which are ubiquitous, and therefore do not need to be shown everywhere.&lt;/p&gt;
&lt;p&gt;A via is strongly typed like any pin; when the first pin is wired to a via, the via implicitly takes the type of that pin. Vias are to be drawn as little circles.&lt;/p&gt;
&lt;p&gt;Ribbons&lt;/p&gt;
&lt;p&gt;Sometimes there may be multiple parallel wires that travel over  long distances on a diagram. Some of them might even go in opposite directions.&lt;/p&gt;
&lt;p&gt;To reduce clutter, the toolset must make it possible to group such wires together in a ribbon. At each end of a ribbon is a connector, which breaks the ribbon into individual pins and shows the name and type of each pin, so that individual wires can be drawn from there to component pins.&lt;/p&gt;
&lt;p&gt;Ribbons and connectors are pseudo-elements, in the sense that they only exist in the design diagram and have no counterpart in code. Ribbons are to be drawn as two parallel hairlines with a slanted hash between them. The shape of connectors is to be determined, but it will probably be borrowed from electronic design. Ribbons can also be routed in and out of vias. Ribbon vias are to be slightly bigger than single-wire vias.&lt;/p&gt;
&lt;h4 id=&#34;establish-a-universal-notation&#34;&gt;Establish a universal notation.
&lt;/h4&gt;&lt;p&gt;To ensure that every developer can easily understand a design document that they see for the first time, the toolset must standardize the notation used in software diagrams, the same way that electronic schematic diagrams follow a standard notation which is universally understood by all electronic engineers.&lt;/p&gt;
&lt;p&gt;The details are to be decided, but some preliminary ideas about styling and conventions are as follows:&lt;/p&gt;
&lt;p&gt;(Need to show an illustration here.)&lt;/p&gt;
&lt;p&gt;Diagrams are drawn using nothing but monochrome lines. (Black lines on a white background, or white lines on a blue background, etc.) This is because color opens up too many possibilities for distractions and for non-standard representations. The use of color should be reserved for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Distinguishing between different layers when multiple layers are drawn superimposed.&lt;/li&gt;
&lt;li&gt;Transient concepts such as:
&lt;ul&gt;
&lt;li&gt;Mouse-over in the graphical editor&lt;/li&gt;
&lt;li&gt;Selection in the graphical editor&lt;/li&gt;
&lt;li&gt;Validation errors&lt;/li&gt;
&lt;li&gt;Visualization of statistics (especially heat maps)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Nonetheless, people will probably figure out that they can present a design in a colorful way by placing different components on different layers, choosing a different color for each layer, and having all layers displayed simultaneously. However, should they decide to do that, they are on their own: the toolset will not offer any features specifically intended to facilitate this.&lt;/p&gt;
&lt;p&gt;Wires are to be drawn using hairlines.&lt;/p&gt;
&lt;p&gt;Pins are also to be drawn using hairlines. Outputs will be triangular arrows pointing out of a component, inputs will be triangular arrows pointing into a component. The name and type of each pin is to be drawn outside the shape of the component, allowing components to be relatively small and requiring a lot of empty space around them to fit the names of the pins. The pin name is to be drawn with a bigger font than for the pin type.&lt;/p&gt;
&lt;p&gt;Wires may bend only in right angles. When two wires cross, this means that they are isolated from each other. When multiple outputs converge into a single input, a small but discernible dot at the point of convergence indicates that the wires are connected.&lt;/p&gt;
&lt;p&gt;At various points along a wire there can be tiny skinny arrows to remind the viewer of the direction of the wire (always from the output to the input.)&lt;/p&gt;
&lt;p&gt;Component shapes are to be drawn using thick lines. The default shape for every component type is a plain rectangle, with the name and type of the component rendered in the center. The component name is to be drawn using a bigger font than the component type.&lt;/p&gt;
&lt;p&gt;Some component types perform simple and standard functions, which can usually be inferred from their pins, for example adapters from one interface to another, or converters that transform data from one form to another. For such simple components, there is merit in refraining from displaying their name and type, and instead displaying them with special shape, thereby making them occupy less space in the design, and making the design more expressive. The toolset will initially offer a few special shapes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A triangular component shape intended for component types that act as converters.&lt;/li&gt;
&lt;li&gt;An AND-gate component shape for component types that play the role of adapters.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Over time, more component types that perform simple and standard functions will inevitably be identified. This will lead to a demand to introduce additional component shapes, bearing some resemblance to electronic or flowchart symbols, to represent those components; however, the intention is to be conservative in this, and only introduce new shapes if the demand for them is strong and widespread.&lt;/p&gt;
&lt;p&gt;The preferred placement of pins on the perimeter of a component shall be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Inputs along the left and top edges&lt;/li&gt;
&lt;li&gt;Outputs along the right and bottom edges&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The convention for pin placement shall be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;General-purpose and cross-cutting concern interfaces:
&lt;ul&gt;
&lt;li&gt;inputs along the top edge&lt;/li&gt;
&lt;li&gt;outputs along the bottom edge.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Application-specific interfaces:
&lt;ul&gt;
&lt;li&gt;inputs along the left edge.&lt;/li&gt;
&lt;li&gt;outputs along the right edge.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This arrangement is analogous to electronic design, where the convention is that signals flow from left to right and voltages from top to bottom.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;See &lt;a class=&#34;external&#34; 
   href=&#34;https://thinkrelevance.com/blog/2011/11/15/documenting-architecture-decisions&#34; target=&#34;_blank&#34;
   &gt;Architectural Decision Records by Michael Nygard&lt;/a&gt;-&amp;gt; link is dead, &lt;a class=&#34;external&#34; 
   href=&#34;https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions&#34; target=&#34;_blank&#34;
   &gt;new link here&lt;/a&gt;. For ADRs as a vehicle of engagement between architects and developers instead of documentation, see &lt;a class=&#34;external&#34; 
   href=&#34;https://www.youtube.com/watch?v=n6G5qtJHmgw&#34; target=&#34;_blank&#34;
   &gt;Mark Richards - The Intersection of Architecture and Implementation - DDD Europe&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;See the concept of &amp;ldquo;Team Architecture&amp;rdquo; in &lt;a class=&#34;external&#34; 
   href=&#34;https://youtu.be/BNTt2aLB1tg?t=464&#34; target=&#34;_blank&#34;
   &gt;Practical (a.k.a. Actually Useful) Architecture by Stefan Tilkov, GOTO 2023, section 2, &amp;ldquo;Explicitly architect your team setup&amp;rdquo;&lt;/a&gt; &amp;ndash; Related term: &lt;em&gt;Team Topologies.&lt;/em&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>Definition: Collaborator</title>
        <link>//localhost:1313/post/2023-01-16-collaborator/</link>
        <pubDate>Mon, 16 Jan 2023 12:58:35 +0000</pubDate>
        
        <guid>//localhost:1313/post/2023-01-16-collaborator/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2023-01-16-collaborator/media/collaboration.svg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;
&lt;/p&gt;
&lt;p&gt;I have been coming across the term &lt;em&gt;&lt;strong&gt;collaborator&lt;/strong&gt;&lt;/em&gt; in software literature, and I have been using it too in my own writings, but without having seen it defined. I tried searching for its definition, but could not find any. In UML the term &lt;em&gt;&lt;strong&gt;collaboration&lt;/strong&gt;&lt;/em&gt; is vaguely described, but not the term &lt;em&gt;collaborator&lt;/em&gt;. After &lt;a class=&#34;external&#34; 
   href=&#34;https://softwareengineering.stackexchange.com/questions/443097/definition-of-collaborators-of-an-object-in-software-design&#34; target=&#34;_blank&#34;
   &gt;asking on Software Engineering Stack Exchange&lt;/a&gt; I was pointed to what is in almost all certainty the original definition, but it turns out that it is very old, and slightly problematic, so I thought I should provide a modern definition here, at the very least for use in my own writings.&lt;/p&gt;
&lt;p&gt;Here it goes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt;  **A *collaborator* is a component invoked by another component to do a    job.**
&lt;/code&gt;&lt;/pre&gt;&lt;/blockquote&gt;
&lt;p&gt;(And since the context is software, these are, of course, software components.)&lt;/p&gt;
&lt;h3 id=&#34;origin-of-the-term&#34;&gt;Origin of the term
&lt;/h3&gt;&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Collaborators were introduced as a concept in a paper by Kent Beck and Ward Cunningham in 1989 (See &lt;a class=&#34;external&#34; 
   href=&#34;https://c2.com/doc/oopsla89/paper.html&#34; target=&#34;_blank&#34;
   &gt;http://c2.com/doc/oopsla89/paper.html&lt;/a&gt;) and defined as &amp;ldquo;objects which will send or be sent messages in the course of satisfying responsibilities&amp;rdquo;.&lt;/p&gt;
&lt;h3 id=&#34;problems-with-the-original-definition&#34;&gt;Problems with the original definition
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;The original paper was written in the context of Smalltalk, which relied on message-passing, but more generally, collaborators exchange invocations.&lt;/li&gt;
&lt;li&gt;The &amp;ldquo;in the course of satisfying responsibilities&amp;rdquo; part seems to convey no information, despite the fact that it comprises about half of the definition; it is just filler and it needs to go.&lt;/li&gt;
&lt;li&gt;The paper allowed a collaborator to be either &amp;ldquo;a service with little regard or even awareness of its client&amp;rdquo; or a &amp;ldquo;near-equal&amp;rdquo; in a &amp;ldquo;symmetric relation&amp;rdquo;; however, nowadays we tend to put emphasis on loose coupling, so collaborators are generally services: a component has knowledge of collaborators that it employs, but a collaborator has no specific knowledge of components that it is employed by.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;components-vs-interfaces&#34;&gt;&lt;strong&gt;Components vs. Interfaces&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;Depending on the scope of the discussion, the term collaborator may mean two things of different nature:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When discussing a component and its collaborators, the term collaborator usually refers to an interface, because a component is supposed to be invoking interfaces, not actual implementations.&lt;/li&gt;
&lt;li&gt;When discussing a system and the components in it, the term collaborator refers to an actual component implementing one or more interfaces, because components is what systems consist of.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When there is a need to differentiate between the two, the terms &lt;em&gt;Collaborator Interface&lt;/em&gt; and &lt;em&gt;Collaborator Component&lt;/em&gt; can be used.&lt;/p&gt;
&lt;h3 id=&#34;availability&#34;&gt;&lt;strong&gt;Availability&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;The term does not imply any particular mechanism for making a collaborator component available to a component that wants to use it. The collaborator might be hard-coded, might be supplied as a parameter to an interface method call, might be injected, etc. If the mechanism by which a collaborator is being made available is unclear, and if it matters, then it should be explicitly stated.&lt;/p&gt;
&lt;p&gt;However, in software architecture we are usually discussing collaborators that may appear in architectural diagrams, and these tend to be injectable. Collaborators that are hard-coded or supplied as parameters tend to be small-scale implementation details that generally do not appear in architectural diagrams.&lt;/p&gt;
&lt;h3 id=&#34;delivery-of-invocations&#34;&gt;&lt;strong&gt;Delivery of invocations&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;The term does not imply any particular mechanism for placing invocations; one collaborator might be invokable via programmatic interface method calls, while another might be invokable via message-passing, and yet another might be invokable via REST request-response pairs; if the mechanism of placing invocations is unclear, and if it matters, then it should be explicitly stated.&lt;/p&gt;
&lt;p&gt;Having said that, I should add that in most cases it should not matter, because writing software using any invocation mechanism other than programmatic interface method calls is misguided; things like message-passing or REST requests and responses are:&lt;/p&gt;
&lt;p&gt;a) Invocation delivery details, and&lt;/p&gt;
&lt;p&gt;b) System deployment and wiring concerns.&lt;/p&gt;
&lt;p&gt;Therefore, they should always be abstracted away, ideally in a completely automatic and transparent way, so that we never have to deal with them in any way whatsoever when writing code. Thus, when I speak of invocations between collaborators, and unless I explicitly state otherwise, I mean programmatic interface method calls, with the provision that some automatic and transparent conversion between such calls and some other invocation delivery mechanism might be taking place under the hood if necessary.&lt;/p&gt;
&lt;h3 id=&#34;similarities-and-differences-from-dependencies&#34;&gt;Similarities and differences from dependencies
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;From an architectural point of view, where any components worth discussing are injectable, collaborator components are never dependencies, because no component depends on any particular implementation of another component. However, the interfaces of the collaborators are dependencies of the components that invoke them, because a component needs to import an interface in order to make invocations to it, otherwise it will not compile. (Assuming we are using a &lt;em&gt;real&lt;/em&gt; programming language, meaning a &lt;em&gt;strongly typed&lt;/em&gt; programming language.)&lt;/li&gt;
&lt;li&gt;Collaborator components that are available via hard-coding are of course dependencies, because when a component is hard-coded to make use of a certain component, it explicitly depends on that particular concrete implementation.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Reference:
&lt;a class=&#34;external&#34; 
   href=&#34;https://softwareengineering.stackexchange.com/q/443097/41811&#34; target=&#34;_blank&#34;
   &gt;softwareengineering.stackexchange.com - Definition of &amp;ldquo;collaborators&amp;rdquo;
(of an object) in Software Design?&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: &amp;ldquo;Collaboration&amp;rdquo; by michael.gr, using &lt;a class=&#34;external&#34; 
   href=&#34;https://thenounproject.com/icon/gear-1031260/&#34; target=&#34;_blank&#34;
   &gt;&amp;lsquo;Gear&amp;rsquo; by Lluisa Iborra&lt;/a&gt; and &lt;a class=&#34;external&#34; 
   href=&#34;https://thenounproject.com/icon/hands-making-a-circle-4289633/&#34; target=&#34;_blank&#34;
   &gt;&amp;lsquo;hands making a circle&amp;rsquo; by Oleksandr Panasovskyi&lt;/a&gt; from the Noun Project.&lt;/p&gt;</description>
        </item>
        <item>
        <title>If you are using mock objects you are doing it wrong</title>
        <link>//localhost:1313/post/2023-01-14-mocking/</link>
        <pubDate>Sat, 14 Jan 2023 14:13:37 +0000</pubDate>
        
        <guid>//localhost:1313/post/2023-01-14-mocking/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2023-01-14-mocking/images/mocking.svg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;
&lt;/p&gt;
&lt;h4 id=&#34;abstract&#34;&gt;Abstract:
&lt;/h4&gt;&lt;p&gt;The practice of using Mock Objects in automated software testing is examined from a critical point of view and found to be highly problematic. Opinions of some well known industry speakers are cited. The supposed benefits of Mock Objects are shown to be either no real benefits, or achievable via alternative means.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction
&lt;/h3&gt;&lt;p&gt;The automated software testing technique which is predominant in the industry today is Unit Testing. The goal of Unit Testing is to achieve defect localization, and to this effect it requires each component to be tested in strict isolation from its collaborators.&lt;/p&gt;
&lt;p&gt;Testing components in isolation from each other poses certain challenges:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;While being tested, the component-under-test makes invocations to collaborator interfaces; since the collaborator components are not present, some kind of substitute must be there to implement the collaborator interfaces and receive those invocations.&lt;/li&gt;
&lt;li&gt;For each invocation that the component-under-test makes to a collaborator, it expects to receive back some result; therefore, the substitute receiving the invocation must be capable of generating a result that matches the result that would be generated by the real collaborator.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The technique which is predominant in the industry today for providing the component-under-test with substitutes of its collaborators is &lt;em&gt;&lt;strong&gt;Mock Objects&lt;/strong&gt;&lt;/em&gt;, or just mocks.&lt;/p&gt;
&lt;h3 id=&#34;how-do-mocks-work&#34;&gt;How do mocks work?
&lt;/h3&gt;&lt;p&gt;Mocks are based on the premise that the real work done by collaborators in a production environment is irrelevant during testing, and all that the component-under-test really needs from them is the results that they return when invoked. A test exercises the component-under-test in a specific way, therefore the component-under-test is expected to invoke its collaborators in ways which are known in advance; thus, regardless of how the real collaborators would work, the mocks which replace them do not need to contain any functionality; all they need to do is to yield the same results that the real collaborators would have returned, which are also known in advance.&lt;/p&gt;
&lt;p&gt;To this effect, each test dynamically creates and configures as many mocks as necessary to substitute each one of the collaborators of the component-under-test, with the help of some mocking framework. These frameworks are so popular that there exists a proliferation of them: JMock, EasyMock, Mockito, NMock, Moq, JustMock, and the list goes on.&lt;/p&gt;
&lt;p&gt;A mock object is configured to expose the same interface as the real collaborator that it substitutes, and to expect specific methods of this interface to be invoked, with specific argument values, sometimes even in a specific order of invocation. If anything goes wrong, such as an unexpected method being invoked, or a parameter having an unexpected value, the mock fails the test. A very common practice is to also fail the test if an expected method is &lt;em&gt;not&lt;/em&gt; invoked.&lt;/p&gt;
&lt;p&gt;For each one of the expected methods, the mock is configured to yield a prefabricated result which is intended to match the result that the real collaborator would have produced if it was being used, and if it was working exactly according to its specification.&lt;/p&gt;
&lt;p&gt;Or at least, that is the intention.&lt;/p&gt;
&lt;h4 id=&#34;drawbacks-of-mocks&#34;&gt;Drawbacks of Mocks
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Complex and laborious&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;In each test it is not enough to invoke the component-under-test to perform a computation and check the results; we also have to configure a mock for each one of the collaborators of the component, to anticipate every single call that the component will be making to them while performing the computation, and for each call to fabricate a result which matches the result that the real collaborator would have returned from that call.&lt;/li&gt;
&lt;li&gt;Luckily, mocking frameworks lessen the amount of code necessary to accomplish this, but no matter how terse the mocking code is, the fact still remains that it constitutes substantial additional functionality which represents considerable additional complexity.&lt;/li&gt;
&lt;li&gt;One of the well-known caveats of software testing is that a test failure does not necessarily indicate a defect in the production code; it always indicates a defect either in the production code or in the test itself, and the only way to know is to troubleshoot. Thus, the more code we put in tests, and the more complex this code is, the more time we end up wasting in chasing and fixing bugs in the tests themselves rather than in the code that they are meant to test.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Over-specified&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;By anticipating every single call that the component-under-test makes to its collaborators, we are claiming to have detailed knowledge of the inner workings of the component-under-test, and we are concerned not only with what it accomplishes, but also with every little detail about how it goes on about accomplishing it. Essentially, we are implementing all of our application logic twice: once with production code expressing the logic in imperative mode, and once more with testing code expressing the same logic in expectational mode. In both cases, we write copious amounts of code describing what should happen in excruciatingly meticulous detail.&lt;/li&gt;
&lt;li&gt;Note that over-specification might not even be a goal in and of itself in some cases, but with mocking it is unavoidable in all cases: Each request that the component-under-test sends to its collaborators could conceivably be ignored, but the component-under-test still needs to receive some meaningful result in response to that request, so as to continue functioning during the remainder of the test; unfortunately, the only way that mocks can fabricate individual responses is by anticipating individual requests, even if the intention of the test is not to verify whether the requests are being made.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Presumptuous&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;When using mocks we are claiming to not only have detailed knowledge of the calls that the component-under-test makes to its collaborators, but also detailed knowledge of the results that would be returned by the real collaborators in a production environment.&lt;/li&gt;
&lt;li&gt;Furthermore, the results returned by a collaborator depend on the state that the collaborator is in, which in turn depends on previous calls made to it, but a mock is by its nature incapable of emulating state, so when using mocks we are also claiming to have knowledge of the state transitions that the real collaborators undergo in a production environment, and of the effect that these state transitions have on the results that they return.&lt;/li&gt;
&lt;li&gt;Such exorbitant presumptuousness might be okay if we are building high-criticality software, where each collaborator is likely to have requirements and specification that are well-defined and unlikely to change; however, in all other software, which is regular, commercial, non-high-criticality software, things are a lot less strict: not only the requirements and specifications change all the time, but also, by established practice, both the requirements, and the specification, and even the documentation, tend to be the code itself, and the code changes every time a new commit is made to the source code repository. Thus, the only way to know exactly how a collaborator behaves tends to be to actually invoke it and see what it does, while the mechanism which ensures that it does what it is supposed to do is the tests of that collaborator itself, which are unrelated to the tests of components that invoke it.&lt;/li&gt;
&lt;li&gt;As a result of all this, the practice of mocking often places us in the all too familiar situation where our Unit Tests all pass with flying colors, but our Integration Tests miserably fail because the behavior of the real collaborators turns out to be different from what the mocks assumed it would be.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fragile&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;By its nature, a mock object has no option but to fail the test if the interactions between the component under test and its collaborators deviate from what it expects. However, these interactions may legitimately change as software evolves. This may happen due to the application of a bug-fix, due to refactoring, or simply because as we write new code we invariably have to also modify existing code to interact with the new code that we are adding. Thus, when using mocks, every time we change the behavior of production code, we also have to fix tests to expect the new behavior. (Not only do we have to write all of our application logic twice, we also have to perform all of its maintenance twice.)&lt;/li&gt;
&lt;li&gt;The original promise of Automated Software Testing was to enable us to continuously evolve our software without fear of breaking it. The idea is that whenever you modify the production code, you can re-run the tests to ensure that everything still works. When using mocks this does not work, because every time you change the slightest thing in the production code, the tests break. As a result, many programmers are hesitant to make needed changes to production code because of all the changes in testing code that would be required. The understanding is growing within the software engineering community that mock objects actually hinder software development instead of facilitating it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Non-reusable&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Mocks exercise the implementation of a component rather than its interface. Thus, when using mocks, it is impossible to reuse the same testing code to validate multiple different components that implement the same public interface but employ different collaborators. For example:
&lt;ul&gt;
&lt;li&gt;It is impossible to completely rewrite the component and reuse the old tests to make sure that the new implementation works exactly as the old one did.&lt;/li&gt;
&lt;li&gt;It is impossible to use a single test suite to exercise both a real component and its fake.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Unenlightening&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Ideally, a set of tests for a certain component should act as sample code demonstrating usage scenarios of that component. A programmer who is not familiar with a particular component should be able to read the tests of that component and gain a fairly good idea of what it can do, what it cannot do, and how to write production code that interacts with it.&lt;/li&gt;
&lt;li&gt;Unfortunately, when using mocks, the tests are full of cryptic mock-related jabber, which obscures the actual usage of the component-under-test, and so the enlightening bits are lost in the noise.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;what-do-others-say&#34;&gt;What do others say?
&lt;/h4&gt;&lt;p&gt;I am certainly not the only one to voice dissatisfaction with mocks. People have been noticing that although automated software testing is intended to facilitate refactoring by ensuring that the code still works after each change that we make, the use of mocks often hinders refactoring, because the tests are so tied to the implementation that you cannot change anything without breaking the tests.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the video &lt;em&gt;Thoughtworks - TW Hangouts: Is TDD dead?&lt;/em&gt; (&lt;a class=&#34;external&#34; 
   href=&#34;https://www.youtube.com/watch?v=z9quxZsLcfo&#34; target=&#34;_blank&#34;
   &gt;youtube&lt;/a&gt;, &lt;a class=&#34;external&#34; 
   href=&#34;https://martinfowler.com/articles/is-tdd-dead/&#34; target=&#34;_blank&#34;
   &gt;text digest&lt;/a&gt;) at 21&amp;rsquo;:10&amp;rsquo;&amp;rsquo; Kent Beck states &amp;ldquo;My personal practice is I mock almost nothing.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;In the same video, at 23&amp;rsquo;:56&amp;rsquo;&amp;rsquo; Martin Fowler adds &amp;ldquo;I&amp;rsquo;m with Kent, I hardly ever use mocks.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;In the &lt;em&gt;Fragile Test&lt;/em&gt; section of his book &lt;em&gt;xUnit Test Patterns: Refactoring Test Code&lt;/em&gt; (&lt;a class=&#34;external&#34; 
   href=&#34;https://xunitpatterns.com/&#34; target=&#34;_blank&#34;
   &gt;xunitpatterns.com&lt;/a&gt;) author Gerard Meszaros admits that &amp;ldquo;extensive use of Mock Objects causes overcoupled tests.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;In his presentation &lt;em&gt;TDD, where did it all go wrong?&lt;/em&gt; (&lt;a class=&#34;external&#34; 
   href=&#34;https://www.infoq.com/presentations/tdd-original/&#34; target=&#34;_blank&#34;
   &gt;InfoQ&lt;/a&gt;, &lt;a class=&#34;external&#34; 
   href=&#34;https://www.youtube.com/watch?v=EZ05e7EMOLM&#34; target=&#34;_blank&#34;
   &gt;YouTube&lt;/a&gt;) at 49&amp;rsquo;:32&amp;rsquo;&amp;rsquo; Ian Cooper states &amp;ldquo;I argue quite heavily against mocks because they are overspecified.&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that in an attempt to avoid sounding too blasphemous, these people refrain from suggesting that mocks should be abolished; however, it is evident that 3 out of 4 of them are strongly against mocks, and we do not need to read much between the lines to figure out that they would probably be calling for the complete abolition of mocks if they had a viable and universally applicable alternative to propose.&lt;/p&gt;
&lt;h4 id=&#34;so-if-not-mocking-then-what&#34;&gt;So, if not mocking, then what?
&lt;/h4&gt;&lt;p&gt;Mocking has been such a great hit with the software industry because it achieves multiple different goals at once. Here is a list of the supposed benefits of mocking, and for each one of them an explanation of why it is not really a benefit, or how it can be achieved without mocking:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mocking achieves defect localization by eliminating collaborators from the picture and allowing components to be tested in strict isolation from each other.
&lt;ul&gt;
&lt;li&gt;Defect localization is useful, but it is not an absolute necessity, and it does not have to be done to absolute perfection as mocking aims to do; we can achieve more than good enough defect localization by testing each component in integration with its collaborators, simply by arranging the order in which tests are executed to ensure that by the time a component gets tested, all of its collaborators have already passed their tests. See &lt;a 
   href=&#34;//localhost:1313/post/2022-10-incremental-integration-testing/&#34;
   &gt;Incremental Integration Testing&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mocking allows a component to be tested without the performance overhead of instantiating and invoking its real collaborators.
&lt;ul&gt;
&lt;li&gt;The performance overhead of instantiating and invoking the real collaborators is not always prohibitive, or even noticeable, so in many cases it is perfectly fine to test a component in integration with its real collaborators. See &lt;a 
   href=&#34;//localhost:1313/post/2022-10-incremental-integration-testing/&#34;
   &gt;Incremental Integration Testing&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;In the limited number of cases where the performance overhead is indeed prohibitive, it can be avoided with the use of Fakes instead of Mocks. See &lt;a 
   href=&#34;//localhost:1313/post/2022-10-testing-with-fakes/&#34;
   &gt;Testing with Fakes instead of Mocks&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mocking allows us to examine invocations being made by the component-under-test to its collaborators, to ensure that they are issued exactly as expected.
&lt;ul&gt;
&lt;li&gt;In most cases, examining the invocations made by the component-under-test to its collaborators is in fact bad practice, because it constitutes white-box testing. The only reason why this is being widely practiced in the industry is because mocking does not work otherwise, so in this regard mocking contains a certain element of a self-serving paradigm.&lt;/li&gt;
&lt;li&gt;In those rare cases where examining the invocations is in fact necessary, it is still bad practice to do so programmatically, because it results in tests that are over-specified and fragile.&lt;/li&gt;
&lt;li&gt;What we can do instead is to record the interactions during each test run, visually compare the latest recording with that of the last known good run, and decide whether the differences match our expectations; if they do not match, then we must keep working on our code; but if they do match, then we are done without the need to go fixing any tests. See &lt;a 
   href=&#34;//localhost:1313/post/2024-04-audit-testing/&#34;
   &gt;Audit Testing&lt;/a&gt; and &lt;a 
   href=&#34;//localhost:1313/post/2023-01-06-collaboration-monitoring/&#34;
   &gt;Collaboration Monitoring&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mocking allows us to fabricate the results returned from a collaborator to the component-under-test, so as to guarantee that they are free from defects that could be caused by bugs in the implementation of the real collaborator.
&lt;ul&gt;
&lt;li&gt;Fabricating the results that would have been returned by a real collaborator is in fact bad practice, because it will not magically make any bugs go away, (in this sense it can be likened to ostrich policy,) and because as I have already explained, it is highly presumptuous. The definitive authority on what results are returned by a certain collaborator is the real implementation of that collaborator, or a fake thereof, which in turn necessitates integration testing. See &lt;a 
   href=&#34;//localhost:1313/post/2022-10-incremental-integration-testing/&#34;
   &gt;Incremental Integration Testing&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mocking allows us to verify the correctness of components that generate their output by means of forwarding results to collaborators rather than by returning results from invocations.
&lt;ul&gt;
&lt;li&gt;Even in this case, &lt;em&gt;Collaboration Monitoring&lt;/em&gt; can be used instead of mocking, to verify that the results are generated as expected without having to programmatically describe what the results should be and without having to go fixing tests each time we modify the component under test and deliberately change something about the results it generates. See &lt;a 
   href=&#34;//localhost:1313/post/2024-04-audit-testing/&#34;
   &gt;Audit Testing&lt;/a&gt; and &lt;a 
   href=&#34;//localhost:1313/post/2023-01-06-collaboration-monitoring/&#34;
   &gt;Collaboration Monitoring&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mocking allows us to start testing a component while one or more of its collaborators are not ready yet for integration because they are still in development, and no fakes of them are available either.
&lt;ul&gt;
&lt;li&gt;This is true, but once the collaborators (or fakes thereof) become available, it is best to integrate them in the tests, and to unceremoniously throw away the mocks. See &lt;a 
   href=&#34;//localhost:1313/post/2022-10-incremental-integration-testing/&#34;
   &gt;Incremental Integration Testing&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mocking allows us to develop a component without depending on factors that we have no control over, such as the time of delivery of collaborators, the quality of their implementation, and the quality of their testing. With the use of Mocks we can claim that our component is complete and fully tested, based on nothing but the specification of its collaborators, and we can claim that it should work fine in integration with its collaborators when they happen to be delivered, and if they happen to work according to spec.
&lt;ul&gt;
&lt;li&gt;True, but this implies a very bureaucratic way of working, and utter lack of trust towards the developers of the collaborators; it is best if it never comes to that.&lt;/li&gt;
&lt;li&gt;We can still avoid the use of mocks by creating fakes of the collaborators ourselves. See &lt;a 
   href=&#34;//localhost:1313/post/2022-10-testing-with-fakes/&#34;
   &gt;Testing with Fakes instead of Mocks&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To summarize, mocks can always be replaced with one or more of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fakes (see &lt;a 
   href=&#34;//localhost:1313/post/2022-10-testing-with-fakes/&#34;
   &gt;Testing with Fakes instead of Mocks&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Incremental Integration Testing (see &lt;a 
   href=&#34;//localhost:1313/post/2022-10-incremental-integration-testing/&#34;
   &gt;Incremental Integration Testing&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Audit Testing (see &lt;a 
   href=&#34;//localhost:1313/post/2024-04-audit-testing/&#34;
   &gt;Audit Testing&lt;/a&gt;) and Collaboration Monitoring (see &lt;a 
   href=&#34;//localhost:1313/post/2023-01-06-collaboration-monitoring/&#34;
   &gt;Collaboration Monitoring&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h4&gt;&lt;p&gt;As we have shown, the practice of using Mock Objects in automated software testing is laborious, over-specified, presumptuous, and leads to tests that are fragile and non-reusable, while each of the alleged benefits of using mocks is either not a real benefit, or can be realized by other means, which we have named.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;img src=&#34;//localhost:1313/post/2023-01-14-mocking/images/grumpy-cat-mock-objects.jpg&#34;
	width=&#34;797&#34;
	height=&#34;1024&#34;
	srcset=&#34;//localhost:1313/post/2023-01-14-mocking/images/grumpy-cat-mock-objects_hu_8156248a341d61af.jpg 480w, //localhost:1313/post/2023-01-14-mocking/images/grumpy-cat-mock-objects_hu_5b4ff396469f2342.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;77&#34;
		data-flex-basis=&#34;186px&#34;
	
&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;Mandatory grumpy cat meme - &amp;ldquo;Mock objects - they are horrible&amp;rdquo;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: &amp;ldquo;Mocking&amp;rdquo; by michael.gr, based on &lt;a class=&#34;external&#34; 
   href=&#34;https://thenounproject.com/icon/mock-2657532/&#34; target=&#34;_blank&#34;
   &gt;&amp;lsquo;mock&amp;rsquo; by &amp;lsquo;Iconbox&amp;rsquo; from the noun project.&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>Collaboration Monitoring</title>
        <link>//localhost:1313/post/2023-01-06-collaboration-monitoring/</link>
        <pubDate>Fri, 06 Jan 2023 13:03:22 +0000</pubDate>
        
        <guid>//localhost:1313/post/2023-01-06-collaboration-monitoring/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2023-01-06-collaboration-monitoring/images/collaboration-monitoring.png&#34;
	width=&#34;1024&#34;
	height=&#34;512&#34;
	srcset=&#34;//localhost:1313/post/2023-01-06-collaboration-monitoring/images/collaboration-monitoring_hu_3c58b5508de82250.png 480w, //localhost:1313/post/2023-01-06-collaboration-monitoring/images/collaboration-monitoring_hu_1f58869c4f30abf2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;200&#34;
		data-flex-basis=&#34;480px&#34;
	
&gt;
&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract
&lt;/h3&gt;&lt;p&gt;An automated software testing technique is presented which solves the fragile test problem of white-box testing by allowing us to ensure that the component-under-test interacts with its collaborators according to our expectations without having to stipulate our expectations as test code, without having the tests fail each time our expectations change, and without having to go fixing test code each time this happens.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;p&gt;In automated software testing it is sometimes necessary to ensure not only that given specific input, the component-under-test produces correct output, (&lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Black-box_testing&#34; target=&#34;_blank&#34;
   &gt;Black-Box Testing&lt;/a&gt;,) but also that while doing so, it interacts with its collaborators in certain expected ways. (&lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/White-box_testing&#34; target=&#34;_blank&#34;
   &gt;White-Box Testing&lt;/a&gt;.) The prevailing technique for achieving white-box testing (&lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Mock_object&#34; target=&#34;_blank&#34;
   &gt;Mock Objects&lt;/a&gt;) requires copious amounts of additional code in the tests to describe the interaction that are expected to happen, and fails the tests if the actual interactions deviate from the expected ones.&lt;/p&gt;
&lt;p&gt;Unfortunately, the interactions often change due to various reasons, for example applying a bug fix, performing refactoring, or modifying existing code in order to accommodate the addition of new code intended to introduce new functionality; so, tests keep breaking all the time, (the &lt;a class=&#34;external&#34; 
   href=&#34;https://xunitpatterns.com/Fragile%20Test.html&#34; target=&#34;_blank&#34;
   &gt;Fragile Test&lt;/a&gt; problem,) requiring constant maintenance, which imposes a heavy burden on the Software Development process.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Collaboration Monitoring&lt;/strong&gt;&lt;/em&gt; is a technique for white-box testing where during a test run we record detailed information about the interactions between collaborators, we compare the recording against that of a previous test run, and we visually examine the differences to determine whether the changes observed in the interactions are as expected according to the changes that were made in the code. Thus, no code has to be written to describe in advance how collaborators are expected to interact, and no tests have to be fixed each time the expectations change.&lt;/p&gt;
&lt;h3 id=&#34;the-problem&#34;&gt;The problem
&lt;/h3&gt;&lt;p&gt;Most software testing as conventionally practiced all over the world today consists of two parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;Result Validation:&lt;/strong&gt;&lt;/em&gt; ascertaining that given specific input, the component-under-test produces specific expected output.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;Collaboration Validation:&lt;/strong&gt;&lt;/em&gt; ensuring that while performing a certain computation, the component-under-test interacts with its collaborators in specific expected ways.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As I argue elsewhere, in the vast majority of cases, Collaboration Validation is ill-advised, because it constitutes white-box testing; however, there are some cases where it is necessary, for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In high-criticality software, which is all about safety, not only the requirements must be met, but also nothing must be left to chance. Thus, the cost of white-box testing is justified, and the goal is in fact to ensure that the component-under-test not only produces correct results, but also that while doing so, it interacts with its collaborators as expected.&lt;/li&gt;
&lt;li&gt;In reactive programming, the component-under-test does not produce output by returning results from function calls; instead, it produces output by forwarding results to collaborators. Thus, even if all we want to do is to ascertain the correctness of the component&amp;rsquo;s output, we have to examine how it interacts with its collaborators, because that is the only way to observe its output.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The prevalent mechanism by which the Software Industry achieves Collaboration Validation today is Mock Objects. As I argue elsewhere, (see &lt;a 
   href=&#34;//localhost:1313/post/2023-01-14-mocking/&#34;
   &gt;If you are using mock objects you are doing it wrong&lt;/a&gt;) the use of mocks is generally ill-advised due to various reasons, but with respect to Collaboration Validation in specific, the problem with mocks is that their use is extremely laborious:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When we write a test for a certain component, it is counter-productive to have to stipulate in code exactly how we expect it to interact with its collaborators.&lt;/li&gt;
&lt;li&gt;When we revise the implementation of a component, the component may now legitimately start interacting with its collaborators in a different way; when this happens, it is counter-productive to have the tests fail, and to have to go fix them so that they stop expecting the old interactions and start expecting the new interactions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The original promise of automated software testing was to allow us to modify code without the fear of breaking it, but with the use of mocks the slightest modification to the code causes the tests to fail, so the code always looks broken, and the tests always require fixing.&lt;/p&gt;
&lt;p&gt;This is particularly problematic in light of the fact that there is nothing about the concept of Collaboration Validation which requires that the interactions between collaborators must be stipulated in advance, nor that the tests must fail each time the interactions change; all that is required is that we must be able to tell whether the interactions between collaborators are as expected or not. Thus, Collaboration Validation does not necessitate the use of mocks; it could conceivably be achieved by some entirely different means.&lt;/p&gt;
&lt;h3 id=&#34;the-solution&#34;&gt;The Solution
&lt;/h3&gt;&lt;p&gt;If we want to ensure that given specific input, a component produces expected results, we do of course have to write some test code to exercise the component as a black-box. If we also want to ensure that the component-under-test interacts with its collaborators in specific ways while it is being exercised, this would be white-box testing, so it would be best if it does not have to also be written in code. To achieve this without code, all we need is the ability to somehow capture the interactions so that we can visually examine them and decide whether they are in agreement with our expectations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If they are not as expected, then we have to keep working on the production code and/or the black-box testing code.&lt;/li&gt;
&lt;li&gt;If they are as expected, then we are done: we can commit our code, and call it a day, without having to modify any white-box tests!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The trick is to do so in a convenient, iterative, and fail-safe way, meaning that the following must hold true:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When a change in the code causes a change in the interactions, there should be some kind of indication telling us that the interactions have now changed, and this indication should be so clear that we cannot possibly miss it.&lt;/li&gt;
&lt;li&gt;Each time we modify some code and run the tests, we want to be able to see what has changed in the interactions as a result of only those modifications, so that we do not have to pore through long lists of irrelevant interactions, and so that no information gets lost in the noise.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To achieve this, I use a technique that I call Collaboration Monitoring.&lt;/p&gt;
&lt;p&gt;Collaboration Monitoring is based on another testing technique that I call Audit Testing, so it might be a good idea to read the related paper before proceeding: &lt;a 
   href=&#34;//localhost:1313/post/2024-04-audit-testing/&#34;
   &gt;Audit Testing&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let us assume that we have a component that we want to test, which invokes interface T as part of its job. In order to test the component, we have to wire it with a collaborator that implements T. For this, we can use either the real collaborator that would be wired in the production environment, or a Fake thereof. Regardless of what we choose, we have a very simple picture which looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2023-01-06-collaboration-monitoring/images/collaboration-monitor-1.png&#34;
	width=&#34;422&#34;
	height=&#34;74&#34;
	srcset=&#34;//localhost:1313/post/2023-01-06-collaboration-monitoring/images/collaboration-monitor-1_hu_8cbeb5070d7d33.png 480w, //localhost:1313/post/2023-01-06-collaboration-monitoring/images/collaboration-monitor-1_hu_422fd14dddc93b76.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;570&#34;
		data-flex-basis=&#34;1368px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;Note that with this setup we can exercise the component-under-test as a black-box, but we cannot yet observe how it interacts with its collaborator.&lt;/p&gt;
&lt;p&gt;In order to observe how the component-under-test interacts with its collaborator, we interject between the two of them a new component, called a &lt;em&gt;&lt;strong&gt;Collaboration Monitor&lt;/strong&gt;&lt;/em&gt;, which is a decorator of T. The purpose of this Collaboration Monitor is to record into a text file information about each function call that passes through it. The text file is called a &lt;em&gt;&lt;strong&gt;Snoop File&lt;/strong&gt;&lt;/em&gt;, and it is a special form of &lt;em&gt;&lt;strong&gt;Audit File&lt;/strong&gt;&lt;/em&gt;. (See &lt;a 
   href=&#34;//localhost:1313/post/2024-04-audit-testing/&#34;
   &gt;Audit Testing&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;Thus, we now have the following picture:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2023-01-06-collaboration-monitoring/images/collaboration-monitor-2.png&#34;
	width=&#34;568&#34;
	height=&#34;193&#34;
	srcset=&#34;//localhost:1313/post/2023-01-06-collaboration-monitoring/images/collaboration-monitor-2_hu_6876382b85ecd6f0.png 480w, //localhost:1313/post/2023-01-06-collaboration-monitoring/images/collaboration-monitor-2_hu_88f51d25c12dfe11.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;294&#34;
		data-flex-basis=&#34;706px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;The information that the Collaboration Monitor saves for each function call includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The name of the function.&lt;/li&gt;
&lt;li&gt;A serialization of the value of each parameter that was passed to the function.&lt;/li&gt;
&lt;li&gt;A serialization of the return value of the function.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As per Audit Testing, the Snoop File is saved in the source code tree, right next to the source code file of the test that generated it, and gets committed into the Source Code Repository / Version Control System along with the source code. For example, if we have &lt;code&gt;SuchAndSuchTest.java&lt;/code&gt;, then after running the tests for the first time we will find a &lt;code&gt;SuchAndSuchTest.snoop&lt;/code&gt; file right next to it. We can examine this file to ensure that the component-under-test interacted with the collaborator exactly as expected.&lt;/p&gt;
&lt;p&gt;As we continue developing our system, the modifications that we make to the code will sometimes have no effect on how collaborators interact with each other, and sometimes will cause the collaborators to start interacting differently. Thus, as we continue running our tests while developing our system, we will be observing the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For as long as the collaborations continue in exactly the same way, the contents of the Snoop Files remain unchanged, despite the fact that the files are re-generated on each test run.&lt;/li&gt;
&lt;li&gt;As soon as some collaborations change, the contents of some Snoop Files will change.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As per Audit Testing, we can then leverage our Version Control System and our Integrated Development Environment to take care of the rest of the workflow, as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When we make a revision in the production code or in the testing code, and as a result of this revision the interactions between the component-under-test and its collaborators are now even slightly different, we will not fail to take notice because our Version Control System will show the corresponding Snoop File as modified and in need of committing.&lt;/li&gt;
&lt;li&gt;By asking our Integrated Development Environment to show us a &amp;ldquo;diff&amp;rdquo; between the current snoop file and the unmodified version, we can see precisely what has changed without having to pore through the entire snoop file.&lt;/li&gt;
&lt;li&gt;If the observed interactions are not exactly what we expected them to be according to the revisions we just made, we keep working on our revision.&lt;/li&gt;
&lt;li&gt;When we are confident that the differences in the interactions are exactly as expected according to the changes that we made to the code, we commit our revision, along with the Snoop Files.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-about-code-review&#34;&gt;What about code review?
&lt;/h3&gt;&lt;p&gt;As per Audit Testing, the reviewer is able to see both the changes in the code, and the corresponding changes in the Snoop Files, and vouch for them, or not, as the case might be.&lt;/p&gt;
&lt;h3 id=&#34;requirements&#34;&gt;Requirements
&lt;/h3&gt;&lt;p&gt;For Collaboration Monitoring to work, snoop files must be free from non-deterministic noise, and it is best if they are also free from deterministic noise. For more information about these types of noise and what you can do about them, see &lt;a 
   href=&#34;//localhost:1313/post/2024-04-audit-testing/&#34;
   &gt;Audit Testing&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;automation&#34;&gt;Automation
&lt;/h3&gt;&lt;p&gt;When using languages like Java and C# which support reflection and intermediate code generation, we do not have to write Collaboration Monitors by hand; we can instead create a facility which will be automatically generating them for us on demand, at runtime. Such a facility can be very easily written with the help of Intertwine (see &lt;a 
   href=&#34;//localhost:1313/post/2022-12-intertwine/&#34;
   &gt;Intertwine&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;Using Intertwine, we can create a Collaboration Monitor for any interface T. Such a Collaboration Monitor works as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Contains an Entwiner of T so that it can expose interface T without any hand-written code implementing interface T. The Entwiner delegates to an instance of &lt;code&gt;AnyCall&lt;/code&gt;, which expresses each invocation in a general-purpose form.&lt;/li&gt;
&lt;li&gt;Contains an implementation of &lt;code&gt;AnyCall&lt;/code&gt; which serializes all necessary information about the invocation into the Snoop File.&lt;/li&gt;
&lt;li&gt;Contains an untwiner of T, so that it can convert each invocation from &lt;code&gt;AnyCall&lt;/code&gt; back to an instance of T, without any hand-written code for invoking interface T.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;comparison-of-workflows&#34;&gt;Comparison of Workflows
&lt;/h4&gt;&lt;p&gt;Here is a step-by-step comparison of the software development process when using mocks, and when using collaboration monitoring.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Workflow using Mock Objects:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Modify the production code and/or the black-box part of the tests.&lt;/li&gt;
&lt;li&gt;Run the tests.
&lt;ul&gt;
&lt;li&gt;If the tests pass:
&lt;ul&gt;
&lt;li&gt;Done.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If the tests fail:
&lt;ul&gt;
&lt;li&gt;Troubleshoot why this is happening.
&lt;ul&gt;
&lt;li&gt;If either the production code or the black-box part of the tests is
wrong:
&lt;ul&gt;
&lt;li&gt;Go to step 1.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If the white-box part of the tests is wrong:
&lt;ul&gt;
&lt;li&gt;Modify the white-box part of the tests (the mocking code) to stop expecting the old interactions and start expecting the new interactions.&lt;/li&gt;
&lt;li&gt;Go to step 2.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Workflow using Collaboration Monitoring:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Modify the production code and/or the tests.&lt;/li&gt;
&lt;li&gt;Run the tests.
&lt;ul&gt;
&lt;li&gt;If the tests pass:
&lt;ul&gt;
&lt;li&gt;If the interactions have remained unchanged:
&lt;ul&gt;
&lt;li&gt;Done.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If the interactions have changed:
&lt;ul&gt;
&lt;li&gt;Visually inspect the changes.
&lt;ul&gt;
&lt;li&gt;If the interactions agree with our expectations:
&lt;ul&gt;
&lt;li&gt;Done.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If the interactions differ from our expectations:
&lt;ul&gt;
&lt;li&gt;Go to step 1.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If the tests fail:
&lt;ul&gt;
&lt;li&gt;Go to step 1.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h4&gt;&lt;p&gt;Collaboration Monitoring is an adaptation of Audit Testing which allows the developer to write black-box tests which only exercise the public interface of the component-under-test, while remaining confident that the component interacts with its collaborators inside the black box according to their expectations, without having to write white-box testing code to stipulate the expectations, and without having to modify white-box testing code each time the expectations change.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: &amp;ldquo;Collaboration Monitoring&amp;rdquo; by michael.gr based on original work &lt;a class=&#34;external&#34; 
   href=&#34;https://thenounproject.com/icon/monitoring-4861371/&#34; target=&#34;_blank&#34;
   &gt;&amp;lsquo;monitoring&amp;rsquo; by Arif Arisandi&lt;/a&gt; and &lt;a class=&#34;external&#34; 
   href=&#34;https://thenounproject.com/icon/gears-1705750/&#34; target=&#34;_blank&#34;
   &gt;&amp;lsquo;Gears&amp;rsquo; by Free Fair &amp;amp; Healthy&lt;/a&gt; from the Noun Project.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Testing with Fakes instead of Mocks</title>
        <link>//localhost:1313/post/2022-10-testing-with-fakes/</link>
        <pubDate>Fri, 30 Dec 2022 14:01:26 +0000</pubDate>
        
        <guid>//localhost:1313/post/2022-10-testing-with-fakes/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2022-10-testing-with-fakes/media/fake.png&#34;
	width=&#34;2000&#34;
	height=&#34;1000&#34;
	srcset=&#34;//localhost:1313/post/2022-10-testing-with-fakes/media/fake_hu_94f7aa407fc2e88a.png 480w, //localhost:1313/post/2022-10-testing-with-fakes/media/fake_hu_fbb249274ecaf5fb.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;200&#34;
		data-flex-basis=&#34;480px&#34;
	
&gt;
&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract
&lt;/h3&gt;&lt;p&gt;What are &lt;em&gt;fakes&lt;/em&gt;, what are their benefits, and why they are incontestably preferable over &lt;em&gt;mocks&lt;/em&gt;. Also, how to create fakes if needed.&lt;/p&gt;
&lt;h4 id=&#34;introduction&#34;&gt;Introduction
&lt;/h4&gt;&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;When testing a component it is often necessary to refrain from connecting it with the real collaborators that it would be connected with in a production environment, and instead to connect it with special substitutes of its collaborators, also known as &lt;em&gt;test doubles&lt;/em&gt;, which are more suitable for testing than the real ones.&lt;/p&gt;
&lt;p&gt;One book that names and describes various kinds of test doubles is &lt;em&gt;xUnit Test Patterns: Refactoring Test Code&lt;/em&gt; by Gerard Meszaros, (&lt;a class=&#34;external&#34; 
   href=&#34;https://xunitpatterns.com/&#34; target=&#34;_blank&#34;
   &gt;xunitpatterns.com&lt;/a&gt;) though I first read about them from &lt;a class=&#34;external&#34; 
   href=&#34;https://martinfowler.com/bliki/TestDouble.html&#34; target=&#34;_blank&#34;
   &gt;martinfowler.com - TestDouble&lt;/a&gt;, which refers to Meszaros as the original source.&lt;/p&gt;
&lt;p&gt;There exist a few different kinds of test doubles; by far the most commonly used kind is mocks, which, as I explain elsewhere, are a very bad idea and should be avoided like COVID-19. (See &lt;a 
   href=&#34;//localhost:1313/post/2023-01-14-mocking/&#34;
   &gt;If you are using mock objects you are doing it wrong&lt;/a&gt;.) Another kind of test double, which does not suffer from the disadvantages of mocks, is &lt;em&gt;&lt;strong&gt;Fake Objects&lt;/strong&gt;&lt;/em&gt;, or simply &lt;em&gt;&lt;strong&gt;fakes&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id=&#34;what-are-fakes&#34;&gt;What are fakes
&lt;/h3&gt;&lt;p&gt;In just one word, a fake is an emulator.&lt;/p&gt;
&lt;p&gt;In a bit more detail, a fake is a component that fully implements the interface of the real component that it substitutes, or at any rate the subset of that interface that we have a use for; it maintains state which is equivalent to the state of the real component, and based on this state it provides the full functionality of the real component, or a very convincing illusion thereof; to achieve this, it makes some compromises which either do not matter during testing, or are actually desirable during testing. Examples of such compromises are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Having limited capacity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Not being scalable.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Not being distributed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Not remembering any state from run to run.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pretending to interact, but not actually interacting, with the physical world.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generating fake data that would be unusable in a real production scenario.&lt;/p&gt;
&lt;p&gt;A fake can be more suitable for testing than the real thing in the following ways:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;By performing much better than the real thing; for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;by keeping state in-memory instead of persisting to the file-system.&lt;/li&gt;
&lt;li&gt;by working locally instead of over the network.&lt;/li&gt;
&lt;li&gt;by pretending that the time has come for the next timer to fire instead of having to wait for that timer to fire.&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;By being deterministic; for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;by fabricating time-stamps instead of querying the system clock.&lt;/li&gt;
&lt;li&gt;by fabricating entities such as GUIDs, that would otherwise introduce randomness.&lt;/li&gt;
&lt;li&gt;by utilizing a single thread, or forcing threads to work in a lock-step fashion.&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;By avoiding undesirable interactions with the real world; for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;by pretending that a mass e-mail was sent instead of actually sending it.&lt;/li&gt;
&lt;li&gt;by pretending that an application-modal message box popped up, and that the user picked one of the available choices, instead of allowing an actual modal message box to block the running of tests on the developer&amp;rsquo;s computer, or, worse yet, on some continuous build server in some data center out there.&lt;/li&gt;
&lt;li&gt;by pretending that an industrial robot made a certain movement, instead of causing an actual robot to move on a factory floor.&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A few examples of frequently used fakes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Various in-memory file-system libraries exist for various platforms, which can be used in place of the actual file-systems on those platforms.&lt;/li&gt;
&lt;li&gt;HSQLDB and H2 for Java, in-memory DbContext for DotNet EntityFramework, etc. are in-memory database systems that can be used in place of actual Relational Database Management Systems when testing.&lt;/li&gt;
&lt;li&gt;EmbeddedKafka can be used in place of an actual pair of Kafka + Zookeeper instances.&lt;/li&gt;
&lt;li&gt;A pseudo-random number generator seeded with a known constant value acts as a fake of the same pseudo-random number generator seeded with a practically random value such as the current time coordinate.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To recap:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fakes refrain from performing the actual operations that the real thing would perform, (e.g. when a file is created while using an in-memory file-system, no file gets created on disk,) but:&lt;/li&gt;
&lt;li&gt;They do go through all the motions, (e.g. attempting to create a file using an invalid filename will cause an error just as in a real file-system,) and:&lt;/li&gt;
&lt;li&gt;They do maintain the same state, (e.g. reading a file from an in-memory file-system will yield the exact same data that were previously written to
it,) so:&lt;/li&gt;
&lt;li&gt;They do fully behave as if the operations were actually performed as far as the component-under-test is concerned, while:&lt;/li&gt;
&lt;li&gt;The compromises that they make in order to achieve this are inconsequential or even desirable when testing. (e.g. during a test run it does not matter if files created during a previous test run do not exist anymore, and as a matter of fact it is better if they do not exist.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that the terminology is a bit unfortunate: fakes are not nearly as fake as mocks.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mocks are the ultimate in fakery because:
&lt;ul&gt;
&lt;li&gt;They only respond to invocations that we prescribe in each test, based on our assumptions as to how the component-under-test would invoke the real thing.&lt;/li&gt;
&lt;li&gt;They maintain no state.&lt;/li&gt;
&lt;li&gt;They contain no functionality.&lt;/li&gt;
&lt;li&gt;They only return results that we prefabricate in each test, based on our assumptions as to how the real thing would respond.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fakes are not quite as fake as their name suggests, because:
&lt;ul&gt;
&lt;li&gt;They expose the same interface as the real thing.&lt;/li&gt;
&lt;li&gt;They maintain an equivalent state as the real thing.&lt;/li&gt;
&lt;li&gt;They implement equivalent functionality as the real thing.&lt;/li&gt;
&lt;li&gt;They return the exact same results as the real thing.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;benefits-of-fakes&#34;&gt;Benefits of fakes
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;By using a fake instead of the real thing:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;We achieve better performance, so that our tests run quickly.&lt;/li&gt;
&lt;li&gt;We avoid non-determinism during testing, so our tests are repeatable.&lt;/li&gt;
&lt;li&gt;We avoid undesirable interactions with the real world, so nobody gets hurt.&lt;/li&gt;
&lt;li&gt;We have less code to write, since a fake is usually simpler to set up than the real thing.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;By using a fake instead of a mock:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;We save ourselves from having to write complicated mocking code in each test.&lt;/li&gt;
&lt;li&gt;We do not need to claim any knowledge as to how the component under test invokes its collaborators.&lt;/li&gt;
&lt;li&gt;We do not have to make assumptions about the state in which the collaborators are at any given moment.&lt;/li&gt;
&lt;li&gt;We do not have to make assumptions as to what results would be returned by each collaborator in each invocation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;In both cases:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;We are incorporating in our tests a collaborator which has already been tested and can be reasonably assumed to be free of defects. Thus, in the event of a test failure we can be fairly confident that the defect lies in the component-under-test, (or in the test itself,) but not in one of the collaborators, so we achieve defect localization, which is the aim of Unit Testing.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;creating-fakes-of-our-own-components&#34;&gt;Creating fakes of our own components
&lt;/h3&gt;&lt;p&gt;In some cases we may want to create a fake ourselves, as a substitute of one of our own components. Not only will this allow other components to start their testing as early as possible without the need for mocks, but also, a non-negligible part of the effort invested in the creation of the fake will be reusable in the creation of the real thing, while the process of creating the fake is likely to yield valuable lessons which can guide the creation of the real thing. Thus, any effort that goes into creating a fake of a certain component represents a much better investment than the effort of creating a multitude of throw-away mocks for various isolated operations on that component.&lt;/p&gt;
&lt;p&gt;One might argue that keeping a fake side-by-side with the real thing may represent a considerable additional maintenance overhead, but in my experience the overhead of doing so is nowhere near the overhead of maintaining a proliferation of mocks for the real thing.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Each time the implementation of the real thing changes without any change to its specification, (such as, for example, when applying some refactoring, or a bug fix,) some mocks must be modified, some must even be rewritten, while the fake usually does not have to be touched at all.&lt;/li&gt;
&lt;li&gt;When the specification of the real thing changes, the mocks have to be rewritten, and the fake has to be modified, but the beauty of the fake is that it is a self-contained module which implements a known abstraction, so it is easy to maintain, whereas every single snippet of mocking code is nothing but incidental complexity, and thus hard to maintain.&lt;/li&gt;
&lt;li&gt;In either case, a single change in the real thing will generally require a single corresponding change in the fake, whereas if we are using mocks we invariably have to go changing an arbitrary number of mocking snippets scattered throughout the tests.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Furthermore, the use of fakes instead of mocks promotes the creation of black-box tests instead of white-box tests. Once we get into the habit of writing all of our tests as black-box tests, new possibilities open up which greatly ease the development of fakes: we can now write a test for a certain module, and then reuse that test in order to test its fake. The test can be reused because it is a black-box test, so it does not care how the module works internally, therefore it can test the real thing just as well as the fake of the real thing. Once we run the test on the real thing, we run the same test on the fake, and if both pass, then from that moment on we can continue using the fake in place of the real thing in all other tests.&lt;/p&gt;
&lt;p&gt;The tests that exercise the real thing will be slow, but the real thing does not change very often, (if ever,) so here is where a testing tool like Testana shines: by using Testana we ensure that the tests exercising the real thing will only run in the rare event that the real thing actually changes. For more information about Testana, see &lt;a 
   href=&#34;//localhost:1313/post/2024-10-testana/&#34;
   &gt;Testana: A better way of running tests&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;creating-fakes-of-external-components&#34;&gt;Creating fakes of external components
&lt;/h3&gt;&lt;p&gt;If we are using an external component for which no fake is available, we may wish to create a fake for it ourselves. First, we write a test suite which exercises the external component, not really looking for defects in it, but instead using its behavior as reference for writing the tests. Once we have built our test suite to specifically pass the behavior of the external component, we can reuse it against the fake, and if it also passes, then we have sufficient reasons to believe that the behavior of the fake matches the behavior of the external component. A similar technique is described by Martin Fowler in his &lt;a class=&#34;external&#34; 
   href=&#34;https://martinfowler.com/bliki/ContractTest.html&#34; target=&#34;_blank&#34;
   &gt;Contract Test&lt;/a&gt; post.&lt;/p&gt;
&lt;p&gt;In an ideal world where everyone would be practicing Black-Box testing, we should even be able to obtain from the creators of the external component the test suite that they have already built for testing their creation, and use it to test our fake.&lt;/p&gt;
&lt;p&gt;In an even more ideal world, anyone who develops a component for others to use would be shipping it together with its fake, so that nobody needs to get dirty with its test suite.&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;Despite widespread practices in the industry, fakes are the preferred alternative to mocks. Even though they might at first seem laborious, they are actually very convenient to use, and on the long run far less expensive than mocks.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: fake moustache by michael.gr based on &lt;a class=&#34;external&#34; 
   href=&#34;https://thenounproject.com/icon/fake-mustache-31744/&#34; target=&#34;_blank&#34;
   &gt;art by Claire Jones from the Noun Project&lt;/a&gt;.&lt;/p&gt;</description>
        </item>
        <item>
        <title>On messages and message-passing</title>
        <link>//localhost:1313/post/2022-12-messages-and-message-passing/</link>
        <pubDate>Sun, 18 Dec 2022 08:59:25 +0000</pubDate>
        
        <guid>//localhost:1313/post/2022-12-messages-and-message-passing/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2022-12-messages-and-message-passing/media/message-passing.png&#34;
	width=&#34;2673&#34;
	height=&#34;1494&#34;
	srcset=&#34;//localhost:1313/post/2022-12-messages-and-message-passing/media/message-passing_hu_cac0be91696add81.png 480w, //localhost:1313/post/2022-12-messages-and-message-passing/media/message-passing_hu_4c50d0e4091ea6ab.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;178&#34;
		data-flex-basis=&#34;429px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;Over the decades, numerous software system architectures have emerged which require invocations across subsystems to be done via message-passing instead of programmatic interface method calls. Such architectures are so common that many programmers have come to regard message-passing as an end in and of itself, oblivious of the fact that it is nothing but a (poor) technical mechanism for accomplishing a certain architectural goal.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;The architectural goal is to be able to perform general-purpose operations on invocations, for example routing the invocations according to configuration, or queuing the invocations for delivery on a different thread. In order to be able to do things like that, the invocations must first be expressed in a general-purpose form.&lt;/p&gt;
&lt;p&gt;Message-passing is simply the only general-purpose form that could be imagined by the pioneers who built the first asynchronous event-driven systems, or perhaps the only form that could readily be implemented using the programming languages available back then. However, in succeeding decades our thinking and our tools have advanced considerably, to the point where we now have much better ways of achieving things technically, so it might be worth taking a moment to re-examine the concept of message-passing.&lt;/p&gt;
&lt;p&gt;Here is a list of problems with message passing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Custom message classes have to be written and maintained, usually in large numbers, constituting nothing but incidental complexity which steers focus away from the class hierarchy of the problem domain, and towards the class hierarchy of the overelaborate inter-module communication apparatus.&lt;/li&gt;
&lt;li&gt;For each invocation, a message class needs to be instantiated, filled, and submitted, requiring several lines of custom-written code. This is also nothing but incidental complexity, diverting the attention of programmers from solving the problem at hand to negotiating the trifling technicalities of placing invocations.&lt;/li&gt;
&lt;li&gt;On the receiving end, each message must be examined in order to determine what kind of message it is, usually by means of an unwieldy switch statement, and its contents have to be extracted before any useful work can be done. Again, this is all incidental complexity, contributing nothing towards the end-goal of the software system; its sole purpose is to serve the message-passing bureaucracy.&lt;/li&gt;
&lt;li&gt;In order to reduce the total number of different message classes that need to be defined, programmers often reuse message classes for different purposes, filling different parts according to each purpose. This habit further increases the total amount of incidental complexity both at the sending and at the receiving end, and very often leads to bugs due to wrongly packed or wrongly unpacked messages.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, message-passing exists for the sole purpose of expressing invocations in a general-purpose form, but as it turns out, its use is laborious, and it tends to flood systems with debilitating amounts of incidental complexity.&lt;/p&gt;
&lt;p&gt;The most natural, simple, convenient, straightforward, robust, maintainable, and self-documenting paradigm for making and receiving invocations, which facilitates problem-solving instead of hindering it, is programmatic interface method calls. Unfortunately, interfaces are not general-purpose in and of themselves, because each interface constitutes a unique type, requiring custom-written code to place calls to it and custom-written code to receive calls for it, thus preventing us from applying general-purpose operations on it.  So, we have two separate and seemingly conflicting concerns:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How to express invocations in the most convenient way&lt;/li&gt;
&lt;li&gt;How to perform general-purpose operations on the invocations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ideally, separate concerns should not be mixed; the need to somehow apply general-purpose operations on invocations should not be dictating how we write code, and it should certainly not be making our job harder. Therein lies perhaps the biggest objection to message-passing: they are an onerous contrivance that programmers by themselves would never opt to use out of their own free will, but usually gets imposed on them by software architects who do not actually have to write code using this contrivance.&lt;/p&gt;
&lt;p&gt;Message-passing has enjoyed widespread use mainly due to the historical inability of application programmers to think in terms of abstractions: it is always possible, even in systems that require message-passing, to write all application code so that it never deals with any messages at all, and uses nothing but application-specific programmatic interfaces instead; the trick is to create packaging and unpackaging adaptors, where on the sending side we are simply invoking a programmatic interface which is implemented by a packaging adaptor that creates messages, packs them, and sends them off to be enqueued, while on the receiving side a corresponding unpackaging adaptor is fed with messages from the queue, unpacks them, and calls the corresponding implementation of the interface. Alas, this arrangement requires a modicum of abstract thinking, and application programmers are generally not into that sort of thing.&lt;/p&gt;
&lt;p&gt;Furthermore, if we bother creating such packaging and unpackaging adaptors, the realization quickly starts to sink-in that all the message classes are irrelevant; there is no need to define a special message class containing a separate field for each parameter of each method, because the only code that would ever deal with such a class would be the corresponding pair of packaging and unpackaging adaptors; so, the adaptors might as well use a single universal message class which simply stores all parameters in an array of object, and voila, the entire menagerie of message classes becomes entirely unnecessary.&lt;/p&gt;
&lt;p&gt;Thus, it becomes evident that what we are really after is not message-passing per se; it is some general-purpose form of expressing invocations, so that general-purpose operations can be performed on them, and some mechanism for converting back and forth between this general-purpose form and the natural form, which is programmatic interface method calls, so that we can write code naturally. Ideally, the conversion mechanism would be automatic and transparent, so that we do not even have to write those adaptors. Messages have only existed due to the historical absence of such an automatic and transparent mechanism.&lt;/p&gt;
&lt;p&gt;Fortunately, with modern reflecting, intermediate-code-based, just-in-time compiled programming languages, today we have at our disposal all that is necessary  to build such mechanisms. For more information see &lt;a 
   href=&#34;//localhost:1313/post/2022-12-intertwine/&#34;
   &gt;Intertwine&lt;/a&gt;.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;img src=&#34;//localhost:1313/post/2022-12-messages-and-message-passing/media/grumpy-cat-message-passing.jpg&#34;
	width=&#34;493&#34;
	height=&#34;555&#34;
	srcset=&#34;//localhost:1313/post/2022-12-messages-and-message-passing/media/grumpy-cat-message-passing_hu_292667b1799fe58a.jpg 480w, //localhost:1313/post/2022-12-messages-and-message-passing/media/grumpy-cat-message-passing_hu_6ad615b796b41427.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;88&#34;
		data-flex-basis=&#34;213px&#34;
	
&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;Mandatory grumpy cat meme: &amp;ldquo;Message-Passing: it&amp;rsquo;s awful&amp;rdquo; by michael.gr&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: Conceptual illustration of message-passing, by michael.gr, based on original art by Youmena and Made from the Noun Project.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Intertwine</title>
        <link>//localhost:1313/post/2022-12-intertwine/</link>
        <pubDate>Sun, 11 Dec 2022 16:18:00 +0000</pubDate>
        
        <guid>//localhost:1313/post/2022-12-intertwine/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2022-12-intertwine/media/intertwine-logo.svg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;
&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract
&lt;/h3&gt;&lt;p&gt;A mechanism is described for automatically converting method invocations of any programmatic interface into a single-method &lt;em&gt;&lt;strong&gt;normal form&lt;/strong&gt;&lt;/em&gt; and converting back to invocations of the original interface, so that general-purpose operations can be performed on the normal form without explicit knowledge of the interface being invoked. Implementations are provided for C# and for Java.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id=&#34;the-problem&#34;&gt;The Problem
&lt;/h3&gt;&lt;p&gt;When creating software systems of nontrivial complexity we often need to be able to apply certain operations on the invocations that are being made between certain components. Examples of such operations are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Logging:&lt;/strong&gt; Recording information about each invocation being made.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multicasting:&lt;/strong&gt; Delivering a single invocation to multiple recipients.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Remoting:&lt;/strong&gt; Placing invocations across machine boundaries.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Desynchronization:&lt;/strong&gt; Queuing invocations for later execution, possibly on a different thread.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Synchronization:&lt;/strong&gt; Obtaining and holding a lock for the duration of the invocation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transformation:&lt;/strong&gt; Converting between invocation formats, e.g. method calls to REST and back.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ordinarily, the components doing the invocations are application-specific, and the interfaces between them are also application-specific, but the operators that we want to interject between them are general-purpose, so they need to remain agnostic of the application-specific details of the invocations, in a way analogous to how a general-purpose sorting algorithm is agnostic of the application-specific format of the data it sorts.&lt;/p&gt;
&lt;p&gt;Therefore, we need some way of expressing application-specific invocations in a general-purpose form.&lt;/p&gt;
&lt;h3 id=&#34;prior-art&#34;&gt;Prior Art
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Messages and message-passing:&lt;/strong&gt; The mechanism historically used for expressing invocations in a general-purpose form is message-passing. Unfortunately, its use is laborious, and it floods systems with debilitating amounts of incidental complexity. For details, see &lt;a 
   href=&#34;//localhost:1313/post/2022-12-messages-and-message-passing/&#34;
   &gt;On messages and message-passing&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Parameterless lambdas:&lt;/strong&gt; Application-specific method calls can be wrapped inside parameterless lambdas, and since all parameterless lambdas look the same, they can be handled by general-purpose code which may for example add them to a queue, and later dequeue and invoke them.
Unfortunately:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The wrapping of each application-specific method call inside a parameterless lambda must happen at each call site, which is cumbersome and reveals details about the underlying invocation delivery mechanism.&lt;/li&gt;
&lt;li&gt;The evaluation of the parameters that are passed to the application-specific method happens at the moment that the lambda makes the call, not at the moment that the lambda is constructed, which can lead to insidious bugs even if the evaluations have no side-effects. (And &lt;em&gt;woe to you on earth and sea&lt;/em&gt; if they do have side-effects.)&lt;/li&gt;
&lt;li&gt;The parameterless lambda completely hides the values of the parameters that are being passed to the application-specific method, as well as the identity of the method being invoked. Thus, parameterless lambdas cannot be used in scenarios that require information about each call being made.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Dynamic Proxies:&lt;/strong&gt; Both in Java and in C# there exist mechanisms that can be used to convert application-specific invocations to a general-purpose form, but not the other way around. These are &lt;code&gt;java.lang.reflect.Proxy&lt;/code&gt; for Java, and various libraries like Castle&amp;rsquo;s and LinFu for C#. The reverse operation can be achieved using reflection, but this involves a round-trip to native-land, which incurs a heavy performance penalty. Furthermore, these mechanisms suffer from additional issues, such as messing with exceptions, doing more work than necessary, etc.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-solution&#34;&gt;The Solution
&lt;/h3&gt;&lt;p&gt;In order to be able to perform general-purpose operations on application-specific invocations we need a mechanism for converting application-specific invocations into a general-purpose form and back, so that the operators can act upon the general-purpose form. What follows is a description of such a mechanism, which I call &lt;em&gt;&lt;strong&gt;Intertwine&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Intertwine introduces a general-purpose form for expressing invocations, which is called &lt;em&gt;&lt;strong&gt;the normal form of invocations&lt;/strong&gt;&lt;/em&gt;, and is represented by a single method of the following signature:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-CSharp&#34; data-lang=&#34;CSharp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;Object&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AnyCall&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MethodKey&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Object&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;arguments&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;In C#, &lt;code&gt;AnyCall&lt;/code&gt; would be a &lt;em&gt;delegate.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;In Java, &lt;code&gt;AnyCall&lt;/code&gt; would be a &lt;em&gt;single-method interface&lt;/em&gt;, otherwise known as a &lt;em&gt;functional interface&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This method signature represents the fact that every conceivable interface method call can be fully described in terms of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A return value, of the common denominator type &lt;code&gt;Object&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;A unique key which identifies which method of the interface is being invoked.&lt;/li&gt;
&lt;li&gt;An array containing arguments, of the common denominator type &lt;code&gt;Object&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please note that the method identifier is &lt;code&gt;MethodKey&lt;/code&gt; in the Java implementation, but &lt;code&gt;int selector&lt;/code&gt; in the C# implementation. This is because the Java implementation was made a considerable time after the C# implementation, and is therefore a bit more advanced.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;MethodKey&lt;/code&gt; used in the Java implementation allows the caller and the callee to unambiguously identify methods even in situations where binary compatibility between the caller and the callee is not guaranteed, and therefore an integer method index does not necessarily refer to the same method on both the caller and the callee.&lt;/p&gt;
&lt;p&gt;The Java implementation of intertwine provides efficient means of converting back and forth between a &lt;code&gt;MethodKey&lt;/code&gt; and any of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The reflection &amp;ldquo;Method&amp;rdquo; object of the method. (This is &lt;code&gt;java.lang.reflect.Method&lt;/code&gt; in Java, or &lt;code&gt;System.Reflection.MethodInfo&lt;/code&gt; in C#.)&lt;/li&gt;
&lt;li&gt;The string representation of the prototype of the method.&lt;/li&gt;
&lt;li&gt;The zero-based method index of the method.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The sample code that follows was written for C#, so it uses an &lt;code&gt;int selector&lt;/code&gt;  instead of &lt;code&gt;MethodKey key&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For methods of &lt;code&gt;void&lt;/code&gt; return type the value returned by AnyCall is unspecified. (It will in all likelihood be &lt;code&gt;null&lt;/code&gt;, but nobody should rely on this.)&lt;/li&gt;
&lt;li&gt;Value types (primitives) are boxed and unboxed as necessary.&lt;/li&gt;
&lt;li&gt;Certain features such as the &lt;code&gt;ref&lt;/code&gt; and &lt;code&gt;out&lt;/code&gt; parameters in C#, receive special handling.&lt;/li&gt;
&lt;li&gt;Other features such as properties, indexers, virtual events, etc. are nothing but syntactic sugar which is implemented using regular method calls under the hood, so they require no special handling.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, the problem can now be restated as follows:&lt;/p&gt;
&lt;p&gt;How to convert any interface method invocation to an invocation of an AnyCall method, and how to convert back from an invocation of an AnyCall method to an invocation of the original interface method.&lt;/p&gt;
&lt;p&gt;For this, Intertwine introduces two new concepts: &lt;em&gt;&lt;strong&gt;Entwiners&lt;/strong&gt;&lt;/em&gt; and &lt;em&gt;&lt;strong&gt;Untwiners&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An Entwiner of interface &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt; is a class which exposes (implements) interface &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt; and delegates to an instance of &lt;em&gt;AnyCall&lt;/em&gt;. It can also be thought of as a &lt;em&gt;normalizer&lt;/em&gt; or &lt;em&gt;generalizer&lt;/em&gt; or &lt;em&gt;multiplexer.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;An Untwiner of interface &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt; is a class which exposes an &lt;em&gt;AnyCall&lt;/em&gt; method and delegates to an instance of &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt;. It can also be thought of as a &lt;em&gt;denormalizer&lt;/em&gt; or &lt;em&gt;specializer&lt;/em&gt; or &lt;em&gt;demultiplexer.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More specifically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The entwiner of &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt; does the following:
&lt;ul&gt;
&lt;li&gt;Accepts an instance of &lt;code&gt;Anycall&lt;/code&gt; as a constructor parameter and stores it in a &lt;code&gt;final&lt;/code&gt;/&lt;code&gt;readonly&lt;/code&gt; field.&lt;/li&gt;
&lt;li&gt;Implements each method of &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt; as follows:
&lt;ul&gt;
&lt;li&gt;Packs the parameters that were passed to the method into an array of &lt;code&gt;Object&lt;/code&gt;, performing any boxing necessary.&lt;/li&gt;
&lt;li&gt;Invokes anyCall passing it a key that uniquely identifies the method, and the array of parameters.&lt;/li&gt;
&lt;li&gt;Returns, possibly after unboxing, whatever was returned by the invocation of anyCall.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The untwiner of &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt; performs the opposite and complementary operation of the entwiner, namely:
&lt;ul&gt;
&lt;li&gt;Accepts an instance of &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt; as a constructor parameter and stores it in a &lt;code&gt;final&lt;/code&gt;/&lt;code&gt;readonly&lt;/code&gt; field.&lt;/li&gt;
&lt;li&gt;Implements the &lt;code&gt;anycall&lt;/code&gt; method of the &lt;code&gt;Anycall&lt;/code&gt; interface as follows:&lt;/li&gt;
&lt;li&gt;It uses the supplied &lt;code&gt;MethodKey&lt;/code&gt; to determine which method of  &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt; is being invoked, and for each method it does the
following:
&lt;ul&gt;
&lt;li&gt;Unpacks the parameters from the array of &lt;code&gt;Object&lt;/code&gt;, performing any unboxing necessary.&lt;/li&gt;
&lt;li&gt;Invokes the method of &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt;, passing it the unpacked parameters.&lt;/li&gt;
&lt;li&gt;Returns, possibly after boxing, whatever was returned by the method, or &lt;code&gt;null&lt;/code&gt; if the method was of &lt;code&gt;void&lt;/code&gt; return type.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;a-hand-crafted-implementation&#34;&gt;A hand-crafted implementation
&lt;/h3&gt;&lt;p&gt;Before we look at the automatic creation of entwiners and untwiners, let us take a look at an example of how we would implement an entwiner and untwiner for a certain interface if we were to do it by hand.&lt;/p&gt;
&lt;p&gt;Let us consider the following interface:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-CSharp&#34; data-lang=&#34;CSharp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;interface&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;IFooable&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Moo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Boo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;bool&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;And let us consider the following class implementing that interface:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-CSharp&#34; data-lang=&#34;CSharp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;FooImplementation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IFooable&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IFooable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Moo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Console&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;WriteLine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;i: &amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IFooable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Boo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;bool&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Console&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;WriteLine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;s: &amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;, b: &amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;And then let us consider the following method which invokes the interface:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-CSharp&#34; data-lang=&#34;CSharp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;InvokeFoo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IFooable&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fooable&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;fooable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Moo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;42&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;fooable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Boo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;fubar!&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;The InvokeFoo method can be directly hooked up to an instance of the implementing class in a completely conventional way as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-CSharp&#34; data-lang=&#34;CSharp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Run1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;IFooable&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fooable&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;FooImplementation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;InvokeFoo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fooable&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Now, an entwiner for our IFooable interface could be hand-crafted as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-CSharp&#34; data-lang=&#34;CSharp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;EntwinerForFooable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IFooable&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kd&#34;&gt;private&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;readonly&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AnyCall&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AnyCall&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;Constructor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AnyCall&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;anycall&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AnyCall&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;anycall&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IFooable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Moo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AnyCall&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;object&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]{&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IFooable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Boo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;bool&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AnyCall&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;object&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]{&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Whereas an untwiner for IFooable could be hand-crafted as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-CSharp&#34; data-lang=&#34;CSharp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;UntwinerForFooable&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;readonly&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IFooable&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Constructor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IFooable&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Target&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;object&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AnyCall&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;object&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;args&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;switch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;selector&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Moo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;break&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Boo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;bool&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;break&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;throw&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;InvalidOperationException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;null&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;With the above classes, we can now write the following piece of awesomeness:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-CSharp&#34; data-lang=&#34;CSharp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Run2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;IFooable&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fooable&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;FooImplementation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;untwiner&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;UntwinerForFooable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fooable&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;entwiner&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;EntwinerForFooable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;untwiner&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AnyCall&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;InvokeFoo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;entwiner&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Note that &lt;code&gt;Run2()&lt;/code&gt; has exactly the same end-result as &lt;code&gt;Run1()&lt;/code&gt;, but there is a big difference in what goes on under the hood: all outbound interface method calls from the &lt;code&gt;InvokeFoo&lt;/code&gt; function are now arriving at the entwiner, which converts them to &lt;code&gt;AnyCall&lt;/code&gt; invocations, which are then forwarded to the untwiner, which converts them back to &lt;code&gt;IFooable&lt;/code&gt; calls, which are then forwarded to our &lt;code&gt;FooImplementation&lt;/code&gt; object. This means that if we wanted to, we could interject a chain of objects between the entwiner and the untwiner, each one of these objects implementing an &lt;code&gt;AnyCall&lt;/code&gt; delegate and invoking another &lt;code&gt;AnyCall&lt;/code&gt; delegate, thus enabling us to perform any conceivable operation upon those invocations without having any built-in knowledge of the &lt;code&gt;IFooable&lt;/code&gt; interface.&lt;/p&gt;
&lt;p&gt;As the complexity of the interface increases, and as additional subtleties come into the picture, such as parameters passed with ref or out, coding entwiners and untwiners by hand can become very tedious and error-prone, so, obviously, we would like to have it automated.&lt;/p&gt;
&lt;h3 id=&#34;automating-it-with-reflection&#34;&gt;Automating it with reflection
&lt;/h3&gt;&lt;p&gt;It is possible to write a general-purpose untwiner that does its job using reflection, but reflection is slow, so the result is going to suffer performance-wise. For the sake of completeness, here is a possible implementation for a general-purpose reflecting untwiner using reflection:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-CSharp&#34; data-lang=&#34;CSharp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;ReflectingUntwiner&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;//WARNING: SLOW AS MOLASSES&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kd&#34;&gt;private&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;readonly&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;object&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kd&#34;&gt;private&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;readonly&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Reflection&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MethodInfo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Methodinfos&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Constructor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Type&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;twinee&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;object&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;Target&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;Methodinfos&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;twinee&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GetMethods&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;BindingFlags&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Public&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;n&#34;&gt;BindingFlags&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;NonPublic&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;BindingFlags&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Instance&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;object&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AnyCall&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;object&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;arguments&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Methodinfos&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;].&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Invoke&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;arguments&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Note that untwiner creation could be optimized by caching the MethodInfos of frequently used types, but that&amp;rsquo;s not the problem; the real bottleneck is the &lt;code&gt;MethodInfo.Invoke()&lt;/code&gt; call. If you put a breakpoint on the target and examine the stack, you will see that between the &lt;code&gt;AnyCall&lt;/code&gt; frame and the target frame there will be a managed-to-native transition and a native-to-managed transition, which is something to be avoided at all costs.&lt;/p&gt;
&lt;p&gt;Also note: it is impossible to write a reflecting entwiner.&lt;/p&gt;
&lt;h3 id=&#34;automating-it-with-intertwine&#34;&gt;Automating it with Intertwine
&lt;/h3&gt;&lt;p&gt;The Intertwine library will automatically generate for us a pair of optimally-performing entwiner and untwiner classes for any interface. These classes are generated at runtime, so no extra build step is needed. To accomplish this, the C# implementation of Intertwine generates MSIL and creates assemblies from it; the Java Implementation generates bytecode and creates classes from it.&lt;/p&gt;
&lt;p&gt;The following method of the &lt;code&gt;Intertwine.Factory&lt;/code&gt; class creates an entwiner:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-CSharp&#34; data-lang=&#34;CSharp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;static&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;T&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;NewEntwiner&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AnyCall&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;anycall&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;For &lt;code&gt;T&lt;/code&gt; we give the type of our interface, and for &lt;code&gt;anycall&lt;/code&gt; we give a delegate of ours that will be receiving calls. This method returns a reference to an implementation of our interface, provided by an Entwiner-derived class that has been dynamically generated specifically for our interface, and instantiated to work with the given &lt;code&gt;AnyCall&lt;/code&gt; instance. For every call received through a method of our interface, this special entwiner will be marshalling the arguments and forwarding the call to our &lt;code&gt;AnyCall&lt;/code&gt; delegate.&lt;/p&gt;
&lt;p&gt;The following method of the &lt;code&gt;Intertwine.Factory&lt;/code&gt; class creates an untwiner:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-CSharp&#34; data-lang=&#34;CSharp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;static&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AnyCall&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;NewUntwiner&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;T&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;For target we give an implementation of our interface, and what we get is a reference to an &lt;code&gt;AnyCall&lt;/code&gt; delegate implemented by an Untwiner-derived class that was dynamically generated specifically for our interface, and instantiated to work with the given target instance. For every call received through the &lt;code&gt;AnyCall&lt;/code&gt; delegate, this special untwiner will be unmarshalling the arguments and forwarding the call to the appropriate method of our target interface.&lt;/p&gt;
&lt;p&gt;So, with the dynamically generated entwiners and untwiners we can now do the following epicness:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-CSharp&#34; data-lang=&#34;CSharp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Run3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;IFooable&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fooable&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;FooImplementation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;AnyCall&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;untwiner&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Intertwine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Factory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;NewUntwiner&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;IFooable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fooable&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;IFooable&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;entwiner&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Intertwine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Factory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;NewEntwiner&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;IFooable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;untwiner&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;InvokeFoo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;entwiner&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;The actual implementation of &lt;code&gt;Intertwine.Factory&lt;/code&gt; is pretty straightforward, so there is not much to talk about. As one might expect, the generated types are cached. A static factory method is generated with each generated type, for instantiating the type, so as to avoid having to call &lt;code&gt;Activator.CreateInstance()&lt;/code&gt;, because that method uses reflection. The static factory method is invoked using &lt;code&gt;Delegate.Invoke()&lt;/code&gt;, which does not use reflection. You will find the code-generating code choke-full of comments, explaining exactly what each emitted opcode does.&lt;/p&gt;
&lt;p&gt;Intertwine for C#:
&lt;a class=&#34;external&#34; 
   href=&#34;https://github.com/mikenakis/IntertwineCSharp&#34; target=&#34;_blank&#34;
   &gt;https://github.com/mikenakis/IntertwineCSharp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Intertwine for Java:
&lt;a class=&#34;external&#34; 
   href=&#34;https://github.com/mikenakis/Public/tree/master/intertwine&#34; target=&#34;_blank&#34;
   &gt;https://github.com/mikenakis/Public/tree/master/intertwine&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;appendix-an-example-interface-multicasts-events-in-c&#34;&gt;Appendix: An example: Interface multicasts (events) in C#
&lt;/h3&gt;&lt;p&gt;If you are still with me you may be thinking that it is about time for a demonstration. What follows is not just an example, but actually a complete and useful application of intertwine which you may be able to start utilizing in your projects right away.&lt;/p&gt;
&lt;p&gt;The C# language has built-in support for multicasts (events) but only delegates can be used as event observers. There are many cases, however, where interfaces would be more suitable. Java does not even have built-in support for multicasts, so programmers generally have to write their own, using single-method (functional) interfaces. In either language, if you want to achieve multicasting on multi-method interfaces, you have to rewrite the multicasting code for every single method of every single interface.&lt;/p&gt;
&lt;p&gt;Consider the following interface:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-CSharp&#34; data-lang=&#34;CSharp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;interface&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;ITableNotification&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RowInserted&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Fields&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fields&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RowDeleted&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Key&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RowUpdated&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Key&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Fields&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fields&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;And consider the following hypothetical (not actually possible) way of using it:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-CSharp&#34; data-lang=&#34;CSharp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;event&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ITableNotification&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tableNotificationEvent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;tableNotificationEvent&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;my_observer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;tableNotificationEvent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RowUpdated&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fields&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;The above does not work because events in C# work only with delegates, not with interfaces. However, with Intertwine, the next best thing is actually possible:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-CSharp&#34; data-lang=&#34;CSharp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tableNotificationEventManager&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;InterfaceEventManager&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ITableNotifcation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;tableNotificationEventManager&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Source&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RegisterObserver&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;my_observer&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;tableNotificationEventManager&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Trigger&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RowUpdated&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fields&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;This approach is self-explanatory, and the amount of code you have to write in order to use it is optimal; you do not need to deal with anything more than what is necessary, and if you ever add a notification, it will be a new interface method, so all existing implementations of that interface will automatically be flagged by the compiler as incomplete. With the help of Intertwine, this event manager is implemented in just 150 lines of code, including extensive comments.&lt;/p&gt;
&lt;h3 id=&#34;end-notes&#34;&gt;End-notes
&lt;/h3&gt;&lt;p&gt;Back in 2011 I posted a question on stackoverflow.com, titled &lt;a class=&#34;external&#34; 
   href=&#34;https://stackoverflow.com/questions/6154205/multiplexing-interface-method-calls-into-a-single-delegate-and-demultiplexing&#34; target=&#34;_blank&#34;
   &gt;Multiplexing interface method calls into a single delegate and demultiplexing&lt;/a&gt; asking if anyone knows of anything like Intertwine, but nobody did, so I built it myself.&lt;/p&gt;
&lt;p&gt;This post supersedes the original post from 2011: &lt;a 
   href=&#34;//localhost:1313/post/2011-10-16-intertwine-normalizing-interface/&#34;
   &gt;Intertwine: Normalizing Interface Invocations&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: The Intertwine Logo, by michael.gr&lt;/p&gt;</description>
        </item>
        <item>
        <title>On Microsoft &#34;Visual&#34; products</title>
        <link>//localhost:1313/post/2022-08-on-microsoft-visual-products/</link>
        <pubDate>Tue, 16 Aug 2022 11:35:17 +0000</pubDate>
        
        <guid>//localhost:1313/post/2022-08-on-microsoft-visual-products/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2022-08-on-microsoft-visual-products/images/visio-logo.png&#34;
	width=&#34;512&#34;
	height=&#34;512&#34;
	srcset=&#34;//localhost:1313/post/2022-08-on-microsoft-visual-products/images/visio-logo_hu_1ee2c59c93abfae8.png 480w, //localhost:1313/post/2022-08-on-microsoft-visual-products/images/visio-logo_hu_8a189bfcc0cec774.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;240px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;This post is intended as support material for another post of mine; see &lt;a 
   href=&#34;//localhost:1313/post/2023-12-09-authoritative-technical-design/&#34;
   &gt;Towards Authoritative Software Design&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;One day back in the early nineties, when people were using &lt;strong&gt;Windows 3.0&lt;/strong&gt; and the &lt;strong&gt;Microsoft C/C++ Compiler&lt;/strong&gt;, a colleague showed me a software design that for the first time he had done not on whiteboard, nor on paper, but on a computer screen, using a new drawing tool called &lt;strong&gt;Visio&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading:  &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2022-08-on-microsoft-visual-products/images/visio-1.0-screenshot1.png&#34;
	width=&#34;640&#34;
	height=&#34;480&#34;
	srcset=&#34;//localhost:1313/post/2022-08-on-microsoft-visual-products/images/visio-1.0-screenshot1_hu_827134514accb683.png 480w, //localhost:1313/post/2022-08-on-microsoft-visual-products/images/visio-1.0-screenshot1_hu_6568a10c471fe3c3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2022-08-on-microsoft-visual-products/images/visio-1.0-screenshot2.png&#34;
	width=&#34;640&#34;
	height=&#34;480&#34;
	srcset=&#34;//localhost:1313/post/2022-08-on-microsoft-visual-products/images/visio-1.0-screenshot2_hu_4063c9b7f6c3f47c.png 480w, //localhost:1313/post/2022-08-on-microsoft-visual-products/images/visio-1.0-screenshot2_hu_a3f52817d811c4cc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;Screenshots of Visio 1.0 running under Windows 3.1.&lt;/p&gt;
&lt;p&gt;He showed me interconnected components laid out on a canvas, and as he moved one of the components, the drawing tool re-routed the lines to maintain the connections to other components. This meant that Visio was not just a pixel drawing utility like Microsoft Paint; it had some understanding of the structure of the information that was being displayed.&lt;/p&gt;
&lt;p&gt;We both knew that the next logical thing to ask from such a tool would be to automatically produce an actual running software system according to that design; alas, Visio could do no such thing. In our eyes, the product embodied a latent promise for such functionality, but no such functionality was there.&lt;/p&gt;
&lt;p&gt;Back then, Visio was not yet owned by Microsoft, but the two companies were obviously in talks, because the first pre-release version of Visio had been distributed by Microsoft in a floppy disc containing other Microsoft Software. (For more information about the early relationship between
Microsoft and Visio, read &lt;a class=&#34;external&#34; 
   href=&#34;https://www.visiocorp.info/early-days.aspx&#34; target=&#34;_blank&#34;
   &gt;The Early Days of Visio Corporation - Recollections by Ted Johnson, Visio Co-founder&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;Then, in 1993 Microsoft announced the successor to their &lt;strong&gt;Microsoft C/C++&lt;/strong&gt; compiler, and the name of the new product was going to be &lt;strong&gt;Microsoft Visual C++&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2022-08-on-microsoft-visual-products/images/microsoft-visual-cpp-touched.jpg&#34;
	width=&#34;1106&#34;
	height=&#34;1026&#34;
	srcset=&#34;//localhost:1313/post/2022-08-on-microsoft-visual-products/images/microsoft-visual-cpp-touched_hu_ae1eb30e1d2d7a23.jpg 480w, //localhost:1313/post/2022-08-on-microsoft-visual-products/images/microsoft-visual-cpp-touched_hu_3f9f702db12a2ad4.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;107&#34;
		data-flex-basis=&#34;258px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;Even before we could get our hands on the new compiler, we could not help but speculate what Microsoft might mean by &amp;ldquo;visual&amp;rdquo; in the product name, and our hopes were high that they would have made good on the promise of visual tools for software design.&lt;/p&gt;
&lt;p&gt;Alas, nothing of that sort happened; Microsoft Visual C++ was just another command-line toolset, and the term &amp;ldquo;visual&amp;rdquo; in the title was nothing but marketing deceit.&lt;/p&gt;
&lt;p&gt;Then a few more years passed, and in 1997 Microsoft announced their first true Integrated Development Environment (IDE), which was going to be called &lt;strong&gt;Microsoft Visual Studio&lt;/strong&gt; starting with version 5.0, a.k.a. &amp;lsquo;97.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2022-08-on-microsoft-visual-products/images/visual-studio-97.jpg&#34;
	width=&#34;570&#34;
	height=&#34;437&#34;
	srcset=&#34;//localhost:1313/post/2022-08-on-microsoft-visual-products/images/visual-studio-97_hu_1556da44acd52c59.jpg 480w, //localhost:1313/post/2022-08-on-microsoft-visual-products/images/visual-studio-97_hu_8f837d95c2f22452.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;130&#34;
		data-flex-basis=&#34;313px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;Again, we hoped that this time they would deliver visual software design tools, and again were disappointed: sure, Microsoft was finally providing programmers with an IDE, and an IDE is admittedly a visual sort of thing, but there was still no sign of any actual visual software design tools.&lt;/p&gt;
&lt;p&gt;A few more years passed, and in 2000 Visio was acquired by Microsoft and became &lt;em&gt;&lt;strong&gt;Microsoft Visio&lt;/strong&gt;&lt;/em&gt; (&lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Microsoft_Visio&#34; target=&#34;_blank&#34;
   &gt;see Wikipedia&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2022-08-on-microsoft-visual-products/images/microsoft-visio-2000.gif&#34;
	width=&#34;550&#34;
	height=&#34;344&#34;
	srcset=&#34;//localhost:1313/post/2022-08-on-microsoft-visual-products/images/microsoft-visio-2000_hu_cb57b82d78dfa1b3.gif 480w, //localhost:1313/post/2022-08-on-microsoft-visual-products/images/microsoft-visio-2000_hu_12b7f4612b1968ea.gif 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;159&#34;
		data-flex-basis=&#34;383px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;When we saw that acquisition happening, we thought that perhaps it was the one thing that was missing for that long unfulfilled promise to finally become a reality; surely, the next release of Visual Studio would have Visio built-in, allowing us to create our software designs and then launch them, right?&lt;/p&gt;
&lt;p&gt;So, a couple of years later, in 2002 another major release of Visual Studio was announced, which was  to be named &lt;strong&gt;Visual Studio Dot Net.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2022-08-on-microsoft-visual-products/images/microsoft-visual-studio-net-professional-logo.png&#34;
	width=&#34;672&#34;
	height=&#34;179&#34;
	srcset=&#34;//localhost:1313/post/2022-08-on-microsoft-visual-products/images/microsoft-visual-studio-net-professional-logo_hu_5f4aa20bd28191ac.png 480w, //localhost:1313/post/2022-08-on-microsoft-visual-products/images/microsoft-visual-studio-net-professional-logo_hu_bddccdbcfe032a46.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;375&#34;
		data-flex-basis=&#34;901px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;As it turned out, that new version was nothing but the exact same old version, with bundled support for the Dot Net platform, and a tacky product name slapped onto it. Visio was not in any way connected to Visual Studio, and instead it had become part of the offerings around Microsoft Office.&lt;/p&gt;
&lt;p&gt;So, by that time, we finally accepted the realization that Microsoft&amp;rsquo;s plan for world domination was not so much about actual software development breakthroughs but more about tacky product names.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: The logo from Visio version 1.0.&lt;/p&gt;</description>
        </item>
        <item>
        <title>On UML (oh, do not get me started)</title>
        <link>//localhost:1313/post/2022-08-uml/</link>
        <pubDate>Tue, 16 Aug 2022 09:20:46 +0000</pubDate>
        
        <guid>//localhost:1313/post/2022-08-uml/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2022-08-uml/media/uml-logo.png&#34;
	width=&#34;824&#34;
	height=&#34;548&#34;
	srcset=&#34;//localhost:1313/post/2022-08-uml/media/uml-logo_hu_de0c20afdc618ca9.png 480w, //localhost:1313/post/2022-08-uml/media/uml-logo_hu_f720d5921c77bad1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;360px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;This post is intended as support material for another post of mine; see &lt;a 
   href=&#34;//localhost:1313/post/2023-12-09-authoritative-technical-design/&#34;
   &gt;Towards Authoritative Software Design&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The Universal Modeling Language (UML) (&lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Unified_Modeling_Language&#34; target=&#34;_blank&#34;
   &gt;Wikipedia&lt;/a&gt;) was intended to be a standard notation for expressing software designs, and to replace the multitude of ad-hoc notations that software architects have been using on various mediums such as whiteboard, paper, and general-purpose box-and-arrow diagram-drawing software. The idea was that by following a standard notation which prescribes a specific way of expressing each concept, every diagram would be readily and unambiguously understood by everyone.&lt;/p&gt;
&lt;p&gt;It has miserably failed.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;UML is probably very close to the top of the list of things that everyone mentions, but nobody uses, and this is due to a number of good reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is incredibly comprehensive, to the point where its sheer size acts as a very strong deterrent to most people attempting to learn it. There are about 20 different types of diagrams for different purposes, each with its own complete set of meticulously detailed notation and rules. UML actually begins to make sense once you realize that it has mostly been an effort to catalogue every imaginable type of diagram used in software development, and standardize the notation used in it, while most of these diagram types are actually irrelevant, or very seldom relevant, to our daily job. However, even if you pick a single diagram type that you happen to have some use for, and decide to learn just that one, the notation is still so comprehensive that the task is daunting.&lt;/li&gt;
&lt;li&gt;Most of UML is so rarely useful that it is not worth the learning effort. In the extremely rare event that a software development team is to have a meeting in which they could benefit from having an &lt;em&gt;&lt;strong&gt;Interaction Overview Diagram&lt;/strong&gt;&lt;/em&gt; to point at, it will be a lot easier to use some ad-hoc but intuitive notation to get the point across, than to only schedule the meeting &lt;em&gt;&lt;strong&gt;after&lt;/strong&gt;&lt;/em&gt; every single one of the attendees has completed a UML course to refresh upon the intricacies of the &lt;em&gt;UML Interaction Overview Diagram&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;The type of UML diagram that has received most attention in the software engineering profession is the &lt;em&gt;&lt;strong&gt;UML Class Diagram&lt;/strong&gt;&lt;/em&gt; (&lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Class_diagram&#34; target=&#34;_blank&#34;
   &gt;see Wikipedia&lt;/a&gt;) which deals with representing a class, the structure of a class, and its relationships with other classes. Unfortunately:
&lt;ul&gt;
&lt;li&gt;The UML Class Diagram insists on prescribing a very specific type of notation for everything about a class, and this notation is not always intuitive, thus posing the same obstacles to understanding as posed by program code written in apocryphal syntax and convoluted structure: in both cases, it is all jargon. This might not be an issue for those who have already gone through the trouble of learning the jargon, but the uninitiated are bound to question the usefulness of the entire exercise.&lt;/li&gt;
&lt;li&gt;The UML Class Diagram prescribes its notation in excruciatingly meticulous detail, so there is no information hiding, and no abstraction: the amount of information contained in a UML Class Diagram is roughly the same as the amount of information contained in a C or C++ header file, or in a Java Interface, so there is virtually nothing to be gained by looking at one vs. looking at the other, which in turn seriously begs the question of why should we be doing double book-keeping.&lt;/li&gt;
&lt;li&gt;The UML Class Diagram is much too low-level and too finely detailed to be pertinent to software systems design, where the unit of interest is the system component, corresponding to an entire module, rather than to individual classes within a module. It is also becoming even less pertinent as classes are becoming less important in programming due to the modern shift towards functional rather than object-oriented programming.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;UML is mostly used as documentation, meaning that its role tends to be indicative or suggestive, and usually non-enforceable and non-materializable. This means that mistakes made in the use of the meticulously detailed notation generally go undetected, or might be detected by colleagues, but not by automated validation tools, because for most types of UML diagrams, there exist no such tools.&lt;/li&gt;
&lt;li&gt;UML is trying to solve problems which do not exist: When a human needs to communicate something to a machine, this has to be done in a perfectly inambiguous fashion, which makes special notation necessary, i.e. jargon. However, when there is no machine involved, and a human simply needs to communicate something to other humans, what matters most is to get the point across, so jargon is actually undesirable, despite the unambiguousness that it would bring. That is okay, because humans thrive in ambiguity. In other words, UML is an attempt to apply a rigid engineering discipline to a form of communication which is fine as it is: free and fluid. (One of the &amp;ldquo;Three Amigos&amp;rdquo; that created UML had a military background; coincidence? maybe.)&lt;/li&gt;
&lt;li&gt;In an attempt to make UML more pertinent to the software development process, some UML tools offer some automatic code generation features. Unfortunately, automatic code generation is almost always a bad idea, because each time the design changes, code generation must be re-applied, but this invariably results in the following bad things happening to code that has already been hand-written by programmers:
&lt;ul&gt;
&lt;li&gt;Hand-written code is overwritten with auto-generated code and thus forever lost, or&lt;/li&gt;
&lt;li&gt;Hand-written code does not compile anymore due to dependencies on automatically generated definitions which have now changed, or, more often,&lt;/li&gt;
&lt;li&gt;Both of the above.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The idea that you can apply automatic code generation once and never repeat it stems from the &amp;ldquo;all design up-front&amp;rdquo; doctrine, which may have been strong back in the 1990s when the foundations of UML were laid down, but the doctrine died soon thereafter, and it has been dead for decades now.&lt;/li&gt;
&lt;li&gt;From the plethora of diagram types offered by UML, the only one that could perhaps be useful in our daily jobs is the &lt;em&gt;&lt;strong&gt;UML Component Diagram&lt;/strong&gt;&lt;/em&gt; (&lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Component_diagram&#34; target=&#34;_blank&#34;
   &gt;see Wikipedia&lt;/a&gt;) but there exist no tools that I am aware of that are capable of either guiding the composition of such a diagram from existing software components, or materializing such a diagram into a running system. Furthermore, if any such tools were to be introduced, they are unlikely to be well-received, because by now people have developed a distaste towards UML and anything associated with it.&lt;/li&gt;
&lt;li&gt;UML literature follows a lofty &lt;em&gt;&lt;strong&gt;standardspeak&lt;/strong&gt;&lt;/em&gt; writing style which is incomprehensible. I tried looking up the term &amp;ldquo;collaboration&amp;rdquo; and here is what I found &lt;a class=&#34;external&#34; 
   href=&#34;https://www.ibm.com/docs/en/idsa?topic=diagrams-collaborations&#34; target=&#34;_blank&#34;
   &gt;in IBM literature&lt;/a&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;In UML diagrams, a collaboration is a type of structured classifier in which roles and attributes co-operate to define the internal structure of  a classifier.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;There are two problems with this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The definition depends on other definitions. This happens everywhere in UML. So, in order to understand a certain term you first have to understand other terms, and quite often the definitions make circles, so in order to understand anything you have to have superpowers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This kind of looks like a recursive definition. They may be implying that there is something hierarchical in the nature of the concept, but they are not saying it. Definitions are written with the goal of being correct, not with the goal of being understood.  (And since we do not understand them, we cannot tell whether they are correct.)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Okay, let&amp;rsquo;s look at the next sentence:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You use a collaboration when you want to define only the roles and connections that are required to accomplish a specific goal of the collaboration.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Surprise! Recursion again. Sorry, but now it makes absolutely no sense. And that&amp;rsquo;s how it goes with UML.&lt;/p&gt;
&lt;p&gt;To summarize:&lt;/p&gt;
&lt;p&gt;UML is &lt;em&gt;&lt;strong&gt;insufferably baroque&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;It should have never been, and it should cease to be.&lt;/p&gt;
&lt;p&gt;It should be let go into the good night.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2022-08-uml/media/grumpy-cat-uml.jpg&#34;
	width=&#34;1715&#34;
	height=&#34;1553&#34;
	srcset=&#34;//localhost:1313/post/2022-08-uml/media/grumpy-cat-uml_hu_bef019e84b4ea75.jpg 480w, //localhost:1313/post/2022-08-uml/media/grumpy-cat-uml_hu_1719cd72479ad91e.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;110&#34;
		data-flex-basis=&#34;265px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;Mandatory Grumpy Cat Meme. &amp;ldquo;UML: I hate it.&amp;rdquo;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: The UML logo, by Object Management Group, Inc. from &lt;a class=&#34;external&#34; 
   href=&#34;https://www.uml.org/&#34; target=&#34;_blank&#34;
   &gt;uml.org&lt;/a&gt;; Public Domain.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Incremental Integration Testing</title>
        <link>//localhost:1313/post/2022-10-incremental-integration-testing/</link>
        <pubDate>Tue, 14 Dec 2021 09:07:09 +0000</pubDate>
        
        <guid>//localhost:1313/post/2022-10-incremental-integration-testing/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2022-10-incremental-integration-testing/media/incremental_integration_testing.svg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;
&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract
&lt;/h3&gt;&lt;p&gt;A new method for &lt;em&gt;&lt;strong&gt;Automated Software Testing&lt;/strong&gt;&lt;/em&gt; is presented as an alternative to &lt;em&gt;&lt;strong&gt;Unit Testing&lt;/strong&gt;&lt;/em&gt;. The new method retains the benefit of Unit Testing, which is &lt;em&gt;&lt;strong&gt;Defect Localization&lt;/strong&gt;&lt;/em&gt;, but eliminates white-box testing and mocking, thus greatly lessening the effort of writing and maintaining tests.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary
&lt;/h3&gt;&lt;p&gt;Unit Testing aims to achieve Defect Localization by replacing the collaborators of the Component Under Test with Mocks. As we will show, the use of Mocks is laborious, complicated, over-specified, presumptuous, and constitutes testing against the implementation, not against the interface, thus leading to brittle tests that hinder refactoring rather than facilitating it.&lt;/p&gt;
&lt;p&gt;To avoid these problems, &lt;em&gt;&lt;strong&gt;Incremental Integration Testing&lt;/strong&gt;&lt;/em&gt; allows each component to be tested in integration with its collaborators, (or with Fakes thereof,) thus completely abolishing Mocks. Defect Localization is achieved by arranging the order in which tests are executed so that the collaborators of a component get tested before the component gets tested, and stopping as soon as a defect is encountered.&lt;/p&gt;
&lt;p&gt;Thus, when a test discovers a defect, we can be sufficiently confident that the defect lies in the component being tested, and not in any of its collaborators, because by that time, the collaborators have passed their tests.&lt;/p&gt;
&lt;h3 id=&#34;the-problem&#34;&gt;The problem
&lt;/h3&gt;&lt;p&gt;The goal of automated software testing in general, regardless of what kind of testing it is, is to exercise a software system under various usage scenarios to ensure that it meets its requirements and that it is free from defects. The most simple and straightforward way to achieve this is to set up some input, invoke the system to perform a certain job, and then examine the output to ensure that it is what it is expected to be.&lt;/p&gt;
&lt;p&gt;Unfortunately, this approach only really works in the &amp;ldquo;sunny day&amp;rdquo; scenario: if no defects are discovered by the tests, then everything is fine; however, if defects are discovered, we are faced with a problem: the system consists of a large network of collaborating software components, and the test is telling us that there is a defect somewhere, but it is unclear in which component the problem lies. Even if we divide the system into subsystems and try to test each subsystem separately, each subsystem may still consist of many components, so the problem remains.&lt;/p&gt;
&lt;p&gt;What it ultimately boils down to is that each time we test a component, and a defect is discovered, it is unclear whether the defect lies in the component being tested, or in one or more of its collaborators.&lt;/p&gt;
&lt;p&gt;Ideally, we would like each test to be conducted in such a way as to detect defects specifically in the component that is being tested, instead of extraneous defects in its collaborators; in other words, we would like to achieve &lt;em&gt;Defect Localization&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id=&#34;the-existing-solution-unit-testing&#34;&gt;The existing solution: Unit Testing
&lt;/h3&gt;&lt;p&gt;&lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Unit_testing&#34; target=&#34;_blank&#34;
   &gt;Unit Testing&lt;/a&gt; was invented specifically in order to achieve defect localization. It takes an extremely drastic approach: if the use of collaborators introduces uncertainties, one way to eliminate those uncertainties is to eliminate the collaborators. Thus, Unit Testing aims to test each component in strict isolation. Hence, its name.&lt;/p&gt;
&lt;p&gt;To achieve this remarkably ambitious goal, Unit Testing refrains from supplying the component under test with the actual collaborators that it would normally receive in a production environment; instead, it supplies the component under test with specially crafted &lt;em&gt;&lt;strong&gt;substitutes&lt;/strong&gt;&lt;/em&gt; of its collaborators, otherwise known as &lt;em&gt;&lt;strong&gt;test doubles&lt;/strong&gt;&lt;/em&gt;. There exist a few different kinds of substitutes, but by far the most widely used kind is &lt;em&gt;&lt;strong&gt;Mocks.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Each Mock must be hand-written for every individual test that is performed; it exposes the same interface as the real collaborator that it substitutes, and it expects specific methods of that interface to be invoked by the component-under-test, with specific argument values, sometimes even in a specific order of invocation. If anything goes wrong, such as an unexpected method being invoked, an expected method &lt;em&gt;not&lt;/em&gt; being invoked, or a parameter having an unexpected value, the Mock fails the test. When the component-under-test invokes one of the methods that the Mock expects to be invoked, the Mock does nothing of the sort that the real collaborator would do; instead, the Mock is hard-coded to yield a fabricated response which is intended to exactly match the response that the real collaborator would have produced if it was being used, and if it was working exactly according to its specification.&lt;/p&gt;
&lt;p&gt;Or at least, that is the intention.&lt;/p&gt;
&lt;h3 id=&#34;drawbacks-of-unit-testing&#34;&gt;Drawbacks of Unit Testing
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Complex and laborious&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;In each test it is not enough to simply set up the input, invoke the component, and examine the output; we also have to anticipate every single call that the component will make to its collaborators, and for each call we have to set up a mock, expecting specific parameter values, and producing a specific response aiming to emulate the real collaborator under the same circumstances. Luckily, mocking frameworks lessen the amount of code necessary to accomplish this, but no matter how terse the mocking code is, the fact still remains that it implements a substantial amount of functionality which represents considerable complexity.&lt;/li&gt;
&lt;li&gt;One of the well-known caveats of software testing at large (regardless of what kind of testing it is) is that a test failure does not necessarily indicate a defect in the production code; it always indicates a defect either in the production code, or in the test itself. The only way to know is to troubleshoot. Thus, the more code we put in tests, and the more complex this code is, the more time we end up wasting in chasing and fixing bugs in the tests themselves rather than in the code that they are meant to test.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Over-specified&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Unit Testing is concerned not only with what a component accomplishes, but also with every little detail about how the component goes on about accomplishing it. This means that when we engage in Unit Testing we are essentially expressing all of our application logic twice: once with production code expressing the logic in imperative mode, and once more with testing code expressing the same logic in expectational mode. In both cases, we write copious amounts of code describing what should happen in excruciatingly meticulous detail.&lt;/li&gt;
&lt;li&gt;Note that with Unit Testing, over-specification might not even be goal in and of itself in some cases, but it is unavoidable in all cases. This is due to the elimination of the collaborators: the requests that the component under test sends to its collaborators could conceivably be routed into a black hole and ignored, but in order for the component under test to continue working so as to be tested, it still needs to receive a meaningful response to each request; thus, the test has to expect each request in order to produce each needed response, even if the intention of the test was not to know how, or even whether, the request is made.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Presumptuous&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Each Unit Test claims to have detailed knowledge of not only how the component-under-test invokes its collaborators, but also how each real collaborator would respond to each invocation in a production environment, which is a highly presumptuous thing to do.&lt;/li&gt;
&lt;li&gt;Such presumptuousness might be okay if we are building high-criticality software, where each collaborator is likely to have requirements and specification that are well-defined and unlikely to change; however, in all other software, which is regular, commercial, non-high-criticality software, things are a lot less strict: not only the requirements and specifications change all the time, but also quite often, the requirements, the specification, even the documentation, is the code itself, and the code changes every time a new commit is made to the source code repository. This might not be ideal, but it is pragmatic, and it is established practice. Thus, the only way to know exactly how a component behaves tends to be to actually invoke the latest version of that component and see how it responds, while the mechanism which ensures that these responses are what they are supposed to be is the tests of that component itself, which are unrelated to the tests of components that depend on it.&lt;/li&gt;
&lt;li&gt;As a result of this, Unit Testing often places us in the all too familiar situation where our Unit Tests all pass with flying colors, but our Integration Tests miserably fail because the behavior of the real collaborators turns out to be different from what the mocks assumed it would be.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fragile&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;During Unit Testing, if the interactions between the component under test and its collaborators deviate even slightly from our expectations, the test fails. However, these interactions may legitimately change as software evolves. This may happen due to the application of a bug-fix, due to refactoring, or due to the fact that whenever new code is added to implement new functionality, preexisting code must almost always be modified to accommodate the new code. With Unit Testing, every time we change the inner workings of production code, we have to go fixing all related tests to expect the new inner workings of that code.&lt;/li&gt;
&lt;li&gt;The original promise of Automated Software Testing was to enable us to continuously evolve software without fear of breaking it. The idea is that whenever you make a modification to the software, you can re-run the tests to ensure that everything still works as before. With Unit Testing this does not work, because every time you change the slightest thing in the production code you have to also change the tests, and you have to do this even for changes that are only internal. The understanding is growing within the software engineering community that Unit Testing with mocks actually hinders refactoring instead of facilitating it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Non-reusable&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Unit Testing exercises the implementation of a component rather than its interface. As such, the Unit Test of a certain component can only be used to test that component and nothing else. Thus, with Unit Testing the following things are impossible:
&lt;ul&gt;
&lt;li&gt;Completely rewrite a piece of production code and then reuse the old tests to make sure that the new implementation works exactly as the old one did.&lt;/li&gt;
&lt;li&gt;Reuse the same test to test multiple different components that implement the same interface.&lt;/li&gt;
&lt;li&gt;Use a single test to test multiple different implementations of a certain component, created by independently working development teams taking different approaches to solving the same problem.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The above disadvantages of Unit Testing are direct consequences of the fact that it is White-Box Testing by nature. What we need to be doing instead is Black-Box testing, which means that Unit Testing should be avoided, despite the entire Software Industry&amp;rsquo;s addiction to it.&lt;/p&gt;
&lt;p&gt;Note that I am not the only one to voice dissatisfaction with Unit Testing with Mocks. People have been noticing that although tests are intended to facilitate refactoring by ensuring that the code still works after refactoring, tests often end up hindering refactoring, because they are so tied to the implementation that you can&amp;rsquo;t refactor anything without breaking the tests. This problem has been identified by renowned personalities such as Martin Fowler and Ian Cooper, and even by Ken Beck, the inventor of Test-Driven Development (TDD).&lt;/p&gt;
&lt;p&gt;In the video &lt;em&gt;Thoughtworks - TW Hangouts: Is TDD dead?&lt;/em&gt; (&lt;a class=&#34;external&#34; 
   href=&#34;https://www.youtube.com/watch?v=z9quxZsLcfo&#34; target=&#34;_blank&#34;
   &gt;youtube&lt;/a&gt;) at 21&amp;rsquo;:10&amp;rsquo;&amp;rsquo; Kent Beck says &amp;ldquo;My personal practice is I mock almost nothing&amp;rdquo; and at 23&amp;rsquo;:56&amp;rsquo;&amp;rsquo; Martin Fowler says &amp;ldquo;I&amp;rsquo;m with Kent, I hardly ever use mocks&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;In the &lt;em&gt;Fragile Test&lt;/em&gt; section of his book &lt;em&gt;xUnit Test Patterns: Refactoring Test Code&lt;/em&gt; (&lt;a class=&#34;external&#34; 
   href=&#34;https://xunitpatterns.com/&#34; target=&#34;_blank&#34;
   &gt;xunitpatterns.com&lt;/a&gt;) author Gerard Meszaros states that extensive use of Mock Objects causes overcoupled tests.&lt;/p&gt;
&lt;p&gt;In his presentation &lt;em&gt;TDD, where did it all go wrong?&lt;/em&gt; (&lt;a class=&#34;external&#34; 
   href=&#34;https://www.infoq.com/presentations/tdd-original/&#34; target=&#34;_blank&#34;
   &gt;InfoQ&lt;/a&gt;, &lt;a class=&#34;external&#34; 
   href=&#34;https://www.youtube.com/watch?v=EZ05e7EMOLM&#34; target=&#34;_blank&#34;
   &gt;YouTube&lt;/a&gt;) at 49&amp;rsquo;:32&amp;rsquo;&amp;rsquo; Ian Cooper says &amp;ldquo;I argue quite heavily against mocks because they are overspecified.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Note that in an attempt to avoid sounding too blasphemous, none of these people calls for the complete abolition of mocks, they only warn against the excessive use of mocks. Furthermore, do not seem to be isolating the components under test, and yet they seem to have little, if anything, to say about any alternative means of achieving defect localization.&lt;/p&gt;
&lt;h3 id=&#34;a-new-solution-incremental-integration-testing&#34;&gt;A new solution: Incremental Integration Testing
&lt;/h3&gt;&lt;p&gt;If we were to abandon Unit Testing with mocks, then one might ask what should we be doing instead. Obviously, we must somehow continue testing our software, and it would be nice if we can continue to be enjoying the benefits of defect localization.&lt;/p&gt;
&lt;p&gt;As it turns out, eliminating the collaborators is just one way of achieving defect localization; another, more pragmatic approach is as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Allow each component to be tested in integration with its collaborators, but only after each of the collaborators has undergone its own testing, and has successfully passed it.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Thus, any observed malfunction can be attributed with a high level of confidence to the component being tested, and not to any of its collaborators, because the collaborators have already been tested.&lt;/p&gt;
&lt;p&gt;I call this &lt;em&gt;&lt;strong&gt;Incremental Integration Testing&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;An alternative way of arriving at the idea of Incremental Integration Testing begins with the philosophical observation that strictly speaking, there is no such thing as a Unit Test; there always exist collaborators which by established practice we never mock and invariably integrate in Unit Tests without blinking an eye; these are, for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Many of the external libraries that we use.&lt;/li&gt;
&lt;li&gt;Most of the functionality provided by the Runtime Environment in which our software runs.&lt;/li&gt;
&lt;li&gt;Virtually all of the functionality provided by the Runtime Library of the language we are using.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Nobody mocks standard collections such as array-lists, linked-lists, hash-sets, and hash-maps; very few people bother with mocking filesystems; nobody would mock a math library, a serialization library, and the like; even if one was so paranoid as to mock those, at the extreme end, nobody mocks the MUL and DIV instructions of the CPU; so clearly, there are always some things that we take for granted, and we allow ourselves the luxury of taking these things for granted because we believe that they have been sufficiently tested by their respective creators and can be reasonably assumed to be free of defects.&lt;/p&gt;
&lt;p&gt;So, why not also take our own creations for granted once we have tested them? Are we testing them sufficiently or not?&lt;/p&gt;
&lt;h3 id=&#34;prior-art&#34;&gt;Prior Art
&lt;/h3&gt;&lt;p&gt;An internet search for &amp;ldquo;Incremental Integration Testing&amp;rdquo; does yield some results. An examination of those results reveals that they refer to some strategy for integration testing which is meant to be performed manually by human testers, constitutes an alternative to big-bang integration testing, and requires full Unit Testing of the traditional kind to have already taken place. I am hereby appropriating this term, so from now on it shall mean what I intend it to mean. If a context ever arises where disambiguation is needed, the terms &amp;ldquo;automated&amp;rdquo; vs. &amp;ldquo;manual&amp;rdquo; can be used.&lt;/p&gt;
&lt;p&gt;The first hints to Incremental Integration Testing can actually be found in the classic 1979 book &lt;em&gt;The Art of Software Testing&lt;/em&gt; by Glenford Myers. In chapter 5 &amp;ldquo;Module (Unit) Testing&amp;rdquo; the author plants the seeds of what later became white-box testing with mocks by writing:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[] since module B calls module E, something must be present to receive control when B calls E. A stub module, a special module given the name &amp;ldquo;E&amp;rdquo; that must be coded to simulate the function of module E, accomplishes this.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;then, the author proceeds to write:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The alternative approach is incremental testing. Rather than testing each module in isolation, the next module to be tested is first combined with the set of modules &lt;em&gt;&lt;strong&gt;that have already been tested.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;(emphasis mine.)&lt;/p&gt;
&lt;p&gt;Back in 1979, Glen Myers envisioned these approaches to testing as being carried out by human testers, manually launching tests and receiving printouts of results to examine. He even envisioned employing multiple human testers to perform multiple tests in parallel. In the last several decades we have much better ways of doing all of that.&lt;/p&gt;
&lt;h3 id=&#34;implementing-the-solution-the-poor-mans-approach&#34;&gt;Implementing the solution: the poor man&amp;rsquo;s approach
&lt;/h3&gt;&lt;p&gt;As explained earlier, Incremental Integration Testing requires that when we test a component, all of its collaborators must have already been tested. Thus, Incremental Integration Testing necessitates exercising control over the order in which tests are executed.&lt;/p&gt;
&lt;p&gt;Most testing frameworks execute tests in alphanumeric order, so if we want to change the order of execution all we have to do is to appropriately name the tests, and the directories in which they reside.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;p&gt;Let us suppose that we have the following modules:&lt;/p&gt;
&lt;p&gt;com.acme.alpha_depends_on_bravo&lt;br&gt;
com.acme.bravo_depends_on_nothing&lt;br&gt;
com.acme.charlie_depends_on_alpha&lt;/p&gt;
&lt;p&gt;Note how the modules are listed alphanumerically, but they are not listed in order of dependency.&lt;/p&gt;
&lt;p&gt;Let us also suppose that we have one test suite for each module. By default, the names of the test suites follow the names of the modules that they test, so again, a listing of the test suites in alphanumeric order does not match the order of dependency of the modules that they test:&lt;/p&gt;
&lt;p&gt;com.acme.alpha_depends_on_bravo_&lt;strong&gt;tests&lt;/strong&gt;&lt;br&gt;
com.acme.bravo_depends_on_nothing_&lt;strong&gt;tests&lt;/strong&gt;&lt;br&gt;
com.acme.charlie_depends_on_alpha_&lt;strong&gt;tests&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To achieve Incremental Integration Testing, we add a suitably chosen prefix to the name of each test suite, as follows:&lt;/p&gt;
&lt;p&gt;com.acme.&lt;strong&gt;T02&lt;/strong&gt;_alpha_depends_on_bravo_tests&lt;br&gt;
com.acme.&lt;strong&gt;T01&lt;/strong&gt;_bravo_depends_on_nothing_tests&lt;br&gt;
com.acme.&lt;strong&gt;T03&lt;/strong&gt;_charlie_depends_on_alpha_tests&lt;/p&gt;
&lt;p&gt;Note how the prefixes have been chosen in such a way as to establish a new alphanumerical order for the tests. Thus, an alphanumeric listing of the test suites now lists them in order of dependency of the modules that they test:&lt;/p&gt;
&lt;p&gt;com.acme.T01_bravo_depends_on_nothing_tests&lt;br&gt;
com.acme.T02_alpha_depends_on_bravo_tests&lt;br&gt;
com.acme.T03_charlie_depends_on_alpha_tests&lt;/p&gt;
&lt;p&gt;At this point Java developers might object that this is impossible, because in Java, the tests always go in the same module as the production code, directory names must match package names, and test package names always match production package names. Well, I have news for you: they don&amp;rsquo;t have to. The practice of doing things this way is very widespread in the Java world, but there are no rules that require it: the tests do not in fact have to be in the same module, nor in the same package as the production code. The only inviolable rule is that directory names must match package names, but you can call your test packages whatever you like, and your test directories accordingly.&lt;/p&gt;
&lt;p&gt;Java developers tend to place tests in the same module as the production code simply because the tools (maven) have a built-in provision for this, without ever questioning whether there is any actual benefit in doing so. Spoiler: there isn&amp;rsquo;t. As a matter of fact, in the DotNet world there is no such provision, and nobody complains. Furthermore, Java developers tend to place tests in the same package as the production code for no purpose other than to make package-private entities of their production code accessible from their tests, but this is testing against the implementation, not against the interface, and therefore, as I have already explained, it is misguided.&lt;/p&gt;
&lt;p&gt;So, I know that this is a very hard thing to ask from most Java developers, but trust me, if you would only dare to take a tiny step off the beaten path, if you would for once do something in a certain way for reasons other than &amp;ldquo;everyone else does it this way&amp;rdquo;, you can very well do the renaming necessary to achieve Incremental Integration Testing.&lt;/p&gt;
&lt;p&gt;Now, admittedly, renaming tests in order to achieve a certain order of execution is not an ideal solution. It is awkward, it is thought-intensive since we have to figure out the right order of execution by ourselves, and it is error-prone because there is nothing to guarantee that we will get the order right. That&amp;rsquo;s why I call it &amp;ldquo;the poor man&amp;rsquo;s approach&amp;rdquo;. Let us now see how all of this could be automated.&lt;/p&gt;
&lt;h3 id=&#34;implementing-the-solution-the-automated-approach&#34;&gt;Implementing the solution: the automated approach
&lt;/h3&gt;&lt;p&gt;Here is an algorithm to automate Incremental Integration Testing:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Begin by building a model of the dependency graph of the entire software system.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;This requires system-wide static analysis to discover all components in our system, and all dependencies of each component. I did not say it was going to be easy.&lt;/li&gt;
&lt;li&gt;The graph should not include external dependencies, since they are presumed to have already been tested by their respective creators.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Test each leaf node in the model.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;A leaf node in the dependency graph is a node which has no dependencies; at this level, a Unit Test is indistinguishable from an Integration Test, because there are no dependencies to either integrate or mock.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;If any malfunction is discovered during step 2, then stop as soon as step 2 is complete.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;If a certain component fails to pass its test, it is counter-productive to proceed with the tests of components that depend on it. Unit Testing seems to be completely oblivious to this little fact; Incremental Integration Testing fixes this.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Remove the leaf nodes from the model of the dependency graph.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Thus removing the nodes that were previously tested in step 2, and obtaining a new, smaller graph, where a different set of nodes are now the leaf nodes.&lt;/li&gt;
&lt;li&gt;The dependencies of the new set of leaf nodes have already been successfully tested, so they are of no interest anymore: they are as good as external dependencies now.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Repeat starting from step 2, until there are no more nodes left in the model.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Allowing each component to be tested in integration with its collaborators, since they have already been tested.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;No testing framework that I know of (JUnit, MSTest, etc.) is capable of doing the above; for this reason, I have developed a utility which I call &lt;em&gt;&lt;strong&gt;Testana&lt;/strong&gt;&lt;/em&gt;, that does exactly that.&lt;/p&gt;
&lt;p&gt;Testana will analyze a system to discover its structure, will analyze modules to discover dependencies and tests, and will run the tests in the right order so as to achieve Incremental Integration Testing. It will also do a few other nice things, like keep track of last successful test runs, and examine timestamps, so as to refrain from running tests whose dependencies have not changed since the last successful test run. For more information, see &lt;a 
   href=&#34;//localhost:1313/post/2024-10-testana/&#34;
   &gt;Testana: A better way of running tests&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;what-if-my-dependencies-are-not-discoverable&#34;&gt;What if my dependencies are not discoverable?
&lt;/h3&gt;&lt;p&gt;Some very trendy practices of our modern day and age include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using scripting languages, where there is no notion of types, and therefore no way of discovering dependencies via static analysis.&lt;/li&gt;
&lt;li&gt;Breaking up systems into disparate source code repositories, so there is no single system on which to perform system-wide static analysis to discover dependencies.&lt;/li&gt;
&lt;li&gt;Incorporating multiple different programming languages in a single system, (following the polyglot craze,) thus hindering system-wide static analysis, since it now needs to be performed on multiple languages and across language barriers.&lt;/li&gt;
&lt;li&gt;Making modules interoperate not via normal programmatic interfaces, but instead via various byzantine mechanisms such as REST, whose modus operandi is binding by name, thus making dependencies undiscoverable.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you are following any of the above trendy practices, then you cannot programmatically discover dependencies, so you have no way of automating Incremental Integration Testing, so you will have to manually specify the order in which your tests will run, and you will have to keep maintaining this order manually.&lt;/p&gt;
&lt;p&gt;Sorry, but silly architectural choices do come with consequences.&lt;/p&gt;
&lt;h3 id=&#34;what-about-performance&#34;&gt;What about performance?
&lt;/h3&gt;&lt;p&gt;One might argue that Incremental Integration Testing does not address one very important issue which is nicely taken care of by Unit Testing with Mocks, and that issue is performance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When collaborators are replaced with Mocks, the tests tend to be fast.&lt;/li&gt;
&lt;li&gt;When actual collaborators are integrated, such as file systems, relational database management systems, messaging queues, and what not, the tests can become very slow.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To address the performance issue I recommend the use of &lt;em&gt;&lt;strong&gt;Fakes&lt;/strong&gt;&lt;/em&gt;, not Mocks. For an explanation of what Fakes are, and why they are incontestably preferable over Mocks, please read &lt;a 
   href=&#34;//localhost:1313/post/2022-10-testing-with-fakes/&#34;
   &gt;Testing with Fakes instead of Mocks&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;By supplying a component under test with a Fake instead of a Mock we benefit from great performance, while utilizing a collaborator which has already been tested by its creators and can be reasonably assumed to be free of defects. In doing so, we continue to avoid White-Box Testing and we keep defects localized.&lt;/p&gt;
&lt;p&gt;Furthermore, nothing prevents us from having our CI/CD server run the test of each component twice:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Once in integration with Fakes&lt;/li&gt;
&lt;li&gt;Once in integration with the actual collaborators&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This will be slow, but CI/CD servers generally do not mind. The benefit of doing this is that it gives further guarantees that everything works as intended.&lt;/p&gt;
&lt;h3 id=&#34;benefits-of-incremental-integration-testing&#34;&gt;Benefits of Incremental Integration Testing
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;It greatly reduces the effort of writing and maintaining tests, by eliminating the need for mocking code in each test.&lt;/li&gt;
&lt;li&gt;It allows our tests to engage in Black-Box Testing instead of White-Box Testing. For an in-depth discussion of what is wrong with White-Box Testing, see &lt;a 
   href=&#34;//localhost:1313/post/2021-12-white-box-vs-black-box-testing/&#34;
   &gt;White-Box vs. Black-Box Testing&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;It makes tests more effective and accurate, by eliminating assumptions about the behavior of the real collaborators.&lt;/li&gt;
&lt;li&gt;It simplifies our testing operations by eliminating the need for two separate testing phases, one for Unit Testing and one for Integration Testing.&lt;/li&gt;
&lt;li&gt;It is unobtrusive, since it does not dictate how to construct the tests, it only dictates the order in which the tests should be executed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;arguments-and-counter-arguments&#34;&gt;Arguments and counter-arguments
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Argument: Incremental Integration Testing assumes that a component which has been tested is free of defects.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A well-known caveat of software testing is that it cannot actually prove that software is free from defects, because it necessarily only checks for defects that we have anticipated and tested for. As Edsger W. Dijkstra famously put it, &amp;ldquo;program testing can be used to show the presence of bugs, but never to show their absence!&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Counter-arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I am not claiming that once a component has been tested, it has been proven to be free from defects; all I am saying is that it can reasonably be assumed to be free from defects. Incremental Integration Testing is not meant to be a perfect solution; it is meant to be a pragmatic solution.&lt;/li&gt;
&lt;li&gt;The fact that testing cannot prove the absence of bugs does not mean that everything is futile in this vain world, and that we should abandon all hope in despair: testing might be imperfect, but it is what we can do, and it is in fact what we do, and practical, real-world observations show that it is quite effective.&lt;/li&gt;
&lt;li&gt;Most importantly: Any defects in an insufficiently tested component will not magically disappear if we mock that component in the tests of its dependents.
&lt;ul&gt;
&lt;li&gt;In this sense, the practice of mocking collaborators can arguably be likened to &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Ostrich_policy&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;Ostrich policy&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;On the contrary, continuing to integrate that component in subsequent tests gives us incrementally more opportunities to discover defects in it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Argument: Incremental Integration Testing fails to achieve complete defect localization.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If a certain component has defects which were not detected when it was being tested, these defects may cause tests of collaborators of that component to fail, in which case it will be unclear where the defect lies.&lt;/p&gt;
&lt;p&gt;Counter-arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is true that Incremental Integration Testing may fall short of achieving defect localization when collaborators have defects despite having already been tested. It is also true that Unit Testing with Mocks does not suffer from that problem when collaborators have defects; but then again, neither does it detect those defects. For that, it is necessary to always follow a round of Unit Testing with a round of Integration Testing. However, when the malfunction is finally observed during Integration Testing, we are facing the exact same problem that we would have faced if we had done a single round of Incremental Integration Testing instead: a malfunction is being observed which is not due to a defect in the root component of the integration, but instead due to a defect in some unknown collaborator. The difference is that Incremental Integration Testing gets us there faster.&lt;/li&gt;
&lt;li&gt;Let us not forget that the primary goal of software testing is to guarantee that software works as intended, and that defect localization is an important but nonetheless secondary goal. Incremental Integration Testing goes a long way towards achieving defect localization, but it may not achieve it perfectly, in favor of other conveniences, such as making it far more easy to write and maintain tests. So, it all boils down to whether Unit Testing represents overall more or less convenience than Incremental Integration Testing. I assert that Incremental Integration Testing is unquestionably far more convenient than Unit Testing.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Argument: Incremental Integration Testing only tests behavior; it does not check what is going on under the hood.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;With Unit Testing, you can ensure that a certain module not only produces the right results, but also that it follows an expected sequence of steps to produce those results. With Incremental Integration Testing you cannot observe the steps, you can only check the results. Thus, the internal workings of a component might be slightly wrong, or less than ideal, and you would never know.&lt;/p&gt;
&lt;p&gt;Counter-arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This is true, and this is why Incremental Integration Testing might be unsuitable for high-criticality software, where White-Box Testing is the explicit intention, since it is necessary to ensure not only that the software produces correct results, but also that its internals are working exactly according to plan. However, Incremental Integration Testing is not being proposed as a perfect solution, it is being proposed as a pragmatic solution: the vast majority of software being developed in the world is regular, commercial-grade, non-high-criticality software, where Black-Box Testing is appropriate and sufficient, since all that matters is that the requirements be met. Essentially, Incremental Integration Testing represents the realization that in the general case, tests which worry not only about the behavior, but also about the inner workings of a component, constitute over-engineering. For a more in-depth discussion about this, please read &lt;a 
   href=&#34;//localhost:1313/post/2021-12-white-box-vs-black-box-testing/&#34;
   &gt;White-Box vs. Black-Box Testing&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;In order to make sure that everything is happening as expected under the hood, you do not have to stipulate in excruciating detail what should be happening, you do not have to fail the tests at the slightest sign of deviation from what was expected, and you do not have to go fixing tests each time the expectations change. Another way of ensuring the same thing is to simply:
&lt;ul&gt;
&lt;li&gt;Gain visibility into what is happening under the hood.&lt;/li&gt;
&lt;li&gt;Be notified when something different starts happening.&lt;/li&gt;
&lt;li&gt;Visually examine what is now different.&lt;/li&gt;
&lt;li&gt;Vouch for the differences being as expected.
For more details about this, see &lt;a 
   href=&#34;//localhost:1313/post/2023-01-06-collaboration-monitoring/&#34;
   &gt;Collaboration Monitoring&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Argument: Incremental Integration Testing prevents us from picking a single test and running it.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;With Unit Testing, we can pick any individual test and run it. With Incremental Integration Testing, running an individual test of a certain component is meaningless unless we first run the tests of the collaborators of that component.&lt;/p&gt;
&lt;p&gt;Counter-arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Picking an individual test and running it is meaningless under all scenarios. It is usually done in the interest of saving time, but it is based on the assumption that we know what tests have been affected by the changes we just made to the source code. This is never a safe assumption to make.&lt;/li&gt;
&lt;li&gt;Instead of picking an individual test and running it, we need a way to automatically run all tests that have been affected by the changes we just made, which requires knowledge of the dependency graph of the system.&lt;/li&gt;
&lt;li&gt;If you are unsure as to exactly what you just changed, and exactly what depends on it, then consider using a tool like Testana, which figures all this out for you. See &lt;a 
   href=&#34;//localhost:1313/post/2024-10-testana/&#34;
   &gt;Testana: A better way of running tests&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Argument: Incremental Integration Testing requires additional tools.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Incremental Integration Testing is not supported by any of the popular testing frameworks, which means that in order to start practicing it, new tools are necessary. Obtaining such tools might be very difficult, if not impossible, and creating such tools might be difficult, because they would have to do advanced stuff like system-wide static analysis to discover the dependency graph of a system.&lt;/p&gt;
&lt;p&gt;Counter-arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;My intention is to show the way; if people see the way, the tools will come.&lt;/li&gt;
&lt;li&gt;I have already built such a tool which is compatible with some combinations of programming languages, build systems, and testing frameworks; see &lt;a 
   href=&#34;//localhost:1313/post/2024-10-testana/&#34;
   &gt;Testana: A better way of running tests&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Even in lack of tools, it is possible to start experimenting with Incremental Integration Testing today by following the poor-man&amp;rsquo;s approach, which consists of simply naming the tests, and the directories in which they reside, in such a way that your existing testing framework will run them in the right order. This is described in the &amp;ldquo;poor man&amp;rsquo;s approach&amp;rdquo; section of this paper.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;Unit Testing was invented in order to achieve defect localization, but as we have shown, it constitutes White-Box Testing, so it is laborious, over-complicated, over-specified, and presumptuous. Furthermore, it is not even, strictly speaking, necessary. Incremental Integration Testing is a pragmatic approach which achieves almost the same degree of defect localization but without the use of mocks, and in so doing it greatly reduces the effort of developing and maintaining tests.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: &lt;em&gt;Incremental Integration Testing&lt;/em&gt; by michael.gr&lt;/p&gt;</description>
        </item>
        <item>
        <title>So, what is a Microservice, anyway?</title>
        <link>//localhost:1313/post/2021-10-so-what-is-microservice-anyway/</link>
        <pubDate>Thu, 14 Oct 2021 17:39:23 +0000</pubDate>
        
        <guid>//localhost:1313/post/2021-10-so-what-is-microservice-anyway/</guid>
        <description>&lt;p&gt;This article attempts to shed some light on what a microservice really is; it
is meant as support material for other posts of mine that discuss
microservices, mainly
&lt;a 
   href=&#34;//localhost:1313/post/2021-10-14-the-stateful-microservice/&#34;
   &gt;The Stateful Microservice&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2021-10-so-what-is-microservice-anyway/media/microservices.svg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;
&lt;/p&gt;
&lt;h3 id=&#34;what-is-a-microservice&#34;&gt;What is a microservice?
&lt;/h3&gt;&lt;p&gt;If you go looking for information on what a microservice is, you will find
many different descriptions, exhibiting considerable difference of opinion.
Most claims about microservices are non-technical rather than technical, for
example the allegedly &amp;ldquo;independent&amp;rdquo; software development style around
microservices, or some alleged organization of microservices &amp;ldquo;around business
capabilities&amp;rdquo;. Even when the claims do stick within the technical realm, they
are often unwarranted; for example, I have seen statements to the effect that
a microservice is supposed to live in its very own source code repository,
that microservices must communicate with each other via nothing but REST, etc.
My favorite one is that they must necessarily be stateless. This paper is a
first step in dispelling the statelessness myth.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;To clear up the confusion a little bit, I would like to propose a purely
technical definition of a microservice which is brief and to the point:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;From a purely technical standpoint, a microservice is a scalable module.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;So, what I am proposing here is that the only fundamental technical
requirement for a microservice is scalability, and that all other purported
characteristics mentioned in the literature are either non-technical, or they
are byproducts of this fundamental technical requirement.&lt;/p&gt;
&lt;p&gt;You see, there was a time back in the late 1990s to early 2000s when users
were joining websites at exponential rates, and servers running monolithic web
apps were reaching capacity and could not deliver service anymore; the
business people were asking the technologists to fix this, because they were
losing money, and the technologists were saying that they could not do
anything, because they already had the biggest, most expensive server that
money could buy. The business people would na?vely say &amp;ldquo;well, add more
servers!&amp;rdquo; to which the technologists would (equally na?vely) reply &amp;ldquo;you don&amp;rsquo;t
understand, that&amp;rsquo;s impossible!&amp;rdquo; Later on the technologists started realizing
that it is in fact possible, it just requires a radical change in their way of
thinking, and a radical redesign of all their systems. When the sums of money
at stake were high enough to justify redoing everything from scratch, scalable
systems started appearing, and are commonplace today.&lt;/p&gt;
&lt;p&gt;The new software development paradigm that was allowing web sites to achieve
scalability received a name quite some time after it first started being put
to use; the naming happened some time in the mid 2000s, and it was
&lt;em&gt;microservices&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Then of course came the evangelists. Unfortunately, when people become
salespersons of a cause, for some reason they never seem to be satisfied with
simply mentioning the one real, game-changing advantage that their product has
over the alternatives; instead, they feel compelled to throw as much as
possible at the customer, inventing advantages if possible. That&amp;rsquo;s how all the
fictitious characteristics of microservices came to be. However, the truth
remains that there was one and only one thing that business needed which could
not be achieved otherwise, and therefore business was willing to pay for it
limitlessly, and that one thing was scalability, nothing else. (1)&lt;/p&gt;
&lt;p&gt;Business could not care less whether the software gets deployed in pieces or
in a big bang; business could not care less whether development is done by
autonomous teams or by all the programmers shouting at each other in one big
room; business could not care less whether the software communicates via REST
or via pheromone secretion. Things were getting done before, and things would
continue getting done, regardless of those alleged &amp;ldquo;advantages&amp;rdquo; of
microservices. Scalability was the only thing that was impossible before
microservices and was made possible by microservices.&lt;/p&gt;
&lt;p&gt;Of course, you might not agree with this definition; if not, then please take
it as nothing but a working definition, and only for the purpose of these
papers about statelessness.&lt;/p&gt;
&lt;p&gt;There is one more characteristic of microservices which is not really fundamental, because it is a direct
consequence of the first, but it is so
important that it deserves mentioning as a requirement, and this is resilience.&lt;/p&gt;
&lt;p&gt;You see, scalable architectures are not magically capable of performing better
than monolithic ones; in fact, quite the opposite is true: in terms of raw
throughput per unit of hardware, scalable architectures perform much worse
than monolithic ones. In order to accommodate the same workload that you used
to have with a single server running a monolithic application, you might need several
servers running microservices. The benefit of the scalable architecture is
that you can in fact now throw more hardware at the problem, instead of being
stuck with a single piece of hardware. So, given enough money to buy enough
hardware you can end up with a higher sum of throughput despite the worse
throughput per unit of hardware. Thus, when we are talking about scalability, we
are usually talking about a lot of hardware. And by this I mean &lt;em&gt;an awful lot&lt;/em&gt; of hardware.&lt;/p&gt;
&lt;p&gt;Now, it just so happens that hardware, being necessarily bound to the
constraints of the &lt;em&gt;physical world?&lt;/em&gt;, has this inconvenient
characteristic called &amp;ldquo;Mean Time Before Failure&amp;rdquo; (MTBF) which is of a somewhat
statistical nature: the more pieces of hardware you have, the higher the
chances are that any one of them will fail at any given moment. Furthermore,
as these pieces age, their individual chances of failure at any given moment
increase. The result of all this is that hardware failure in server farms
becomes not just something that there is a high risk of; not even just
something that is inevitable; it actually becomes a regularly occurring
phenomenon. As such, hardware failure cannot be addressed on an as-needed
basis via crisis management responses; it must be addressed systematically, as
a normal part of the operation of the system. This means that the software
that runs on that hardware must be capable of continuing to function as if
nothing happened despite pieces of the hardware randomly failing and being
replaced all the time.&lt;/p&gt;
&lt;p&gt;A software system that manages to continue functioning despite parts of it
ceasing to work is called a resilient software system. If we want to add the
resilience concern into our definition, then this is what we are left with:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;From a purely technical standpoint, a microservice is a scalable and resilient
module.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Further reading: &lt;a 
   href=&#34;//localhost:1313/post/2021-10-on-stateless-microservices/&#34;
   &gt;On Stateless Microservices&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;(1) According to Neal Ford, this started with Pets.com; see &lt;a class=&#34;external&#34; 
   href=&#34;https://youtu.be/fYWvTYFmVYs?t=2156&#34; target=&#34;_blank&#34;
   &gt;Neal Ford: &amp;ldquo;Stories Every Developer Should Know&amp;rdquo; at YOW! 2018, starting at 35:56&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>The Stateful Microservice</title>
        <link>//localhost:1313/post/2021-10-14-the-stateful-microservice/</link>
        <pubDate>Thu, 14 Oct 2021 16:58:10 +0000</pubDate>
        
        <guid>//localhost:1313/post/2021-10-14-the-stateful-microservice/</guid>
        <description>&lt;p&gt;I did a quick search for the term and did not find anything concrete, so I
thought I might as well publicly document my thoughts.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2021-10-14-the-stateful-microservice/media/elephants.jpg&#34;
	width=&#34;2048&#34;
	height=&#34;1365&#34;
	srcset=&#34;//localhost:1313/post/2021-10-14-the-stateful-microservice/media/elephants_hu_cfac862bf8819bb5.jpg 480w, //localhost:1313/post/2021-10-14-the-stateful-microservice/media/elephants_hu_6c0c09c376128914.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;360px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;(Useful pre-reading:
&lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Almost everyone doing microservices today will tell you that microservices
need to be stateless. In another post of mine I explain that statelessness is
not an end in and of itself; instead, it is just a means to an end. The
desired technical ends are scalability and resilience, and statelessness is just one way of achieving them. Furthermore, I explain that statelessness
in particular is a very cowardly solution from an engineering standpoint, and
it performs very badly. For details, please see
&lt;a 
   href=&#34;//localhost:1313/post/2021-10-on-stateless-microservices/&#34;
   &gt;On Stateless Microservices&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What remains to be shown is whether there exists an alternative.&lt;/p&gt;
&lt;p&gt;Obviously, an alternative to the stateless microservice would be the stateful
microservice, so what we are about to examine here is what a stateful
microservice could possibly be, and how it would compare to a stateless
microservice.&lt;/p&gt;
&lt;h4 id=&#34;what-is-a-stateful-microservice&#34;&gt;What is a stateful microservice
&lt;/h4&gt;&lt;p&gt;A stateful microservice maintains state for the purpose of expediting the
processing of incoming requests, reducing overall server load, (trading memory
for processing power and data storage traffic,) and achieving certain things
that are difficult to achieve otherwise, such as server-initiated client
updates.&lt;/p&gt;
&lt;p&gt;The state kept by a stateful microservice can include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;State that has been obtained from the main data store and has possibly
undergone expensive transformations. The benefit of maintaining such
transient state within the microservice is that the data store does not
need to be re-queried, and the possibly expensive transformations do not
need to be repeated, with each incoming request; the loading and
processing of the data only needs to happen once when the microservice
starts, and to be repeated only in response to a notification from the
system&amp;rsquo;s messaging backbone that the original data in the main data store
has changed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;State that does not exist in the main data store, and does not need to,
because it is of a transient nature, for example information that is only
needed during user&amp;rsquo;s visit to a web site and can be dismissed afterwards.
This can include information necessary for maintaining a session, such as
the session token, and view-related information, such as which page (or
pages) of the web site the user is currently viewing. View-related
information may be useful for the server to have for various reasons, for
example for the purpose of sending server-initiated client updates that
are specific to the web page(s) that are being viewed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;State that may eventually be entered into the main data store but has not
yet been entered due to various workflow demands or optimization concerns.
For example, the user may be sequentially visiting each page of a wizard
workflow, and entering information on each page, but this information
should not be merged into the main data store unless the user first
reaches the last page of the wizard workflow and confirms their actions.&lt;/p&gt;
&lt;p&gt;From the above it should be obvious that a stateful microservice is
necessarily session-oriented, meaning that it requires a specific client to
talk to. Session-agnostic stateful microservices already exist, and we do not
think of them as anything special; they are microservices that implement
caches, containing information that is pertinent to not just one client, but
to all clients. These microservices are already scalable and resilient because
a cache can be trivially duplicated to an arbitrary degree and it can also be
destroyed and trivially re-created from scratch.&lt;/p&gt;
&lt;p&gt;We now need to show how a stateful microservice can still be called a
microservice.&lt;/p&gt;
&lt;p&gt;In a previous post of mine I examined what a microservice really is, and I
came to the conclusion that from a purely technical standpoint, it is simply a scalable and resilient module. (See
&lt;a 
   href=&#34;//localhost:1313/post/2021-10-so-what-is-microservice-anyway/&#34;
   &gt;So, what is a Microservice, anyway?&lt;/a&gt;) Even if you disagree with this definition, and you regard microservices as
necessarily more than that, I hope you will at least agree that the purpose of
statelessness in microservices is precisely to achieve scalability and
resilience, so the definition of a microservice as a scalable and resilient
module can serve as a working definition for the purposes of this discussion.&lt;/p&gt;
&lt;p&gt;So, we need to show how stateful microservices can be scalable and resilient,
just as their stateless counterparts are.&lt;/p&gt;
&lt;p&gt;Scalability in stateful microservices can be achieved by means of a
header-inspecting, session-aware, load balancing gateway which routes new
session requests to the least busy server, and from that moment on keeps
routing requests of that same session to the same server. Under such a
scenario, rebalancing of the server farm can be achieved simply by killing
microservices on overloaded servers and letting the resilience mechanism
described next make things right.&lt;/p&gt;
&lt;p&gt;Resilience can be achieved by having each instance of a stateful microservice
continuously persisting its transient state in an efficient manner into a
high-performance backup store which is accessible by all servers in the farm.
Thus, if a microservice unexpectedly ceases to exist, it can be reconstructed
from that backup on any other server. The trick, as we shall see, is that the
backup is taken very efficiently, and in the event that the microservice needs
to be reconstructed, the restoration from the backup is also done very
efficiently.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In more detail, it works as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When a client initially connects to the server farm, no session has been
established yet, so the first request that it sends is sessionless.&lt;/li&gt;
&lt;li&gt;The sessionless request arrives at the load-balancing gateway, which routes
it to the least busy server in the farm. This mostly takes care of
scalability, since we can always add more servers, which will initially be
idle, but as requests for new sessions keep arriving, they are routed to the
idle servers instead of the busy ones, so over time, the load distribution
evens out.&lt;/li&gt;
&lt;li&gt;The server that receives the sessionless request creates a new instance of a
stateful microservice to handle that request, and the session is established
between that microservice and the client.&lt;/li&gt;
&lt;li&gt;From that moment on, any further incoming requests for that same session are
routed by the gateway to the same server, and the server delegates them to
the same instance of the stateful microservice. (Alternatively, the
microservice and the client may negotiate a direct persistent connection
between the two, thus bypassing any middlemen from that moment on.)&lt;/li&gt;
&lt;li&gt;The newly spawned stateful microservice registers with the messaging
backbone of the system to receive notifications about system-wide events, so
as to be able to keep its state always up to date.&lt;/li&gt;
&lt;li&gt;The newly spawned stateful microservice loads whatever state it is going to
need, and keeps that state in memory.&lt;/li&gt;
&lt;li&gt;The microservice processes the request and sends back a response.
&lt;ul&gt;
&lt;li&gt;Possibly also changing its own transient state.&lt;/li&gt;
&lt;li&gt;Possibly also updating the main data store with information that must
always be globally available and up to date, and issuing system-wide
notifications about these changes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The microservice takes a backup of itself.
&lt;ul&gt;
&lt;li&gt;The microservice serializes the entirety of its state into a binary blob&lt;/li&gt;
&lt;li&gt;The blob is written into a persistent key-value store, using the session
id as the key.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt;This persistent key-value store is used as a backup, meaning that it is
written often, but it is never read unless something bad happens.
&lt;/code&gt;&lt;/pre&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Continuous persistence of stateful microservices is not expected to pose a
performance problem, because:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Serialization to and from a binary format performs much better than
general-purpose serialization into a textual markup like JSON or XML.&lt;/li&gt;
&lt;li&gt;The size of the blob is expected to be relatively small. (Of the order of
kilobytes.)&lt;/li&gt;
&lt;li&gt;Key-value stores tend to have very high performance characteristics.&lt;/li&gt;
&lt;li&gt;The backup store can be physically separate from the main data store,
(even on a different network,) thus avoiding contention.&lt;/li&gt;
&lt;li&gt;The act of serializing an in-memory data structure into a single in-memory
blob and then sending that blob as one piece into persistent storage is
bound to perform far better than a series of operations to update a
structured data store. (For one thing, there are no index updates.)&lt;/li&gt;
&lt;li&gt;Persisting the blob can be done asynchronously and in parallel to the
sending of the response to the client, so it does not contribute to
user-perceived latency.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For as long as the session does not expire, the stateful microservice can
remain alive, continuing to serve requests efficiently, taking advantage of
the transient state that it contains and keeps up-to-date. Contrast this
with the stateless microservice approach, which requires that any request
can be handled by any server, therefore each microservice must contain no
state at all:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The processing of each request begins with zero knowledge of the state of
the system, so persistent storage must always be queried to obtain state.&lt;/li&gt;
&lt;li&gt;These queries represent overhead, and this overhead must be suffered in
full before the request can be serviced, thus manifesting as latency to
the user.&lt;/li&gt;
&lt;li&gt;The results of these queries may not be cached, because they may at any
moment be rendered out-of-date by any other microservice in the system.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;An instance of a stateful microservice may prematurely cease to exist due to
a number of reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The microservice may be terminated on demand in order to rebalance the
server farm.&lt;/li&gt;
&lt;li&gt;The server hosting the microservice may become unavailable due to hardware
failure.&lt;/li&gt;
&lt;li&gt;The microservice may fall victim to the whim of the chaos monkey.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If for whatever reason a microservice ceases to exist, the gateway discovers
this either on its own, or when the next request arrives from the client.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The gateway routes the request to the least busy server in the farm.&lt;/li&gt;
&lt;li&gt;The server that receives the request sees that there is no microservice to
handle requests for that session, so it creates a new one.&lt;/li&gt;
&lt;li&gt;The newly instantiated microservice checks, whether the key-value store
contains a backup for the current session, and discovers that it does.&lt;/li&gt;
&lt;li&gt;The microservice restores its state from the backup.&lt;/li&gt;
&lt;li&gt;Operation continues from that moment on as if nothing happened.&lt;/li&gt;
&lt;li&gt;Between the moment in time that a certain microservice instance
prematurely ceases to exist, and the moment in time that a new incarnation
of that microservice is ready for showtime on a freshly assigned server,
some events from the messaging backbone may be lost. To avoid
inconsistencies in the state of the microservice, we must utilize a
messaging backbone which is capable of replaying events. For example, if
we use Kafka, then the stateful microservice can make sure to include
among its persistent state what is known in Kafka terminology as the
&amp;ldquo;consumer offset&amp;rdquo;. Thus, when the microservice gets reconstructed, it asks
Kafka for events starting at that offset, so Kafka replays any missed
events before it starts sending new ones. Thus, we ensure that the state
of the microservice is always up to date, even in the case of termination
and reconstruction.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thus, stateful microservices can achieve not only scalability but also
resilience.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: Photo of two elephants friendly interacting with each other, from
&lt;a class=&#34;external&#34; 
   href=&#34;https://www.scientificamerican.com/article/elephants-never-forget/&#34; target=&#34;_blank&#34;
   &gt;The Scientific American: &lt;em&gt;Fact or Fiction?: Elephants Never Forget&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>On Stateless Microservices</title>
        <link>//localhost:1313/post/2021-10-on-stateless-microservices/</link>
        <pubDate>Thu, 14 Oct 2021 10:53:38 +0000</pubDate>
        
        <guid>//localhost:1313/post/2021-10-on-stateless-microservices/</guid>
        <description>&lt;p&gt;This post discusses the stateless microservice design pattern; it is meant as
support material for other posts of mine that discuss microservices, mainly
&lt;a 
   href=&#34;//localhost:1313/post/2021-10-14-the-stateful-microservice/&#34;
   &gt;The Stateful Microservice&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2021-10-on-stateless-microservices/media/8.png&#34;
	width=&#34;1378&#34;
	height=&#34;2048&#34;
	srcset=&#34;//localhost:1313/post/2021-10-on-stateless-microservices/media/8_hu_48b7be9e0748ac79.png 480w, //localhost:1313/post/2021-10-on-stateless-microservices/media/8_hu_56b2bd321fd1677a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;67&#34;
		data-flex-basis=&#34;161px&#34;
	
&gt;
&lt;/p&gt;
&lt;h4 id=&#34;is-statelessness-a-requirement-for-a-microservice&#34;&gt;Is statelessness a requirement for a microservice?
&lt;/h4&gt;&lt;p&gt;In another post (see
&lt;a 
   href=&#34;//localhost:1313/post/2021-10-so-what-is-microservice-anyway/&#34;
   &gt;So, what is a Microservice, anyway?&lt;/a&gt;) I examine what a microservice really is, and I come to the conclusion that from a purely technical standpoint, a working definition could be
as simple as this:&lt;/p&gt;
&lt;p&gt;A microservice is a scalable and resilient module.&lt;/p&gt;
&lt;p&gt;Even if you disagree with the terseness of this definition, and you regard
microservices as necessarily more than that, I hope you will at least agree
that it is precisely scalability and resilience that statelessness in microservices aims to address, so this definition serves its
purpose at least in the context of this series of posts.&lt;/p&gt;
&lt;p&gt;There are many who will try to convince you that in order to build a scalable
and resilient system, you need statelessness; so much so, that microservices
have almost come to be regarded as synonymous with statelessness. This post
examines whether this is that in fact so, and what is the cost of doing things
this way.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;If we take a step back for a moment and examine the issue from a somewhat
distanced point of view, we notice that there is no such thing as a stateless
software system. If there was such a thing, it would not be capable of
performing any function worth speaking of, and it would necessarily be less
useful than a brick, because a brick has physical existence, so you can, at
the very least, throw it at someone.&lt;/p&gt;
&lt;p&gt;If there is one thing that a software system necessarily has, it is state, so
there is no word that is more unsuitable to go with the word &amp;ldquo;software&amp;rdquo; than
the word &amp;ldquo;stateless&amp;rdquo;. (By the way, that is also a little something that
functional programming aficionados should perhaps take a moment to
philosophically ponder about.)&lt;/p&gt;
&lt;p&gt;What this all means is that even if you build a system using so-called
stateless microservices, that system will still have state; for example, if it
is a web shop, it will very conveniently remember me when I come to visit
again, and if I order any goods during my visit, it will very inconveniently
&lt;em&gt;not&lt;/em&gt; forget to send me an invoice. That is all happening due to state, which is
stored in the database system of the web shop. So, when people speak of
microservices with no state what they actually mean is microservices with no
&lt;em&gt;transient&lt;/em&gt; state. The state is definitely there, the system just does
not rely on any microservice remembering any of it. Each microservice
refrains from keeping any state in memory for any longer than it absolutely
has to; it always begins the processing of every single transaction by
querying the database for all necessary state, and it makes sure to persist
any changed state into the database before proclaiming the transaction
complete.&lt;/p&gt;
&lt;p&gt;Stateless microservices were invented because statelessness is an easy way of
achieving scalability and resilience: if a module does not keep any state, then an
indefinite number of copies of that module can be created to process requests in
parallel; any request arriving at the server farm can be serviced by any
instance of that module, and any subset of copies of the module can be destroyed at any moment,
without depriving the system from its ability to function.&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s great, but statelessness is not an end in and of itself; it is a means
to an end; it is just one way of achieving scalability and
resilience. This is proven by the fact that the database systems upon which
stateless microservice architectures are built are most certainly not
stateless at all, and yet they do somehow manage to be scalable and resilient.
Obviously, they are doing something differently.&lt;/p&gt;
&lt;h4 id=&#34;what-is-wrong-with-statelessness&#34;&gt;What is wrong with statelessness?
&lt;/h4&gt;&lt;p&gt;When building a system which needs to be scalable and resilient, and also
needs to be very stateful as a whole, one has to begin with a scalable and
resilient data layer as a foundation. Luckily, there exist various
commercially available products that accomplish this. On top of that
foundation, one has to build their application-specific logic in a way that is
also scalable and resilient. Stateless microservices will achieve this, but
they are one of the &lt;strong&gt;worst performing&lt;/strong&gt;, and from an engineering
standpoint most &lt;em&gt;&lt;strong&gt;cowardly&lt;/strong&gt;&lt;/em&gt; ways of achieving scalability and
resilience. Choosing the stateless microservices approach is like saying the
following:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;State is hard; we do not have the slightest clue as to how we can maintain
state and at the same time remain scalable and resilient; but look, the
creators of our database system are very smart folks, they seem to have
figured it all out! So, here is what we will do: we will delegate the entire
task of maintaining state to them!&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That is how we arrived at the stateless microservice model, which I like to
call the &amp;ldquo;Dory&amp;rdquo; model, after the fish that suffered from amnesia in the
&lt;em&gt;Finding Nemo&lt;/em&gt; movie.&lt;/p&gt;
&lt;p&gt;In the Dory model, every single incoming transaction gets processed by a
microservice that is drawing a complete blank. Upon receiving the request, the
microservice starts with very basic questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Who am I, and what is this strange place I am running in?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Who are these folks sending me requests, and why?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Should I respond to them, or should I four-oh-three them away?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Let&amp;rsquo;s start by authenticating them&amp;hellip;&lt;/p&gt;
&lt;p&gt;&amp;hellip;and it goes on like that. For every single request, there are multiple
round-trips to the database while the microservice is discovering more and more
about what it is being requested to do and whether it should in fact do it,
and even more round-trips to retrieve the information that will go into the
response, including very basic information that hardly ever changes, such as
the name of the visitor on whose behalf the request was sent, and in multi-tenancy scenarios even
the name of the tenant on whose behalf the website is being served.&lt;/p&gt;
&lt;p&gt;When the transaction is nearing completion, the stateless microservice will
meticulously store every single little piece of changed state in its exact
right place in the database, as if it is making notes to itself, lest it
forgets.&lt;/p&gt;
&lt;p&gt;Finally, once the transaction is completed, the microservice will proceed to
deliberately forget absolutely everything that it learned during the
processing of the transaction, before it starts to wait for the next
transaction.&lt;/p&gt;
&lt;p&gt;I am not going to say that this is preposterously inefficient, but
it is &lt;em&gt;&lt;strong&gt;preposterously inefficient.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Incidentally, the magnificent inefficiency of stateless microservices makes
them to a certain extent a self-serving paradigm: in order to scale up you
might think you need them, but once you have them, they will perform so badly,
that boy oh boy, are you going to need to scale up!&lt;/p&gt;
&lt;p&gt;Another problem with stateless microservices is that they cannot take any
initiative of their own, they are restricted to only responding to incoming
requests. This poses a problem with server-initiated client updates, which in
certain circles are known as &amp;ldquo;push notifications&amp;rdquo;. A server-initiated client
update happens when the server decides to send some data to the client at an
arbitrary moment in time, as a result of some event occurring on the server,
without the client first having to request that data.&lt;/p&gt;
&lt;p&gt;Actually, the very term &amp;ldquo;push notification&amp;rdquo; seems to have originated from
system designs in which such sending of data is a difficult task, as if the
developers have to put their shoulders against the notification and push it
all together to make it straddle the great divide between the server and the
client. In other designs, where asynchronous bi-directional communication is
the default mode of operation, there is no need for such laboriousness;
server-initiated client updates are just part of the normal way things work.
Alas, you cannot have that with stateless microservices, because
bi-directional communication requires the notion of a session, which in turn
implies a notion of state, which is a no-no.&lt;/p&gt;
&lt;p&gt;Consequently, software systems that utilize the stateless microservice design
pattern address the problem of server-initiated client updates in various
wacky hacky ways:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Some opt to not have any; if the user wants to see what has changed, let
them refresh the page. This can cause serious problems in systems where
multiple clients may edit the same data, since the system has no way of
alerting a client that the data they are editing is also being edited by
another client at the same time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Some use polling, meaning that each client keeps sending requests to the
server at regular intervals asking whether there are any updates. This is wasteful, because each of these requests represents work that needs to
be done, but very few of them will result in anything useful happening. At
the same time, in order to reduce server load, the polling cannot be too
frequent, which in turn means that there will always be a time
lapse between the moment that an event occurs on the server and the moment
that the clients take notice.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Some opt to have special stateful modules working side by side with the
stateless microservices to handle the push notifications in a completely
separate way, under the assumption that notifications are a kind of optional, &amp;ldquo;nice to have&amp;rdquo; thing anyway, so if performance suffers due to lack
of scaling, or if service is interrupted due to lack of resilience, it will
not hurt too much. On top of being clunky, this approach is also
short-sighted because from the entire broad topic of server-initiated client
updates it only considers the narrow case of updates being used for the sole
purpose of on-screen notifications.&lt;/p&gt;
&lt;p&gt;Further reading: &lt;a 
   href=&#34;//localhost:1313/post/2021-10-14-the-stateful-microservice/&#34;
   &gt;The Stateful Microservice&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: &lt;em&gt;Dory&lt;/em&gt;, the yellow-blue fish (a &lt;em&gt;Royal Blue Tang&lt;/em&gt;) that
suffered from amnesia in the 2003 movie &lt;em&gt;Finding Nemo&lt;/em&gt; by Pixar.&lt;/p&gt;</description>
        </item>
        <item>
        <title>White-Box vs- Black-Box Testing</title>
        <link>//localhost:1313/post/2021-12-white-box-vs-black-box-testing/</link>
        <pubDate>Wed, 22 Sep 2021 13:47:17 +0000</pubDate>
        
        <guid>//localhost:1313/post/2021-12-white-box-vs-black-box-testing/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;external&#34; 
   href=&#34;https://blogger.googleusercontent.com/img/a/AVvXsEjW7YbG075F9q253nTW0xSWiTzN9msG1BuZ2TgZO-mztpIBkgk9or5PoE2z-KhAx_WmfsT86Z5y6NFntAxir_gDF9PE3CCPaGQDmtx6ypfaffZirjHodfq1rM5SP8ONNI7AUmT3xHoijMhReRWmeHJZKjyPtZuyhHPAFJ6MrPUuPE7BXsGJ4gFWE36yyg=s1000&#34; target=&#34;_blank&#34;
   &gt;&lt;img src=&#34;//localhost:1313/post/2021-12-white-box-vs-black-box-testing/media/tag-blogger.com,1999-blog-3494795920779884230.post-69667484864678488091.jpg&#34;
	width=&#34;640&#34;
	height=&#34;256&#34;
	srcset=&#34;//localhost:1313/post/2021-12-white-box-vs-black-box-testing/media/tag-blogger.com,1999-blog-3494795920779884230.post-69667484864678488091_hu_f50f246ab2524aaf.jpg 480w, //localhost:1313/post/2021-12-white-box-vs-black-box-testing/media/tag-blogger.com,1999-blog-3494795920779884230.post-69667484864678488091_hu_cde10918de1bcfd0.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;250&#34;
		data-flex-basis=&#34;600px&#34;
	
&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I have something blasphemous to tell you.&lt;/p&gt;
&lt;p&gt;Unit Testing is wrong.&lt;/p&gt;
&lt;p&gt;There, I said it.&lt;/p&gt;
&lt;p&gt;I know I just insulted most people&amp;rsquo;s sacred cow.&lt;/p&gt;
&lt;p&gt;Sorry, not sorry.&lt;/p&gt;
&lt;p&gt;I will explain, bear with me.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h4 id=&#34;so-what-is-unit-testing-anyway&#34;&gt;So, what is Unit Testing anyway?
&lt;/h4&gt;&lt;p&gt;Unit Testing, according to its definition, aims to examine a module in
isolation, to make sure that it behaves as expected without uncertainties
introduced by the behavior of other modules that it interacts with. These
other modules are known as dependencies. To achieve this, the test refrains
from connecting the module with its dependencies, and instead emulates the
behavior of the dependencies. That is what makes it a Unit Test, as opposed to
an Integration Test.&lt;/p&gt;
&lt;p&gt;The emulation of the dependencies is meant to be done in a very
straightforward and inexpensive way, because if it was complicated, then it
would introduce uncertainties of its own. So, if we were to imagine for a
moment that the math library is a dependency of the module under test, (just
for the sake of the example,) when the module under test asks for the cosine
of an angle, the Unit Test does not want to invoke the actual math library to perform the cosine
computation; instead, the Unit Test makes sure beforehand to supply the module
under test with such inputs that will cause the module to work with a known
angle of say 60 degrees, so the Unit Test can anticipate that the module will ask for the cosine of a 60 degree
angle, at which point the Unit Test will supply the module under test with a hard-coded value of 0.5,
which is known to be the cosine of 60 degrees. The Unit Test then proceeds to
make sure that the module does the right thing with that 0.5 and produces the
right results.&lt;/p&gt;
&lt;p&gt;In doing so, the Unit Test expects the module under test to interact with each of its
dependencies in a strictly predetermined way: a specific set of calls is
expected to be made, in a specific order, with specific arguments. Thus, the
unit test has knowledge of exactly how the module is implemented: not only the
outputs of the module must be according to spec, but also every single little
detail about the inner workings of the module must go exactly as expected.
Therefore, Unit Testing is white-box testing by nature.&lt;/p&gt;
&lt;h4 id=&#34;what-is-wrong-with-white-box-testing&#34;&gt;What is wrong with White-Box Testing
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;White-box testing is not agnostic enough.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Just as users tend to test software in ways that the developer never
thought of, (the well known &amp;ldquo;works for me but always breaks in the hands
of the user&amp;rdquo; paradox,) software tests written by developers who maintain
an agnostic stance about the inner workings of the production code are
likely to test for things that were never considered by those who wrote
the production code.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;White-box testing is a laborious endeavor.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The amount of test code that has to be written and maintained often far
exceeds the amount of production code that is being tested.&lt;/li&gt;
&lt;li&gt;Each modification to the inner workings of production code requires corresponding modifications to the testing code, even if the interface and behavior of
the production code remains unchanged.&lt;/li&gt;
&lt;li&gt;With respect to procedural logic within the module under test, the Unit Test has to make sure
that every step of each workflow is followed, so the test essentially has to anticipate
every single decision that the module will make. This means that the test
duplicates all of the knowledge embodied within the module, and
essentially constitutes a repetition of all of the procedural logic of the
module, expressed in a different way. This problem has also been identified by others, and it is sometimes called the &amp;ldquo;over-specified tests problem&amp;rdquo;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;White-box testing suffers from &lt;em&gt;The Fragile Test Problem&lt;/em&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A bug fix in the production code more often than not causes tests to
break, which then have to be fixed. Note that this often happens even if we first write a test for the bug, which is expected to initially fail, and to start passing once the bug fix is applied: other previously existing tests will break. Unfortunately, it is often unclear to
what extent the tests are wrong, and to what extent the tests are right
but the production code suffers from other, dormant bugs, that keep
causing the tests to fail. When fixing tests as a result of bug fixes in
production, the general assumption is that the production is now correct,
therefore the test must be wrong, so the test is often hastily modified to make it pass
the existing production code. This often results in tests that &amp;ldquo;test
around&amp;rdquo; pre-existing bugs, meaning that the tests only pass if the bugs
are there.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;White-box tests are not re-usable.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It should be possible to completely rewrite a piece of production code and
then reuse the old tests to make sure that the new code works exactly as
the old one did. This is impossible with white-box testing.&lt;/li&gt;
&lt;li&gt;It should be possible to write a test once and use it to test multiple
different implementations of a certain module, created by independently working
development teams taking different approaches to solving the same problem.
This is also impossible with white-box testing.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;White-box testing hinders refactoring.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Quite often, refactorings which would affect the entire code base are unattainable because they would necessitate rewriting all unit tests, even if the refactorings themselves would  have no effect on the behavior of the module, and would only require limited and harmless modifications to the production code, such as the case is when replacing one third-party library with another.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;White-box testing is highly presumptuous.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;White-box testing claims to have knowledge of exactly how the dependencies behave,
which may not be accurate. As an extreme example, the cosine of 60 is 0.5 only if that 60 is in degrees; if the cosine function of the actual math library used in production works with radians instead of degrees, then the result will
be something completely different, and the Unit Test will be achieving
nothing but ensuring that the module will only pass the test if it
severely malfunctions. In real-world scenarios the wrongful assumptions are much more subtle than a degrees vs radians discrepancy, making them a lot harder to detect and troubleshoot.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the preface of the book &lt;em&gt;&lt;strong&gt;The Art of Unit Testing&lt;/strong&gt;&lt;/em&gt; (Manning,
2009) by &lt;strong&gt;Roy Osherove&lt;/strong&gt;, the author admits to having participated in a
project which failed to a large part due to the tremendous development
burden imposed by badly designed unit tests which had to be maintained
throughout the duration of the development effort. The author does not go
into details about the design of those unit tests and what was so bad about
it, but I would dare to postulate that it was simply the fact that they were&amp;hellip;
Unit Tests.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;is-white-box-testing-good-for-anything&#34;&gt;Is white-box testing good for anything?
&lt;/h4&gt;&lt;p&gt;If you are sending humans to space, or developing any other high-criticality
system, then fine, go ahead and do white-box testing, as well as inside-out
testing, and upside-down testing, and anything else that you can think of,
because in high-criticality software, there is no amount of testing that
constitutes too much testing. However, the vast majority of software written
in the world today is not high criticality software, it is just plain normal,
garden variety, commercial software. Applying space-grade practices in the
development of commercial software does not make business sense, because
space-grade practices tend to be much more expensive than
commercial practices.&lt;/p&gt;
&lt;p&gt;In high criticality, it is all about safety; in commercial, it is all about
cost effectiveness.&lt;/p&gt;
&lt;p&gt;In high criticality, it is all about leaving nothing to chance; in commercial,
it is all about meeting the requirements.&lt;/p&gt;
&lt;h4 id=&#34;what-about-leaving-nothing-to-chance&#34;&gt;What about leaving nothing to chance?
&lt;/h4&gt;&lt;p&gt;It is true that if you do black-box testing you
cannot be absolutely sure that absolutely everything goes absolutely as
intended. For example, you may be testing a module to ensure that given a
certain input, a certain record is written to the database.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you do white-box testing, you can ensure not only that the record has the correct content,
but also that the record is written once and only once.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you do black-box
testing, all you care is that at the end of the day, a record with the correct content can be found
in the database; there may be a bug which inadvertently
causes the record to be written twice, and you would not know.&lt;/p&gt;
&lt;p&gt;So, at this point some might argue that in promoting black-box testing I am
actually advocating imperfect software. Well, guess what: in the commercial sector, there is no such
thing as perfect software; there is only software that meets its requirements,
and software that does not. If the requirements are met, then some record being written twice is just a performance concern. Furthermore, it is a performance concern not only in the sense of the performance of the running software system, but also in the sense of the performance of your development process: By established practice, it is perfectly fine to knowingly allow a record to be written twice if eliminating this duplication would require too much development work to be worth it, so how is this any different from following an efficient development methodology which might allow that record to be written twice?&lt;/p&gt;
&lt;p&gt;This is in line with the observation that nobody aims to write software that is free from imperfections. Virtually
every single method that returns a collection in all of Java code written
since the dawn of time makes a safety copy of that collection; these safety
copies are almost always unnecessary, and yet people keep making them, because
they do not want to be concerned with what is safe and what is not safe on a
case by case basis; case-by-case addressing of safety concerns is the stuff
that bugs are made of. Software that is free of bugs is software that meets
the requirements, and that&amp;rsquo;s all that counts.&lt;/p&gt;
&lt;p&gt;(Note: personally, I never make safety copies of collections; I use special
unmodifiable collection interfaces instead; but that&amp;rsquo;s a different story.)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h4&gt;&lt;p&gt;In the book
&lt;em&gt;&lt;strong&gt;Design Patterns: Elements of Reusable Object-Oriented Software&lt;/strong&gt;&lt;/em&gt;
(Addison-Wesley, 1994) by &lt;em&gt;&lt;strong&gt;The Gang of Four&lt;/strong&gt;&lt;/em&gt; (Erich Gamma, Richard
Helm, Ralph Johnson, and John Vlissides) one of the principles listed is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Program against the interface, not against the implementation.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Virtually all software engineers agree with this self-evident maxim, and
nobody in their right mind would take issue with it. To program against the
implementation rather than the interface is universally considered a misguided
practice.&lt;/p&gt;
&lt;p&gt;In the context of testing, the corollary to this maxim is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Test against the interface, not against the implementation.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In other words, do black-box testing, not white-box testing.&lt;/p&gt;
&lt;p&gt;This is not a unique idea of my own, others have had the same idea before, and have similar things to say. Ian Cooper in his &amp;ldquo;TDD, where did it all go wrong&amp;rdquo; talk states that in TDD a Unit Test is defined as a test that runs in isolation from other tests, not a test that isolates the unit under test from other units.  In other words, the unit of isolation is the test, not the unit under test. Some excerpts from the talk are here: &lt;a class=&#34;external&#34; 
   href=&#34;https://www.youtube.com/watch?v=HNjlJpuA5kQ&#34; target=&#34;_blank&#34;
   &gt;Build Stuff &amp;lsquo;13: Ian Cooper - TDD, where did it all go wrong&lt;/a&gt; and the full talk is here: &lt;a class=&#34;external&#34; 
   href=&#34;https://www.youtube.com/watch?v=EZ05e7EMOLM&#34; target=&#34;_blank&#34;
   &gt;TDD, Where Did It All Go Wrong (Ian Cooper, 2017)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Other references:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;external&#34; 
   href=&#34;https://eng.libretexts.org/Bookshelves/Computer_Science/Programming_and_Computation_Fundamentals/Book%3A_Object-Oriented_Reengineering_Patterns_%28Demeyer_Ducasse_and_Nierstrasz%29/06%3A_Tests__Your_Life_Insurance/6.05%3A_Test_the_Interface_Not_the_Implementation&#34; target=&#34;_blank&#34;
   &gt;Object-Oriented Reengineering Patterns (Demeyer, Ducasse, and Nierstrasz) - Tests - Your Life Insurance - 6.05 - Test the Interface Not the Implementation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;external&#34; 
   href=&#34;https://web.archive.org/web/20180825215727/http://www.richardlord.net/blog/tdd/test-the-interface-not-the-implementation.html&#34; target=&#34;_blank&#34;
   &gt;Richard Lord - Test the interface, not the implementation&lt;/a&gt; (via archive.org)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;if-not-unit-testing-then-what&#34;&gt;If not Unit Testing, then what?
&lt;/h4&gt;&lt;p&gt;So, one might ask: if Unit Testing is wrong, then what should we be doing
instead? The original impetus behind the invention of Unit Testing still
remains: when we test a module we want to make sure that the observed behavior
is not affected by potential malfunction in its dependencies. How can we avoid that?&lt;/p&gt;
&lt;p&gt;The way I have been handling this in recent years is by means of a method that
I call &lt;em&gt;Incremental Integration Testing&lt;/em&gt;. You can read about it here: &lt;a 
   href=&#34;//localhost:1313/post/2022-10-incremental-integration-testing/&#34;
   &gt;Incremental Integration Testing&lt;/a&gt;.&lt;/p&gt;</description>
        </item>
        <item>
        <title>The MVVM architectural design pattern</title>
        <link>//localhost:1313/post/2021-01-the-mvvm-architectural-design-pattern/</link>
        <pubDate>Sat, 16 Jan 2021 14:47:04 +0000</pubDate>
        
        <guid>//localhost:1313/post/2021-01-the-mvvm-architectural-design-pattern/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2021-01-the-mvvm-architectural-design-pattern/media/mvvm.png&#34;
	width=&#34;800&#34;
	height=&#34;242&#34;
	srcset=&#34;//localhost:1313/post/2021-01-the-mvvm-architectural-design-pattern/media/mvvm_hu_8fa849595e07c30f.png 480w, //localhost:1313/post/2021-01-the-mvvm-architectural-design-pattern/media/mvvm_hu_400ee7376db477fb.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;330&#34;
		data-flex-basis=&#34;793px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;This is a brief technical explanation of MVVM, with enough detail (borrowed from its WPF implementation) and examples to allow the reader to grasp how it actually works.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;MVVM&lt;/em&gt; is an architectural design pattern for building interactive applications. Its aim is to achieve complete decoupling of application logic from presentation logic.&lt;/li&gt;
&lt;li&gt;MVVM is not something new, and it was not even new at the time that it became popular. It was named by &lt;a class=&#34;external&#34; 
   href=&#34;https://docs.microsoft.com/en-us/archive/blogs/johngossman/introduction-to-modelviewviewmodel-pattern-for-building-wpf-apps&#34; target=&#34;_blank&#34;
   &gt;John Gossman in 2005&lt;/a&gt;, who states that it is the same as the &lt;em&gt;Presentation Model&lt;/em&gt; pattern named by &lt;a class=&#34;external&#34; 
   href=&#34;https://martinfowler.com/eaaDev/PresentationModel.html&#34; target=&#34;_blank&#34;
   &gt;Martin Fowler in 2004&lt;/a&gt;, who in turn states that it was previously known as the &lt;em&gt;Application Model&lt;/em&gt; pattern in &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/VisualWorks&#34; target=&#34;_blank&#34;
   &gt;certain Smalltalk circles&lt;/a&gt; as early as in the 1980s, and that&amp;rsquo;s where we lose track of it: for all we know, it may have originated in Ancient Egypt.&lt;/li&gt;
&lt;li&gt;The acronym stands for &lt;em&gt;Model&lt;/em&gt;, &lt;em&gt;View&lt;/em&gt;, &lt;em&gt;Viewmodel&lt;/em&gt;.
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;/em&gt; refers to the main &lt;em&gt;estate&lt;/em&gt; data model of our application; it is optional and largely irrelevant, so it will only be mentioned a couple of times here.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;View&lt;/strong&gt;&lt;/em&gt; refers to the user interface.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;Viewmodel&lt;/strong&gt;&lt;/em&gt; is the secret sauce, but in essence it refers to the application logic.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Application logic is placed in objects known as viewmodels. A viewmodel does the following:
&lt;ul&gt;
&lt;li&gt;Publicly exposes state, part of which is publicly mutable.&lt;/li&gt;
&lt;li&gt;Issues notifications about any mutation of its state.&lt;/li&gt;
&lt;li&gt;Responds to state mutations with behavior, such as querying and updating data stores, issuing events in some messaging backbone, etc.&lt;/li&gt;
&lt;li&gt;Manifests its behavior by means of further modifying its own state, which in turn generates more state mutation notifications.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;This allows the following very simple workflow:
&lt;ul&gt;
&lt;li&gt;When the presentation layer modifies a property of a viewmodel, the viewmodel takes notice and exhibits its behavior.&lt;/li&gt;
&lt;li&gt;When a viewmodel modifies one of its own properties, the presentation layer takes notice and updates the screen.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Thus, a viewmodel essentially implements a fully interactive and yet completely abstract (i.e. not graphical) user interface, with mutable properties instead of editable controls. The viewmodel is free from presentation concerns such as where on the screen the properties may be shown, what user interface controls may be used to show them, etc.
&lt;ul&gt;
&lt;li&gt;Note: GUI pushbuttons, which have no state, are implemented as special &amp;ldquo;Command&amp;rdquo; objects that are exposed by a viewmodel besides its properties, but they could also be implemented as Boolean properties, where a transition from say, true to false triggers behavior. Command objects make viewmodels more self-documenting and more usable, but they are nothing but a nice-to-have feature: in principle, everything could work with just properties.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If we wanted to allow the user to edit a &lt;code&gt;Customer&lt;/code&gt; entity in a modal dialog box:
&lt;ul&gt;
&lt;li&gt;There will be a viewmodel for this dialog box, which exposes:
&lt;ul&gt;
&lt;li&gt;One property for each editable field of &lt;code&gt;Customer&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;One command for the &amp;lsquo;OK&amp;rsquo; button&lt;/li&gt;
&lt;li&gt;One boolean property which stands for the &amp;rsquo;enabled&amp;rsquo; state of the &amp;lsquo;OK&amp;rsquo; button.&lt;/li&gt;
&lt;li&gt;One command for the &amp;lsquo;Cancel&amp;rsquo; button, presumed to be always enabled.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The viewmodel may set the enabled state of the &amp;lsquo;OK&amp;rsquo; command to true only once the user has made changes to the fields.&lt;/li&gt;
&lt;li&gt;When the &amp;lsquo;OK&amp;rsquo; command is triggered, the viewmodel performs validation.&lt;/li&gt;
&lt;li&gt;If validation fails, the viewmodel instantiates another viewmodel which stands for an error message, and the view chooses how to show it, e.g. with a modal dialog box or with a temporary &amp;ldquo;toast&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;If validation succeeds, the viewmodel persists the entered information in the data store.&lt;/li&gt;
&lt;li&gt;If the user opts to cancel, then the viewmodel discards the edited information.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Viewmodels are so agnostic of presentation concerns that they can in fact be instantiated without any user interface at all. This allows us to test the entirety of the behavior of our application logic without a user interface and without having to examine any of its private implementation details such as its data store. Our application logic tests simply modify the public state of viewmodels and examine how the viewmodels further modify their public state in response.&lt;/li&gt;
&lt;li&gt;The presentation layer consists of views.
&lt;ul&gt;
&lt;li&gt;In a desktop application, views are user-defined controls, panels, windows, dialogs, etc.&lt;/li&gt;
&lt;li&gt;In a web application, views would be HTML fragments.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Each view type is specific to a particular viewmodel type, and contains bindings, which describe how each property of the viewmodel is bound to each property of a control within the view.
&lt;ul&gt;
&lt;li&gt;So, a &lt;code&gt;CustomerForm&lt;/code&gt; view which is meant to display a &lt;code&gt;Customer&lt;/code&gt; viewmodel has a binding which specifies that the &lt;code&gt;Name&lt;/code&gt; property of the customer should be bound to the &lt;code&gt;Text&lt;/code&gt; property of a certain &lt;code&gt;TextBox&lt;/code&gt; control within the view.&lt;/li&gt;
&lt;li&gt;Note that these associations are purely declarative, and they reference nothing but statically available information, (data types and their members,) which means that they can be described using a markup language, i.e. without the need to write any application-specific code to build up the user interface.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A viewmodel may contain a property which is in turn another viewmodel. Let us call that a child viewmodel. In this case, the view can do one of two things:
&lt;ul&gt;
&lt;li&gt;Specify a particular child view type to display that particular child viewmodel.&lt;/li&gt;
&lt;li&gt;Specify a mapping table which defines what type of child view to use for displaying any different possible type of child viewmodel.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Views are resolved at runtime, based on the actual type of the child viewmodel, which can be more derived than the advertised type of the child viewmodel property; so, if a viewmodel exposes a &lt;code&gt;Customer&lt;/code&gt; child viewmodel property which can be either of type &lt;code&gt;Customer&lt;/code&gt; or of a more derived type &lt;code&gt;WholesaleCustomer&lt;/code&gt;, the mapping table can specify a different child view type for each of these child viewmodel types, and the right child view will be instantiated at runtime depending on the actual type of the child viewmodel.&lt;/li&gt;
&lt;li&gt;Any child view can in turn contain its own mapping table which defines more associations, or redefines existing associations, so that for example:
&lt;ul&gt;
&lt;li&gt;In the scope of an &lt;code&gt;AllCustomers&lt;/code&gt; view, the &lt;code&gt;Customer&lt;/code&gt; viewmodel can be associated with a &lt;code&gt;CustomerRow&lt;/code&gt; view, so as to present the customer as a row in a tabular control.&lt;/li&gt;
&lt;li&gt;In the scope of a &lt;code&gt;CustomerDetails&lt;/code&gt; view, the same &lt;code&gt;Customer&lt;/code&gt; viewmodel can be associated with a &lt;code&gt;CustomerForm&lt;/code&gt; view, to present the customer using individual fields laid out on a surface.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Note that again, this mapping table consists of nothing but statically available information, (view types and viewmodel types,) so everything is still achievable in markup.&lt;/li&gt;
&lt;li&gt;A child viewmodel property can be optional or nullable, thus allowing the application logic to control whether an entire section of the user interface is available or not at any given moment.&lt;/li&gt;
&lt;li&gt;A child viewmodel property can be a collection of viewmodels, allowing for a corresponding child view which is a list control or a tab control. Viewmodel type mapping still applies, so if the collection contains viewmodels of different types at runtime, the resulting list control will consist of different kinds of rows, or the resulting tab control will consist of different kinds of tabs.&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>Object Lifetime Awareness</title>
        <link>//localhost:1313/post/2020-12-27-object-lifetime-awareness/</link>
        <pubDate>Sun, 27 Dec 2020 10:46:17 +0000</pubDate>
        
        <guid>//localhost:1313/post/2020-12-27-object-lifetime-awareness/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2020-12-27-object-lifetime-awareness/images/le-penseur.jpg&#34;
	width=&#34;3648&#34;
	height=&#34;5472&#34;
	srcset=&#34;//localhost:1313/post/2020-12-27-object-lifetime-awareness/images/le-penseur_hu_9d5b056aaaccb843.jpg 480w, //localhost:1313/post/2020-12-27-object-lifetime-awareness/images/le-penseur_hu_c19a599b08f288b2.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;66&#34;
		data-flex-basis=&#34;160px&#34;
	
&gt;
&lt;/p&gt;
&lt;h4 id=&#34;abstract&#34;&gt;Abstract
&lt;/h4&gt;&lt;p&gt;Garbage collectors have given us a false sense of security with respect to what happens to an object once we stop thinking about it. The assumption is that it will be magically taken care of, but this does not always go as hoped, resulting in memory leaks and bugs due to failure to perform necessary cleanup. Tools for troubleshooting such problems are scarce, and not particularly helpful, so finding and fixing such problems is notoriously difficult.&lt;/p&gt;
&lt;p&gt;A methodology is presented, which differs from current widespread practices, for maintaining awareness of, and exercising full deterministic control over, the lifetime of certain objects in a garbage-collected environment. We issue hard errors in the event of misuse, and accurate diagnostic messages in the event of omissions, thus improving the robustness of software and lessening the troubleshooting burden.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h4 id=&#34;definition&#34;&gt;Definition
&lt;/h4&gt;&lt;p&gt;An object can be said to have a concept of lifetime if at some point it must perform some cleanup actions, after which it must never be accessed again.&lt;/p&gt;
&lt;h4 id=&#34;a-first-look-at-the-problem&#34;&gt;A first look at the Problem
&lt;/h4&gt;&lt;p&gt;One of the original promises of garbage collectors was that we should not have to worry about the lifetime of objects; however, there exist various known situations where objects do, by their very nature, have an inherent notion of lifetime, so we do have to worry about it; for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Objects that model real-world processes with an inherent concept of lifetime, such as:
&lt;ul&gt;
&lt;li&gt;A user&amp;rsquo;s visit to a web site, represented by a web session which at some moment expires.&lt;/li&gt;
&lt;li&gt;The printing of a document, represented by a print job which at some moment completes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Objects implementing application behaviors with a clearly defined end, such as:
&lt;ul&gt;
&lt;li&gt;A dialog window which at some moment gets dismissed and ceases to exist.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additionally, there exist certain programmatic constructs which require a notion of lifetime; for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An event observer which must at some point unregister from the event source that it had previously registered with.&lt;/li&gt;
&lt;li&gt;A database transaction which must at some point end, either by committing it or rolling it back.&lt;/li&gt;
&lt;li&gt;Generally, any situation where:
&lt;ul&gt;
&lt;li&gt;We must remember to undo something which was previously done.&lt;/li&gt;
&lt;li&gt;Some initialization must be balanced by some corresponding cleanup.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Furthermore, any object which contains an object that has a notion of lifetime needs to have a notion of its own lifetime, so as to be in a position of controlling the lifetime of the contained object. Thus, there tends to be a need for objects with a notion of lifetime to form a containment hierarchy whose root is the main application object.&lt;/p&gt;
&lt;p&gt;Unfortunately, in garbage collected environments, object lifetime is not given as much attention as it deserves. Software architectures tend to underestimate its importance, give it only a partial treatment, and invariably do it in ad-hoc ways, without any clearly defined methodology or aiding infrastructure. All to often, an object with an inherent notion of lifetime is built without explicit knowledge of it; instead, its lifetime is treated only implicitly. Thus, the software design has no knowledge of, and no control over, the lifetime of that object, and relies on the garbage collector to magically take care of it.&lt;/p&gt;
&lt;p&gt;Once we leave an object up to the garbage collector to take care of, we completely relinquish control over what happens next: there are no guarantees as to when the object will be collected, or even as to whether it will in fact be collected; there will be nothing to inform us of the outcome, and we have no way of influencing the outcome. Thus, when object-lifetime related trouble happens, it is by its nature very difficult to troubleshoot, diagnose, and fix; nonetheless, most programmers try to avoid dealing with object lifetime if they can, and each time problems pop up, they try to fix them on an as needed basis.&lt;/p&gt;
&lt;p&gt;The following kinds of trouble are common:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Direct failure to perform necessary cleanup:&lt;/strong&gt; the false sense of security offered by the garbage collector sometimes makes programmers forget that it only reclaims unused memory, it does not do any other cleanup for us, such as unregistering observers from event sources. This usually needs to be done manually, and it requires that the observer must have a notion of lifetime. An event source could in theory be asserting that every single observer did eventually remember to deregister; however, such a technique would require not only observers to have a notion of lifetime, but also the event source itself. Thus, there is no widespread use of such a technique, because there is no widespread use of object lifetime awareness in the first place.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memory leaks:&lt;/strong&gt; in an ideal world, the magic of the garbage collector would always be strong and true, but in practice it is not, due to subtle human error such as inadvertently keeping around a reference to an object, thus preventing it from being garbage collected. Lack of object lifetime awareness only exacerbates this problem.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Troubleshooting in the dark:&lt;/strong&gt; an object with a notion of lifetime can either be alive or dead. If the lifetime of the object is explicit, we can always inspect that state with the debugger. If not, then we never know whether the object that we are looking at is meant to be alive or not.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inability to detect misuse:&lt;/strong&gt; a very common mistake is continuing to access an object even after its lifetime is over. When the object has no explicit knowledge of its own lifetime, it cannot assert against such mistakes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;existing-mechanisms&#34;&gt;Existing mechanisms
&lt;/h4&gt;&lt;p&gt;Garbage collectors and their associated execution environments do provide some machinery which is related to the topic of object lifetime management, namely &lt;em&gt;&lt;strong&gt;finalization&lt;/strong&gt;&lt;/em&gt;, &lt;em&gt;&lt;strong&gt;disposal&lt;/strong&gt;&lt;/em&gt;, &lt;em&gt;&lt;strong&gt;&amp;ldquo;automatic&amp;rdquo; disposal&lt;/strong&gt;&lt;/em&gt;, and &lt;em&gt;&lt;strong&gt;weak references&lt;/strong&gt;&lt;/em&gt;, but as we shall see this machinery alone is woefully inadequate.&lt;/p&gt;
&lt;h3 id=&#34;finalization&#34;&gt;Finalization
&lt;/h3&gt;&lt;p&gt;In Java we have the &lt;code&gt;Object.finalize()&lt;/code&gt; method, and in C# we have &amp;ldquo;destructors&amp;rdquo;, which are actually not destructors at all, they are finalizers, too. &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;  The garbage collector will invoke the finalizer of an object right before reclaiming the memory occupied by it, so that the object can in theory perform some cleanup at that moment. Unfortunately, this mechanism is notoriously unreliable:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An object will not be finalized unless it first becomes eligible for collection, and in order for that to happen, it must first become unreachable. However, the object may remain reachable due to subtle mistakes such as unknowingly keeping a reference to it in some list, thus resulting in objects which never get finalized.&lt;/li&gt;
&lt;li&gt;When an object does become eligible for collection, the moment that it will actually be collected largely depends upon the whim of the garbage-collector, which is non-deterministic, both according to the documentation and as observed by experimentation. There are no guarantees as to when an object will be collected, or even as to whether it will ever be collected, despite being eligible.
&lt;ul&gt;
&lt;li&gt;If the garbage collector works in aggressive mode, (common in servers,) the object will be collected sooner rather than later, but how soon depends on variables that we practically have no control over, such as at what rate existing objects are becoming eligible for collection, how many objects are pending to be finalized, etc. So:
&lt;ul&gt;
&lt;li&gt;Even though the object may be finalized within milliseconds, there are no guarantees as to how many milliseconds, and also please note that &amp;ldquo;milliseconds&amp;rdquo; is still a far cry from &amp;ldquo;now&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;Even if the object gets finalized as quickly as possible, this is still going to happen in a separate thread, so finalization will always be desynchronized from the set of instructions which rendered the object eligible for finalization. If these instructions are followed by another set of instructions that in any way rely on finalization having already taken place, the second set of instructions will almost always fail.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If the garbage collector works in non-aggressive mode, (common in desktop and console applications,) then:
&lt;ul&gt;
&lt;li&gt;The object might not be collected unless the virtual machine starts running out of memory, which is at an entirely unknown and usually distant time in the future.&lt;/li&gt;
&lt;li&gt;The object may still not be collected at all if our software completes before exhausting its available memory. If we are only dealing with unmanaged resources that belong to the current process, they will be automatically reclaimed upon process termination, so all will be good, but if we are dealing with resources that are external to our process, (e.g. controlling a peripheral,) these resources will not be released.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The garbage collector orchestrates collection and finalization according to memory availability concerns, but not according to other concerns which it has no knowledge of; consequently, if we are acquiring instances of a certain scarce resource at a high rate, the garbage collector will not hasten collection and finalization in response to the scarcity of that resource, because it has no knowledge of that scarcity. However, if that resource only gets recycled when collection and finalization occurs, and if we do not happen to be allocating and freeing memory fast enough to trigger frequent enough collection and finalization, then we will be consuming the resource faster than it is being recycled, so we will run out of it, despite everything seemingly being done right.&lt;/li&gt;
&lt;li&gt;Finalization is unordered and does not respect containment hierarchy, which means that when the finalizer is invoked on an object, a random subset of the objects contained in this object may have already been finalized. This is a completely chaotic situation which makes it impossible to get anything non-trivial done within a finalizer.&lt;/li&gt;
&lt;li&gt;The chaotic and non-deterministic conditions under which the finalizer executes make it virtually impossible to test any code that you put in a finalizer, so virtually all finalizers are written on a best-effort basis: if it seems to work as written, it will hopefully keep working, fingers crossed.&lt;/li&gt;
&lt;li&gt;Finalization is documented as having a high performance cost, so the standing advice is that it is best to minimize its use, or avoid it altogether if possible.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Therefore, relying on finalization does not give us control over anything, on the contrary it takes control away from us. The official literature of both Microsoft DotNet and the Java Virtual Machine recommends using finalization for the purpose of releasing unmanaged resources, which is not just unhelpful but actually wrongful advice to give. The entire software industry has been blindly following this advice without first questioning its correctness, which has resulted in lots of buggy software out there.&lt;/p&gt;
&lt;h3 id=&#34;disposal&#34;&gt;Disposal
&lt;/h3&gt;&lt;p&gt;In Java we have the &lt;code&gt;Closeable&lt;/code&gt; interface, and in C# we have the &lt;code&gt;IDisposable&lt;/code&gt; interface. The benefit of using these interfaces is that they allow explicit (i.e. deterministic and synchronous) triggering of cleanup, instead of relying on finalization to trigger it.&lt;/p&gt;
&lt;p&gt;A C#-only note: In the C# world there is an understanding that &lt;code&gt;IDisposable&lt;/code&gt; may also be used for performing regular cleanup at the end of an object&amp;rsquo;s lifetime; however, its primary reason of existence is still regarded as being the release of unmanaged resources, so people are trying to use it for both purposes. At the same time, the releasing of unmanaged resources is still regarded as something that must always be attempted during finalization, so people are trying to write disposal methods which must work both when explicitly invoked during normal program flow, and when invoked by the finalizer. Needless to say, the complexity of this task is daunting, and the result is incredible amounts of confusion. The &lt;a class=&#34;external&#34; 
   href=&#34;https://docs.microsoft.com/en-us/dotnet/standard/garbage-collection/implementing-dispose&#34; target=&#34;_blank&#34;
   &gt;&lt;code&gt;Dispose(bool)&lt;/code&gt; pattern&lt;/a&gt; has been invented to help manage the chaos, but the result is still preposterously complicated, it suffers from boilerplate code on every single object that implements the pattern, it is largely untestable, and what is most disappointing is that absolutely no thinking seems to have gone in the direction of avoiding all this chaos in the first place.&lt;/p&gt;
&lt;p&gt;Overall, the problem with disposal is that it is very easy to accidentally omit, and when it is omitted there is usually nothing to tell us that we did something wrong, other than performance degradation and inexplicable malfunction. As a matter of fact, the designers of both Java and C# anticipated the inevitability of such omissions, so they invented finalization as a fallback mechanism which is hoped to save the day despite the omissions. However, since finalization is notoriously unreliable, it is not a solution either; it is more like implementing an insurance policy by purchasing lottery tickets.&lt;/p&gt;
&lt;p&gt;Unfortunately, the availability of finalization, and its deceitful promise of making everything right by magic, has steered programmers to regard disposal as largely optional, while in reality it is essential. All that disposal needs in order to be actually useful is a mechanism that will warn us when we forget to perform it, instead of a mechanism that will try to magically fix our omissions.&lt;/p&gt;
&lt;h3 id=&#34;automatic-disposal&#34;&gt;&amp;ldquo;Automatic&amp;rdquo; disposal
&lt;/h3&gt;&lt;p&gt;Both Java and C# provide special &amp;ldquo;automatic&amp;rdquo; disposal constructs, namely the &lt;code&gt;try-with-resources&lt;/code&gt; statement of java, and the &lt;code&gt;using&lt;/code&gt; keyword of C#, both of which implicitly invoke the disposal method even if an exception is thrown.  However:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The only thing that is automatic about these constructs is that if you remember to use them, then they will save you from having to write some code that disposes an object; unfortunately,
&lt;ul&gt;
&lt;li&gt;You may very easily forget to use them.&lt;/li&gt;
&lt;li&gt;You may very easily forget that your object requires disposal and therefore be unaware of the fact that you should have used them.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;These constructs can only be used in the simplistic scenario where the lifetime of an object is fully contained within the scope of a single method; unfortunately, in all but the most trivial situations what we actually have is objects which are contained within other objects and live for a prolonged time, so the method that creates them is different from the method that destroys them. In all these cases, the automatic disposal constructs are of no use whatsoever, and the programmer must remember to do everything right.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;weak-references&#34;&gt;Weak References
&lt;/h3&gt;&lt;p&gt;A weak reference is an object which receives special treatment by the execution environment, to achieve something which is not normally possible. It contains a reference to a target object, which is disregarded by the garbage collector when determining whether the target object is accessible. Therefore, if there are no other references to the target object, then the target object is allowed to be garbage-collected, at which point the reference inside the weak reference object is replaced with null.&lt;/p&gt;
&lt;p&gt;Weak references do not actually help us manage the lifetime of objects, but they have been suggested as a mechanism that can help us design things so that there is no need to manage the lifetime of objects. The idea is that we can implement the observer pattern using weak references, so that observers do not need to remember to unregister themselves from the event source; instead, they can simply be allowed to become garbage-collected, and the event source will subsequently forget them.&lt;/p&gt;
&lt;p&gt;This approach suffers from a number of drawbacks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Weak references might save us from having to worry about the lifetime of event observers, but they do nothing for a wide range of other situations that require cleanup at the end of an object&amp;rsquo;s lifetime.&lt;/li&gt;
&lt;li&gt;Weak observers run the danger of being prematurely garbage-collected. When this happens, it is very difficult to troubleshoot, and the fix tends to require tricks and hacks.&lt;/li&gt;
&lt;li&gt;Weak references are a bit too low level, a bit too esoteric, and a bit like magic, so suggesting their widespread use by the average programmer is a bit of a tough proposition.&lt;/li&gt;
&lt;li&gt;The use of weak references represents a step backwards from the stated goal of gaining more control over the inner workings of our software.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;a-deeper-look-at-the-problem&#34;&gt;A deeper look at the problem
&lt;/h4&gt;&lt;p&gt;In a language like C++, which has proper destructors, the lifetime of an object is well defined, and the compiler does all the work necessary to guarantee that this lifetime will end at the exact right moment, as long as we are using either local storage or smart pointers. However, in garbage-collected languages we have none of that; the lifetime of objects is not well defined by the language, so there is virtually nothing that the compiler can do for us. (As we have already shown, the &lt;code&gt;try-with-resources&lt;/code&gt; statement of Java and the &lt;code&gt;using&lt;/code&gt; keyword of C# are of very limited usefulness.)&lt;/p&gt;
&lt;p&gt;In order to implement necessary cleanup at the end of an object&amp;rsquo;s lifetime in garbage-collected languages, programmers either rely on finalization, or explicitly invoke objects to let them know that their lifetime is over. As we have already shown, finalization is asynchronous and non-deterministic, so it is unsuitable for basing any essential function of our software upon it, which means that explicit object lifetime termination is the only viable option.&lt;/p&gt;
&lt;p&gt;Unfortunately, explicit object lifetime termination suffers from its own range of problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There is usually nothing in the code to give us a hint that we should place a call to end the lifetime of an object.&lt;/li&gt;
&lt;li&gt;When we forget to end the lifetime of an object, there is never any immediate error to tell us that we forgot.&lt;/li&gt;
&lt;li&gt;The problems that subsequently occur tend to be subtle, so we often do not notice them until a considerable time after the fact. For example, forgetting to unregister an observer from an event source turns the observing object into a memory leak, and causes the observing method to keep being needlessly invoked by the event source, to perform actions that in the best case only waste clock cycles without any value or effect, and in the non-best case cause malfunction.&lt;/li&gt;
&lt;li&gt;When the malfunction does get noticed, it often seems inexplicable and does not tend to point to the source of the problem.&lt;/li&gt;
&lt;li&gt;Even when we discover that a certain malfunction is due to the lifetime of an object not having been ended, it is usually difficult to tell at which point in the code it should have been ended. Often, in order to know this, we first need to know where in the code the object was allocated, but this information is not normally available.&lt;/li&gt;
&lt;li&gt;Writing tests to catch omissions in object lifetime control is not only hard and tedious, but it also requires testing against the implementation rather than testing against the interface, which violates recommended best practices. (To test whether object A properly ends the lifetime of object B, we have to mock B and ensure that its lifetime termination method is invoked by A, but if we do this then we are by definition testing against the implementation of A.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;the-solution&#34;&gt;The Solution
&lt;/h4&gt;&lt;p&gt;Whereas it is generally true that &amp;ldquo;if you do everything right there will be no problems&amp;rdquo;, this is a very bad rule to live by, because it completely disregards another very important rule which says &amp;ldquo;there will be mistakes&amp;rdquo;. Reliance on everything being done right tends to result in brittle software designs, because some things will inevitably go wrong. We are definitely not advocating designs that are tolerant of mistakes; however, a software design must at the very least offer means of detecting mistakes and responding to them with hard error, diagnostic messages, or both; a design which relies on mistakes not being made, and at the same time is incapable of detecting the mistakes that will nonetheless be made, is doomed to run into trouble.&lt;/p&gt;
&lt;p&gt;Object lifetime awareness is a design pattern for writing robust software. It begins by acknowledging that in garbage collected languages there tends to be widespread uncertainty with respect to the lifetime of objects, which results in bugs that are very difficult to troubleshoot and fix. While the garbage collector would ideally be taking care of a lot of things, by its nature it cannot take care of everything, and in practice it often does not even take care of things that it is expected to, due to subtle human error.&lt;/p&gt;
&lt;p&gt;The impetus behind object lifetime awareness is that we have had enough of this uncertainty, so we are taking matters into our own hands by establishing definitive knowledge of the lifetime of our objects and taking full control over it. When an object has an inherent notion of lifetime, this notion must always be made explicit, and handled in a certain structured and recognizable manner, so that when mistakes occur, we receive hard errors and diagnostic messages, allowing us to fix problems without troubleshooting in the dark.&lt;/p&gt;
&lt;p&gt;Specifically, every lifetime-aware object must do the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Encapsulate an &amp;ldquo;alive&amp;rdquo; state which:
&lt;ul&gt;
&lt;li&gt;Starts as &amp;ldquo;true&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;At some moment transitions to &amp;ldquo;false&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;Is not exposed.&lt;/li&gt;
&lt;li&gt;It can be asserted.&lt;/li&gt;
&lt;li&gt;Can be inspected with a debugger.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;On debug runs, the lifetime-aware object must respond with hard error to any attempt to invoke any of its public instance methods once its lifetime is over.&lt;/li&gt;
&lt;li&gt;On debug runs, the lifetime-aware object must discover any omission to end its lifetime, and generate a diagnostic message if so.  (More on how to achieve this later.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please note that the definition of a &amp;ldquo;debug run&amp;rdquo; varies depending on which language you are using:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In C# it is a run of the debug build.&lt;/li&gt;
&lt;li&gt;In Java it is a run with assertions enabled.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please also note that automated test runs are usually debug runs.&lt;/p&gt;
&lt;p&gt;Luckily we do not have to add lifetime awareness to all objects, we only need to add it to objects that belong to one or more of the following categories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Objects that by their nature have a concept of lifetime, such as timers, windows, files, network connections, notification suppressors, etc.&lt;/li&gt;
&lt;li&gt;Objects that once initialized, are known to have some cleanup to do eventually.&lt;/li&gt;
&lt;li&gt;Objects with which other objects may register in some way. (To ensure that each object that registers does not forget to unregister.)&lt;/li&gt;
&lt;li&gt;Objects that contain (own) other lifetime-aware objects.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In each system the objects that can benefit from lifetime awareness tend to be relatively few, while the majority of objects can continue being blissfully unaware of their lifetime, letting the garbage collector handle it.&lt;/p&gt;
&lt;p&gt;In certain rare cases, a lifetime-aware object may control its own lifetime; however, far more often, the lifetime of an object is meant to be controlled by other objects. In these cases, the lifetime-aware object should implement the disposal interface of the language, primarily in order to document the fact that it is lifetime-aware, and secondarily so that the &amp;ldquo;automatic&amp;rdquo; disposal mechanism of the language can be used when the opportunity arises.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In Java, that would be an object implementing the &lt;code&gt;Closeable&lt;/code&gt; interface, thus allowing us to sometimes make use of the &lt;code&gt;try-with-resources&lt;/code&gt; statement.&lt;/li&gt;
&lt;li&gt;In C#, that would be the an object implementing the &lt;code&gt;IDisposable&lt;/code&gt; interface, thus allowing us to sometimes make use of the &lt;code&gt;using&lt;/code&gt; keyword.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please note that the use of these interfaces here has nothing to do with releasing unmanaged resources;  The goal is object lifetime awareness, while the releasing of unmanaged resources is at best a side note and largely a red herring in this discussion. It is true that the original intention of these interfaces was to allow releasing unmanaged resources, but there is absolutely nothing, either in the interfaces themselves, or in the language specifications, or in the respective compilers, or in the respective runtime environments, which says that this has to be the only purpose of these interfaces, or the only way they should be used, or the only way they can be used. So, here we are using them for something else. Please completely disregard the issue of unmanaged resources for now, we will address them later.&lt;/p&gt;
&lt;p&gt;By making objects aware of their own lifetime, we achieve the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Any discrepancy between an object&amp;rsquo;s expected alive state and its actual alive state (i.e. whether we think it should be alive vs. whether it actually is alive) can be asserted against and therefore be swiftly and infallibly detected without any need for white-box testing.&lt;/li&gt;
&lt;li&gt;The alive state of an object can be explicitly and deterministically controlled without ever having to rely on finalization to do it for us.&lt;/li&gt;
&lt;li&gt;All necessary cleanup can be done when the alive state transitions to false, thus ensuring that each initialization action is always balanced by its corresponding cleanup action. This includes ending the lifetime of any contained (owned) objects, unregistering the object from whatever it had previously registered with, etc.&lt;/li&gt;
&lt;li&gt;At the end of the object&amp;rsquo;s lifetime we can take whatever extra measures are within our power to take in order to ensure that the lifetime of other objects is being correctly managed. For example, we can assert that any objects which had previously registered with this object have by now unregistered themselves.&lt;/li&gt;
&lt;li&gt;More broadly, we construct our software to be in complete control over its inner workings, instead of leaving things to chance.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;&#34;&gt;
&lt;/h4&gt;&lt;h4 id=&#34;detecting-omissions&#34;&gt;Detecting omissions
&lt;/h4&gt;&lt;p&gt;The main thing which makes object lifetime awareness a viable proposition is the promise of useful diagnostic messages in response to omissions to explicitly end the lifetime of objects. Without such diagnostic messages, object lifetime awareness would not be much different from existing practices.&lt;/p&gt;
&lt;p&gt;Interestingly enough, (or perversely enough, depending on how you would like to see it,) the mechanism that we leverage in order to detect such omissions is the garbage collector itself. The idea is that an object can check during finalization whether it is still alive or not: if it discovers that it is being finalized while still alive, then this means that the programmer forgot to explicitly end the lifetime of the object at an earlier moment.&lt;/p&gt;
&lt;p&gt;It is very important to note that once we detect that an object is still alive during finalization, we specifically refrain from repeating the widespread mistake of trying to correct the problem: we most certainly do not attempt to end the lifetime of the object at that moment; instead, we only generate a diagnostic message, alerting the programmer that they forgot to end the lifetime of the object at an earlier time. This is important because the checks performed during finalization are meant to be of a strictly diagnostic nature, (a quality assurance mechanism if you wish,) so they are only meant to be performed on debug runs, so our software better be working correctly without them on release runs.&lt;/p&gt;
&lt;p&gt;One might protest that an object which has accidentally become a memory leak will never be finalized, so it will never discover that its lifetime was not ended. Luckily, this can be taken care of with a bit of infrastructural support and a bit of discipline: During application shutdown we ensure that our system undergoes an orderly and thorough cleanup phase, where all remaining lifetime-aware objects are terminated. Typically, this simply means ending the lifetime of the main application object, and this should cascade throughout the entire containment hierarchy, ending the lifetime of all objects. Once this cleanup phase is complete, and if this is a debug run, we force a full garbage collection, and we wait for it to complete before exiting the application. In doing so, we ensure that all finalizers are invoked, and this includes the finalizers of any objects that were inadvertently memory-leaked. Thus, any omission to end the lifetime of an object is detectable in the worst case during application shutdown. For this to work optimally, some extra discipline is necessary, for example avoiding to directly or indirectly anchor lifetime-aware objects in static storage.&lt;/p&gt;
&lt;p&gt;In actual practice most omissions to control the lifetime of objects happen without the objects necessarily also becoming memory-leaked, so the objects do get garbage-collected, so the omissions are detected at various moments during runtime when garbage collection occurs. For this reason, it is beneficial on debug runs to introduce regular forced garbage collection, thus detecting omissions as soon as possible after they happen. The right moment to force garbage collection tends to be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On web servers, immediately after servicing each client request.&lt;/li&gt;
&lt;li&gt;On desktop applications, immediately after each application logic idle event.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(An application logic idle event is similar to the graphical user interface idle event, except that it happens less frequently, i.e. not after every single event from the input system such as a mouse move, but only after the application logic has actually had some work to do.)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On data processing systems with a main loop, at the end of each iteration of the main loop.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is worth stressing that forced garbage collection only needs to be employed as a diagnostic tool, and only on debug runs. On release runs there is never a need to force garbage collection because all object lifetime control issues are presumed to have already been addressed.&lt;/p&gt;
&lt;p&gt;Forced garbage collection can also be used as a diagnostic tool during automated software testing; however, if our tests are fine-grained, (as the case usually is with unit tests,) it is advisable to refrain from forcing garbage collection after each test, because a full run of the garbage collector tends to be expensive, so its frequent use may multiply the total run time of a test suite by a very large factor. The ideal is to perform just one forced garbage collection at the end of all tests, and if any object lifetime control failures are detected, then and only then do another run of all tests with forced garbage collection enabled after each test, to detect precisely in which tests the failures occur.&lt;/p&gt;
&lt;p&gt;In order to force garbage collection at will during testing, one needs a testing framework which supports this, and I am not aware of any, but if you do not make use of any exotic features of your existing testing framework, it is easy to write your own and take control yourself.&lt;/p&gt;
&lt;h4 id=&#34;addendum-lifeguards&#34;&gt;Addendum: Lifeguards
&lt;/h4&gt;&lt;p&gt;For an object to be aware of its own lifetime and to issue diagnostic messages when its lifetime is not properly controlled, a certain amount of functionality is needed, and we do not want to be coding this functionality by hand in each class that we write, so we will be delegating as much of the work as possible to a separate class. An appropriate name for such a class would be &lt;code&gt;ObjectLifetimeGuard&lt;/code&gt;, but this is a mouthful, so we will simply abbreviate it to &lt;code&gt;LifeGuard&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The lifeguard exposes only 2 methods:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A lifetime-assertion method which is invoked to assert that the lifeguard is still alive.&lt;/li&gt;
&lt;li&gt;An end-of-lifetime method which is invoked to let the lifeguard know that its lifetime is over.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With the introduction of the lifeguard, each lifetime-aware class only needs to do the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Obtain during construction, and fully encapsulate, an instance of &lt;code&gt;LifeGuard&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Perform an assertion at the beginning of each public instance method, (by definition only on debug runs, since it is an assertion,) which simply delegates to the lifetime-assertion method of the lifeguard.&lt;/li&gt;
&lt;li&gt;Implement the object disposal interface of the language at hand, performing whatever cleanup actions are necessary, and then delegating to the end-of-lifetime method of the lifeguard.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The lifeguard does the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On debug runs, it encapsulates an &lt;code&gt;alive&lt;/code&gt; state which starts as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;It implements the is-alive-assertion method as follows:
&lt;ul&gt;
&lt;li&gt;On debug runs, it returns &lt;code&gt;true&lt;/code&gt; if the object is alive, and throws an exception if not.&lt;/li&gt;
&lt;li&gt;On release runs, it always throws an exception, because it is only meant to be invoked from within assertions, and assertions are not meant to execute on release runs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;It implements the end-of-lifetime method as follows:
&lt;ul&gt;
&lt;li&gt;On debug runs, it first asserts that the object is currently alive, and then transitions the alive state to false.&lt;/li&gt;
&lt;li&gt;On release runs, it does nothing.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;On debug runs it defines a finalizer which checks whether the object is still alive during finalization, and generates a diagnostic message if so.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A lifeguard is obtained by invoking a factory method instead of using the &lt;code&gt;new&lt;/code&gt; keyword, because this method will return something different depending on whether this is a debug run or a release run. The factory can come in the form of a &lt;code&gt;static&lt;/code&gt; method for simplicity, or it can come in some other form if necessary.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The interface of the lifeguard has been designed in such a way that its alive state can be asserted without being exposed. This has the effect of:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Preventing misuse&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Allowing for a high performance implementation for release runs which does not even contain that state.&lt;/li&gt;
&lt;li&gt;Still allowing the alive state to be inspected with a debugger on debug runs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lifetime-aware objects that have a need for some similar state which is queryable must implement it separately. The fact that on debug runs this state will be mirroring the &lt;code&gt;alive&lt;/code&gt; state of the lifeguard is irrelevant.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In certain environments which support asynchronous method invocations it might be impossible to guarantee that no method is ever invoked past end of lifetime; these are exceptions to the rule, which need special handling by means of &lt;code&gt;if&lt;/code&gt; statements instead of assertions. Since the lifeguard only allows asserting the alive state without exposing it, such objects will need to implement their own &lt;code&gt;alive&lt;/code&gt; state in parallel to the lifeguard.&lt;/li&gt;
&lt;li&gt;As a rule, triggering hard error is preferable over generating diagnostic messages; however, an omission to end the lifetime of an object can only be detected during finalization, and by that time it is already too late for any fail-fast measures, so what we have here is an exception to the rule: in this particular case, it is okay if we just generate a diagnostic message. If needed, extra measures can be taken to alert the programmer to not forget to look at the diagnostic messages.&lt;/li&gt;
&lt;li&gt;The diagnostic message generated in the event of an omission to end the lifetime of an object is meant to include a stack trace, complete with source filenames and line numbers, showing precisely where in the source code the object was allocated, to help us easily locate and fix the problem.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unfortunately, this stack trace needs to be collected by the lifeguard during construction, just in case it will need to be displayed during finalization, but in many environments collecting a stack trace is unreasonably expensive, so if each lifeguard instantiation was to involve collecting a stack trace, this would run the danger of slowing down our debugs runs to the point of making them unusable. (Obtaining a stack trace with source filenames and line numbers a few dozen times per second incurs a noticeable penalty on the JVM, while under DotNet the penalty is catastrophically more severe.)&lt;/p&gt;
&lt;p&gt;For this reason, a special procedure is necessary: by default, stack traces are not collected, so a lifeguard which detects an omission to end the lifetime of an object reports only enough information to help us identify the class of the containing object. Once we know the class, we can go to the source code and flip a flag which enables stack trace collection for lifeguards of that specific class only, so that we can then re-run and obtain a message which includes a stack trace. Once we have solved the problem, we put the flag back to its default value to avoid the performance hit.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Both in C# and in Java there is an established tradition which says that methods involved in the closing or disposing of things should be forgiving, in the sense that multiple invocations should be permitted with no penalty. In my opinion this practice is ill-conceived, so instead I prescribe an end-of-lifetime method which asserts that it is never invoked twice. This is in line with the overall theme of object lifetime awareness, which is to gain greater control over the inner workings of our software. I am perfectly aware of the fact that this is parting ways with a tradition cherished by the entire industry; it is perfectly fine to part ways with traditions when you know better, especially since another term for tradition is &amp;ldquo;capricious progress-stopper&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;The lifeguard is designed in such a way that on release runs it contains no state and performs no action; therefore, it need not be instantiated once per lifetime-aware object; instead, it can be a singleton, and all lifetime-aware objects can receive the same reference to its one and only dummy instance. Thus, the performance cost of using the lifeguard on release runs is near zero.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An implementation of lifeguard in C# is as follows:&lt;/p&gt;
&lt;p&gt;#nullable enable&lt;/p&gt;
&lt;p&gt;using Sys = System;&lt;/p&gt;
&lt;p&gt;using Collections = System.Collections.Generic;&lt;/p&gt;
&lt;p&gt;using System.Linq;&lt;/p&gt;
&lt;p&gt;using SysDiag = System.Diagnostics;&lt;/p&gt;
&lt;p&gt;using SysComp = System.Runtime.CompilerServices;&lt;/p&gt;
&lt;p&gt;public abstract class LifeGuard : Sys.IDisposable&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;p&gt;public static LifeGuard Create( bool collectStackTrace = false, //&lt;/p&gt;
&lt;p&gt;[SysComp.CallerFilePath] string? callerFilePath = null, //&lt;/p&gt;
&lt;p&gt;[SysComp.CallerLineNumber] int callerLineNumber = 0 )&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;p&gt;if( !DebugMode )&lt;/p&gt;
&lt;p&gt;return ProductionLifeGuard.Instance;&lt;/p&gt;
&lt;p&gt;Assert( callerFilePath != null );&lt;/p&gt;
&lt;p&gt;if( collectStackTrace )&lt;/p&gt;
&lt;p&gt;return new VerboseDebugLifeGuard( 1 );&lt;/p&gt;
&lt;p&gt;return new TerseDebugLifeGuard( callerFilePath!, callerLineNumber );&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;public abstract void Dispose();&lt;/p&gt;
&lt;p&gt;public abstract bool IsAliveAssertion();&lt;/p&gt;
&lt;p&gt;private sealed class ProductionLifeGuard : LifeGuard&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;p&gt;public static readonly ProductionLifeGuard Instance = new ProductionLifeGuard();&lt;/p&gt;
&lt;p&gt;private ProductionLifeGuard() { } //nothing to do&lt;/p&gt;
&lt;p&gt;public override void Dispose() { } //nothing to do&lt;/p&gt;
&lt;p&gt;public override bool IsAliveAssertion()&lt;/p&gt;
&lt;p&gt;=&amp;gt; throw new Sys.Exception(); //never invoke on a release build&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;private class DebugLifeGuard : LifeGuard&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;p&gt;private bool alive = true;&lt;/p&gt;
&lt;p&gt;private readonly string message;&lt;/p&gt;
&lt;p&gt;protected DebugLifeGuard( string message )&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;p&gt;this.message = message;&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;public sealed override void Dispose()&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;p&gt;Assert( alive );&lt;/p&gt;
&lt;p&gt;alive = false;&lt;/p&gt;
&lt;p&gt;System.GC.SuppressFinalize( this );&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;public sealed override bool IsAliveAssertion()&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;p&gt;Assert( alive );&lt;/p&gt;
&lt;p&gt;return true;&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;protected static string GetSourceInfo( string? filename, int lineNumber )&lt;/p&gt;
&lt;p&gt;=&amp;gt; $&amp;quot;{filename}({lineNumber})&amp;quot;;&lt;/p&gt;
&lt;p&gt;~DebugLifeGuard()&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;p&gt;SysDiag.Debug.WriteLine( &amp;ldquo;Object still alive!&amp;rdquo; );&lt;/p&gt;
&lt;p&gt;SysDiag.Debug.WriteLine( message );&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;public override string ToString() =&amp;gt; alive ? &amp;quot;&amp;quot; : &amp;ldquo;END-OF-LIFE&amp;rdquo;;&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;private sealed class TerseDebugLifeGuard : DebugLifeGuard&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;public TerseDebugLifeGuard( string callerFilePath, int callerLineNumber )&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;base( $&amp;quot;    {GetSourceInfo( callerFilePath, callerLineNumber )}&amp;quot; )&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;{ }&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;private sealed class VerboseDebugLifeGuard : DebugLifeGuard&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;public VerboseDebugLifeGuard( int framesToSkip )&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;base( buildMessage( framesToSkip + 1 ) )&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;{ }&lt;/p&gt;
&lt;p&gt;private static string buildMessage( int framesToSkip )&lt;/p&gt;
&lt;p&gt;=&amp;gt; string.Join( &amp;ldquo;\r\n&amp;rdquo;, getStackFrames( framesToSkip + 1 ) //&lt;/p&gt;
&lt;p&gt;.Select( getSourceInfoFromStackFrame ) );&lt;/p&gt;
&lt;p&gt;private static SysDiag.StackFrame[] getStackFrames( int framesToSkip )&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;p&gt;var                  stackTrace = new SysDiag.StackTrace( framesToSkip + 1, true );&lt;/p&gt;
&lt;p&gt;SysDiag.StackFrame[] frames     = stackTrace.GetFrames()!;&lt;/p&gt;
&lt;p&gt;Sys.Type             type       = frames[0].GetMethod().DeclaringType;&lt;/p&gt;
&lt;p&gt;Assert( typeof(Sys.IDisposable).IsAssignableFrom( type ) );&lt;/p&gt;
&lt;p&gt;return frames.
Where( f =&amp;gt; f.GetFileName() != null ) //&lt;/p&gt;
&lt;p&gt;.ToArray();&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;private static string getSourceInfoFromStackFrame( SysDiag.StackFrame frame )&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;p&gt;string sourceInfo = GetSourceInfo( frame.GetFileName(), frame.GetFileLineNumber() );&lt;/p&gt;
&lt;p&gt;return $&amp;quot;    {sourceInfo}: {frame.GetMethod().DeclaringType}.{frame.GetMethod().Name}()&amp;quot;;&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;Note that in theory, &lt;code&gt;private readonly string message&lt;/code&gt; may have already been finalized by the time the destructor attempts to use it. In reality, I have never encountered this happening. If it becomes a problem, a simple &lt;code&gt;string.Intern()&lt;/code&gt; could be used to permanently anchor these strings in memory, and that is okay despite the fact that it essentially introduces a memory leak, because it is only applicable to debug runs.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;DebugMode&lt;/code&gt; is defined as follows:&lt;/p&gt;
&lt;p&gt;public static bool DebugMode&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;p&gt;get&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;p&gt;#if DEBUG&lt;/p&gt;
&lt;p&gt;return true;&lt;/p&gt;
&lt;p&gt;#else&lt;/p&gt;
&lt;p&gt;return false;&lt;/p&gt;
&lt;p&gt;#endif&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;This allows us to minimize the use of &lt;code&gt;#if DEBUG&lt;/code&gt;, which is ugly and cumbersome, and often results in code rot in the &lt;code&gt;#endif&lt;/code&gt; part, which is only discoverable when trying to compile the release build.&lt;/p&gt;
&lt;h4 id=&#34;addendum-ad-hoc-alive-states&#34;&gt;Addendum: Ad-hoc alive states
&lt;/h4&gt;&lt;p&gt;Object lifetime awareness comes with a piece of advice:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Avoid ad-hoc alive states, implement them as separate lifetime-aware objects instead.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;What this means is that a class should refrain from exposing a pair of methods for entering and exiting some special state of that class, and instead it should expose only one method which creates a new lifetime-aware object to represent that special state, and to exit the state when its lifetime is ended. Then, if the class has any methods which may only be invoked while in that special state, these methods must be moved into the special state object, so that they are not even available unless the special state has been entered.&lt;/p&gt;
&lt;p&gt;By following this advice we split the interface of our object into smaller interfaces that are more simple and intuitive, we clearly document what is going on by making use of the lifetime-awareness pattern, and we take advantage of the error-checking and diagnostic facilities of the lifetime-awareness mechanism.&lt;/p&gt;
&lt;p&gt;An example of an interface which could have benefited from this advice is the JDBC API. This interface exposes a multitude of methods for dealing with a relational database, and among them it exposes a pair of methods for beginning and ending a transaction. A better way of structuring that interface would have been to expose a single method for creating a new transaction object, which in turn ends the transaction when disposed. Then, all the data manipulation methods would be moved into that object, so that it is impossible to manipulate data unless a transaction is active.&lt;/p&gt;
&lt;h4 id=&#34;addendum-unmanaged-resources&#34;&gt;Addendum: Unmanaged Resources
&lt;/h4&gt;&lt;p&gt;As we have shown, by leveraging hard error and diagnostic messages on debug runs and test runs, the object lifetime awareness pattern guarantees cleanup at the end of an object&amp;rsquo;s lifetime.&lt;/p&gt;
&lt;p&gt;Conveniently enough, this cleanup can, and should, include the releasing of unmanaged resources.&lt;/p&gt;
&lt;p&gt;This in turn means that we never need to involve finalization for this task, not even as a fallback mechanism: unmanaged resources can be released infallibly, deterministically, and synchronously, i.e. &lt;em&gt;always right now,&lt;/em&gt; as opposed to at some unknown moment later in time, if at all.  This also means that on release runs we do not need finalization at all.&lt;/p&gt;
&lt;p&gt;In essence, the releasing of unmanaged resources loses the special status that it has enjoyed so far, and becomes regular cleanup just as any other kind of cleanup. Our software sees to it that all necessary cleanup is always performed, without leaving anything to chance, and without any distinctions between really important cleanup and not-so-important cleanup.&lt;/p&gt;
&lt;p&gt;C#-only note: This also means that there is no more need for that &lt;code&gt;Dispose(bool)&lt;/code&gt; nonsense, either.&lt;/p&gt;
&lt;h4 id=&#34;further-research-and-recommendations&#34;&gt;Further research and recommendations
&lt;/h4&gt;&lt;p&gt;Lifetime aware objects may benefit from a lifetime control service being propagated throughout the containment hierarchy so that they can register and unregister from it, thus:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Eliminating the need for a static factory of lifeguard;&lt;/li&gt;
&lt;li&gt;Allowing us to at any given moment traverse the entire graph of lifetime-aware objects to see who is still alive;&lt;/li&gt;
&lt;li&gt;Making it impossible to inadvertently construct a lifetime-aware object without having explicit knowledge of the fact that it is lifetime-aware, since the lifetime control service must be passed to its constructor.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Object lifetime awareness has the theoretic potential of completely eliminating all finalization overhead. Unfortunately, as things stand today, this potential cannot be realized, because existing runtime environments still offer essential classes that make unconditional use of finalization; e.g. classes that represent files, sockets, etc. These environments could benefit from new implementations of such essential classes that make use of the object lifetime awareness pattern so as to also avoid finalization. (While at it, please also note that these same classes could really benefit from not being needlessly multithreading-aware; when we have a use for multithreading awareness, we can add it ourselves, thank you.)&lt;/p&gt;
&lt;p&gt;Additionally, if it could be definitively established that finalization is to be used only for the purpose of generating diagnostic messages, then the entire machinery implementing finalization in runtime environments could be greatly simplified from the monster of complexity that it is today. Consider, for example, that garbage collectors are currently built to handle such preposterous situations as &amp;ldquo;object resurrection&amp;rdquo;, which is what may happen if a finalizer decides to anchor an object in memory, thus taking an object which had previously become eligible for collection and making it not eligible anymore. If finalization could be made trivial, then object resurrection could become impossible, or it could result in hard error rather than having to be handled.&lt;/p&gt;
&lt;p&gt;Also see my previous post &lt;a 
   href=&#34;//localhost:1313/post/2015-03-on-dispose-bool-disposing-abomination/&#34;
   &gt;Mandatory disposal vs. the &amp;ldquo;Dispose-disposing&amp;rdquo; abomination&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: &lt;em&gt;The Thinker&lt;/em&gt; (French: &lt;em&gt;Le Penseur&lt;/em&gt;) by Auguste Rodin (From &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/The_Thinker&#34; target=&#34;_blank&#34;
   &gt;Wikipedia&lt;/a&gt;)&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;The language feature that C# calls &amp;ldquo;destructor&amp;rdquo; is a misnomer; it is not a destructor, it is a finalizer, and the choice of the tilde syntax to denote finalizers in C# as if they were C++ destructors has caused nothing but confusion. Microsoft has been reluctantly &lt;a class=&#34;external&#34; 
   href=&#34;https://docs.microsoft.com/en-us/archive/blogs/ericlippert/whats-the-difference-between-a-destructor-and-a-finalizer&#34; target=&#34;_blank&#34;
   &gt;acknowledging this&lt;/a&gt; and quietly &lt;a class=&#34;external&#34; 
   href=&#34;https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/destructors&#34; target=&#34;_blank&#34;
   &gt;correcting their terminology&lt;/a&gt; in their documentation.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>Coherence: The Assertable Lock</title>
        <link>//localhost:1313/post/2020-12-12-coherence/</link>
        <pubDate>Sat, 12 Dec 2020 13:51:31 +0000</pubDate>
        
        <guid>//localhost:1313/post/2020-12-12-coherence/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2020-12-12-coherence/media/coherence.jpg&#34;
	width=&#34;1280&#34;
	height=&#34;853&#34;
	srcset=&#34;//localhost:1313/post/2020-12-12-coherence/media/coherence_hu_774fdb15a774b77.jpg 480w, //localhost:1313/post/2020-12-12-coherence/media/coherence_hu_d8603833f9d0eb32.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;360px&#34;
	
&gt;
&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract
&lt;/h3&gt;&lt;p&gt;A Software Design Pattern for concurrent systems is presented, which makes race conditions something that can be asserted against and thus &lt;strong&gt;deterministically eliminated&lt;/strong&gt; rather than stochastically reduced or minimized.&lt;/p&gt;
&lt;h3 id=&#34;a-description-of-the-problem&#34;&gt;A description of the problem
&lt;/h3&gt;&lt;p&gt;Every Software Engineer who has dealt with concurrency knows that it is hard. The bane of concurrency is race conditions: when a thread accesses data without taking into account the fact that the data is shared with other concurrently running threads which may alter that data at any unforeseeable moment in time.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading:  &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;There exist two kinds of race conditions that I can think of, let&amp;rsquo;s call them &lt;em&gt;&lt;strong&gt;physical&lt;/strong&gt;&lt;/em&gt; and &lt;em&gt;&lt;strong&gt;logical&lt;/strong&gt;&lt;/em&gt;. (I just made up these terms, perhaps they have already been studied and given other names, but I am unaware of that.)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Physical Race Conditions&lt;/strong&gt; happen due to the way the underlying hardware works. One example is trying to read a variable consisting of who machine words, thus requiring two successive read operations which are not atomic, while another thread is simultaneously writing to that variable, resulting in garbage being read. Another example is two threads simultaneously performing increment operations on the same memory location, where a memory increment is implemented by the CPU as a non-atomic sequence of read-increment-write operations, resulting in some of the increments being lost.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Logical Race Conditions&lt;/strong&gt; happen when application logic fails to account for concurrency. For example, checking whether a collection contains a value, and if not, adding the value to the collection: when two threads try to do this, it will sometimes happen that they will both find that the collection does not contain the value in question, and will both add it, resulting in a duplicate. Depending on whether the implementation of the collection allows duplicates or not, this will result either in soft malfunction, (a duplicate where it was not intended,) or in hard failure due to the collection throwing a &amp;ldquo;duplicate element&amp;rdquo; exception.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that logical race conditions can occur even if we have taken all necessary precautions (i.e. locking) to avoid physical race conditions. Incidentally, this is the reason why many of the so-called &amp;ldquo;concurrent&amp;rdquo; collections like the &amp;ldquo;concurrent map&amp;rdquo; are of very limited use: sure, they guarantee that they will not crash and burn, but they do not guarantee correct results.&lt;/p&gt;
&lt;p&gt;Race conditions exhibit a disastrous combination of unfortunate qualities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Non-deterministic:&lt;/strong&gt; you cannot reproduce them at will, they just appear to happen at random, so you can almost never use the debugger to troubleshoot them.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sensitive to troubleshooting instrumentation:&lt;/strong&gt; not only they never manifest while single-stepping through code, but if you introduce extra code to detect them, they may seemingly disappear, because they are highly dependent on timing. The moment you remove the instrumentation however, they may start manifesting again.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Elusive:&lt;/strong&gt; their effects are usually observed not at the moment that they occur but after the fact, so it is difficult to tell what happened and why it happened.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Confusing:&lt;/strong&gt; sometimes, the malfunction that they cause seems at first impossible to happen, requiring extensive troubleshooting before the realization sinks in that it must be due to a race condition.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-faced:&lt;/strong&gt; in many cases the effects of a race condition differ on each manifestation, so you are never sure whether you are chasing one issue or several issues at the same time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Untestable:&lt;/strong&gt; there is no unit test that can catch race conditions or give any assurances for their absence.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Treacherous:&lt;/strong&gt; a race condition which happens on average once every million seconds of usage may take months before it manifests in your development environment, and yet once there are a million customers using your software, there will be one customer encountering it roughly every second.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Catastrophic:&lt;/strong&gt; program state corruption tends to result in complete failure of the software.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;solutions-that-try-to-avoid-the-problem&#34;&gt;Solutions that try to avoid the problem
&lt;/h3&gt;&lt;p&gt;Since concurrency with locks is so hard, a number of mechanisms have been invented that try to implement concurrency without locking.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Immutability (functional programming):&lt;/strong&gt; if all program state is immutable, then there is no possibility of one thread modifying some state while another thread is trying to read it, because there is no state that can be modified. Therefore, no locking is necessary.&lt;/p&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Functional programming and immutability are not ubiquitous, and it is yet to be seen whether they will ever become ubiquitous.&lt;/li&gt;
&lt;li&gt;Many implementations of Functional Programming are not purely functional, they mix mutability with immutability, so the problem remains.&lt;/li&gt;
&lt;li&gt;Functional programming is only common in high-level systems running on garbage-collecting virtual machines. It is rare in mid-level systems and virtually absent in low-level systems.&lt;/li&gt;
&lt;li&gt;Many of the data structures that give the illusion of mutability while their inner workings are immutable tend to be computationally more expensive than their straightforward mutable counterparts.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Message-passing:&lt;/strong&gt; threads never share any data, instead they only work on data that they exclusively own, and they exchange data by means of immutable messages passed through message queues. Essentially, in the entire system there is only one little piece of code which employs locking, and that is the concurrent message queue implementation. The idea is that we should be able to get at least that small part right.&lt;/p&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Performance suffers as the amount of data exchanged among threads increases.&lt;/li&gt;
&lt;li&gt;Performance also suffers since data can never be manipulated in-place, it must be placed in a message, the message must be posted into a queue, a thread context switch must usually occur for the receiving thread to process the message, and then the reverse path must be followed for the original thread to receive the result. (When manipulating data in-place, a thread context switch will only occur when attempting to obtain a lock while another thread already holds that lock, which may be a rare occurrence.)&lt;/li&gt;
&lt;li&gt;Nowadays in order to avoid the tedious creation of countless message classes you are more likely to just post a lambda into the message queue, but then you have a lambda which is declared in one thread but executed in another thread, so you still have to be extremely careful with what that lambda is allowed to touch.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Other:&lt;/strong&gt; exotic mechanisms such as the single-writer principle of the Rust programming language.&lt;/p&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;They tend to require compiler support. (So, a mechanism that can be implemented in any language would still be of value.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, avoiding race conditions when practicing concurrency by means of locking is an existing problem in need of a solution.&lt;/p&gt;
&lt;h3 id=&#34;a-deeper-look-at-the-problem&#34;&gt;A deeper look at the problem
&lt;/h3&gt;&lt;p&gt;At the heart of the race condition problem lies the &amp;ldquo;to lock or not to lock&amp;rdquo; conundrum. The choice of what to do lies in a continuum between two absurd extremes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Ultra-fine grain locking:&lt;/strong&gt; Always lock every single little piece of mutable state when accessing it, and only while accessing it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ultra-coarse grain locking:&lt;/strong&gt; Place a global lock on the entirety of your mutable state on program start and release it on program exit.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Obviously, neither of these extreme approaches would work.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ultra-fine grain locking would result in an unreasonable amount of bloat in
all code that we write, it would suffer performance-wise, and although it
would eliminate physical race conditions, it would do nothing for
logical race conditions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ultra-coarse grain locking would not work either because increasing the
lifetime of a lock also increases the chances that other threads will be
blocked, with the absurd extreme of the lock lifetime being equal to program
runtime resulting in all threads becoming permanently blocked and no actual
sharing of any mutable state ever taking place.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, the answer to the &amp;ldquo;to lock or not to lock&amp;rdquo; conundrum always lies somewhere in-between:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Always lock for as long as necessary, but try not to lock any longer than necessary.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This leads to the number one cause of race conditions:&lt;/p&gt;
&lt;p&gt;Trying to lock for as long as necessary but to avoid locking longer than necessary means that there will always be code which is accessing mutable state without first acquiring a fine grain lock, and instead is &lt;em&gt;&lt;strong&gt;assuming&lt;/strong&gt;&lt;/em&gt; that a coarser grain lock has already been acquired by some other code higher up the call-tree. (Remember, computer science trees are upside-down.) This assumption leaves open the possibility of human error, as the programmer who wrote the code higher up the call-tree may have forgotten to lock, thus putting all code below it at risk of race conditions.&lt;/p&gt;
&lt;p&gt;This situation is so widespread that it may be hard to realize its full extent: every single time we invoke a standard runtime library mutable collection class (which is one of the most frequent things we do) we are engaging in this assumption: the collection is not concurrency aware, so it is not placing any locks, but it is manipulating mutable state, so under conditions of concurrency it will fail unless a lock is in place. Essentially, the collection class is doing its job while &lt;em&gt;praying&lt;/em&gt; that someone up the call tree has remembered to acquire the necessary lock.&lt;/p&gt;
&lt;p&gt;The grain of locks affects two things: performance and correctness.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Choosing the grain of the locks in the most performant way is more of an art than a science, requiring a master of the craft to do it right, and that is okay: experts will always be useful. If no expert is available, performance might end up being suboptimal, but the software will still run, so strictly speaking the expert is not necessary.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Choosing the grain of the locks in such a way that the program remains correct is also more of an art than a science as things stand today, so it also requires a master of the craft to do it right; however, if we want to be thinking of our profession as a science rather than an art, we cannot have software that tends to crash and burn unless a master of the craft has written it. Therefore, we need a mechanism for detecting and protecting ourselves against the human error which is practically inevitable when an apprentice rather than a master touches the code, or even when the master touches the code while having a bad day.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;restating-the-problem&#34;&gt;Restating the problem
&lt;/h3&gt;&lt;p&gt;A very important first step in solving a problem often is to restate it
using terminology that is more conducive to solving it. The term &amp;ldquo;Race
Condition&amp;rdquo; is somewhat cumbersome because it refers to an unfortunate event
which may or may not happen, depending on non-deterministic
circumstances. The original 1954 paper by David Huffman, titled &amp;ldquo;The synthesis of sequential switching circuits&amp;rdquo;, which contains the
first known mention of the term, regards race conditions as something which
may exist when a certain instability is detected, so even the original sense referred to events that may potentially occur.&lt;/p&gt;
&lt;p&gt;However, if we care about software correctness, then we do not want to be leaving anything to chance, so the fact that the unfortunate event &lt;em&gt;&lt;strong&gt;may&lt;/strong&gt;&lt;/em&gt; happen is irrelevant: if circumstances can arise at all which would potentially allow a race condition to occur, then for all practical purposes it must be assumed that the race condition &lt;em&gt;&lt;strong&gt;will&lt;/strong&gt;&lt;/em&gt; occur. Therefore, the race conditions themselves should be of no interest to us; what should be of interest is modes of operation that allow race conditions to occur. We will call them Race Modes.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A &lt;strong&gt;Race Mode&lt;/strong&gt; is an erroneous mode of operation in which a race condition can potentially occur.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A piece of software either enters race modes, or it does not. If it does enter race modes, then race conditions may occur, and as already established, it should be presumed that they will occur. If the software never enters any race modes, then no race conditions can occur.&lt;/p&gt;
&lt;p&gt;So, the problem has been restated from &amp;ldquo;avoiding race conditions&amp;rdquo; to &amp;ldquo;avoiding race modes&amp;rdquo;.  The difference may be subtle, but it is important enough to make.&lt;/p&gt;
&lt;h3 id=&#34;the-solution&#34;&gt;The solution
&lt;/h3&gt;&lt;p&gt;In restating the problem as described above we have set ourselves a new goal: how to assert against race modes. If race modes can be asserted against, then the concurrency problem stops being subject to chance and becomes quite deterministic instead: if our software runs and no assertion failures occur, then it never enters a race mode, and therefore no race conditions are possible. (Note that the assertions are not meant to catch race conditions; the assertions are meant to catch race modes.)&lt;/p&gt;
&lt;p&gt;The mechanism that I have come up with for asserting against race modes is called &lt;em&gt;&lt;strong&gt;Coherence&lt;/strong&gt;&lt;/em&gt; and in its simplest form it can be thought of as an abstraction of an &lt;em&gt;Assertable Lock&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;There are two things you can do with coherence: enter it, and assert it. (By entering coherence we mean executing a piece of code while in coherence, so once that piece of code is done executing, coherence will be exited.) So, coherence gives us the ability to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Take measures at certain places in our code to prevent entering a race mode.&lt;/li&gt;
&lt;li&gt;Ensure in all other places in our code that the necessary measures have been taken to guarantee we are not in a race mode.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thus, coherence saves us from doing ultra-fine grain locking and from making assumptions about locking: by turning locks into something assertable, we do not have to acquire a lock every single time we touch mutable state, but we can assert that a lock has been acquired by code higher up the call tree. Since assertions can compile to nothing on the release build, this is a zero-runtime-cost solution.&lt;/p&gt;
&lt;p&gt;The name Coherence was chosen as opposed to Assertable Lock because Coherence is meant to be a high level abstraction. The use of an abstraction is necessary for two reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Coherence is meant to be asserted ubiquitously by any code that accesses mutable state, even by general purpose code such as the standard collection classes. However, general purpose code tends to be (and should remain) agnostic of concurrency, so it should not be burdened with such a low-level and concurrency-specific concept as locking.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Depending on the concurrency characteristics of the execution environment, there can be different implementations of coherence, some of which do not even involve actual locking, so using the term &amp;lsquo;Lock&amp;rsquo; would be inaccurate and misleading.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples of possible coherence implementations depending on the concurrency characteristics of the execution environment:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In a strictly single-threaded environment, a dummy implementation is needed which never places any locks and never fails a coherence check.&lt;/li&gt;
&lt;li&gt;In a share-nothing environment, a simple implementation will suffice which never places any locks and only fails a coherence check if the currently executing thread is not the thread that owns the mutable state, i.e. the thread in which the mutable state was created.&lt;/li&gt;
&lt;li&gt;In a thread-pooled, share-nothing environment, a somewhat more elaborate implementation is needed which takes into account the fact that the thread which owns the mutable state may not necessarily be the thread that created the mutable state, since threads are picked from a pool.&lt;/li&gt;
&lt;li&gt;In a multi-threaded environment with a small amount of shared state, a singular locking implementation will suffice which enters coherence by obtaining a lock on the totality of the shared state and fails the coherence check when that lock has not been obtained. This represents a coarse grain lock, so it might result in sub-optimal performance, but it has the advantage of being simple and avoiding deadlocks.&lt;/li&gt;
&lt;li&gt;In a multi-threaded environment with a large amount of shared state and high thread contention over it, necessitating finer grain locking for good enough performance, a plural coherence implementation can be used which allows placing independent locks on independent subsets of the shared state, and fails a coherence check when the lock corresponding to a particular subset of state has not been obtained. Care must be exercised to always enter and assert the correct instance of coherence for each subset of state, and to avoid deadlocks in doing so.&lt;/li&gt;
&lt;li&gt;Regardless of the concurrency characteristics of the execution environment, when the lifetime of a certain piece of mutable state is confined within a single call tree, a simple coherence implementation will again suffice which does not place a lock and simply asserts that the current thread is the thread in which the state was created. (To guard against the mutable state somehow escaping the scope of the call tree in which it was meant to be confined.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that Coherence only allows asserting its state and purposefully disallows testing its state. In other words, you cannot have an &amp;ldquo;if coherence is entered then&amp;hellip;&amp;rdquo; construct. This is done so as to prevent misuse and to allow for high performance coherence implementations that, on the release build, may not have explicit knowledge of whether coherence has been entered or not.&lt;/p&gt;
&lt;p&gt;Note that unlike most existing locking mechanisms, which explicitly allow a thread to obtain a lock multiple times, coherence explicitly disallows re-entrance. I have chosen to do it this way because my approach to Software Engineering is &amp;ldquo;leave nothing to chance&amp;rdquo;, so if you are unsure whether you have already obtained a lock on something, and you would like the locking mechanism to be forgiving in case you try to lock twice, then you must be doing something wrong. It is my firm belief that when a piece of framework is in a position of alerting you that you are doing something wrong, it should be alerting you that you are doing something wrong.  Of course it may be that I am wrong here, and unbeknownst to me there exist legitimate reasons for having to allow coherence reentrancy; this remains to be seen.&lt;/p&gt;
&lt;h3 id=&#34;further-research&#34;&gt;Further Research
&lt;/h3&gt;&lt;p&gt;As mentioned earlier, in multi-threaded environments with a large amount of shared state and high thread contention over it, performance concerns often necessitate dividing the state into subsets and having an individual lock for each subset, so that different subsets can be locked independently of each other.&lt;/p&gt;
&lt;p&gt;Unfortunately, when we do this, we run the danger of entering deadlocks, and as it stands, the plural coherence implementation, which is suitable for these scenarios, does not address the issue of deadlocks.&lt;/p&gt;
&lt;p&gt;Some research is necessary to determine whether the plural coherence implementation could do any of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Detect a deadlock once it happens and provide diagnostic information.&lt;/li&gt;
&lt;li&gt;Detect a deadlock once it happens and somehow take corrective measure.&lt;/li&gt;
&lt;li&gt;Detect the possibility of deadlocks and alert the programmer by means of hard error.&lt;/li&gt;
&lt;li&gt;Be structured in such a way as to make deadlocks impossible.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Cover image by reginasphotos from pixabay.com&lt;/p&gt;</description>
        </item>
        <item>
        <title>Domain Oriented Programming</title>
        <link>//localhost:1313/post/2020-06-26-domain-oriented-programming/</link>
        <pubDate>Fri, 26 Jun 2020 18:46:47 +0000</pubDate>
        
        <guid>//localhost:1313/post/2020-06-26-domain-oriented-programming/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2020-06-26-domain-oriented-programming/media/DomainOrientedProgramming.png&#34;
	width=&#34;1253&#34;
	height=&#34;783&#34;
	srcset=&#34;//localhost:1313/post/2020-06-26-domain-oriented-programming/media/DomainOrientedProgramming_hu_46f0896593c4ea4d.png 480w, //localhost:1313/post/2020-06-26-domain-oriented-programming/media/DomainOrientedProgramming_hu_80495cb7faae492e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;384px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;A Software Design Pattern which brings the principles of Inheritance, Encapsulation and Polymorphism one level up from the Class level to the Subsystem level, and offers a way of realizing relationships between classes so as to achieve dependency inversion by means of propagation instead of injection.&lt;/p&gt;
&lt;h3 id=&#34;part-1-dependency-inversion&#34;&gt;Part 1: Dependency Inversion
&lt;/h3&gt;&lt;p&gt;The software that we write often invokes other software to get parts of the job done. These are known as &lt;em&gt;&lt;strong&gt;Services&lt;/strong&gt;&lt;/em&gt; or &lt;em&gt;&lt;strong&gt;Dependencies&lt;/strong&gt;&lt;/em&gt;. If Class A is making use of some Class B, then Class A depends on Class B, so Class B is a dependency of Class A.&lt;/p&gt;
&lt;p&gt;The principle of &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Dependency_inversion_principle&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;&lt;strong&gt;Dependency Inversion&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt; says that a class should not contain any direct calls to specific instances of any of its dependencies. Instead, it should receive these instances as parameters during initialization.&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s all very nice, but passing dependencies around can become quite a complicated business, and in large systems it can become a nightmare.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Various mechanisms have been devised for solving this problem. Two that I know of are &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Service_locator_pattern&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;&lt;strong&gt;Service Locators&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt;, and &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Dependency_injection&#34; target=&#34;_blank&#34;
   &gt;&lt;strong&gt;Dependency Injection Frameworks&lt;/strong&gt;&lt;/a&gt;. Unfortunately, each of them has some serious disadvantages.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Service Locators&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A service locator is a mandatory global dependency. That&amp;rsquo;s a bad thing to have. At some point you will want to reuse a module in a different system, and that service locator will not be available there, and you will have to start rewriting stuff. Trust me, you will sooner or later regret having it.&lt;/li&gt;
&lt;li&gt;A service locator may defer compile-time errors to run-time errors. These errors occur when a system is being wired together, but tests are usually wired up differently, so these errors cannot be detected with unit testing or integration testing, you have to do end-to-end testing in order to discover them.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Dependency Injection Frameworks&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;They work by magic, and I don&amp;rsquo;t like magic.&lt;/li&gt;
&lt;li&gt;They tend to embrace silent failure, while I mandate hard failure.&lt;/li&gt;
&lt;li&gt;They don&amp;rsquo;t have an API that you can call, so you cannot use code completion, you have to know stuff by heart.&lt;/li&gt;
&lt;li&gt;They tend to make application startup time slow as molasses, while I like application startup to be snappy.&lt;/li&gt;
&lt;li&gt;They are also a mandatory global dependency.&lt;/li&gt;
&lt;li&gt;The individual class is a much too fine-grained unit to be applying dependency injection onto.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In my 35 years of programming I have encountered the problem of dependency injection a lot, and in the last decade or so I have started solving it with a paradigm that I call &lt;em&gt;&lt;strong&gt;Domain Oriented Programming&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Note that Domain Oriented Programming does not have any direct relation to &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Domain-driven_design&#34; target=&#34;_blank&#34;
   &gt;&lt;strong&gt;Domain Driven Design&lt;/strong&gt;&lt;/a&gt;, although it may be a suitable pattern to use when implementing systems designed using the Domain Driven Design paradigm.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Introducing Domain Oriented Programming (DOP)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Domain Oriented Programming Design Pattern can be roughly described as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Classes do not exist in a vacuum; instead, every class has a special relationship with another class by which it is instantiated and from which it obtains its dependencies. The class doing the instantiation and providing dependencies is called &lt;em&gt;&lt;strong&gt;Domain&lt;/strong&gt;&lt;/em&gt;, the instantiated class is called &lt;em&gt;&lt;strong&gt;Subject.&lt;/strong&gt;&lt;/em&gt; Sometimes a class can be Subject to multiple Domains, more on that later.&lt;/li&gt;
&lt;li&gt;Every Subject has specific knowledge of its Domain.&lt;/li&gt;
&lt;li&gt;In some cases Domains also have specific knowledge of their Subjects, and in some cases they do not, more on that later.&lt;/li&gt;
&lt;li&gt;A Domain contains references to all services that are used by itself and by all of its Subjects; so, when a Subject needs to use some service, it obtains the service from its Domain. Therefore, dependencies do not need to be injected into Subjects.&lt;/li&gt;
&lt;li&gt;The Domain-Subject relation is hierarchical, so a Subject of one Domain may in turn be Domain to other Subjects. This way, dependencies are propagated from the root of a system all the way down to the leaf nodes without the need to use any special framework to achieve this.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The domain-subject relation can exist in two forms: &lt;em&gt;&lt;strong&gt;Closed (a.k.a. Realm)&lt;/strong&gt;&lt;/em&gt; and &lt;em&gt;&lt;strong&gt;Open (a.k.a. Free)&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Closed (a.k.a. Realm) Domains
&lt;ul&gt;
&lt;li&gt;The Domain is the one and only Domain for its Subjects. It is passed to each Subject as its first constructor parameter.&lt;/li&gt;
&lt;li&gt;The Domain has complete control over the lifetime of its Subjects. This means that the Domain is the exclusive factory of its Subjects, and can also decide when and if a Subject is destroyed.&lt;/li&gt;
&lt;li&gt;The Domain and its Subjects are &lt;em&gt;&lt;strong&gt;Closely Coupled.&lt;/strong&gt;&lt;/em&gt; This means that not only the Subjects have specific knowledge of their Domain, but also the Domain has specific knowledge of its Subjects. (Close coupling is perfectly okay as long as the Domain limits itself to acting as a factory and the Realm is kept small.)&lt;/li&gt;
&lt;li&gt;Subjects are usually exposed to the outside world as interfaces rather than as objects.&lt;/li&gt;
&lt;li&gt;The Realm forms a coherent, closed group which cannot be extended without modifying the Domain class.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Open (a.k.a. Free) Domains
&lt;ul&gt;
&lt;li&gt;The Domain does not have specific knowledge of any Subjects, it only exists for the purpose of making dependencies available to other Domains.&lt;/li&gt;
&lt;li&gt;Open Domains are usually provided as interfaces rather than as actual objects.&lt;/li&gt;
&lt;li&gt;A Subject of Open Domains can be freely instantiated as long as all the domains necessary for its instantiation are available. It can also be freely disposed.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are a few interesting things to notice here:&lt;/p&gt;
&lt;p&gt;The Domain is to a Subject what the Object is to a Method. Hopefully a DOP oriented language will be introduced one day which realizes the DOP construct in its grammar, making the Domain reference implicit, just as in Object Oriented Programming the Object reference is always the implicit first parameter to every Method.&lt;/p&gt;
&lt;p&gt;(Incidentally, Java and other languages are already doing something along these lines with non-static &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Inner_class&#34; target=&#34;_blank&#34;
   &gt;inner classes&lt;/a&gt;, but we do not want to have to nest the source code of each Subject within the source code of its Domain, especially since a Domain may in turn be Subject of another Domain.)&lt;/p&gt;
&lt;p&gt;Domain Oriented Programming does not require any platform or library: it is just a way of structuring code. So, with DOP, no omnipresent framework is needed for injecting dependencies, and no magic is involved in their propagation; nobody needs to query any service locators for services, (the availability of services is practically guaranteed by the compiler,) and no huge lists of dependencies are passed to constructors, either. Still, at various places where domains are constructed and wired together, all necessary services are supplied, so any one of them can be replaced with a &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Test_double&#34; target=&#34;_blank&#34;
   &gt;&lt;em&gt;&lt;strong&gt;Test Double&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Furthermore, Domain Oriented Programming is interoperable with non-DOP systems: A group of classes making use of DOP among themselves can be introduced into a system which is already using some other mechanism of Dependency Inversion.&lt;/p&gt;
&lt;p&gt;At first glance, Domain Oriented Programming can be thought of as employing something like &lt;em&gt;Half-Way Dependency Injection,&lt;/em&gt; or &lt;em&gt;&lt;strong&gt;Subsystem-level Dependency Injection&lt;/strong&gt;&lt;/em&gt; as opposed to &lt;em&gt;&lt;strong&gt;Class-level Dependency Injection&lt;/strong&gt;&lt;/em&gt;. Dependencies are injected into the Domain, and from that moment on Subjects of the Domain can go ahead and fetch their dependencies from the Domain as needed, instead of having their dependencies injected into them.&lt;/p&gt;
&lt;p&gt;Things become even more interesting when we consider Domains that are in turn Subjects of other Domains, forming a hierarchy of Domains, where at each level we have &lt;em&gt;&lt;strong&gt;SuperDomains&lt;/strong&gt;&lt;/em&gt; and &lt;em&gt;&lt;strong&gt;SubDomains&lt;/strong&gt;&lt;/em&gt;. In this scenario, we do not exactly have Dependency Injection going on anymore, because at each level dependencies are obtained from the level above; however, we still have Dependency Inversion, because dependencies are still not hard-coded in any way, and each Domain has control over each service that it makes available to its subjects, and may, if needed, decide which particular implementation will offer it.&lt;/p&gt;
&lt;p&gt;The lesson to learn from this is that Dependency Injection was never a goal in and of itself; the goal has been Dependency Inversion, (avoiding hard-coded dependencies, &lt;em&gt;Dependency Independence&lt;/em&gt; if you will permit the pun,) and Dependency Injection has been a mechanism for achieving it, but the same goal can be achieved by other means, such as &lt;em&gt;&lt;strong&gt;Dependency Propagation&lt;/strong&gt;&lt;/em&gt;, which is what Domain Oriented Programming offers.&lt;/p&gt;
&lt;h3 id=&#34;part-2-object-orientation-at-the-subsystem-level&#34;&gt;Part 2: Object Orientation at the Subsystem Level
&lt;/h3&gt;&lt;p&gt;Domain Oriented Programming is not only about Dependency Propagation. It reflects the realization that Software being created today is immensely more complex than what it used to be back when Object Oriented Programming was invented and the first Object Oriented languages were laid down, about half a century ago.&lt;/p&gt;
&lt;p&gt;It used to be that all we needed was a means of coupling groups of functions with the data that they operate on, and that Inheritance, Encapsulation and Polymorphism were only necessary at the class-and-method level; however, as we build more elaborate software, we find ourselves more and more thinking not so much in terms of classes and methods, but in terms of subsystems and classes, or systems and subsystems. Therefore, there appears to be a need for terminology which brings Inheritance, Encapsulation and Polymorphism one level up, to the subsystem level, and by recursive application, to the entire system.&lt;/p&gt;
&lt;p&gt;Domain Oriented Programming offers the Domain as the unit upon which to apply the principles of Object Oriented Programming.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In DOP the Domain is the principal polymorphic unit, providing an implementation for a complex interface, and instantiating subjects to polymorphically implement smaller scope interfaces.&lt;/li&gt;
&lt;li&gt;In DOP the Domain encapsulates its subjects, hiding their nature and lifetime from the outside world.&lt;/li&gt;
&lt;li&gt;In DOP inheritance is only utilized among Subjects, while the Domain hides from the outside world the fact that it is being utilized.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My first public mention of this concept was in &lt;a class=&#34;external&#34; 
   href=&#34;https://softwareengineering.stackexchange.com/a/304041/41811&#34; target=&#34;_blank&#34;
   &gt;this answer of mine on Software Engineering Stack Exchange.&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>On Validation vs- Error Checking</title>
        <link>//localhost:1313/post/2020-05-30-on-validation-vs-error-checking/</link>
        <pubDate>Sat, 30 May 2020 17:33:41 +0000</pubDate>
        
        <guid>//localhost:1313/post/2020-05-30-on-validation-vs-error-checking/</guid>
        <description>&lt;p&gt;Let me start with a couple of pedantic definitions; stay with me, the beef follows right afterwards.&lt;/p&gt;
&lt;p&gt;Conventional wisdom says that validation is different from error checking.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Validation&lt;/strong&gt; is performed at the boundaries of a system, to check the validity of incoming data, which is at all times presumed to be potentially invalid. When invalid data is detected, validation is supposed to reject it. Validation is supposed to be always on, you cannot switch it off on release builds and only have it enabled on debug builds.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Error checking&lt;/strong&gt;, on the other hand, is performed inside a system, checking against conditions that should never occur, to keep making sure that everything is working as intended. In the event that an error is encountered, the intent is to signal a catastrophic failure. Essentially, the term &lt;em&gt;Error Checking&lt;/em&gt; is shorthand for &lt;em&gt;&lt;strong&gt;Internal&lt;/strong&gt; Error Checking.&lt;/em&gt; It can be implemented using assertions, thus being active on the debug build only, and having a net cost of &lt;em&gt;&lt;strong&gt;zero&lt;/strong&gt;&lt;/em&gt; on the release build.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So far so good, right?&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Well, the problem with this conventional view of validation vs error checking is that it heavily relies on the notion of &amp;ldquo;system boundaries&amp;rdquo;, which is not a well-defined notion.  Unless you are an application programmer, whatever you are building will in all likelihood be a subsystem of a larger system, and that system will in turn be a subsystem of an even larger system, and so on. Therefore, what you think of as the boundaries of your system will never be the actual boundaries of the actual system. You cannot have any claim to knowledge of the boundaries of any system that might incorporate your little creation as a component of it.&lt;/p&gt;
&lt;p&gt;As a reaction to this uncertainty, most programmers maintain a self-centered view of the component they are developing as &lt;em&gt;&lt;strong&gt;the&lt;/strong&gt;&lt;/em&gt; system, and a short-sighted view of the boundaries of their component as &lt;em&gt;&lt;strong&gt;the&lt;/strong&gt;&lt;/em&gt; system boundaries. So, on those boundaries they keep doing validation.&lt;/p&gt;
&lt;p&gt;Here is what&amp;rsquo;s wrong with that:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Your subsystem will be embedded in a larger system, which will be doing its best to always supply your subsystem with valid data. This larger system will be tested by its creators, and will be known to work correctly. This means that it will always supply your system with valid data, so your validation will be useless, and it will just be wasting time on the release build.&lt;/li&gt;
&lt;li&gt;The validation results returned by your boundary methods will have to somehow be dealt with by the containing system, since ignoring results is considered a terrible practice, even when nothing is expected to go wrong. So, you are forcing the caller to litter their code with checks for your validation results.&lt;/li&gt;
&lt;li&gt;However, since the caller does not expect anything to go wrong, they will not be able to do anything other than throw an exception in the event that you return a validation failure result. So, not only you are forcing the caller to litter their code with checks for validation results, but these checks in turn will never be triggered. Think about it: this is code that will never be covered by any coverage run.&lt;/li&gt;
&lt;li&gt;Even in the extremely unlikely event that the containing system will in fact supply your component with invalid input, triggering the scenario where your component returns a validation failure result, and the containing system throws, this is virtually indistinguishable from the scenario where you simply just throw in the first place, as part of your error checking, not validation. So, there is no need for you to return some validation result, no need for the caller to check it, no need for the caller to throw.&lt;/li&gt;
&lt;li&gt;To put it in simple words, &lt;em&gt;&lt;strong&gt;a subsystem&amp;rsquo;s validation failure is a supersystem&amp;rsquo;s internal error&lt;/strong&gt;&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So, what the above means is that the entire industry is doing it wrong. Nothing but the outermost layer of a system should be performing validation, and that&amp;rsquo;s usually some application-specific integration layer. Subsystems should, at most, and as a convenience, offer free-standing validation facilities which may be utilized by enclosing layers as part of their own validation.&lt;/p&gt;
&lt;p&gt;So, for example, the enclosing system might, in the context of its own validation strategy, ensure that every field in a form has been filled-in, and then it might invoke the date-time subsystem&amp;rsquo;s validation mechanism to verify that the value entered in some date-time field is valid, before feeding that value to that same subsystem, or storing it for feeding it to that subsystem later.&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s because only the component which is dealing with the form knows that the information that it receives is coming from the user and therefore needs validation.  Once this information has passed validation and accepted into the system, it should never be re-validated.  Any inconsistency after that point is an internal error of the system, and therefore a hard error.&lt;/p&gt;</description>
        </item>
        <item>
        <title>What is wrong with Full Stack Development</title>
        <link>//localhost:1313/post/2021-12-full-stack-development/</link>
        <pubDate>Sun, 01 Apr 2018 14:37:37 +0000</pubDate>
        
        <guid>//localhost:1313/post/2021-12-full-stack-development/</guid>
        <description>&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;img src=&#34;//localhost:1313/post/2021-12-full-stack-development/media/tag-blogger.com,1999-blog-3494795920779884230.post-79094073589883987961.jpg&#34;
	width=&#34;408&#34;
	height=&#34;639&#34;
	srcset=&#34;//localhost:1313/post/2021-12-full-stack-development/media/tag-blogger.com,1999-blog-3494795920779884230.post-79094073589883987961_hu_755c7da92bba20ac.jpg 480w, //localhost:1313/post/2021-12-full-stack-development/media/tag-blogger.com,1999-blog-3494795920779884230.post-79094073589883987961_hu_ac4b783d13bec49.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;63&#34;
		data-flex-basis=&#34;153px&#34;
	
&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;Inntel Hotel at Amsterdam, Zaandam&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;table-of-contents&#34;&gt;Table of Contents
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;What is full-stack development&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Why is full-stack development necessary today&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What is wrong with full-stack development&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Conclusion&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(Useful pre-reading:
&lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h4 id=&#34;what-is-full-stack-development&#34;&gt;What is full-stack development
&lt;/h4&gt;&lt;p&gt;The predominant web application development model today requires splitting
application logic in two parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The front-end, running on the browser.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The back-end, running on the server.&lt;/p&gt;
&lt;p&gt;The front-end is typically written in JavaScript, while the back-end is
typically written in Java, Scala, C#, or some other programming language. The
two ends invariably communicate with each other via REST. The choice of
JavaScript and REST is not due to any technical merit inherent in these
technologies, (there is none,) but purely due to historical accident; see
&lt;a 
   href=&#34;//localhost:1313/post/2020-10-19-the-wild-wild-web/&#34;
   &gt;The Wild, Wild Web&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A web application developer can either focus on one part of the stack, or work
on both parts. Due to reasons that will be explained further down, more often
than not, web developers are asked to work on both parts simultaneously. When
this happens, it is known as full-stack development.&lt;/p&gt;
&lt;p&gt;For the purposes of this paper, we will call full-stack development not just
this mode of work, but also this architectural style as a whole: full-stack
development is when application logic must be written both on the server and
on the client.&lt;/p&gt;
&lt;p&gt;Full-Stack Development is a paradox, since it suggests a way of work which is
contrary to what common sense dictates. Common sense calls for specialists
each working on their own area of specialization, so one would expect to see
different developers focusing on different layers of the stack, and nobody
ever attempting something as preposterous as working on all layers
simultaneously. However, there is a technological hurdle which renders this
necessary today.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;why-is-full-stack-development-necessary-today&#34;&gt;Why is full-stack development necessary today
&lt;/h4&gt;&lt;p&gt;Normally, (outside of web application development,) in a system that consists
of multiple layers, only one of the layers tends to be application-specific,
while all other layers tend to be general purpose infrastructure layers that
are agnostic of any application that might put them to use. Under such an
arrangement, the functionality offered by each layer is dictated by what makes
sense for that layer to be doing, so the work to be done at each layer tends
to be rather self-contained and straightforward. In this scenario, each
specialist can indeed work on the layer that they specialize in.&lt;/p&gt;
&lt;p&gt;However, in web development we have a server, and we have a client, and so far
we have been unable to find a solution that would allow us to confine all of
our application logic to only one of them. (There have been some attempts in
that direction, but they were only moderately successful, and virtually none
of them survived the transition from monolithic architectures to microservices
architectures.) As a result, in modern web applications, both layers are
application-specific.&lt;/p&gt;
&lt;p&gt;In the early days people did try to apply specialization and division of labor
to web application development, and they found that when all the layers are
application-specific, collaboration between teams working on different layers
suffers, resulting in low productivity. There are too many details that have
to be agreed upon by people working on different layers; too much waiting for
the guys working on the layer below to finish their part before the guys
working on layer above can do their job; too much disagreement as to whose
fault it is when the system is not working as expected; in general, too much
back and forth, too much friction.&lt;/p&gt;
&lt;p&gt;For this reason, full-stack development was invented: instead of dividing the
workforce horizontally, it ends up being less inefficient to divide them
vertically: when each developer works on a different feature of the product
from top to bottom, they do not have to interact too intensively with other
developers, and this represents a gain which seems to offset the loss of not
having specialists working on their respective areas of specialization.&lt;/p&gt;
&lt;h4 id=&#34;what-is-wrong-with-full-stack-development&#34;&gt;What is wrong with full-stack development
&lt;/h4&gt;&lt;p&gt;In brief, full-stack development has the following disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The front-end:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Has limited capabilities.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Is confined within the sand-boxed execution environment of the browser.&lt;/li&gt;
&lt;li&gt;Admittedly, browsers today are pretty feature-rich, (actually,
monstrously so,) but still, you are writing code which is running out
there, on browsers, and is therefore out of your control, instead of
here, on the server, where you do have control.&lt;/li&gt;
&lt;li&gt;So, there are always things that you would like to accomplish, but you
cannot on the client, so you have to suffer the additional bureaucracy
of having the client communicate what you are trying to accomplish to
the server, having the server do it for you, and receiving the results
back on the client. That?s an awful lot of work for something as simple
as, say, obtaining the current date and time regardless of client
configuration or misconfiguration.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Suffers from incidental complexity.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Peculiarities of the browser environment such as URLs, HTML, the DOM,
HTTP, REST, Ajax, etc.&lt;/li&gt;
&lt;li&gt;Cross-browser incompatibilities and cross-browser-version
incompatibilities.&lt;/li&gt;
&lt;li&gt;Security hazards.
&lt;ul&gt;
&lt;li&gt;Code on the client must not only accomplish application goals, but it
must do so while avoiding various commonly known and not-so-commonly
known security pitfalls.&lt;/li&gt;
&lt;li&gt;Each time a new security hazard is discovered by the security
community, vast amounts of application code must be meticulously
audited and painstakingly fixed.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Must be re-written on each targeted format (web, mobile, desktop.)&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;When targeting a new format besides the web (e.g. desktop, mobile) we
have to re-engineer not only the presentation markup, but also all of
the application logic which is inextricably mangled with it.&lt;/li&gt;
&lt;li&gt;This necessitates the creation and maintenance of multiple separate code
bases that largely duplicate the functionality of each other.&lt;/li&gt;
&lt;li&gt;These code bases are liable to diverge, thus causing user workflows and
overall user experience to unwantedly differ across formats.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Is usually written in a scripting language.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;The code is error-prone due to scripting languages being untyped.&lt;/li&gt;
&lt;li&gt;The code is hard to maintain due to untyped languages being impervious
to refactoring.&lt;/li&gt;
&lt;li&gt;The code is messy due to scripting languages invariably being inferior
to real programming languages.&lt;/li&gt;
&lt;li&gt;The code is transmitted in source code form to the browser, thus
exposing potentially sensitive intellectual property.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Is usually written in JavaScript in particular.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;JavaScript was originally intended for no more than a few, tiny, and
isolated snippets of code per HTML page. The haphazardness of the
language design reflects this intention. However, modern web
applications tend to contain tens of thousands of lines of
application-specific JavaScript. That is an awful lot of code in a
language which is defective by design.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Excludes artists.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Artists are prevented from actively participating in the creation and
maintenance of web pages, because HTML is inextricably mangled with
JavaScript, so they cannot touch it.&lt;/li&gt;
&lt;li&gt;Thus, artists are resigned to creating mock-ups showing how they want
web pages to look like, and programmers are then tasked with making the
web pages look like the mockups. (As if the programmers did not already
have enough in their hands.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The back-end:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Is inextricably tied to REST&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;This is because REST is impervious to abstraction.&lt;/li&gt;
&lt;li&gt;REST forces reliance on binding-by-name, which undermines the coherence
of the entire system and prevents static code analysis, invariably
resulting in a big unknown chaos.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Duplicates part of the client-side application logic.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;This is necessary in order to perform validation on the server-side too,
because from a security standpoint the client must always be considered
compromised.&lt;/li&gt;
&lt;li&gt;This translates to additional development and maintenance cost.&lt;/li&gt;
&lt;li&gt;Inevitable discrepancies between the validation done on the client and
the validation done on the server are a continuous source of bugs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The application as a whole:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Is split in two parts.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Usually having each part written in a different programming language.&lt;/li&gt;
&lt;li&gt;Having &lt;em&gt;The Internet&lt;/em&gt; interjected between the two parts.&lt;/li&gt;
&lt;li&gt;Having the point of split dictated not by business considerations, but
by technological limitations instead.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mixes application with presentation.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;A fundamental principle of graphical user interface application
development is that application logic should be kept completely separate
from presentation logic. This principle warns against inadvertently
allowing application logic to bleed into the presentation layer;
however, with full-stack development we have application logic not just
&lt;em&gt;bleeding&lt;/em&gt; to the presentation layer, but actually
&lt;em&gt;embarking on a massive deliberate large-scale exodus&lt;/em&gt; to the
presentation layer.&lt;/li&gt;
&lt;li&gt;One might naively think that full-stack development accomplishes
separation by keeping application logic on the server and presentation
logic on the client, but this is demonstrably not so:
&lt;ul&gt;
&lt;li&gt;The server is largely reduced to a bunch of dumb REST endpoints that
perform not much more than Create, Read, Update, Delete, List (CRUDL)
operations with validation. That is not application logic; that&amp;rsquo;s
mostly just querying and updating the data store.&lt;/li&gt;
&lt;li&gt;The client not only decides how things should look, but it also
decides what options should be available to the user at any moment,
and what new options will become available to the user as a result of
user actions. Essentially, all application workflows are implemented
on the client. That&amp;rsquo;s application logic
&lt;em&gt;par excellence&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Is hard to test.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;The front-end is not functional without the back-end, so the two ends
usually have to be tested in integration, necessitating such
monstrosities as Selenium.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prevents specialization and division of labor.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Full-stack development necessitates &lt;em&gt;The Full-stack Developer&lt;/em&gt;, who
is:
&lt;ul&gt;
&lt;li&gt;a front-end programmer,&lt;/li&gt;
&lt;li&gt;a back-end programmer,&lt;/li&gt;
&lt;li&gt;a network programmer,&lt;/li&gt;
&lt;li&gt;a security expert,&lt;/li&gt;
&lt;li&gt;a user experience expert,&lt;/li&gt;
&lt;li&gt;an accessibility expert, and&lt;/li&gt;
&lt;li&gt;a graphic artist&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt;  ? all rolled into one, thus running the risk of being a
  *jack of all trades, master of none*.
&lt;/code&gt;&lt;/pre&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h4&gt;&lt;p&gt;By its nature, web application development requires systems that consist of
multiple layers; the current state of affairs is such that
application-specific code must be running on each of these layers, and this is
called full-stack development. However, as I have shown, full-stack
development has a list of disadvantages which is rather extensive, and each of
these disadvantages is rather severe.&lt;/p&gt;
&lt;p&gt;Essentially, we are suffering the consequences of a technological limitation:
we currently have no means of confining all application logic to the server,
so we have to be placing application logic on the client too, so we have no
option but to be engaging in full-stack development.&lt;/p&gt;
&lt;p&gt;Technological limitations require technological solutions, but companies with
commercial goals do not usually take it upon themselves to solve the world&amp;rsquo;s
technological problems. Instead, they tend to make do with the existing
problems, providing non-technological workarounds to them, such as throwing
more manpower into the development effort. This might make sense for each
individual company, but from a global perspective, we have collectively been
&lt;em&gt;too busy mopping the floor to turn off the faucet.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A solution that would confine all application logic to the server and thus
eliminate full-stack development has the potential of being very beneficial to
the industry as a whole.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//localhost:1313/images/images/blog.michael.gr/content/post/generated/2021/2021-12-full-stack-development/images/grumpy-cat-full-stack-development-i-hate-it.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;
&lt;/p&gt;</description>
        </item>
        <item>
        <title>On Code Craftsmanship</title>
        <link>//localhost:1313/post/2018-02-code-craftsmanship/</link>
        <pubDate>Mon, 05 Feb 2018 15:55:42 +0000</pubDate>
        
        <guid>//localhost:1313/post/2018-02-code-craftsmanship/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;//localhost:1313/post/2018-02-code-craftsmanship/media/craftsmanship-guitar.jpg&#34;
	width=&#34;2048&#34;
	height=&#34;1365&#34;
	srcset=&#34;//localhost:1313/post/2018-02-code-craftsmanship/media/craftsmanship-guitar_hu_8f8fb8bbba0d0d17.jpg 480w, //localhost:1313/post/2018-02-code-craftsmanship/media/craftsmanship-guitar_hu_14d10496d9352bee.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;360px&#34;
	
&gt;
&lt;/p&gt;
&lt;p&gt;I will try to make a list of items here, but I could probably write a book on this.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a 
   href=&#34;//localhost:1313/post/2022-11-about-these-papers/&#34;
   &gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id=&#34;assert-everything&#34;&gt;Assert everything
&lt;/h3&gt;&lt;p&gt;Assertions take care of white-box testing your code, so that automated software testing can be confined to the realm of strictly black-box testing, as it should. Assertions do not execute on release builds / production runs, so they essentially cost nothing. This means that you can go wild with them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Go ahead and assert that your array is sorted before performing binary search on it.&lt;/li&gt;
&lt;li&gt;Verify that your binary search worked correctly by comparing its result against the result of a linear search for the same item.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Yes, the time complexity of these assertions is far greater than the time complexity of the operation that they guard, and this is perfectly fine, because:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Remember, assertions do not execute on release runs, so they cost nothing.&lt;/li&gt;
&lt;li&gt;On test runs, you are not supposed to be using large amounts of data anyway. When N is small, then O(N) and even O(N&lt;sup&gt;2&lt;/sup&gt;) are not very different from O(log&lt;sub&gt;2&lt;/sub&gt;(N)), which means that even when assertions do execute, they do not matter.&lt;/li&gt;
&lt;li&gt;To the small extent that assertions might nonetheless slow you down during development, you can see it as one more reason why you, as a developer, should have a computer which is much more powerful than the computers of mere mortals &amp;ndash;er, I mean, users.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When I look at code, I don&amp;rsquo;t ask myself &amp;ldquo;should I assert that?&amp;rdquo; Instead, I ask myself &amp;ldquo;is there anything that I forgot to assert?&amp;rdquo; The idea is to assert everything that could possibly be asserted, leave nothing assertable unasserted. I call this &lt;em&gt;The Maximalistic Approach to Error Checking&lt;/em&gt;, in contrast to the predominant minimalistic approach, where programmers decide on a case by case basis whether to assert something or not, based on completely-oblivious-of-Murphy&amp;rsquo;s-law assumptions about how likely it is to go wrong, inappropriately mixed with misguided performance considerations.&lt;/p&gt;
&lt;p&gt;For more information, see &lt;a 
   href=&#34;//localhost:1313/post/2014-09-assertions-and-testing/&#34;
   &gt;Assertions and Testing&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Also note that the attention horizon of code is the function, so if function &lt;code&gt;f1()&lt;/code&gt; asserts some condition and then invokes function &lt;code&gt;f2()&lt;/code&gt;, it is perfectly fine for &lt;code&gt;f2()&lt;/code&gt; to also assert the same condition. In other words, whether something has already been asserted or not by some other function is irrelevant: each function must assert every condition that pertains to it.&lt;/p&gt;
&lt;h3 id=&#34;do-black-box-testing-avoid-white-box-testing&#34;&gt;Do black-box testing, avoid white-box testing
&lt;/h3&gt;&lt;p&gt;Heed the advice that says &lt;em&gt;test against the interface, not the implementation&lt;/em&gt;. Unit Testing is testing against the implementation, so despite the entire software industry&amp;rsquo;s addiction to it, it should be avoided. Incidentally, this means that mocking, despite being an admirably nifty trick, should never be used: if you are using mocks then you are doing white-box testing, so you are doing it wrong.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For more on why Unit Testing is white-box testing, and why white-box testing is bad, read this: &lt;a 
   href=&#34;//localhost:1313/post/2021-12-white-box-vs-black-box-testing/&#34;
   &gt;White Box vs. Black-Box Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;For more on why mocks in particular are especially bad, read this: &lt;a 
   href=&#34;//localhost:1313/post/2023-01-14-mocking/&#34;
   &gt;If you are using mock objects you are doing it wrong&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For what to use instead of mocks, read this: &lt;a 
   href=&#34;//localhost:1313/post/2022-10-testing-with-fakes/&#34;
   &gt;Testing with Fakes instead of Mocks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;For what to do instead of unit testing, read this: &lt;a 
   href=&#34;//localhost:1313/post/2022-10-incremental-integration-testing/&#34;
   &gt;Incremental Integration Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;If for some reason you &lt;em&gt;must&lt;/em&gt; do white-box testing, then you can at least avoid having to do it in code; read this: &lt;a 
   href=&#34;//localhost:1313/post/2024-04-audit-testing/&#34;
   &gt;Audit Testing&lt;/a&gt; and this: &lt;a 
   href=&#34;//localhost:1313/post/2023-01-06-collaboration-monitoring/&#34;
   &gt;Collaboration Monitoring&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;avoid-non-determinism-in-tests&#34;&gt;Avoid non-determinism in tests
&lt;/h3&gt;&lt;p&gt;Testing must be completely free from non-determinism under all circumstances. Since testing code exercises production code, this means that production code must also be free from non-determinism, or at the very least any source of non-determinism in production code must be replaceable during testing with a fake which is completely deterministic. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Never rely on the garbage-collector doing anything other than reclaiming memory; specifically, never rely on any cleanup operations being initiated by the garbage-collector. Perform all cleanup explicitly. For more information, see &lt;a 
   href=&#34;//localhost:1313/post/2020-12-27-object-lifetime-awareness/&#34;
   &gt;Object Lifetime Awareness&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Never allow any external factors such as file creation times, IP addresses resolved from DNS, etc. to enter into the tests. Fake your file-system; fake The Internet if necessary.&lt;/li&gt;
&lt;li&gt;Never use wall-clock time; always fake the clock, making it start from some arbitrary fixed origin and incrementing by a fixed amount each time it is queried.&lt;/li&gt;
&lt;li&gt;Never use random numbers; if randomness is necessary in some scenario, then fake it using a pseudo-random number generator seeded with a known fixed value. This includes all constructs that utilize randomness, for example GUIDs/UUIDs.&lt;/li&gt;
&lt;li&gt;Never allow any concurrency during testing; all components must be tested while running strictly single-threaded, or at the very least multi-threaded but in lock-step fashion.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;minimize-state-maximize-immutability&#34;&gt;Minimize state, maximize immutability
&lt;/h3&gt;&lt;p&gt;Design so that as much code as possible is dealing with data that is immutable. Re-examine every single class which contains mutable members, and many chances are you will find that it could be replaced with an immutable class. Even if not, you might discover that many of its members could be immutable.&lt;/p&gt;
&lt;p&gt;Eschew frameworks, technologies, and techniques that prevent or hinder immutability. For example, if you are using some dependency-injection (DI) facility that provides you with auto-wiring, use constructor injection &lt;strong&gt;only,&lt;/strong&gt; so that you can always store in final/readonly members. If your DI facility does not support constructor injection, throw away everything and start from scratch with one that does.&lt;/p&gt;
&lt;p&gt;Note, however, that immutability is not important in function-local variables. There is absolutely nothing wrong with function-local mutation if it serves the slightest purpose. Which brings us to the next point:&lt;/p&gt;
&lt;h3 id=&#34;do-overwrite-function-parameters&#34;&gt;Do overwrite function parameters
&lt;/h3&gt;&lt;p&gt;There exists a widespread cargo cult habit among programmers, of never overwriting the value of a parameter to a function within the function. This habit is so unquestioned that it enjoys &amp;ldquo;best practice&amp;rdquo; status, despite being completely misguided. Some languages (e.g. Scala) even prohibit it, which is deplorable. Go ahead and overwrite function parameters (if your language allows it) when the original parameter value should not be used in the remainder of the function. In doing so you are minimizing the number of variables that are in scope, and preventing accidental use of the original value.&lt;/p&gt;
&lt;p&gt;The historical origins of the practice of never overwriting function parameters are actually quite funny: some early versions of Fortran (the first programming language) used to pass everything by reference, including constants. So, if you had function F(X) which was invoked with 3 for X, and within F(X) you assigned 5 to x, then from that moment on the constant 3 would actually have the value 5 in your entire program. As a result, early computer scientists decreed that function parameters should never be reassigned. Fortran was soon fixed to correct this problem, but the advise kept being passed from generation to generation of programmers, who have been accepting it without rethinking it. This is cargo cult programming at its finest.&lt;/p&gt;
&lt;h3 id=&#34;avoid-hail-mary-local-variable-initialization&#34;&gt;Avoid &lt;em&gt;Hail-Mary Local Variable Initialization&lt;/em&gt;
&lt;/h3&gt;&lt;p&gt;Contrary to what many people falsely think of as &amp;ldquo;best practice&amp;rdquo; and &amp;ldquo;common knowledge&amp;rdquo;, you should never initialize any variable before you have a meaningful value to assign to it.  For more information, see &lt;a 
   href=&#34;//localhost:1313/post/2012-01-03-hail-mary-initialization/&#34;
   &gt;Hail-Mary Local Variable Initialization&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;avoid-b-to-a-style-conversions-use-a-from-b-style-instead&#34;&gt;Avoid b-to-a style conversions, use a-from-b style instead
&lt;/h3&gt;&lt;p&gt;When I see &lt;code&gt;A = AfromB( B )&lt;/code&gt; I can immediately tell that it looks correct, since A is on the side of A and B is on the side of B. However, when I see &lt;code&gt;B = AtoB( A )&lt;/code&gt; I have to stare at it for a little while longer before I can tell whether it is correct or not. Of course, this is a trivial example: in real-world situations, the identifiers, as well as the call chain, could be much longer and much more complicated. This is related to Joel Spolsky&amp;rsquo;s notion that &lt;a class=&#34;external&#34; 
   href=&#34;https://www.joelonsoftware.com/2005/05/11/making-wrong-code-look-wrong/&#34; target=&#34;_blank&#34;
   &gt;wrong code should look wrong&lt;/a&gt;, and it is especially important since the entire industry has traditionally been doing it in precisely the wrong way with B-to-A style conversions.&lt;/p&gt;
&lt;h3 id=&#34;avoid-yoda-conditionals&#34;&gt;Avoid &lt;em&gt;Yoda conditionals&lt;/em&gt;
&lt;/h3&gt;&lt;p&gt;This is the practice of reversing the terms around the equality operator when one of the terms is a constant. You might have seen it the following forms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;if( 5 == a )&lt;/code&gt; instead of the normal &lt;code&gt;if ( a == 5 )&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;if( &amp;quot;x&amp;quot;.equals( b ) )&lt;/code&gt; instead of the normal &lt;code&gt;if( b.equals( &amp;quot;x&amp;quot; ) )&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Don&amp;rsquo;t do this. The Principle of Least Surprise is not just violated by this construct, it is gang-raped. Plus, in doing this you are most probably engaging in the cardinal sin of &lt;em&gt;&lt;strong&gt;silent failure&lt;/strong&gt;&lt;/em&gt;. Here are the reasons often cited for using Yoda conditionals, and their rebuttals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Alleged reason #1&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Statement: It will catch accidental use of the assignment operator where the equality operator was intended.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rebuttal: Such accidental use should be impossible because your compiler or your IDE should be issuing a warning if you try to do this. If you are not receiving a warning, then you have other, much bigger problems in need of solving, i.e. using the wrong programming language, using the wrong IDE, or trying to write code without first having figured out how to enable all warnings.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Alleged reason #2&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Statement: It works even if the variable accidentally happens to be null.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rebuttal: No, it does not work; it silently fails. If you follow &lt;em&gt;offensive programming&lt;/em&gt;, the definition of &amp;ldquo;it works&amp;rdquo; is that &lt;em&gt;&lt;strong&gt;it produces correct results when given valid input, and it decisively fails when given invalid input.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So, there are two possibilities: either the variable may legitimately be  null, or it may not.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if the variable may legitimately be null, then make it evident by explicitly checking against null.&lt;/li&gt;
&lt;li&gt;if the variable may not legitimately be null, then write the code so that it will &lt;em&gt;&lt;strong&gt;not fail to fail&lt;/strong&gt;&lt;/em&gt; if the variable ever turns out to be null.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;avoid-unnecessary-braces&#34;&gt;Avoid unnecessary braces
&lt;/h3&gt;&lt;p&gt;Doing so keeps the code more compact, making more statements fit within the screen. The cargo-cult programming convention of enclosing even single-statement blocks within curly braces allegedly avoids bugs caused by trying to add a second statement to the block while forgetting to introduce curly braces.&lt;/p&gt;
&lt;p&gt;This has actually happened to me once, and the programmer who introduced the bug in my code did not even apologize, because he considered it my fault for not having provided the curly braces for him to insert his second statement in.&lt;/p&gt;
&lt;p&gt;The fact of the matter is that a decent IDE will point out such a mistake as a formatting violation, so this is not a problem today. Of course, in order to enable the IDE to point out formatting violations you must be keeping a consistent indentation style everywhere, right?   &lt;em&gt;&lt;strong&gt;Right?&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;avoid-egyptian-style-curly-braces&#34;&gt;Avoid Egyptian-style curly braces
&lt;/h3&gt;&lt;p&gt;People who use Egyptian-style curly braces essentially treat them as noise. I would very much favor a programming language where nesting is based on indentation alone, thus requiring no curly braces; unfortunately, the only such language that I know of is Python, which is a scripting language, and therefore out of the question; so, for as long as we are using programming languages that require curly braces, we have to pay attention to them and we cannot just treat them as noise; therefore, absolutely all curly braces must absolutely always be perfectly aligned; period, end of story, discussion is locked and comments are closed.&lt;/p&gt;
&lt;h3 id=&#34;minimize-flow-control-statements&#34;&gt;Minimize flow control statements
&lt;/h3&gt;&lt;p&gt;Especially the &lt;code&gt;if&lt;/code&gt; statement. If there is any opportunity to structure a piece of code so as to eliminate an &lt;code&gt;if&lt;/code&gt; statement, the opportunity should be pursued &lt;em&gt;tenaciously&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Of course, by this I do not mean replacing &lt;code&gt;if&lt;/code&gt; statements with the conditional operator ( &lt;code&gt;a ? x : y&lt;/code&gt; ); the conditional operator is nice, because it makes code more expressive and compact, but it is equivalent to an &lt;code&gt;if&lt;/code&gt; statement, so it too should be eliminated when possible.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;if&lt;/code&gt; statement can be avoided in many cases with the use of calculations, with lookup tables, with the judicious application of inheritance and polymorphism, etc.&lt;/p&gt;
&lt;h3 id=&#34;favor-one-and-only-one-way-of-doing-any-given-thing&#34;&gt;Favor one and only one way of doing any given thing
&lt;/h3&gt;&lt;p&gt;If you ask a hundred programmers to write some code that accomplishes a certain simple task, you will get a hundred different solutions. These solutions will reflect different ways of thinking, which is inevitable, but they will also reflect different coding conventions, which is entirely unnecessary. Establish conventions that minimize unnecessary differences. One easy way to achieve this is to stipulate that any construct which is optional must be omitted. For example:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Disallow extra parentheses in expressions.&lt;/p&gt;
&lt;p&gt;Unfortunately, compilers by default allow superfluous parentheses without complaining. This has fostered the development of some truly bizarre habits among programmers, such as the construct &lt;code&gt;return (x);&lt;/code&gt; which is so common that some folks are under the impression that this is the correct syntax, and that &lt;code&gt;return x;&lt;/code&gt; would constitute a syntax error. Well, guess what: &lt;code&gt;return x;&lt;/code&gt; is the correct syntax, whereas &lt;code&gt;return (x);&lt;/code&gt; contains a pair of superfluous parentheses. Configure your compiler or your code analysis tool-set to disallow unnecessary parentheses, so that all code that accomplishes the same thing looks the same.&lt;/p&gt;
&lt;p&gt;If you do this, then the tooling will also complain about parentheses that you might be using elsewhere to clarify the order in which calculations are to be performed when you are unsure about the operator precedence rules of the language. Here is what I have to say about that:&lt;/p&gt;
&lt;p&gt;Your programming language has a very specific, very well documented, and rather small set of rules that govern operator precedence; these rules are fundamental, and this programming language is your bread and butter; so, learn them. Learn them all by heart, so that you are never unsure about operator precedence, so that you never need extra parentheses for clarification.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Disallow optional keywords.&lt;/p&gt;
&lt;p&gt;In many languages, certain keywords are implied by default and can be omitted. Unfortunately, in virtually all example code out there, such keywords tend to always be included, which leads people to form the impression that they must be mandatory.&lt;/p&gt;
&lt;p&gt;For example, did you know that in C# every class is &lt;code&gt;internal&lt;/code&gt; by default? This means that you never have to say &lt;code&gt;internal class Foo { ... }&lt;/code&gt;, you can simply say &lt;code&gt;class Foo { ... }&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Furthermore, did you know that in C# every class member is &lt;code&gt;private&lt;/code&gt; by default? This means that you never have to say &lt;code&gt;private int foo() { ... }&lt;/code&gt;, you can simply say &lt;code&gt;int foo() { ... }&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Again, it is fundamental rules of the language that govern these things, which means that every programmer should know them by heart, which in turn means that nobody should be surprised to see &lt;code&gt;int foo() { ... }&lt;/code&gt;, and nobody should be wondering what the visibility of  &lt;code&gt;foo()&lt;/code&gt; is.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Disallow the &lt;code&gt;var&lt;/code&gt; keyword.&lt;/p&gt;
&lt;p&gt;If we were to mandate that two lines of code should look identical if they accomplish the same thing, we have two options: either always require the &lt;code&gt;var&lt;/code&gt; keyword, or completely disallow it.&lt;/p&gt;
&lt;p&gt;Always requiring the &lt;code&gt;var&lt;/code&gt; keyword is not an option, because in many cases the type cannot be inferred from the right hand side, so it must be specified. Thus, we are only left with the option of completely disallowing it, and that is the way to go.&lt;/p&gt;
&lt;p&gt;Furthermore, as I explain elsewhere, &amp;ldquo;absolutely any choice that makes code easier to read is absolutely always preferable over absolutely any choice that makes code easier to write&amp;rdquo;, and the &lt;code&gt;var&lt;/code&gt; keyword is a prime example of a choice which is easy to write but makes code harder to read, so we should not even be debating this.&lt;/p&gt;
&lt;p&gt;If you are not sure about the exact type of the right-hand side of an assignment, or if you do not want to be bothered with having to type it, is perfectly okay to begin with &lt;code&gt;var x = ...&lt;/code&gt;, and once you have written your entire statement you go back to the &lt;code&gt;var&lt;/code&gt; keyword, and ask your IDE to refactor it and replace it with the actual type.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;var&lt;/code&gt; keyword is only useful in type casts; I would rather say &lt;code&gt;var x = (int)y;&lt;/code&gt; than &lt;code&gt;int x = (int)y;&lt;/code&gt; however, the benefits of being able to disallow &lt;code&gt;var&lt;/code&gt; with a rule outweigh the convenience of being able to use it in type casts.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;put-the-complexity-in-the-design-not-in-the-code&#34;&gt;Put the complexity in the design, not in the code
&lt;/h3&gt;&lt;p&gt;If the code does not look so simple that even an idiot can understand it, then the code is too complex. When this happens, it usually means that shortcuts were taken in the design, which had to be compensated for with overly complex code. Make the design as elaborate as necessary so that the code can be as simple as possible. Overly complex code is usually the result of violations of the &lt;em&gt;Single Responsibility Principle.&lt;/em&gt; Which brings us to the next point:&lt;/p&gt;
&lt;h3 id=&#34;adhere-to-the-single-responsibility-principle-like-your-life-depends-on-it&#34;&gt;Adhere to the Single Responsibility Principle like your life depends on it
&lt;/h3&gt;&lt;p&gt;Often, what you &lt;em&gt;think&lt;/em&gt; of as a single responsibility can in fact be further sub-divided into a number of more fundamental responsibilities. Almost all of the code that we write performs, or can be thought of as performing, some kind of transformation, involving a certain number of participants. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;At the lowest level, an assignment operation transforms each bit of the destination variable into the corresponding bit of the source variable. Obviously it involves two participants: the source and the destination.&lt;/li&gt;
&lt;li&gt;At the highest level, a shopping web site transforms relational data and  user input into pixels on the user&amp;rsquo;s browser window and purchase orders in the logistics department. In this simplified view we have four participants, realistically we have many more.
&lt;ul&gt;
&lt;li&gt;Most transformations are of the simplest kind, involving only two participants, transforming one into the other. That&amp;rsquo;s great, that&amp;rsquo;s a single responsibility: convert A to B.&lt;/li&gt;
&lt;li&gt;Many transformations involve three participants, A, B and C, and they tend to be appreciably complex.
&lt;ul&gt;
&lt;li&gt;In some cases they can be simplified into successive operations, one to go from A to B and another to go from B to C, meaning that there were in fact two different responsibilities which were identified and realized as separate steps.&lt;/li&gt;
&lt;li&gt;However, quite often they cannot be simplified, as for example when we are converting A to C by consulting B. That&amp;rsquo;s a single responsibility which cannot be further broken down.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;All to often, people manage to involve four or more participants in a single transformation. These tend to be grotesquely complex, and they invariably constitute violations of the single responsibility principle. It goes without saying that they must be avoided at all costs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Luckily, operations that involve more than 3 participants can always be refactored into multiple successive transformations of no more than 3 participants each, by introducing intermediate participant types if necessary. (I have never heard of this being suggested by anyone before, so this could perhaps be &lt;em&gt;The Mike Nakis Postulate for Simplification&lt;/em&gt;.)&lt;/p&gt;
&lt;h3 id=&#34;refactor-at-the-slightest-indication-that-refactoring-is-due&#34;&gt;Refactor at the slightest indication that refactoring is due
&lt;/h3&gt;&lt;p&gt;Do not allow technical debt to accumulate. Avoid the situation of being &lt;em&gt;too busy mopping the floor to turn off the faucet.&lt;/em&gt; Allow a percentage of sprints to explicitly handle nothing but technical debt elimination. Do not try to spread the task of refactoring over feature development sprints, because:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The refactoring effort will not magically disappear.&lt;/li&gt;
&lt;li&gt;Focus will be diluted.&lt;/li&gt;
&lt;li&gt;Time estimations will suffer.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Managers who feel that every sprint must involve some feature development or else it does not look good on their report should be removed from their positions and be given jobs milking goats.&lt;/p&gt;
&lt;h3 id=&#34;strive-for-abstraction-and-generalization&#34;&gt;Strive for abstraction and generalization
&lt;/h3&gt;&lt;p&gt;The urge to abstract and generalize is often mistaken as having reusability as its sole aim, so it is often met with the YAGNI objection: &amp;ldquo;You Ain&amp;rsquo;t Gonna Need It&amp;rdquo;. The objection is useful to keep in mind so as to avoid over-engineering, but it should not be followed blindly, because abstraction and generalization have important inherent benefits, regardless of the promise of reusability.&lt;/p&gt;
&lt;p&gt;Every problem of a certain complexity and above, no matter how application-specific it might seem to be, can benefit from being divided into a specialized, application-specific part, and an abstract, general-purpose part. Strive to look for such divisions and realize them in the design.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The application-specific part will be simpler to write and to understand, because it will be free from the &lt;em&gt;incidental complexity&lt;/em&gt; represented by the general-purpose part.&lt;/li&gt;
&lt;li&gt;The general-purpose part will be simpler to write and to understand, because it will be implementing a self-contained abstraction that can be independently reasoned about.&lt;/li&gt;
&lt;li&gt;Also, the general-purpose part will be fully testable on its own, so you will have assurances that it works, regardless of how the application-specific part uses it, and regardless of how the application-specific part evolves over time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that the above benefits come in addition to the potential benefit of reusability.&lt;/p&gt;
&lt;p&gt;In other words, if you can choose between the following two:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;adding 5 lines of application code, vs.&lt;/li&gt;
&lt;li&gt;adding only 2 lines of application code but a whole 10 lines of infrastructure code&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;then opt for the latter, even if these 10 lines of infrastructure code are unlikely to ever be reused. Saving 3 lines of application code is worth writing an extra 10 lines of infrastructure code.&lt;/p&gt;
&lt;h3 id=&#34;use-abstraction-even-in-the-spoken-language&#34;&gt;Use abstraction even in the spoken language
&lt;/h3&gt;&lt;p&gt;People have the unfortunate tendency of using the most specific term for any given thing, rather than the most abstract term. I am not sure why people do this, perhaps it is addiction to technicality, perhaps it is trying to sound smart, but it often ends up causing miscommunication. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if your application has a settings file, and this file happens to be a json file, people are likely to form a habit of calling it &amp;ldquo;the json file&amp;rdquo; instead of &amp;ldquo;the settings file&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;if your application stores session state information in a key-value store, and that store happens to be a Redis instance, people are likely to say &amp;ldquo;send it to Redis&amp;rdquo; instead of &amp;ldquo;send it to the session state store&amp;rdquo;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Identify such unwarranted technicalisms and encourage people to switch to using the abstract terms instead. Tell them that the json file was replaced with a yaml file today, and when they all start calling it the yaml file, tell them that it is now an xml file. When they start complaining, tell them that the particular file format of the settings file is none of their business, and they should be calling it by its proper name, which is &amp;ldquo;the settings file&amp;rdquo;.&lt;/p&gt;
&lt;h3 id=&#34;avoid-false-abstractions&#34;&gt;Avoid false abstractions
&lt;/h3&gt;&lt;p&gt;Sometimes programmers give abstract names to things that are not really abstract.  For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;so-called serialization frameworks which expose details of the underlying file format, meaning that they are only capable of serializing to and from that specific file format. A serialization framework which exposes XML-specific details should not be called a &amp;ldquo;Serialization Framework&amp;rdquo;; it should be called an &amp;ldquo;XML Serialization Framework&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;in NuGet (the predominant package manager in DotNet) a version is said to consist of a version prefix and a version suffix, however the toolset interprets the two in a very specific way: the version prefix is not really a prefix, it is the actual version, and the version suffix is not really a suffix, it is a pre-release version identifier.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are examples of pretending that things are more abstract than they really are, which causes misinformation and suffering.&lt;/p&gt;
&lt;h3 id=&#34;use-domain-specific-interfaces&#34;&gt;Use domain-specific interfaces
&lt;/h3&gt;&lt;p&gt;Encapsulate third party libraries behind interfaces of your own devise, tailored to your specific application domain. Strive to make it so that any third-party library can be swapped with another product without you having to rewrite application logic.&lt;/p&gt;
&lt;p&gt;Conventional wisdom says the opposite: we have all heard arguments like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;The best code is the code you don&amp;rsquo;t write&amp;rdquo; (makes me want to invest in the business of &lt;em&gt;not writing software&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;&amp;ldquo;A third-party library will be better documented than your stuff&amp;rdquo; (presumably because documentation is a skill your developers have not mastered)&lt;/li&gt;
&lt;li&gt;&amp;ldquo;If you run into trouble with a library, you can ask for help on Stack Overflow, whereas with something you have developed in-house, you are stuck&amp;rdquo; (presumably because your developers know nothing of it, despite working with it every day.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The truth with application development is that the more you isolate the application logic from peripheral technologies, the more resilient your application logic becomes to the ever changing technological landscape, a considerable part of which is nothing but ephemeral fashions, the use of which is dictated not by actual technological merit, but by &lt;em&gt;C.V. Driven Development&lt;/em&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; instead.&lt;/p&gt;
&lt;p&gt;Incidentally, this also means one more thing:&lt;/p&gt;
&lt;h3 id=&#34;favor-libraries-over-frameworks&#34;&gt;Favor libraries over frameworks
&lt;/h3&gt;&lt;p&gt;The difference between a framework and a library is, simply speaking, that a library is something that your code invokes, whereas a framework is something that invokes your code. The problem with frameworks is that it is impossible to abstract them away behind custom interfaces; therefore, any code you write using a particular framework will forever be a prisoner of that framework: it will be extremely difficult to replace that framework with a different one without rewriting all your code.&lt;/p&gt;
&lt;h3 id=&#34;strive-for-what-is-simple-not-for-what-looks-easy&#34;&gt;Strive for what is simple, not for what looks easy
&lt;/h3&gt;&lt;p&gt;The simple often coincides with the easy, but sometimes the two are at odds with each other. Eschew languages and frameworks that provide the illusion of easiness at the expense of simplicity. The fact that a particular toolset makes &amp;ldquo;hello, world!&amp;rdquo; an easy one-liner probably means that the hundred-thousand liner that you are actually aiming for will be unnecessarily complicated and hard to write.&lt;/p&gt;
&lt;p&gt;Watch this: &lt;a class=&#34;external&#34; 
   href=&#34;https://www.infoq.com/presentations/Simple-Made-Easy&#34; target=&#34;_blank&#34;
   &gt;https://www.infoq.com/presentations/Simple-Made-Easy&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;avoid-binding-by-name-like-the-plague&#34;&gt;Avoid binding by name like the plague
&lt;/h3&gt;&lt;p&gt;Avoid as much as possible mechanisms whose modus operandi is binding by name: use them only for interfacing with external entities, never for communication between your own modules. REST enthusiasts can cry me a river.&lt;/p&gt;
&lt;p&gt;Note that binding by name must be avoided even in comments. If you need to refer to  an identifier from within a comment, use whatever special notation is offered by the language at hand (&lt;code&gt;{@link ...}&lt;/code&gt; in java, &lt;code&gt;&amp;lt;see cref=&amp;quot;...&amp;quot;&amp;gt;&lt;/code&gt; in C#) so that when you later refactor the name of that identifier, the IDE will also update any comments that mention that identifier.&lt;/p&gt;
&lt;h3 id=&#34;always-use-strong-typing&#34;&gt;Always use strong typing
&lt;/h3&gt;&lt;p&gt;Avoid any kind of weak typing (euphemistically called &lt;em&gt;dynamic&lt;/em&gt; typing) and avoid languages and frameworks that require it or even just sympathize with it. Yes, this includes all scripting languages. Scripting language enthusiasts can cry me a river. (And yes, this includes Typescript too, because it &lt;em&gt;sympathizes&lt;/em&gt; with JavaScript.)&lt;/p&gt;
&lt;p&gt;Read this: &lt;a 
   href=&#34;//localhost:1313/post/2017-05-on-scripting-languages/&#34;
   &gt;On Scripting Languages&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;strive-for-debuggability&#34;&gt;Strive for debuggability
&lt;/h3&gt;&lt;p&gt;For example, do not overdo it with the so-called &amp;ldquo;fluent&amp;rdquo; style of invocations, because they are not particularly debuggable. Do not hurry to adopt this or that cool new programming language before you have made sure that debugger support for it is complete and working properly.&lt;/p&gt;
&lt;h3 id=&#34;resist-the-idiomatic-craze&#34;&gt;Resist the idiomatic craze
&lt;/h3&gt;&lt;p&gt;Contrary to popular belief, doing things in whatever way is considered idiomatic for the programming language at hand is never an end in and of itself; Avoid the use of idiomatic ways of doing things unless you are convinced they are superior. Many of them are, but some of them are not.&lt;/p&gt;
&lt;h3 id=&#34;strive-for-testability&#34;&gt;Strive for testability
&lt;/h3&gt;&lt;p&gt;Design interfaces that expose all functionality that makes sense to expose, not only functionality that is known to be needed by the code that will invoke them. For example, the application may only need an interface to expose a &lt;code&gt;register()&lt;/code&gt; and &lt;code&gt;unregister()&lt;/code&gt; pair of methods, but &lt;code&gt;isRegistered()&lt;/code&gt; also makes sense to expose, and it will incidentally facilitate black-box testing.&lt;/p&gt;
&lt;h3 id=&#34;enable-all-warnings-that-can-be-enabled&#34;&gt;Enable all warnings that can be enabled
&lt;/h3&gt;&lt;p&gt;The fact that a certain warning may on occasion be issued on legitimate code is no reason to disable the warning: the warning must be enabled, and each occurrence of the warning must be dealt with on a case-by-case basis.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The best way to deal with a warning is to resolve it. For example:
&lt;ul&gt;
&lt;li&gt;If your compiler is warning you that a certain cast is redundant, remove that redundant cast. (Duh!)&lt;/li&gt;
&lt;li&gt;If the compiler is warning you that you are dereferencing a pointer which might be null at that point, then add a null check before dereferencing it. (Duh!)&lt;/li&gt;
&lt;li&gt;If your compiler is warning you that you are invoking an overridable method from within the constructor of a base class, then do whatever restructuring is needed, throw it all away and rewrite it from scratch if necessary, so that no such thing is happening.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Another way of dealing with warnings is by suppressing them. Of course, this approach should only be used on perfectly legitimate code that would become less perfect if it was to be restructured so as to resolve the warning. Suppression should always be as localized as possible, meaning that it should be done on the individual statement where the warning is issued, instead of the entire function or the entire class. Note, however, that there are certain warnings that should always be properly resolved and never suppressed; take the invocation of an overridable method from within the constructor of a base class for example.
&lt;ul&gt;
&lt;li&gt;Some warnings, like &amp;ldquo;unused identifier&amp;rdquo;, occur on legitimate code too often for selective suppression to be practical. For those warnings, consider using an IDE that supports a &amp;ldquo;weak warning&amp;rdquo; or &amp;ldquo;suggestion&amp;rdquo; level, which is highlighted inconspicuously, so it can be easily filtered out by your eyes, but the visual clue is still there in case it points to something unexpected. Also consider using a better programming language, which supports a construct known as a &amp;ldquo;discard variable&amp;rdquo;, allowing the programmer to explicitly state their intention to let a variable go unused, so that the warning can remain a warning.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course some silly warnings occur on legitimate code all the time, so it goes without saying that they need to be disabled, but in my experience they are far fewer than the average programmer thinks they are.&lt;/p&gt;
&lt;h3 id=&#34;thou-shalt-not-suffer-a-warning-to-live&#34;&gt;Thou shalt not suffer a warning to live
&lt;/h3&gt;&lt;p&gt;Every single warning must always be resolved immediately upon being introduced. Nobody should ever commit code that contains warnings, and therefore nobody should ever check out code that already contains warnings.&lt;/p&gt;
&lt;p&gt;This is because a warning always is (or ought to always be) a cause of alarm; however, long-standing warnings constitute long-standing false alarms, so their continued existence causes two things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;All programmers in the house start becoming insensitive to the alarms, so the alarms start going unnoticed. (The &amp;ldquo;cry wolf&amp;rdquo; effect.)&lt;/li&gt;
&lt;li&gt;Those programmers who are perfectionists (and those are the best kind of programmers) start becoming mighty annoyed.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Which brings us to the next point:&lt;/p&gt;
&lt;h3 id=&#34;treat-warnings-as-errors&#34;&gt;Treat Warnings as Errors
&lt;/h3&gt;&lt;p&gt;Always use the &amp;ldquo;treat warnings as errors&amp;rdquo; option of your compiler. If your compiler does not have such an option, throw away everything and start from scratch with a compiler that has it.&lt;/p&gt;
&lt;p&gt;The conventional understanding of what the difference is between warnings and errors is that with an error, you have to fix it before you can proceed, whereas with a warning, you can just ignore it and proceed.&lt;/p&gt;
&lt;p&gt;This understanding is technically correct, in the sense that this is in fact how compilers tend to behave by default, and this is in turn what most programmers expect, since dumb defaults seem to always suit mindless majorities. However, this conventional understanding, and therefore this default behavior of compilers, is wrong. It has been wrong since the dawn of our discipline, and it continues to be wrong today. The magnitude of the wrongness, multiplied by the pervasiveness of the wrongness, is truly staggering.&lt;/p&gt;
&lt;p&gt;The difference between warnings and errors &lt;em&gt;&lt;strong&gt;should be&lt;/strong&gt;&lt;/em&gt; that you can suppress a warning if you must, whereas you cannot suppress an error; however, you should absolutely have to address and eliminate both, meaning that you should have to either explicitly suppress or otherwise resolve every single warning before being allowed to proceed.&lt;/p&gt;
&lt;p&gt;The &amp;ldquo;treat warnings as errors&amp;rdquo; option corrects the wrong behavior of compilers, and exists precisely for the benefit of those (apparently very few) people in our discipline who happen to have their reasoning right on this issue.&lt;/p&gt;
&lt;p&gt;Be one of those people. Use that option.&lt;/p&gt;
&lt;h3 id=&#34;strive-for-readability&#34;&gt;Strive for readability
&lt;/h3&gt;&lt;p&gt;Readability is one of the most important qualities of code, second only to correctness. Code is generally read far more often that it is written. We tend to read code several times as we write it, at least once more as we review it, and then many more times throughout its lifetime as we extend it, refactor it, or tweak it; as we write nearby code; as we browse through code to understand how things work; as we perform troubleshooting; etc. In other words, over time, the reads-to-writes ratio of any piece of code approaches infinity. Therefore:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Absolutely any&lt;/strong&gt;&lt;/em&gt; choice that makes code easier to read is &lt;em&gt;&lt;strong&gt;absolutely always&lt;/strong&gt;&lt;/em&gt; preferable over &lt;em&gt;&lt;strong&gt;absolutely any&lt;/strong&gt;&lt;/em&gt; choice that makes code easier to write.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This means that languages that achieve great terseness of code are not really delivering anything of value by this alone, (I am looking at you, Scala,) because verbosity of code is not one of the major problems that our profession is faced with; unreadable code is. This also means that certain languages whose grotesquely arcane syntax has earned them the &amp;ldquo;write-only language&amp;rdquo; designation are not to be touched with a 10 ft. pole. Perl enthusiasts can cry me a river.&lt;/p&gt;
&lt;h3 id=&#34;avoid-using-elements-of-prose-in-code&#34;&gt;Avoid using elements of prose in code
&lt;/h3&gt;&lt;p&gt;Identifiers should be pedantic, not creative, and unless they pertain to the problem domain, they should come from the realm of engineering, not from the realm of literature. Think twice before using a term like &amp;ldquo;drop&amp;rdquo; instead of &amp;ldquo;delete&amp;rdquo;, &amp;ldquo;payload&amp;rdquo; instead of &amp;ldquo;content&amp;rdquo;, etc. because &amp;ldquo;drop&amp;rdquo; and &amp;ldquo;payload&amp;rdquo; are metaphors. Metaphor should be avoided unless it helps to express something that would otherwise require an entire sentence to express, for example &amp;ldquo;Factory&amp;rdquo; instead of &amp;ldquo;ObjectThatCreatesOtherObjects&amp;rdquo;.&lt;/p&gt;
&lt;h3 id=&#34;use-an-ide-with-a-spell-checker&#34;&gt;Use an IDE with a spell checker
&lt;/h3&gt;&lt;p&gt;Avoid anything that fails to pass the spell check.&lt;/p&gt;
&lt;p&gt;Add the spell-checking dictionary of the IDE to source control and review any commits to it just as you review any other code.&lt;/p&gt;
&lt;p&gt;This specifically means abandoning certain old habits; all of the following are wrong:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;nrPoints; pointsNr; nPoints; pointsN; noPoints; pointsNo; lenPoints; pointsLen&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Only the following are right:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;numberOfPoints; pointCount; pointsLength&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;avoid-acronyms-and-abbreviations&#34;&gt;Avoid acronyms and abbreviations
&lt;/h3&gt;&lt;p&gt;Use fully spelled-out words of the English language instead.&lt;/p&gt;
&lt;p&gt;Acronyms and abbreviations are cryptic for the uninitiated, and even if they are not, they make the code look unnecessarily technical. Modern IDEs have formidable auto-completion features, so fully spelling out every word does not necessarily mean that you will have to type more, but even if it did, typing is not one of the major problems that our profession is faced with; unreadable code is.&lt;/p&gt;
&lt;p&gt;This means that a huge number of abbreviations which have traditionally been staple terms in programming, should never be used, or their use should be seriously reconsidered. This includes all of the following: abs, addr, alloc, alt, app, arg, async, attr, auth, avg, bg, bat, bin, bool, buf, buff, btn, calc, cert, char, cls, clr, col, coll, cmd, com, cmp, comp, cfg, conf, config, const, ctx, ctrl, conv, coord, cos, cnt, cur, curr, db, dbg, dec, decl, def, deg, del, desc, dest, dev, diff, dim, dir, disp, div, doc, drv, dyn, env, eq, err, exe, exp, expr, ext, fac, fig, fg, fmt, frac, freq, fn, fun, func, gen, geom, hdr, hex, img, imp, impl, inc, idx, info, init, ins, inst, int, iter, lang, len, lib, lnk, max, mem, msg, mid, min, misc, mod, mul, mut, nav, net, num, obj, org, pkg, param, perf, pic, ptr, pos, pow, pwr, pred, pref, prev, priv, proc, prof, pub, rand, rnd, recv, rec, rect, ref, regex, rel, rem, rm, repo, req, res, ret, rev, sel, seq, svc, sess, sin, sln, src, spec, sqrt, std, stmt, stat, str, sub, sync, tan, tmp, temp, txt, usr, util, var, val, vec, ver, win, wiz.&lt;/p&gt;
&lt;p&gt;If a particular acronym is understood by every programmer, then it might be okay to use it in code, but if it is only understood by domain experts, then it is &lt;em&gt;not okay&lt;/em&gt;. This is because programmers often work on software for domains on which they are not experts, and even if they do eventually become domain experts, in the beginning they are not, but the beginning is when everything is difficult, so that is precisely the time that you do not want to be adding any extra difficulty to them. This means that very few acronyms are actually okay.&lt;/p&gt;
&lt;p&gt;Let me stress this to make sure it is understood: Domain Experts may protest that it is awkward to see a particular term fully spelled out in the code, because the term is so well known, that it appears as an acronym in the entirety of the literature in their field; let them find it awkward, and let them protest. Your code is not part of the literature in their field.&lt;/p&gt;
&lt;p&gt;If the choice is made to keep a certain acronym in the code, then the acronym must be turned into a word, meaning that only the first letter may be written in upper-case, while all subsequent letters must always be written in lower-case. For example, if you have decided that you are not going to replace &lt;code&gt;GUID&lt;/code&gt; with &lt;code&gt;GloballyUniqueIdentifier&lt;/code&gt;, I am totally with you, but then you must replace it with &lt;code&gt;Guid&lt;/code&gt;, so that the spell-checker can recognize it as a word and spell-check it. Otherwise, the spell-checker will consider each capital letter individually, and each individual letter passes spell-checking, so anything written in all-capitals essentially circumvents the spell-checker. If &amp;ldquo;Guid&amp;rdquo; as a word violates your English-language sensitivities, then please remember that you are writing code, not prose. There is a reason it is called code: it is specifically &lt;em&gt;not&lt;/em&gt; prose.&lt;/p&gt;
&lt;p&gt;Also beware of abbreviations that do not look like abbreviations. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The word &amp;ldquo;out&amp;rdquo; can be a word on its own, but more often than not, it is used as an abbreviation of &amp;ldquo;output&amp;rdquo;. Spell out the full word.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the methods &lt;code&gt;ToUpper()&lt;/code&gt; and &lt;code&gt;ToLower()&lt;/code&gt;, the terms &amp;ldquo;Upper&amp;rdquo; and &amp;ldquo;Lower&amp;rdquo; have no inherent meaning of their own; the proper terms that these abbreviations stand for are &amp;ldquo;UpperCase&amp;rdquo; and &amp;ldquo;LowerCase&amp;rdquo;. Use the proper terms.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pay-attention-to-naming&#34;&gt;Pay attention to naming
&lt;/h3&gt;&lt;p&gt;Every single concept must have the best name that it could possibly have. Not just a good name, but an excellent name. Unfortunately, finding the right name for things is hard. It is not a coincidence that naming things is &lt;em&gt;One of the Two Hard Problems in Computer Science.&lt;/em&gt; (&lt;a class=&#34;external&#34; 
   href=&#34;https://martinfowler.com/bliki/TwoHardThings.html&#34; target=&#34;_blank&#34;
   &gt;https://martinfowler.com/bliki/TwoHardThings.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Strive for a variety of names that uniquely and accurately reflect each concept that you are dealing with. A Thesaurus is an indispensable programming tool.&lt;/p&gt;
&lt;p&gt;(I once worked in a metrology environment where both the main entity of interest was called a &amp;ldquo;Measurement&amp;rdquo;, and the main thing that you could do with it was to perform a &amp;ldquo;Measurement&amp;rdquo;; that&amp;rsquo;s deplorable.)&lt;/p&gt;
&lt;p&gt;If a certain domain-specific term is problematic in code, then do not use that term in code. Completely ignore the domain experts who will protest that the original term is the established term in the field and it is awkward to see it replaced with something else.&lt;/p&gt;
&lt;p&gt;(In that same metrology environment, the goal of the software was to measure and report how something differs from its ideal form; the term used in that field for this kind of difference was &amp;ldquo;error&amp;rdquo;, so the software was full of identifiers called &amp;ldquo;error&amp;rdquo; that did not stand for error as we know it in software; that&amp;rsquo;s deplorable.)&lt;/p&gt;
&lt;p&gt;Avoid zero-information names; invest the necessary amount of thinking so that each name gives at least some hint as to what it is about to someone who sees it for the first time. A good rule of thumb for deciding whether a name is good is to ask yourself the following question:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Could the same name conceivably also stand for some unrelated entity in my code base?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;(A co-worker of mine once created a namespace called &amp;ldquo;DataInfo&amp;rdquo;; that&amp;rsquo;s deplorable.)&lt;/p&gt;
&lt;p&gt;In special cases, dare to use names that you may have never heard anyone using before. For example, if you need a Factory of Factories, why not call it &lt;em&gt;Industry&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;Read Chapter 2: &lt;em&gt;Meaningful Names&lt;/em&gt; of the book &lt;em&gt;Clean Code&lt;/em&gt; by Robert C. Martin.&lt;/p&gt;
&lt;p&gt;Also read this: &lt;a 
   href=&#34;//localhost:1313/post/2018-05-confucius-on-naming/&#34;
   &gt;Confucius on Naming&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Any code written by a programmer whose English language skills are poor should be reviewed by a programmer whose English language skills are good.&lt;/p&gt;
&lt;p&gt;When words need to be combined to form an identifier, the combination must follow general English grammar rules, except for English grammar special cases.&lt;/p&gt;
&lt;p&gt;Read this: &lt;a class=&#34;external&#34; 
   href=&#34;https://softwareengineering.stackexchange.com/q/409455/41811&#34; target=&#34;_blank&#34;
   &gt;Software Engineering Stack Exchange: Clean Code: long names instead of comments&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the following discussion when we speak of a noun or an adjective or a verb we actually mean a sequence of various parts of speech that effectively constitute a noun or an adjective or a verb. For example, &lt;code&gt;reticulated_spline&lt;/code&gt; is a noun (spline), &lt;code&gt;reticulated_before_dive&lt;/code&gt; is an adjective (reticulated), and &lt;code&gt;dive_for_moog&lt;/code&gt; is a verb (dive).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Types:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Classes:&lt;/strong&gt; The name of a class must always be a noun; it must never be an adjective or a verb; no exceptions. Also, the name of a class must always be in singular form; no exceptions. If you need to signify plurality, do not use plural! Instead, append a plurality-signifying term which is in turn a singular noun. For example, if you have a class that stands for a group of entities, do not call it &amp;lsquo;Entities&amp;rsquo;, call it &amp;lsquo;EntityGroup&amp;rsquo; instead. (Duh!)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interfaces:&lt;/strong&gt; The name of an interface must be either an adjective, (e.g. Comparable,) or a noun, (e.g. Serializer,) no exceptions. Singular form goes without saying.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enums:&lt;/strong&gt; The name of an enum type must always be a noun in singular form, no exceptions. (E.g. WeekDay.Monday instead of WeekDays.Monday.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Variables:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Single-value:&lt;/strong&gt; The name of a single-value variable must always be a noun in singular form, unless it is of boolean type, in which case it may signify a condition, such as isEmpty.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Collection:&lt;/strong&gt; The name of a collection variable must always be a noun in plural form, no exceptions.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Functions:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pure:&lt;/strong&gt; The name of a function that returns a result without mutating anything must always be a noun unless it returns boolean, in which case it may signify a condition, such as hasChildren(). The name must be in singular form, unless a collection is returned, in which case the name must be in plural form.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Impure:&lt;/strong&gt; The name of a function that performs an operation (has side effects) must be a verb, no exceptions. If the impure function returns a result indicating success or failure, the name must begin with &amp;rsquo;try&amp;rsquo; followed by the actual verb, for example &amp;rsquo;tryAdd()&amp;rsquo;. If the name does not begin with &lt;code&gt;try&lt;/code&gt; then the rule is that the function will signal failure by throwing an exception.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When multiple words are combined to form an identifier, they must still make sense. As an example of what to avoid, take the &lt;code&gt;INotifyPropertyChanged&lt;/code&gt; interface of WPF. This name is deplorable because notify is a verb, not a noun or an adjective, and because an object implementing this interface is not a property-changed notification, it is an object which may issue property-changed notifications. Admittedly, it is difficult to come up with a good name to describe such objects; a decent choice might be &lt;code&gt;PropertyChangedNotificationIssuer&lt;/code&gt;, but this might be a bit too long for some people&amp;rsquo;s taste. An alternative is to use a familiar term of broader scope if there is no possibility of confusion. So, another decent choice here might simply be &lt;code&gt;Mutable&lt;/code&gt;. It is true that all kinds of different classes are mutable without issuing property-changed notifications, but then again the only thing that different mutable classes could have in common simply by virtue of being mutable, so as to warrant a common interface for all of them, is issuing notifications about their mutations. The point to take home from all this is that although it is difficult to come up with good names, the application of some actual thinking should produce a name which is at least a bit better than nonsense.&lt;/p&gt;
&lt;p&gt;As mentioned earlier, special cases of the English grammar can, and should, be ignored. An example of this is the simplification of plurals: choose &amp;ldquo;indexes&amp;rdquo; instead of &amp;ldquo;indices&amp;rdquo;, &amp;ldquo;schemas&amp;rdquo; instead of &amp;ldquo;schemata&amp;rdquo;, and, even though I know this is a tough proposition for some, &amp;ldquo;companys&amp;rdquo; instead of &amp;ldquo;companies&amp;rdquo;. See &lt;a class=&#34;external&#34; 
   href=&#34;https://softwareengineering.stackexchange.com/q/290951/41811&#34; target=&#34;_blank&#34;
   &gt;Software Engineering Stack Exchange: Does it make sense to use &amp;ldquo;ys&amp;rdquo; instead of &amp;ldquo;ies&amp;rdquo; in identifiers to ease find-and-replace functionality?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Never begin a function name with the prefix &amp;lsquo;check&amp;rsquo;. Doing so is a typical example of a developer choosing names according to fleeting notions in their head, without the slightest concern as to how these names will be understood by others. The word &lt;code&gt;check&lt;/code&gt; means nothing; a function that only checks something and then does nothing about it would serve absolutely no purpose; presumably, whatever checking the function does culminates in taking some kind of action, or returning some kind of result; this is an extremely important piece of information that the name of the function should not fail to convey; therefore, the name of the function should indicate what kind of action is performed, or what kind of result is returned.&lt;/p&gt;
&lt;h3 id=&#34;avoid-conventions-that-make-code-look-unnecessarily-technical&#34;&gt;Avoid conventions that make code look unnecessarily technical
&lt;/h3&gt;&lt;p&gt;Code is, by definition, already quite technical; we do not need to be making it look even more technical than it already is. Abandon the abhorrent practice of prefixing static variables with &amp;ldquo;s_&amp;rdquo;, prefixing member variables with &amp;ldquo;m_&amp;rdquo;, and prefixing private member variables with &amp;ldquo;_&amp;rdquo;. Modern IDEs can be configured to provide sufficient visual clues about these things via syntax highlighting. If your IDE does not support this, throw it away and find one that does. If you are not using an IDE, then please switch to the arts and humanities.&lt;/p&gt;
&lt;h3 id=&#34;avoid-hungarian-notation&#34;&gt;Avoid *Hungarian Notation.
&lt;/h3&gt;&lt;p&gt;(&lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Hungarian_notation&#34; target=&#34;_blank&#34;
   &gt;https://en.wikipedia.org/wiki/Hungarian_notation&lt;/a&gt;.) For example, no matter how popular it is in the DotNet world, the practice of prefixing interface names with &lt;code&gt;I&lt;/code&gt; is ill-conceived. What also helps in order to avoid Hungarian Notation is &lt;em&gt;The Maximalistic Approach to Typing&lt;/em&gt;, where the nature of a variable is fully determined from its data type without the need for name adornments.&lt;/p&gt;
&lt;p&gt;Which brings us to the next item:&lt;/p&gt;
&lt;h3 id=&#34;use-the-type-system-to-the-fullest&#34;&gt;Use the type system to the fullest
&lt;/h3&gt;&lt;p&gt;Avoid using general purpose data types; try as much as possible to use data types that are specific for the job. A classic example of this is the use of a &lt;code&gt;Duration&lt;/code&gt; data type instead of an &lt;code&gt;int&lt;/code&gt; number of milliseconds, but it goes a lot further than that.&lt;/p&gt;
&lt;p&gt;So, no, your height is not of type &lt;code&gt;double&lt;/code&gt;, it is of type &lt;code&gt;Length&lt;/code&gt;; your married status is not a boolean, it is an instance of &lt;code&gt;MarriedStatus&lt;/code&gt;; a customer id and a product id are not both of type &lt;code&gt;int&lt;/code&gt;; one is of type &lt;code&gt;CustomerId&lt;/code&gt;, while the other is of type &lt;code&gt;ProductId&lt;/code&gt;; and so on. I call this &lt;em&gt;&lt;strong&gt;The Maximalistic Approach To Typing&lt;/strong&gt;&lt;/em&gt;. Untyped programming language aficionados can cry me a river.&lt;/p&gt;
&lt;h3 id=&#34;avoid-defensive-programming-engage-in-offensive-programming-instead&#34;&gt;Avoid defensive programming; engage in &lt;em&gt;offensive&lt;/em&gt; programming instead
&lt;/h3&gt;&lt;p&gt;Defensive programming is summarized by &lt;em&gt;Postel&amp;rsquo;s law&lt;/em&gt;, otherwise known as the &lt;em&gt;Robustness Principle&lt;/em&gt;, which says:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Be conservative in what you do, be liberal in what you accept from others.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;(See &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Robustness_principle&#34; target=&#34;_blank&#34;
   &gt;https://en.wikipedia.org/wiki/Robustness_principle&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;This principle suggests that besides producing output which adheres to the spec, our software should, as much as possible, be capable of coping with input that is off-spec. In other words, it should be tolerant to error. People imagine that when software behaves like that, it is more robust.&lt;/p&gt;
&lt;p&gt;If there is one thing that I have learned in several decades of programming, both from my own code and from code written by others, it is that tolerance towards error leads to anything but bug-free software; it invariably results in chaos; and guess what chaotic software tends to be: &lt;em&gt;&lt;strong&gt;buggy.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Read this: &lt;a class=&#34;external&#34; 
   href=&#34;https://trevorjim.com/postels-law-is-not-for-you&#34; target=&#34;_blank&#34;
   &gt;http://trevorjim.com/postels-law-is-not-for-you&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;So, instead of defensive programming, I advocate &lt;em&gt;offensive&lt;/em&gt; programming, which means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Never allow any slack or leeway, require everything to be exactly as expected.&lt;/li&gt;
&lt;li&gt;Require strict adherence to the spec even if you have no use for the full precision mandated by the spec.&lt;/li&gt;
&lt;li&gt;Keep tolerances not just down to a minimum, but at &lt;em&gt;absolute zero&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Never fail silently; fail &lt;em&gt;loudly&lt;/em&gt; instead. Fail fast; fail hard; fail eagerly, and enthusiastically.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples of offensive programming:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Avoid conversion functions that return &lt;code&gt;null&lt;/code&gt; if given &lt;code&gt;null&lt;/code&gt;; always assert that the parameter is non-null. Better yet, avoid nullability altogether, or use a type system with explicit nullability, so as to restrict it via strong typing to only those places where it is meaningful. The same applies to empty strings: if an empty string is not meaningful somewhere, do not simply cope with it; explicitly and categorically disallow it.&lt;/li&gt;
&lt;li&gt;Avoid things like a &lt;code&gt;Map.put()&lt;/code&gt; method which either adds or replaces, and instead design for an &lt;code&gt;add()&lt;/code&gt; method which asserts that the item being added does not already exist, and a &lt;code&gt;replace()&lt;/code&gt; method which asserts that the item being replaced does in fact already exist.&lt;/li&gt;
&lt;li&gt;In scenarios where an add-or-replace operation seems useful to have, (and in my experience, such scenarios are exceedingly rare,) add such a function but give it a name that clearly indicates the weirdness in what it does: call it &lt;code&gt;addOrReplace()&lt;/code&gt;. (Duh!)&lt;/li&gt;
&lt;li&gt;Avoid things like a &lt;code&gt;close()&lt;/code&gt; method which is allowed to be invoked more than once with no penalty: assert that your &lt;code&gt;close()&lt;/code&gt; methods are invoked exactly once.&lt;/li&gt;
&lt;li&gt;Never use the garbage collector for cleanup; always perform explicit and deterministic clean-up at the exact moment when it is supposed to happen; the cleanup function invoked by the garbage collector should only be used for producing diagnostic messages in case we forgot to do explicit cleanup. Read this: &lt;a 
   href=&#34;//localhost:1313/post/2020-12-27-object-lifetime-awareness/&#34;
   &gt;Object Lifetime Awareness&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;use-inheritance-when-it-is-clearly-the-right-choice&#34;&gt;Use inheritance when it is clearly the right choice
&lt;/h3&gt;&lt;p&gt;The advice that &lt;em&gt;composition should be favored over inheritance&lt;/em&gt; was very good advice back in the mid-1990s, because back then people were overdoing it with inheritance: the general practice was to not even consider composition unless all attempts to get things to work with inheritance failed. That practice was bad, and the fact that the predominant language at that time (C++) supported not just inheritance but actually &lt;em&gt;multiple inheritance&lt;/em&gt; made things even worse. So the advice against that practice was very much needed back then.&lt;/p&gt;
&lt;p&gt;However, the advice is still being religiously followed to this day, as if inheritance had always been a bad thing. This is leading to unnecessarily convoluted designs and much weeping, and wailing, and gnashing of teeth. Even the original advice suggested favoring one over the other, it did not prescribe the complete abolition of the other. So, today it is about time we reword the advice as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Know when to use inheritance and when to use composition.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;For a variety of opinions and a lengthy discussion about this, see &lt;a class=&#34;external&#34; 
   href=&#34;https://stackoverflow.com/q/49002/773113&#34; target=&#34;_blank&#34;
   &gt;https://stackoverflow.com/q/49002/773113&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Also heed the advice by Josh Bloch to &lt;em&gt;design and document for inheritance or else prohibit it&lt;/em&gt;. (See &lt;a class=&#34;external&#34; 
   href=&#34;https://blogs.oracle.com/javamagazine/post/java-inheritance-design-document&#34; target=&#34;_blank&#34;
   &gt;https://blogs.oracle.com/javamagazine/post/java-inheritance-design-document&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id=&#34;favor-early-exits-over-deep-nesting&#34;&gt;Favor early exits over deep nesting
&lt;/h3&gt;&lt;p&gt;This means liberal use of the &lt;code&gt;break&lt;/code&gt; and &lt;code&gt;continue&lt;/code&gt; keywords, as well as &lt;code&gt;return&lt;/code&gt; statements in the middle of a method whenever possible. The code ends up being a lot simpler this way. Yes, this directly contradicts the ancient &amp;ldquo;one return statement per function&amp;rdquo; dogma. I love contradicting ancient dogma.&lt;/p&gt;
&lt;h3 id=&#34;avoid-static-mutable-state-like-anthrax&#34;&gt;Avoid static mutable state like anthrax
&lt;/h3&gt;&lt;p&gt;Yes, this also includes stateful singletons. The fact that it only makes logical sense to have a single instance of a certain object in your world is no reason to design that object, and your world, so that only one instance of them can ever be.&lt;/p&gt;
&lt;p&gt;You see, I guarantee to you that the need will arise in the future, unbeknownst to you today, &lt;em&gt;to multiply instantiate your world&lt;/em&gt;, along with that object in it, which you thought was one-of-a-kind.&lt;/p&gt;
&lt;p&gt;As a matter of fact, it is quite likely that you will have to do that anyway, for the purpose of testing.&lt;/p&gt;
&lt;h3 id=&#34;optimize-performance-bottlenecks-not-performance-penalties&#34;&gt;Optimize performance bottlenecks, not performance penalties
&lt;/h3&gt;&lt;p&gt;The ages-old advice to &lt;em&gt;avoid premature optimization&lt;/em&gt; is considered common knowledge, but it is a bit vague, so it does not actually register with many folks, who will not hesitate to optimize any code construct that they consider as representing a performance penalty, under the reasoning that if it represents a performance penalty then its optimization is not premature.&lt;/p&gt;
&lt;p&gt;For this reason, I like to rephrase the advice as &amp;ldquo;&lt;strong&gt;Optimize performance bottlenecks, not performance penalties&lt;/strong&gt;&amp;rdquo; to stress the point that just because something represents a performance penalty, it does not mean that it should be optimized.&lt;/p&gt;
&lt;p&gt;You see, all code takes clock cycles to run, so every little piece of code that we write represents a performance penalty; if that was sufficient reason to optimize it, then premature optimization would be the order of the day, every day. For something to be considered worthy of optimization, it should not merely represent a performance penalty; it should be proven to represent a performance bottleneck.&lt;/p&gt;
&lt;p&gt;You do not know whether something is a bottleneck unless you run the completed software system, discover that its performance is unacceptable, and use the profiler to determine exactly where the bottlenecks are. Also, what usually happens in these cases is that you tend to find some nice and formal algorithmic optimizations to apply in just a few places, and make your software meet its performance requirements, without having to go all over the entire source code base and tweak and hack things to squeeze clock cycles here and there.&lt;/p&gt;
&lt;h3 id=&#34;put-the-tools-of-the-trade-into-use&#34;&gt;Put the tools of the trade into use
&lt;/h3&gt;&lt;p&gt;Armies of very good developers have worked hard to build these tools, don&amp;rsquo;t you dare make their efforts go in vain.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Use an IDE.&lt;/p&gt;
&lt;p&gt;Programmers who think that they are better off with their favorite text editor should be admitted to rehabilitation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use the &lt;em&gt;build&lt;/em&gt; feature of your IDE, which only compiles modified  files.&lt;/p&gt;
&lt;p&gt;Programmers who habitually perform a full &lt;em&gt;rebuild&lt;/em&gt; instead of a plain build should be fired.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use your IDE for running tests.&lt;/p&gt;
&lt;p&gt;Programmers who habitually run tests via separate tools outside of the IDE should be shot.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The continuous build pipeline is your second line of defense, not your  primary means of building and testing. Your IDE will always be a lot faster, and it has a built-in debugger.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use the debugger of your IDE as your first choice for troubleshooting anything, not as the last resort after all other options have been exhausted. This means that you should be using the debugger not only when there is trouble, but always, by default, so that it is ready when trouble occurs. This in turn means that when you want to fire up your creation, or to run the tests, you should never hit the &amp;ldquo;Run&amp;rdquo; key on your IDE; you should hit the &amp;ldquo;Debug&amp;rdquo; key instead. Always the &amp;ldquo;Debug&amp;rdquo; key. Only the &amp;ldquo;Debug&amp;rdquo; key. You are a programmer; act like it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Having said all that, I should also add that people who are so attached to their IDE that they program by dragging and dropping code snippets around should perhaps consider that some desktop publishing job might suit them better.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do not even think that you are done with testing unless the code coverage tool gives you sufficient reason to believe so.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Have your IDE perform code analysis, and incorporate even more code analysis in the continuous build.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;design-with-reliability-as-a-foundation-not-as-an-afterthought&#34;&gt;Design with reliability as a foundation, not as an afterthought
&lt;/h3&gt;&lt;p&gt;For example, sharing data in a multi-threaded environment by means of traditional locking techniques (&amp;ldquo;synchronization&amp;rdquo;) is both error-prone and untestable, because you cannot test for race conditions. Note that &amp;ldquo;error prone&amp;rdquo; and &amp;ldquo;untestable&amp;rdquo; is a deadly combination; therefore, this way of sharing data should be abandoned. Instead, design for a lock-free, share-nothing approach that works by passing immutable messages, thus eliminating the very possibility of race conditions.&lt;/p&gt;
&lt;h3 id=&#34;design-with-security-as-a-foundation-not-as-an-afterthought&#34;&gt;Design with security as a foundation, not as an afterthought
&lt;/h3&gt;&lt;p&gt;Security is not something that you can add on top of an insecure foundation, because there exist no automated tests that can detect security hazards and no amount of carefulness on behalf of programmers that is careful enough. So, what is necessary is architectural choices that eliminate entire classes of security hazards. (Do not worry, there will always be other classes of security hazards to have to worry about.)&lt;/p&gt;
&lt;p&gt;So, if a certain architectural choice is prone to security vulnerabilities, do not make that choice. An example of a vulnerability-prone architectural choice is putting application code on the web browser, otherwise known as full-stack development. Full-stack developers can cry me a river.&lt;/p&gt;
&lt;p&gt;For more on this, read: &lt;a 
   href=&#34;//localhost:1313/post/2021-12-full-stack-development/&#34;
   &gt;What is wrong with Full Stack Development&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;keep-the-log-clean&#34;&gt;Keep the log clean
&lt;/h3&gt;&lt;p&gt;Do not vex your colleagues, and do not make your own life harder, with torrential info-level or debug-level spam in the log. Keep the info-level messages down to an absolute minimum, and once debugging is done, completely remove all the debug-level log statements. Utilize commit hooks that deliberately fail a commit if it contains debug-level logging statements. Regularly use the &amp;ldquo;blame&amp;rdquo; feature of the version control system to remind developers of info-level logging statements that they should remove. Never use the log for capturing metrics or any other kind of structured information; use some separate, specialized instrumentation facility for that.&lt;/p&gt;
&lt;h3 id=&#34;make-the-best-out-of-the-log&#34;&gt;Make the best out of the log
&lt;/h3&gt;&lt;p&gt;You should at all times be able to click on a log line in the output window of the IDE and be taken to the source line that generated that log entry, and you should also at all times be able to click on any line of a logged exception stack trace and be taken to the corresponding line of source code. I am appalled by how many programming environments do not offer this as the default mode of operation under all circumstances.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the Microsoft Visual Studio world, for a line to be clickable in the output window it must start with a source pathname, followed by an opening parenthesis, a line number, a closing parenthesis, and a colon. It can optionally be prefixed with whitespace.
&lt;ul&gt;
&lt;li&gt;Fortunately, both C++ and C# support efficient means of obtaining source file name and line number information: In C++ it is the &lt;code&gt;__FILE__&lt;/code&gt; and &lt;code&gt;__LINE__&lt;/code&gt; built-in pre-processor macros, while in C# it is the &lt;code&gt;CallerFilePath&lt;/code&gt; and &lt;code&gt;CallerLineNumber&lt;/code&gt; attributes.&lt;/li&gt;
&lt;li&gt;Unfortunately, the pathnames generated by these mechanisms are absolute, meaning that they start from the drive letter and include the kitchen sink, so you might want to programmatically convert them to pathnames relative to the solution folder before logging them. Visual studio also recognizes those, though this is undocumented.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;In the Jetbrains IntellijIdea world, for a line to be clickable in the output window it needs to contain an identifier, followed by an opening parenthesis, a source filename-plus-extension, (but no path,) a colon, a line number, and a closing parenthesis.
&lt;ul&gt;
&lt;li&gt;The identifier is meant to be a package name, but Idea does not interpret it in any way, so it can be anything.&lt;/li&gt;
&lt;li&gt;Due to a long-standing bug (which JetBrains refuses to acknowledge or fix) if the word &amp;ldquo;at&amp;rdquo; appears in the log line, and if it is in any place other than immediately before the package name, then this mechanism breaks. (Note that this is all entirely undocumented.)&lt;/li&gt;
&lt;li&gt;Note that this mechanism suffers from ambiguity in the case of multiple source files with the same filename. An alternative mechanism is to include a &amp;ldquo;file://&amp;rdquo; URI in the log entry, but in order to produce such a URL you would have to figure out the path from the package name, which is doable, but not easy.&lt;/li&gt;
&lt;li&gt;Unfortunately, Java does not provide any efficient means of obtaining source file name and line number information, so one has to generate a stack trace in order to extract this information from it.&lt;/li&gt;
&lt;li&gt;Fortunately, generating a stack trace in the java world is not anywhere near as expensive as in the Microsoft world.&lt;/li&gt;
&lt;li&gt;Unfortunately, it is still unreasonably expensive. You can see this performance penalty as one more reason to keep logging to a minimum.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;take-maxims-with-a-grain-of-salt&#34;&gt;Take maxims with a grain of salt
&lt;/h3&gt;&lt;p&gt;(Especially quantitative maxims, which offer specific numerical limits for things.)&lt;/p&gt;
&lt;p&gt;When someone says &amp;ldquo;no function should accept more than 4 parameters&amp;rdquo; or &amp;ldquo;no class should be longer than 250 lines&amp;rdquo; they are usually talking nonsense.&lt;/p&gt;
&lt;p&gt;A class should be as long as necessary to do its job, and if that is 2000 lines, so be it. I would much rather keep some ugly code confined in a single class than split it into multiple classes and thus propagate the ugliness in the design.&lt;/p&gt;
&lt;p&gt;A function should accept as many parameters as necessary to do its job, and if that is 15 parameters, so be it. I would much rather have a long constructor than a mutable object.&lt;/p&gt;
&lt;p&gt;Breaking things down to smaller units should be done because there is some actual tangible merit in doing so, not because some prophecy said so.&lt;/p&gt;
&lt;h3 id=&#34;private-static-methods-are-fine-really&#34;&gt;Private static methods are fine. Really
&lt;/h3&gt;&lt;p&gt;An instance method has the entire object state at its disposal to read and manipulate, and this state may be altered by any other instance method, including instance methods that this method may invoke. The complexity of this is mind-boggling. A static method on the other hand is obviously not in a position to read nor alter any of the object&amp;rsquo;s state, and it is unable to invoke any instance methods that would do that. By its nature, a static method has to rely exclusively on parameters, which are all clearly visible at each call site. Thus, a static method is an &lt;em&gt;&lt;strong&gt;immensely less complex&lt;/strong&gt;&lt;/em&gt; beast than an instance method. What this means is that private static methods are not the slightest bit evil as some folks believe they are, and we should have more of them.&lt;/p&gt;
&lt;p&gt;Personally, when I have a class that has both complex logic and mutable state, I tend to move the complex logic into private static methods, reducing the instance methods to doing nothing but invoking private static methods, passing instance fields to them and storing results into instance fields as necessary.&lt;/p&gt;
&lt;h3 id=&#34;do-not-fix-it-unless-there-is-a-test-for-it&#34;&gt;Do not fix it unless there is a test for it
&lt;/h3&gt;&lt;p&gt;I do not yet have an opinion about test-driven development, but what I have found to be immensely useful, is &lt;em&gt;test-driven maintenance&lt;/em&gt;. So, when a bug is discovered, which obviously passed whatever automated tests you already had in place, do not hurry to figure out what causes it and fix it. First, write a test that tests for the bug, being completely agnostic of any theory that you might already have as to what is causing the bug. This test should initially fail; if it does not fail, then the bug is not what you think it is, so you have more research to do. If the test fails as it should, then fix the bug according to your theory as to what is causing it. If the test now passes, then your theory was correct. If not, then not only you have not fixed the bug, but you have probably broken something else which used to be fine.&lt;/p&gt;
&lt;h3 id=&#34;avoid-death-by-ten-thousand-little-methods&#34;&gt;Avoid death by ten thousand little methods
&lt;/h3&gt;&lt;p&gt;Again and again I see code bases with multitudes of tiny methods having cryptic names, each containing just one or two lines of trivial code, aiming to ensure that not a single line of code is duplicated anywhere. The downside of this is that it increases the complexity of the call tree and therefore the amount of mental effort required to make sense out of it. A new function is worth introducing if it has a well-defined, meaningful role to play. Difficulty in coming up with a name for a function, or having many functions with names that differ only slightly and fail to readily convey the difference between them, are both good indicators that these functions have no role to play other than to avoid code duplication. Of course there is merit in reducing code duplication, but not when the code in question is trivial. And when you see the possibility to de-duplicate non-trivial code, then the well-defined, meaningful role of the function tends to be immediately obvious, as well as the appropriate name for it.&lt;/p&gt;
&lt;h3 id=&#34;make-the-best-out-of-break-on-exception&#34;&gt;Make the best out of break-on-exception
&lt;/h3&gt;&lt;p&gt;Set up your development tooling, and use whatever runtime mechanisms are necessary, so that the debugger always stops at any statement that throws an unexpected exception.&lt;/p&gt;
&lt;p&gt;Many programmers have the bad habit of doing all their troubleshooting by examining logs and postmortem stack traces and theorizing as to what went wrong, instead of having the debugger break on exception and actually seeing what went wrong. This is extremely counter-productive.&lt;/p&gt;
&lt;p&gt;Unfortunately, exceptions are a somewhat complex topic, programming languages and their run-times behave in complex ways when exceptions are thrown, and debuggers have complex mechanisms for dealing with them, none of which helps. As if that was not enough, it is not always easy to tell when a certain exception should be expected and when it should not be expected.&lt;/p&gt;
&lt;p&gt;Thus, there exist several obstacles to accomplishing proper, usable, break-on-exception:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Our code throws and catches expected exceptions all the time, or uses external libraries that do so, internally, all the time; clearly, we do not want the debugger to stop on any of those.&lt;/li&gt;
&lt;li&gt;One might think that the solution to this problem would be to configure the debugger to ignore caught exceptions and only stop on uncaught exceptions; unfortunately, that will not work either, because quite often we have exceptions that we consider as uncaught, but technically they are caught; for example:
&lt;ul&gt;
&lt;li&gt;An external library invokes our code, and our code throws an exception, which is uncaught as far as our code is concerned, but it is caught by the external library. A typical example of this is event-driven frameworks, i.e. virtually all GUI frameworks, which invoke our code to handle events, and almost always do so from within a try-catch block. Thus, any exception thrown by our event handlers is actually a caught exception, and the debugger will not stop on it.&lt;/li&gt;
&lt;li&gt;In many languages, the &lt;code&gt;try-finally&lt;/code&gt; clause internally catches exceptions and re-throws them at the end of &lt;code&gt;finally&lt;/code&gt;, meaning that any exception thrown within the &lt;code&gt;try&lt;/code&gt; block is technically a caught exception. Thus, a debugger configured to stop on uncaught exceptions will break at the end of the &lt;code&gt;finally&lt;/code&gt; block, which is completely useless and counter-productive. The same problem is encountered with other constructs which are internally implemented using &lt;code&gt;try-finally&lt;/code&gt;, such as the synchronization clause, the automatic disposal clause, etc.&lt;/li&gt;
&lt;li&gt;To complicate matters even further, an exception which is unexpected and unhandled under normal circumstances may temporarily become expected and handled during testing. This happens when a test deliberately causes malfunction to ensure that the component-under-test detects it and responds by throwing an exception, which is then caught by the test and examined to ensure that it is the correct exception and it has been correctly filled-in; when this happens, we do not want the debugger to stop, because we do not want our tests to be interrupted by the debugger while everything is proceeding according to plan.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is a StackOverflow question and answer which simplifies things a lot: &lt;a class=&#34;external&#34; 
   href=&#34;https://stackoverflow.com/q/71115356/773113&#34; target=&#34;_blank&#34;
   &gt;https://stackoverflow.com/q/71115356/773113&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;write-code-as-if-it-will-be-reviewed-by-someone-even-if-it-never-will&#34;&gt;Write code as if it will be reviewed by someone, even if it never will
&lt;/h3&gt;&lt;p&gt;Always try to take one more look at the code from a completely agnostic point of view, supposing that you know nothing about what it does, why it does it, how it does it. Does the code still make sense? Is everything obvious? If not, refactor it until it is as plain as daylight. If comments are necessary to explain what is going on, can the code be refactored so that the comments become unnecessary?&lt;/p&gt;
&lt;p&gt;Which brings us to the next point.&lt;/p&gt;
&lt;h3 id=&#34;avoid-writing-code-comments&#34;&gt;Avoid writing code comments
&lt;/h3&gt;&lt;p&gt;Never add a comment in the code unless absolutely necessary. (Note that this applies to code comments, not to
public interface comments, which can be nice to have.)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The purpose of a code comment should be to alert the reader that something special is happening here, which is not obvious, and cannot be explained by any means other than written prose. This should only be necessary in exceptional situations, while the norm should be that the code is always so simple, and so self-explanatory, that no comments are necessary.&lt;/li&gt;
&lt;li&gt;An example of an exceptional situation is provenance comments, see related section.&lt;/li&gt;
&lt;li&gt;Code comments that simply state what the code does are unwarranted causes of alert, and if you repeat them enough they will force the reader to start treating your comments as noise, and may thus cause the reader to miss that rare comment which was actually important to note.
- Comments tend to be necessary when a piece of code does something unexpected, which is usually code that takes special measures to circumvent some anomalous behavior of some other code. In these cases, explaining what the code does is not even the goal; the goal is to explain &lt;em&gt;why&lt;/em&gt; it does it, and in order to explain that you have to describe the anomalous behavior, which may even necessitate listing various usage scenarios that have been tried and results that have been observed. This in turn means that comments worth writing tend to be entire multi-paragraph-long essays explaining strange and complicated situations. In my experience, one-liners are usually of no value.
- Note that when documenting code that circumvents anomalous behavior it is a good idea to assert, if possible, that the anomalous behavior is in fact still present, so that if it gets fixed in the future, you will take notice so you can remove the code that circumvents it.
- If you find yourself adding a code comment, first ask yourself whether there is anything you can do to avoid that.
&lt;ul&gt;
&lt;li&gt;Instead of adding a comment to some piece of code explaining what it does, extract that code into a separate function that has a self-explanatory name.
&lt;ul&gt;
&lt;li&gt;However, it is even better to restructure the code, if possible, so that even the explanatory name becomes unnecessary. For example, in old C code you might come across a pointer-returning function whose documentation says that the caller is responsible for freeing the pointer. This is deplorable. Do whatever it takes to avoid this; use a callback, use an allocator parameter, have the caller supply the memory, throw it all away and rewrite it in Java, anything but requiring people to read comments or else they get punished with memory leaks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Instead of adding a comment to a hard-coded value, extract that value into a constant that has a self-explanatory name.
&lt;ul&gt;
&lt;li&gt;When performing a calculation which involves a certain fixed value, it goes without saying that you will &lt;em&gt;&lt;strong&gt;not&lt;/strong&gt;&lt;/em&gt; hard-code some magic number in the calculation; instead, you will declare a constant with a nice descriptive name for that value, and use the constant in the calculation. Note that this must be done even
in fairly trivial cases, for example &lt;code&gt;const int BitsPerByte = 8;&lt;/code&gt; and can only be skipped in an exceedingly small number of special cases, for example when directly multiplying something by 2 in order to double it, or by -1 in order to negate it.
- If a comment can be coded as an assertion statement, that&amp;rsquo;s all the better. Comments saying &amp;ldquo;x must be greater than y here&amp;rdquo; are retarded. Assert the darn thing, and spare us from the comment, or perhaps use a comment to explain the &lt;em&gt;why&lt;/em&gt;, but not the &lt;em&gt;what&lt;/em&gt;. The assertion takes care of the &lt;em&gt;what&lt;/em&gt;, and it does so unambiguously and definitively, because it compiles and passes the tests, which is something that no comment will ever do.
- If you modify some code, and there is a comment attached to that code, do not forget to do something about the comment: Ideally, your modifications should make the comment redundant, so you should remove it. If not, then at least make sure that the comment is still valid after the modifications. Unfortunately, programmers often leave comments unchanged while changing the code around them, thus making every single comment in the entire code base liable to devolving into being inaccurate, or even misleading, and thus constituting an instance of sabotage. This is happening because:&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Programmers treat comments as noise, and therefore do not even notice their presence. (This is why comments should be used very rarely, in exceptional situations only.)&lt;/li&gt;
&lt;li&gt;Comments are poorly written, so programmers do not understand them. When a programmer does not understand  a comment, they obviously cannot modify it, but it gets even worse: they do not dare to remove it either, because they assume that it must have some special meaning to some other programmer. Thus, poorly written comments are very similar to &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Persistent_organic_pollutant&#34; target=&#34;_blank&#34;
   &gt;Persistent Organic Pollutants (POPs) a.k.a. &lt;em&gt;&lt;strong&gt;forever chemicals&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt;: once created, they stay in the environment, causing harm for all eternity.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If a comment does not make sense to you, then find the author, ask them what it means, and update it accordingly. If the author is not around anymore, then ask any other experienced programmer in the shop. If they cannot tell what it means either, then trust me, this comment will never make sense to anyone, so go ahead and remove it.&lt;/p&gt;
&lt;h3 id=&#34;if-you-must-write-doc-comments-make-them-good&#34;&gt;If you must write doc-comments, make them good
&lt;/h3&gt;&lt;p&gt;Ideally, an entity (class or method) should have a well-chosen name and a very simple and straightforward interface or prototype, so that everything is clear at a glance, and therefore no doc-comment is needed. If things are not so simple, then it may be necessary to clarify them with a doc-comment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A doc-comment must be as simple and as brief as possible.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do not try to follow templates, or if you do, then treat all template fields as optional: skip any information that is not strictly speaking necessary.&lt;/li&gt;
&lt;li&gt;Some bureaucratic documentation guidelines require the doc-comment of a function to follow a specific template which begins with a summary line, is followed by one line for each parameter, and includes one line for the return value. If your function really needs all this information to be explained in a doc comment, then your function must be doing something extremely bizarre. If your function is not doing anything bizarre, then a single summary line might suffice to explain what it does; if so, then skip the extra lines explaining each parameter, as well as the extra line explaining the return value.&lt;/li&gt;
&lt;li&gt;As an example of what to avoid, see the &lt;code&gt;IEnumerable&amp;lt;T&amp;gt;.GetEnumerator()&lt;/code&gt; method of C#/dotnet. The doc comment says:
Description: Returns an enumerator that iterates through the collection.
Returns: An enumerator that can be used to iterate through the collection.
As you can see, the documentation is repeating itself. This is wasting the time of anyone attempting to read this documentation. This is annoying. Do not do this.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A doc-comment is a public interface comment, not an implementation comment. As such, a doc-comment on an entity should explain, in the most brief and abstract terms possible, the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What task it accomplishes.&lt;/li&gt;
&lt;li&gt;What input it accepts.&lt;/li&gt;
&lt;li&gt;What output it produces.
Note that it does not need to address each one of those items separately; a doc-comment on a method which simply says that it &amp;ldquo;sorts a file in-place&amp;rdquo; explains all three items in one go.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A documentation comment should not make the slightest attempt to explain any of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;How&lt;/em&gt; the task is accomplished.&lt;/li&gt;
&lt;li&gt;Which entities are expected to invoke the entity.&lt;/li&gt;
&lt;li&gt;Which entities are invoked by the entity.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The above points are important to state because many misguided practices from the infancy of our discipline have it all wrong by stipulating that documentation comments should include preposterous things such as who invokes whom, completely missing the whole point behind the notion of &lt;em&gt;general-purpose, reusable software&lt;/em&gt; and even the fundamental notion of &lt;em&gt;abstraction&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;If you are asking &amp;ldquo;but shouldn&amp;rsquo;t documentation describe the how?&amp;rdquo; the answer is no, that&amp;rsquo;s what we write code for. By definition, the only authoritative source of information as to how something is done is the code that does it. As I have already explained, the code must be so simple and so easy to read that English-language prose on top of it should be bringing no added value. As a matter of fact, the presence of prose is dangerous, because quite often people modify the code without bothering to also modify the documentation, which leads to situations where the documentation is misleading.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If, after looking at the code, something is still unclear, then place a breakpoint and launch the tests; the debugger will make things pretty clear to you.&lt;/li&gt;
&lt;li&gt;If you are wondering how the code works under a case which is not covered by the tests, then fix this by adding a test for that case! (Duh!) Also note that even if there was a &amp;ldquo;how&amp;rdquo; section in the doc-comment, it probably would not have covered that special case anyway.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;always-maintain-provenance&#34;&gt;Always maintain provenance
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;When you copy some code from the interwebz, always add a comment containing a link to the original source. Of course this is not necessary if the code that you copied is something fairly standard, like reversing a string; but if the code is anything but standard, (do you have any idea what it takes in Microsoft Windows to have a progress dialog shown while copying files?) then citing your sources is an absolute must.
&lt;ul&gt;
&lt;li&gt;Sources can include:
&lt;ul&gt;
&lt;li&gt;Examples from the official documentation (provide a link to the example page)&lt;/li&gt;
&lt;li&gt;Stack Overflow (provide a link to the answer)&lt;/li&gt;
&lt;li&gt;GitHub (provide a link to the source file(s))&lt;/li&gt;
&lt;li&gt;ChatGPT (give the exact prompt which yielded the code)
etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;This applies not only to code, but also to any piece of information, including individual values. Why did you choose this particular value and not some other value? Unless the value in question is a &lt;a class=&#34;external&#34; 
   href=&#34;https://en.wikipedia.org/wiki/Fundamental_constant&#34; target=&#34;_blank&#34;
   &gt;Fundamental Constant&lt;/a&gt; (e.g. &lt;code&gt;static readonly Velocity SpeedOfLight = 299792458.0&lt;/code&gt;) you also have to add a comment to the constant explaining exactly why this particular value was chosen, or where it came from. For example, if you need to use the population of Mexico City in a calculation, &lt;code&gt;const int MexicoCityPopulation = 9209944;&lt;/code&gt; is not enough; it must be followed by a comment saying &lt;code&gt;//2020 data from https://en.wikipedia.org/wiki/Mexico_City&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;stick-with-utc-everywhere&#34;&gt;Stick with UTC everywhere
&lt;/h3&gt;&lt;p&gt;Use UTC and only UTC for any purpose that involves storing, retrieving, communicating, converting, calculating, and doing really anything whatsoever with time, except for the following two  cases, and only the following two cases:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Parsing a string that was entered by the user into a UTC time variable.&lt;/li&gt;
&lt;li&gt;Converting a UTC time variable to a string to be shown to the user.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;However:&lt;/strong&gt; When dealing with events that happen in the future, make sure to also store the targeted time-zone along with the UTC coordinate, because every few years various countries around the world decide to change their daylight savings policy, which means that the mapping from UTC to local time may change, and you have no way of knowing that in advance.&lt;/p&gt;
&lt;h3 id=&#34;keep-technical-implementation-concerns-separate-from-application-concerns&#34;&gt;Keep technical implementation concerns separate from application concerns
&lt;/h3&gt;&lt;p&gt;Application code should not be making assumptions about the technical details of the system, so that the technical details are free to change with minimal changes to application code, and vice versa. For example, the multi-threading regime under which a system operates (whether the system utilizes a single thread, or multiple discrete threads, or a thread-pool,) is a technical implementation concern. As such, all knowledge of how multi-threading is done should be isolated in the relatively small body of code which wires up (realizes) the system, and all application code should be capable of operating regardless of the multi-threading regime. Incidentally, this facilitates running tests under a strictly single-threaded regime, to ease debugging. Async/await aficionados can cry me a river.&lt;/p&gt;
&lt;h3 id=&#34;maximize-the-consistency-of-code-formatting&#34;&gt;Maximize the consistency of code formatting
&lt;/h3&gt;&lt;p&gt;I would be tempted to say &amp;ldquo;format code with absolute consistency&amp;rdquo;, but I cannot, because we usually lack the tools to achieve this, so the goal is to strive to get as close as possible to achieving absolute formatting consistency.&lt;/p&gt;
&lt;p&gt;In the preface of the highly acclaimed book &amp;ldquo;Clean Code&amp;rdquo; by Robert C. Martin, the author mentions some experimental findings indicating that &amp;ldquo;consistent indentation style was one of the most statistically significant indicators of low bug density.&amp;rdquo; The author also states that &amp;ldquo;style distinguishes excellence from mere competence&amp;rdquo;, which I think is a very good  observation; however, the conclusion at which the author arrives is unwarranted, because correlation does not imply causation: it is probably not the consistent indentation style that causes fewer bugs, it is the kind of mindset of programmers who strive for a consistent indentation style which also happens to be the kind of mindset that produces fewer bugs. Be the programmer who has that mindset.&lt;/p&gt;
&lt;p&gt;If you are one of those programmers who do not particularly care for consistent formatting, I know what you are thinking right now: you are thinking that you are the rare exception to the rule, and that your code is of course awesome and bug-free despite looking sloppy; well, you have every right to think in any way you like about yourself, but I hope you understand that nobody else will be particularly willing to give you the benefit of the doubt.&lt;/p&gt;
&lt;p&gt;Note that this does not mean that every programmer must be forced to follow a specific set of formatting guidelines; on the contrary, by using tools to do the formatting for us, we do not have to worry about formatting. The corollary to this is that as an employer, the only kind of code formatting that you have the right to require from programmers is that which can be achieved by means of automatic code reformatting tools that you already have in place.&lt;/p&gt;
&lt;p&gt;The point to take home from all this is that the formatting style must be specified in the highest detail possible, the tools must be painstakingly configured to reformat code according to that style, and the guidelines of how to work around limitations of the tools must be laid down and agreed upon before any work is done on a software project, no matter how much effort all of this represents.&lt;/p&gt;
&lt;h3 id=&#34;use-tight-abstractions&#34;&gt;Use tight abstractions
&lt;/h3&gt;&lt;p&gt;In other words, avoid leaky abstractions.&lt;/p&gt;
&lt;p&gt;Joel Spolsky&amp;rsquo;s &lt;a class=&#34;external&#34; 
   href=&#34;https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/&#34; target=&#34;_blank&#34;
   &gt;original 2002 article formulating the &lt;em&gt;Law of Leaky Abstractions&lt;/em&gt;&lt;/a&gt; stated that &amp;ldquo;All non-trivial abstractions, to some degree, are leaky&amp;rdquo;. The article focused on examples where implementation details of the underlying layer are exposed not by the interface itself, but by observing the performance  characteristics of the underlying layer. For example, the interface of two-dimensional arrays is generic enough to allow us to iterate over them either row-first or column-first without having to know their internal memory layout; however, which way we choose can have drastic performance implications, due to memory cache utilization. This means that we do of course have to keep in mind the technicalities of the layer which implements the abstraction; it does not, however, mean that the interface should be compromised in any way.&lt;/p&gt;
&lt;p&gt;More often than not, in our daily jobs we have the misfortune of dealing with abstractions that are leaky at the interface level. A glaring example of this, in languages like C# and Java, is &lt;code&gt;class Object&lt;/code&gt;, whose public interface contains a hash-code function, which is entirely out-of-place and unwarranted, because it has to do with an implementation detail of hash-maps.&lt;/p&gt;
&lt;p&gt;This mishap could have been avoided in a number of different ways, for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Require the programmer to supply, upon hash-map construction, the hashing function to use.&lt;/li&gt;
&lt;li&gt;Require objects intended to be used as keys in a hash-map to implement a &lt;code&gt;Hashable&lt;/code&gt; interface which defines a hash-function.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unfortunately, neither of these approaches was chosen, either by Java or by C#, due to some misguided notion of convenience. Instead, the implementation detail of hash-maps that they need a hash function to work with has leaked into &lt;code&gt;Object&lt;/code&gt;, requiring every single class to have a hash-code method, even if the class will never be used as a key in a hash-map, and even if the class &lt;strong&gt;could never conceivably&lt;/strong&gt; be used as a key in a hash-map, due, to for example, it being mutable.&lt;/p&gt;
&lt;p&gt;Another example is serialization frameworks that leak details about the underlying file format that they work with: every single XML or JSON serialization framework that I have come across does that, so it is specifically a JSON serialization framework, or an XML serialization framework, but not a general-purpose serialization framework.&lt;/p&gt;
&lt;p&gt;A proper general-purpose serialization framework would expose no file format details in its interface, thus being replaceable with a different implementation which serializes to and from some other file format, without any changes necessary to the code that uses the framework. I have written such a framework, and I assure you it was not easy, but here is the thing: &lt;em&gt;Doing it right&lt;/em&gt;  is never easy.&lt;/p&gt;
&lt;p&gt;Leaky abstractions are the source of untold suffering in software development, and they must be avoided at all costs. Creating air-tight abstractions is often omitted in the interest of saving time, and people make do with leaky abstractions instead, but this invariably results in orders of magnitude more time wasted over the long run in dealing with the disastrous consequences of the leaky abstractions.&lt;/p&gt;
&lt;p&gt;I would dare to propose that the term abstraction has (or ought to have) an inherent notion of absoluteness; just as one can be either pregnant or non-pregnant but not slightly pregnant or almost pregnant, so can an interface either be an abstraction or not an abstraction; it cannot be somewhere in-between. Thus, an incomplete or leaky abstraction should, for all practical purposes, be regarded as not an abstraction. (Because that&amp;rsquo;s what the almost absolute* is: &lt;em&gt;non-absolute&lt;/em&gt;.)&lt;/p&gt;
&lt;h3 id=&#34;thoroughly-emulate-any-and-all-hardware&#34;&gt;Thoroughly emulate any and all hardware
&lt;/h3&gt;&lt;p&gt;Hardware emulation is a special case of abstraction, where instead of abstracting software we are abstracting hardware. Incomplete hardware emulations are a curse for the same reasons that leaky abstractions are a curse. Hardware emulations must be 100% complete so that any software performing high level operations with the hardware can make use of all of the functionality of the hardware while remaining completely agnostic of whether it is connected to the real hardware or to an emulation thereof.&lt;/p&gt;
&lt;h3 id=&#34;only-use-absolute-file-system-paths&#34;&gt;Only use absolute file-system paths
&lt;/h3&gt;&lt;p&gt;All file-system paths must be absolute. It is fine to provide the user with the convenience of entering a relative path, but the relative path must be converted to absolute immediately upon entering the system. Relative paths are based on the notion of a &amp;ldquo;current directory&amp;rdquo;, which is one of the most ill-conceived, misused, and treacherous notions in the history of programming, because it is a global mutable variable. (I hope I do not need to explain why a global mutable variable is evil, right?) Note that the &amp;ldquo;current directory&amp;rdquo; is global not only across all classes of your application, but also across all threads of your application, and, in DotNet, even global across all AppDomains of your application, which were supposed to be completely isolated. Duh!? What were they thinking?&lt;/p&gt;
&lt;h3 id=&#34;avoid-guids-also-known-as-uuids&#34;&gt;Avoid GUIDs (also known as UUIDs)
&lt;/h3&gt;&lt;p&gt;Never use GUIDs if you can avoid them. If you must use them, then make sure they are an implementation detail and that they constitute a side-note of your design, not a predominant feature of your design. Read this: &lt;a 
   href=&#34;//localhost:1313/post/2017-06-on-uuids-and-guids/&#34;
   &gt;What is wrong with UUIDs and GUIDs&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;do-it-right-&#34;&gt;Do It Right 
&lt;/h3&gt;&lt;p&gt;Avoid taking shortcuts in the name of immediate savings now but at the expense of headaches later, because the later headaches invariably end-up costing orders of magnitude more than the immediate savings. When some colleague, manager, or decision-maker suggests to &amp;ldquo;make it simple now, and worry about making it right later&amp;rdquo; they are imagining that they are being smart and they are helping optimize things, while in fact they are being a smart-ass, and they are suggesting that a technical crime be committed.&lt;/p&gt;
&lt;p&gt;An example of this, which has already been mentioned, is finding proper names for identifiers. If you want to introduce a new identifier, finding a proper name for it may require opening up the thesaurus, spending a considerable amount of time creating a list of candidate words, opening up the dictionary, looking up the exact meaning of each candidate word, applying the process of elimination, etc. So, you can save lots of time right now by skipping all this and simply calling it something meaningless, or worse yet, something inaccurate and therefore misleading. It is a fact that you will indeed experience immediate time savings right now if you do this. However, it is also a fact that the time you save now by performing this act of sabotage against yourself will invariably be paid a hundredfold later, when you and your coworkers will be wondering what on earth was meant by this meaningless name, or struggling with the realization that it is being used in the code in ways that are in conflict with its meaning.&lt;/p&gt;
&lt;p&gt;Of course, &lt;em&gt;Do It Right&lt;/em&gt;  does not apply only to naming, it applies to everything. And when I say everything, I mean &lt;strong&gt;E V E R Y T H I N G&lt;/strong&gt;. The practice of &lt;em&gt;Do It Right&lt;/em&gt;  must be a conditioned reflex; it must be the default, reliable, fail-safe, look-no-further choice that we always make, without spending time calculating the costs vs. savings of &lt;em&gt;Do it Right&lt;/em&gt; , debating whether we should &lt;em&gt;Do It Right&lt;/em&gt;  or not &lt;em&gt;Do It Right&lt;/em&gt; , etc. The term &lt;em&gt;Do It Right&lt;/em&gt;  contains in it the reason why we should &lt;em&gt;Do It Right&lt;/em&gt; .&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;C.V. Driven Development: See  &lt;a class=&#34;external&#34; 
   href=&#34;https://martinjeeblog.com/2015/03/11/cv-driven-development-cdd/&#34; target=&#34;_blank&#34;
   &gt;Martin Jee&amp;rsquo;s blog - CV Driven Development (CDD)&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
        </item>
        
    </channel>
</rss>
