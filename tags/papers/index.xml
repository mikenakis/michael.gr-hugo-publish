<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Papers on Michael's Blog</title><link>https://blog2.michael.gr/tags/papers/</link><description>Recent content in Papers on Michael's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Michael Belivanakis (a.k.a. Mike Nakis)</copyright><lastBuildDate>Fri, 24 Oct 2025 10:19:02 +0200</lastBuildDate><atom:link href="https://blog2.michael.gr/tags/papers/index.xml" rel="self" type="application/rss+xml"/><item><title>Refactoring: strong vs weak</title><link>https://blog2.michael.gr/post/2025-09-refactoring/</link><pubDate>Fri, 12 Sep 2025 10:50:44 +0000</pubDate><guid>https://blog2.michael.gr/post/2025-09-refactoring/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2025-09-refactoring/images/refactoring.svg"
loading="lazy"
&gt;
&lt;/p&gt;
&lt;h3 id="abstract"&gt;Abstract
&lt;/h3&gt;&lt;p&gt;Two distinctly different widely used meanings of the term &lt;em&gt;&lt;strong&gt;code refactoring&lt;/strong&gt;&lt;/em&gt; are identified and named:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Changing how code works, without changing the requirements that it fulfills (refactoring in the weak sense)&lt;/li&gt;
&lt;li&gt;Changing how code is expressed, without changing how it works (refactoring in the strong sense)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id="the-common-understanding"&gt;The common understanding
&lt;/h3&gt;&lt;p&gt;The term &lt;em&gt;&lt;strong&gt;refactoring&lt;/strong&gt;&lt;/em&gt; is commonly understood within the software engineering discipline to have the meaning documented by Martin Fowler in his &lt;a class="external"
href="https://martinfowler.com/bliki/DefinitionOfRefactoring.html" target="_blank"
&gt;Definition Of Refactoring&lt;/a&gt; post:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Refactoring (noun): a change made to the internal structure of software to make it easier to understand and cheaper to modify without changing its observable behavior.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In the case of a software application, the observable behavior is in essence the set of requirements that it fulfills. (And also its look and feel: if you change the font, this is not refactoring.) In the case of a module, or a class, or an individual method, the observable behavior is the mapping of parameter values to results, contracts fulfilled, and side-effects, if any.&lt;/p&gt;
&lt;p&gt;Let us call these things &lt;em&gt;&lt;strong&gt;requirements&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Note that according to this widely used sense of refactoring, we are allowed to take any piece of code, throw it away, and replace it with an entirely different piece of code, and call what we just did refactoring, as long as requirements are still being fulfilled as before.&lt;/p&gt;
&lt;p&gt;The trick is, of course, how can we tell, or who is to say, that requirements are still being fulfilled. It should come as no surprise that in many cases things do not go as intended:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A change in the code might have some subtle consequences that we were not aware of, so we might be thinking that requirements are still fulfilled, while they are not.&lt;/li&gt;
&lt;li&gt;Requirements are never entirely unambiguous, so they might be fulfilled according to our interpretation, but not according to someone else's interpretation.&lt;/li&gt;
&lt;li&gt;Sometimes a combination of the above may occur.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example, the requirement to &amp;quot;create an empty file&amp;quot; might initially be fulfilled by two lines of code that create a binary file and immediately close it; then, one day, someone might decide to refactor those two lines of code by replacing them with a single invocation to a create-file-from-string function, passing it the empty string. One line of code is better than two lines of code, right? What could possibly go wrong? Well, if by &amp;quot;empty file&amp;quot; the requirements meant a file with no text in it, this refactoring was probably okay; however, if by &amp;quot;empty file&amp;quot; the requirements actually meant a zero-length file, then this refactoring may not have been okay, because the create-file-from-string function might, unbeknownst to us, create a file that contains a UTF8 BOM. This is an example of both things going wrong: the requirements were vague, and the &amp;quot;refactoring&amp;quot; had subtle unintended consequences.&lt;/p&gt;
&lt;p&gt;Hopefully we have enough tests in place to catch such violations of the requirements, but this does not always work either, because the tests usually verify &lt;em&gt;&lt;strong&gt;someone's&lt;/strong&gt;&lt;/em&gt; interpretation of the requirements, and they usually do so only &lt;em&gt;&lt;strong&gt;partially&lt;/strong&gt;&lt;/em&gt;, since you cannot anticipate and test for every possible scenario.&lt;/p&gt;
&lt;h3 id="the-mathematical-understanding"&gt;The mathematical understanding
&lt;/h3&gt;&lt;p&gt;There is another sense of refactoring that we are also familiar with: the sense used by Integrated Development Environments (IDEs) that perform useful transformations on code, such as renaming a variable, re-ordering the parameters of a function, etc.&lt;/p&gt;
&lt;p&gt;The transformations performed by IDEs tend to adhere to the mathematical sense of refactoring: the code is transformed in such a way that the new code is &lt;em&gt;&lt;strong&gt;equivalent&lt;/strong&gt;&lt;/em&gt; to the old code, just as in mathematics the refactoring of &lt;strong&gt;x = 2y + 2z&lt;/strong&gt; yields &lt;strong&gt;x = 2(y + z)&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Note that when we perform refactoring operations using an IDE, we usually feel no need to re-run the tests, because the new code works exactly as the old code, barring any bugs in the IDE, or any foolish hacks from our side, such as weak typing or binding by name.&lt;/p&gt;
&lt;h3 id="summing-it-up"&gt;Summing it up
&lt;/h3&gt;&lt;p&gt;The bottom line of all this is that the term refactoring is being widely used within the software engineering discipline to mean two distinctly different things. These two things are so different from each other as to warrant taking notice of this fact, and making the distinction explicit:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The weak (common) sense of refactoring:&lt;/p&gt;
&lt;p&gt;Transformations that (hopefully) result in no change in how requirements are fulfilled.&lt;/p&gt;
&lt;p&gt;They are usually performed manually by the programmer, they may involve extensive changes in the way the code works, and they require thorough testing to guarantee that nothing was inadvertently broken.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The strong (mathematical) sense of refactoring:&lt;/p&gt;
&lt;p&gt;Transformations that result in code that is functionally equivalent to what it was before.&lt;/p&gt;
&lt;p&gt;They are usually performed automatically by the IDE at the programmer's request, they tend to be limited or superficial, they tend to change how code is expressed but not how it works, and they typically do not need to be followed by a round of testing, because the code is typically guaranteed to behave the same way as before.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Also of interest is Martin Fowler's post on the &lt;a class="external"
href="https://martinfowler.com/bliki/EtymologyOfRefactoring.html" target="_blank"
&gt;Etymology of Refactoring&lt;/a&gt;.&lt;/p&gt;</description></item><item><title>The perils of whiteboards</title><link>https://blog2.michael.gr/post/2025-08-the-perils-of-whiteboards/</link><pubDate>Thu, 28 Aug 2025 08:46:25 +0000</pubDate><guid>https://blog2.michael.gr/post/2025-08-the-perils-of-whiteboards/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2025-08-the-perils-of-whiteboards/media/chimera.svg"
loading="lazy"
&gt;
&lt;/p&gt;
&lt;h3 id="summary"&gt;Summary
&lt;/h3&gt;&lt;p&gt;Building upon the realization that conventional means of software design today amount to nothing more than fancy whiteboards, we examine the pitfalls, disadvantages, and consequences of designing software using such tools.&lt;/p&gt;
&lt;p&gt;This post is support material for &lt;a
href="https://blog2.michael.gr/post/2023-12-09-authoritative-technical-design/"
&gt;Towards Authoritative Software Design&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id="the-means"&gt;The means
&lt;/h3&gt;&lt;p&gt;The conventional means of software design today are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pen and paper&lt;/li&gt;
&lt;li&gt;Whiteboard&lt;/li&gt;
&lt;li&gt;General-purpose shape-drawing tools (e.g. Microsoft Word or PowerPoint drawings)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;or, in the best case,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Box-and-arrow drawing applications that are smart enough to keep the arrows connected as we drag the boxes around the canvas. (e.g. Microsoft Visio)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unfortunately, even the box-and-arrow apps have no notion of what the boxes and the arrows stand for; thus, they cannot be used for anything other than modelling, which makes them nothing more than fancy whiteboards.&lt;/p&gt;
&lt;p&gt;Over the years, various tools and techniques have been proposed to better aid the software design process, including UML, but none of them amounts to anything more than a fancy whiteboard. For details, see &lt;a
href="https://blog2.michael.gr/post/2025-08-the-state-of-affairs-in-computer-aided/"
&gt;The state of affairs in computer-aided software design&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="the-drawbacks"&gt;The drawbacks
&lt;/h3&gt;&lt;p&gt;One of the immediately noticeable consequences of having nothing but whiteboards at our disposal is the lack of a standardized notation: every architect is free to express concepts in any way they like, and anyone attempting to make sense out of their design has to undergo initiation rituals. (UML attempted to standardize notation, but it is a failure, see &lt;a
href="https://blog2.michael.gr/post/2022-08-uml/"
&gt;On UML&lt;/a&gt;.) As a result, software design as conventionally practiced is not easy to communicate. This is, however, the least of our problems.&lt;/p&gt;
&lt;p&gt;Here is a list of much more serious consequences of using whiteboards for technical software design:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Designs often include elements that are not well-defined in engineering terms.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You see this with designs containing supposedly technical but actually quite nebulous entities such as a &lt;em&gt;Persistent Data Store&lt;/em&gt; here, a &lt;em&gt;Messaging Backbone&lt;/em&gt; there, or a &lt;em&gt;Remote Server&lt;/em&gt; over there. Such entities are not sufficiently well-defined to be suitable for inclusion in a technical design.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Designs often include elements that are completely outside the realm of engineering.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You see this with designs containing human figures representing users, pictures of money representing payments, etc. The presence of such items in a software design usually indicates a confusion between what is a technical design and what is a functional specification.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Designs often include elements from wrong levels of abstraction.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You see this with designs that mix software components with flowcharts, state diagrams, etc. Notwithstanding the fact that these are also boxes connected with arrows, they represent decision-making logic, which is an implementation detail of the component that contains that logic; as such, they have no place in a design.&lt;/p&gt;
&lt;p&gt;You also see this with designs that confuse interfaces with other kinds of relationships between components, such as ownership, containment, inheritance, data flow, etc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Designs are not informed with what elements are available for incorporation.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The medium on which software designs are conventionally expressed provides no technical means of establishing, or enforcing, a correspondence between a box as it appears in the design, and the actual provisionable, instantiatable, and runnable software module that it represents. This can be okay in the case of modules that have not been developed yet, but more often than not, a design intends to incorporate existing modules. In the absence of any technical means for informing the design about existing modules, the design inescapably represents hypotheses, assumptions, and approximations rather than fact.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Designs often prescribe invalid combinations of elements.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The ways in which conventional designs intend to interconnect components do not necessarily match the ways in which the components can actually be interconnected.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A conventional design may assume that a certain component exposes or invokes a particular interface while in fact the component does not have such an interface.&lt;/li&gt;
&lt;li&gt;A conventional design may prescribe a connection between two components on a particular interface, while in fact the interface exposed by one component is not a valid match for the interface invoked by the other component.&lt;/li&gt;
&lt;li&gt;A conventional design may fancy a connection that goes from one component to another component which is inside a different container. In reality, such crossing of containment boundaries is impossible; especially if it involves different execution environments or different levels of scale, it is complete nonsense.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Designs are often expressed at an unworkably high level of abstraction.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The level of abstraction necessary in order to guarantee the feasibility of a technical software design is that of the component diagram, which shows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The individual components that make up the system.&lt;/li&gt;
&lt;li&gt;The interfaces implemented and/or invoked by each component.&lt;/li&gt;
&lt;li&gt;Connections from interface invocations to interface implementations.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unfortunately, since conventional means of software design are not informed about existing components and their interfaces, they do not have enough factual information at their disposal to delve into the level of detail necessary for a component diagram.&lt;/p&gt;
&lt;p&gt;For this reason, the level of abstraction most commonly used by software architects is that of a block diagram, which might be suitable for abstract architectural work, but it is not detailed enough to give any guarantees about the feasibility of the proposed design.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Designs fail to capture dynamic aspects of software systems.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Conventional means of software design lack the ability to accurately express dynamic constructs such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Plurality: Multiple instantiation of a certain component, where the number of instances is decided at runtime.&lt;/li&gt;
&lt;li&gt;Polymorphism: Fulfilling a certain role by instantiating one of several different component types capable of fulfilling that role, where the choice of which type to instantiate is made at runtime.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Designs are often incomplete.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A design may incorporate a component which needs to invoke a certain interface in order to get its job done, but omit incorporating a component implementing that interface. In such cases, the software system cannot be deployed as
designed, and yet the architects are free to proclaim the design as complete.&lt;/p&gt;
&lt;p&gt;The above long list of problems stems from the lack of technical means of informing the design with what is available, and restricting it to what is possible. This means that whiteboard designs allow the concoction of any &lt;a class="external"
href="https://en.wikipedia.org/wiki/Chimera_%28mythology%29" target="_blank"
&gt;chimera&lt;/a&gt; imaginable.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For further reading, please see &lt;a
href="https://blog2.michael.gr/post/2023-12-09-authoritative-technical-design/"
&gt;Towards Authoritative Software Design&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: &lt;a class="external"
href="https://commons.wikimedia.org/wiki/File:Coa_Illustration_Elements_Chimera.svg" target="_blank"
&gt;Illustration of a chimera by Christie L. Ward, from Wikimedia Commons&lt;/a&gt;, used under &lt;a class="external"
href="https://creativecommons.org/licenses/by-sa/3.0/deed.en" target="_blank"
&gt;CC BY-SA 3.0&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Immutability Assessment</title><link>https://blog2.michael.gr/post/2025-06-immutability-assessment/</link><pubDate>Mon, 02 Jun 2025 13:16:41 +0000</pubDate><guid>https://blog2.michael.gr/post/2025-06-immutability-assessment/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2025-06-immutability-assessment/images/diamond.svg"
loading="lazy"
&gt;
&lt;/p&gt;
&lt;h2 id="abstract"&gt;Abstract
&lt;/h2&gt;&lt;p&gt;The need is identified for programmatically ascertaining, in languages like C# and Java, the immutability of certain objects used in situations where they are expected to be immutable. The technicalities of immutability assessment are discussed. A mechanism is described for achieving it.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h2 id="the-problem"&gt;The Problem
&lt;/h2&gt;&lt;p&gt;Raise your hand if you have ever had to troubleshoot a bug that manifested itself in mysterious ways, defied rational explanation, tenaciously evaded detection, made you rage at the absurdity of the observed behavior, and after much weeping and wailing and gnashing of teeth, turned out to be due to one of the following reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Inadvertently mutating an object that has been added as a key in a hash map.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Inadvertently mutating an object that has been passed to another thread.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;in general:&lt;/p&gt;
&lt;ol start="3"&gt;
&lt;li&gt;One piece of code mutating an object that another piece of code groundlessly assumes that it remains unchanged.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These mishaps of course happen due to the fact that the objects involved should have been immutable, but they were not. If an object is immutable, nobody can mutate it, and therefore nobody has to &lt;em&gt;assume&lt;/em&gt; that it will not change.&lt;/p&gt;
&lt;p&gt;So, could hash maps somehow require that their keys be immutable? Could threads somehow require that objects shared among them be immutable?&lt;/p&gt;
&lt;p&gt;This leads us to the more general question of how to ascertain immutability, which is certainly not an easy task. Most programmers don't even consider it; few talk about it; even fewer attempt it. Programmers all over the world are accustomed to routinely using objects in situations where immutability is an absolute requirement, but without ever ascertaining it, essentially &lt;em&gt;praying&lt;/em&gt; that the objects be immutable.&lt;/p&gt;
&lt;h2 id="compiler-enforced-immutability"&gt;Compiler-Enforced Immutability
&lt;/h2&gt;&lt;p&gt;Inadvertent mutation is not a problem in purely functional programming languages, where there simply is no such thing as mutation. However, most programmers do not use such languages, because they are cumbersome to work with. Most programmers use languages like Java and C#, which are not purely functional, so they allow mutation, and so inadvertent mutation can sometimes happen.&lt;/p&gt;
&lt;p&gt;Java and C# do support a few constructs for defining invariable (final/readonly) class members, but they are woefully inadequate. Systematic compiler support for declaring and requiring immutability would greatly help to reduce the volume of mistakes being made, but nothing like that exists, and even if it did exist, it would not be a panacea, because there are situations where the compiler cannot help.&lt;/p&gt;
&lt;p&gt;Since compiler-enforced immutability is not available, we have to enforce it ourselves, which means that we have to programmatically detect immutability and ascertain it.&lt;/p&gt;
&lt;p&gt;Languages like Java and C# offer full reflection support, so we can examine every field of every type, (static analysis,) and we can even examine the values of fields of instances. (Dynamic analysis.) Furthermore, these languages compile into intermediate code, which is relatively easy to parse and reason about, meaning that we can even analyze executable code if we want to. (More static analysis.)&lt;/p&gt;
&lt;p&gt;So, the question is what to analyze, and how.&lt;/p&gt;
&lt;h3 id="superficial-vs-deep-immutability"&gt;Superficial vs. Deep Immutability
&lt;/h3&gt;&lt;p&gt;Many classes have the term &amp;quot;immutable&amp;quot; in their name, but they are only superficially immutable. Take a generic immutable collection or example: &lt;code&gt;ImmutableCollection&amp;lt;T&amp;gt;&lt;/code&gt;. Let us trust that it does in fact behave perfectly immutably, and therefore it does, arguably, deserve to be called immutable; let us now ask: would an instance of this class be safe to pass to another thread? The answer is that it depends on the actual type of the generic parameter: If &lt;code&gt;T&lt;/code&gt; is immutable, it is safe; but if &lt;code&gt;T&lt;/code&gt; is mutable, then it is absolutely not safe.&lt;/p&gt;
&lt;p&gt;So, in order to reap any benefits whatsoever from immutability, it must be deep immutability. Shallow immutability is irrelevant. Please keep this in mind, as it has severe implications in our quest to ascertain the immutability of anything.&lt;/p&gt;
&lt;h3 id="static-analysis"&gt;Static Analysis
&lt;/h3&gt;&lt;p&gt;The term &amp;quot;static analysis&amp;quot; refers to examining the code that makes a program, (as written, or as compiled,) but not the state of the program as it runs. Consequently, static analysis can examine the definitions of data structures, but not the actual contents of those data structures during runtime.&lt;/p&gt;
&lt;p&gt;A popular but na√Øve understanding of immutability is that it is an inherent characteristic of types, and that the instances of the types (i.e. the objects) simply follow suit. According to this understanding, all we need to do is to ascertain that a certain type is immutable, and from that moment on we know that all of its instances are immutable.&lt;/p&gt;
&lt;p&gt;This understanding is not entirely false, but it is very limiting, because it means that only concrete and non-extensible (a.k.a. final, sealed) types can potentially be assessed as immutable: All interfaces must necessarily be considered as mutable, because we have no idea how they may be implemented, and all abstract or simply extensible types must also necessarily be considered as mutable, because we have no idea how they may be extended.&lt;/p&gt;
&lt;p&gt;This poses an insurmountable problem if we wanted to have, say, a queue for exchanging messages between threads, where the messages are organized in a class hierarchy: such a queue would not be able to ascertain the immutability of the messages it handles, because all it knows is the base-most 'Message' class, which is necessarily extensible, and therefore mutable, as far as static analysis can tell.&lt;/p&gt;
&lt;p&gt;Now, consider that many perfectly immutable classes tend to be passed around as interfaces, (e.g. &lt;code&gt;Comparer&lt;/code&gt;, &lt;code&gt;Hasher&lt;/code&gt;, &lt;code&gt;Predicate&lt;/code&gt;, all sorts of stateless converters, etc.) that these interfaces are often stored in fields, and that a field of mutable type makes the class containing that field also mutable. It quickly becomes evident that static analysis can only work in a universe where no abstraction is utilized; however, we do not live in such a universe: we make use of languages like Java and C# precisely because we want the benefits of &lt;em&gt;unlimited&lt;/em&gt; abstraction.&lt;/p&gt;
&lt;p&gt;One final nail in the coffin of static analysis is the issue of delayed immutability.&lt;/p&gt;
&lt;h3 id="delayed-immutability"&gt;Delayed Immutability
&lt;/h3&gt;&lt;p&gt;Some objects begin life as mutable, so that they can undergo some non-trivial initialization, and become immutable later, once initialization is complete. This behavior is necessary when creating cyclic graphs of immutable objects, or when creating an immutable object while loading its contents from some
external storage. (Alternative terms used by others for this kind of immutability are &lt;em&gt;Freezing&lt;/em&gt; and &lt;em&gt;Popsicle immutability&lt;/em&gt;.)&lt;/p&gt;
&lt;p&gt;There is no standard way of representing delayed immutability, so let me propose one real quick:&lt;/p&gt;
&lt;p&gt;Let there be a &lt;code&gt;SelfAssessing&lt;/code&gt; interface, which is to be implemented by any class that utilizes delayed immutability. This interface is to have just one method, &lt;code&gt;IsImmutable()&lt;/code&gt;, which is expected to return &lt;code&gt;false&lt;/code&gt; for as long as the object is mutable, and to start returning &lt;code&gt;true&lt;/code&gt; once the object becomes immutable.&lt;/p&gt;
&lt;p&gt;Note that static analysis is by nature limited to examining types, but delayed immutability requires invoking a method of an instance of a type. Thus, static analysis completely fails to assess delayed immutability. Furthermore, a delayed immutable may appear as a field in any type, meaning that static analysis fails to assess potentially any type.&lt;/p&gt;
&lt;p&gt;Since static analysis fails in the presence of abstraction and/or delayed immutability, it follows that we have to examine not just types, but also the instances of types in the running software system. This calls for &lt;em&gt;dynamic analysis&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id="dynamic-analysis"&gt;Dynamic Analysis
&lt;/h3&gt;&lt;p&gt;The term &amp;quot;dynamic analysis&amp;quot; refers to examining various aspects of a software system as it runs. In some cases the aim is to examine the behavior of the software, in other cases (such as the case at hand) it is to examine the data structures it creates. Dynamic analysis may require (and in the case at hand it does require) static analysis as a prerequisite.&lt;/p&gt;
&lt;p&gt;With dynamic analysis we can look past the advertised type of a field, which may be abstract, and obtain the instance stored in the field, (the value of the field,) in order to find out the actual, concrete type of that instance.&lt;/p&gt;
&lt;p&gt;Once we have the concrete type of an instance, we can assess whether it is immutable, and this may involve recursively assessing any instances referenced by that instance. If everything is immutable, then and only then can the containing instance assessed as immutable.&lt;/p&gt;
&lt;p&gt;To make all of this work, we begin with static analysis where we use reflection to examine a type with the goal of giving it one of &lt;em&gt;three&lt;/em&gt; possible assessments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mutable&lt;/li&gt;
&lt;li&gt;Immutable&lt;/li&gt;
&lt;li&gt;Inconclusive&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These type assessments are issued as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;strong&gt;mutable&lt;/strong&gt; type assessment is issued if:
&lt;ul&gt;
&lt;li&gt;The type has any fields that are variable, (non-final/non-readonly,) because such fields are mutable no matter what their advertised type (field type) is.&lt;/li&gt;
&lt;li&gt;The type has nothing but invariable fields, but one or more of them is of an advertised type that has received a mutable assessment, because this means that the containing type is not deeply immutable.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;immutable&lt;/strong&gt; type assessment is issued if a type consists exclusively of fields that are both invariable and of an advertised type which has received an immutable assessment.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;inconclusive&lt;/strong&gt; type assessment is issued if:
&lt;ul&gt;
&lt;li&gt;The type is abstract or extensible (non-final/non-sealed.)&lt;/li&gt;
&lt;li&gt;The type is self-assessing.&lt;/li&gt;
&lt;li&gt;The type contains any fields of an advertised type that has in turn received an inconclusive assessment.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that the above are &lt;em&gt;type&lt;/em&gt; assessments, issued on types, by static analysis alone.&lt;/p&gt;
&lt;p&gt;Every instance of a type that has received a mutable or immutable assessment is in turn mutable or immutable without the need to examine the contents of the instance; however, every instance of a type that has received an inconclusive assessment must be further examined to issue a final assessment for that instance only.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The value of each field must be obtained from the instance, and assessment must recursively be applied on that value.&lt;/li&gt;
&lt;li&gt;If the type is self-assessing, then the &lt;code&gt;IsImmutable()&lt;/code&gt; method must be invoked on the instance, to ask it whether it is immutable or not.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both type assessment and instance assessment can be expensive; however, note the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Once a type assessment has been issued, it will never change, so it can be
cached, and never recomputed again.&lt;/li&gt;
&lt;li&gt;Instance assessments can be requested only from within assertions, meaning
that they can incur zero runtime overhead on production.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note that for static analysis we employed nothing but reflection to examine the fields of a type, and for dynamic analysis we also employed nothing but reflection to examine the values of fields of instances, so no code analysis was necessary. However, for the sake of completeness, let us also take a brief look at code analysis.&lt;/p&gt;
&lt;h3 id="code-analysis"&gt;Code analysis
&lt;/h3&gt;&lt;p&gt;There is a school of thought according to which the answer to the immutability assessment question lies in analyzing the executable instructions that comprise a type to determine whether any fields are mutated by code outside of the constructor.&lt;/p&gt;
&lt;p&gt;The problem with code analysis is that it is a form of static analysis, so it suffers from the disadvantages of static analysis that were previously explained.&lt;/p&gt;
&lt;p&gt;Suppose that code analysis determines that a type does not mutate any fields outside of its constructor; suppose, however, that the type contains a field of abstract type, which gets initialized from a constructor parameter; is this type mutable or immutable? Obviously, it depends on the concrete type of the instance that will be stored, at runtime, in that field. So, we are back at square one, where static analysis simply does not work in the face of abstraction. Therefore, code analysis is not the answer.&lt;/p&gt;
&lt;p&gt;Code analysis could potentially be useful, as a supplement to dynamic analysis, in the following ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In some cases, a type contains a field which is written by a method other than the constructor. For this to work, the field has to be variable. (Non-final/non-readonly.) Thus, with the use of reflection alone, this type will be assessed as mutable. However, it may be that the method which writes the field makes sure that the field is only written once during the lifetime of the instance, and that it gets written before it is ever read, so it will never appear to mutate as far as external observers can tell. Thus, the type is effectively immutable. It is in theory possible (though not easy) for code analysis to detect that the field is treated in this way, thus allowing the type to be assessed as immutable.&lt;/li&gt;
&lt;li&gt;Sometimes a type contains fields that are only written by the constructor, but the programmer who wrote that type forgot to declare them as invariable (final/readonly) and did not pay attention to the warnings / inspections / analysis messages. If we were to only use reflection, these fields would be considered variable, so the type would in turn be assessed as mutable. Code analysis can detect that the fields are not written outside of the constructor, allowing them to be assessed as invariable, and therefore the type to be assessed as immutable.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="preassessment"&gt;Preassessment
&lt;/h3&gt;&lt;p&gt;There exist types that would normally receive a mutable assessment, but we know for sure that they are practically immutable. A famous example of such a type, both in Java and in C#, is class &lt;code&gt;String&lt;/code&gt;. In such cases, we must be able to &lt;em&gt;preassess&lt;/em&gt; the type as immutable, which means to assign an immutable assessment to the type, without analyzing it.&lt;/p&gt;
&lt;p&gt;Note that preassessment constitutes a promise, and promises can be false. If a type which is actually mutable is mistakenly preassessed as immutable, bad things are bound to happen.&lt;/p&gt;
&lt;h2 id="generic-shallow-preassessment"&gt;Generic Shallow Preassessment
&lt;/h2&gt;&lt;p&gt;Some generic types are effectively immutable containers. In Java, which uses type erasure, these are essentially containers of elements of type &lt;code&gt;object&lt;/code&gt;, so they are by definition inconclusive; however, in C# the type of the generic type argument is known at runtime, so we do better than that. When a generic effectively immutable container type is constructed with an actual type parameter, the immutability of the resulting type depends on the immutability of that parameter:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the generic type parameter is a mutable type, then the constructed generic container type is mutable, so instances of that type do not need to be assessed.&lt;/li&gt;
&lt;li&gt;If the generic type parameter is an immutable type, then the constructed generic container type is immutable, so again, instances of that type do not need to be assessed.&lt;/li&gt;
&lt;li&gt;If the generic type parameter is inconclusive, then the constructed generic container type is inconclusive, which means that for every instance of that type, all elements in the container must be assessed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In order to be able to assess the elements of a container, the preassessment for the container must include an object known as a &lt;em&gt;deconstructor&lt;/em&gt;. Dynamic analysis will be invoking the deconstructor to enumerate the elements contained within each instance of the container, so that each element can be assessed. Deconstructors are generally trivial:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The deconstructor for collections simply yields all the elements of the collection.&lt;/li&gt;
&lt;li&gt;The deconstructor for maps/dictionaries simply yields all the mappings. (Map entries / key-value pairs.)&lt;/li&gt;
&lt;li&gt;The deconstructor for &lt;code&gt;Lazy&amp;lt;T&amp;gt;&lt;/code&gt; simply yields the one and only value contained within the lazy object.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Preassessment is mainly intended for types that have been defined by others, and thus we cannot modify their source code. For types that we write ourselves, we want a finer level of control: we want to be able to override the assessment of specific fields only, and allow all other fields to be assessed the normal way, to catch situations where we thought that some field was immutable, while in fact assessment of that field shows that it is not immutable. For that, we need &lt;em&gt;field overrides&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id="field-overrides"&gt;Field Overrides
&lt;/h3&gt;&lt;p&gt;Sometimes a field is variable, but we want to promise that we will only vary it in an effectively immutable way. For such cases, there must be an annotation/attribute that we can attach to that field, to indicate that analysis should treat the field as invariable.&lt;/p&gt;
&lt;h3 id="array-field-overrides"&gt;Array Field Overrides
&lt;/h3&gt;&lt;p&gt;Arrays are by definition mutable in Java and C#, and by extension so is any type that contains an array field, even if the field itself is invariable. If we want to be able to create an immutable type that contains an array field, there must be an annotation/attribute that we can attach to that array field, to indicate that analysis should treat the array itself as invariable.&lt;/p&gt;
&lt;h3 id="elucidation"&gt;Elucidation
&lt;/h3&gt;&lt;p&gt;Once we have immutability assessment working as described in the preceding sections, a new challenge becomes apparent: sometimes, a data structure that was intended to be immutable will be assessed as mutable due to some tiny programmer mistake. If the data structure is large and complex, it might not be obvious where the mistake is. The programmer will receive a mutable assessment, but will not know why it was given and where to look to find the problem.&lt;/p&gt;
&lt;p&gt;For this reason, every mutable instance assessment must come with a sentence explaining to the programmer why the assessment was issued. Since every mutable instance assessment typically has one or more other assessments that are the reasons that led to it, these sentences will often form entire trees, each sentence being further explained by nested sentences.&lt;/p&gt;
&lt;p&gt;I call this feature elucidation.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="further-reading"&gt;Further reading
&lt;/h2&gt;&lt;p&gt;Eric Lippert's must-read post about the different kinds of immutability:
&lt;a class="external"
href="https://ericlippert.com/2007/11/13/immutability-in-c-part-one-kinds-of-immutability/" target="_blank"
&gt;Immutability in C# Part One: Kinds of Immutability&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="appendix"&gt;Appendix
&lt;/h2&gt;&lt;p&gt;Immutability assessment is awesome, but the more the compiler can do for us, the better.&lt;/p&gt;
&lt;p&gt;Here are some examples of what compilers of (non-purely functional) programming languages could be doing for us in the direction of compiler-enforced immutability:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A language could support an 'immutable' class modifier, which would require the class to contain only immutable members. An immutable class may not extend a mutable class, and a mutable class may not extend an immutable class. (Although a mutable class may extend a class which has not been marked as immutable, even if that class happens to be immutable.)&lt;/li&gt;
&lt;li&gt;A language could support an 'immutable' modifier for function arguments and for fields, requiring that they may only be assigned from concrete types that are immutable, or from other fields or function arguments that are also immutable.&lt;/li&gt;
&lt;li&gt;A language could support an 'immutable' generic parameter constraint, which would mandate that only immutable types can be used as generic type arguments.&lt;/li&gt;
&lt;li&gt;A language could support a 'stable' field modifier, allowing a mutable field to appear in an immutable class, and acting as a promise that the field will only be mutated in a way which upholds effective immutability.&lt;/li&gt;
&lt;li&gt;A language could support a 'stable array' field modifier for array fields, allowing an array to appear in an immutable class, and acting as a promise that the contents of the array will either not be mutated, or they will only be mutated in a way which upholds effective immutability.&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Cover image from &lt;a class="external"
href="https://thenounproject.com/icon/diamond-4452869/" target="_blank"
&gt;Oleksandr Panasovskyi from The Noun Project&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Scratch&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;(Ignore)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As it turns out, the mutability of value types is largely irrelevant, as explained here:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="external"
href="http://mustoverride.com/tuples%5C_structs/" target="_blank"
&gt;Vladimir Sadov: &amp;quot;C# Tuples. Why mutable structs?&amp;quot;&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Build configurations</title><link>https://blog2.michael.gr/post/2025-06-build-configurations/</link><pubDate>Sun, 04 May 2025 13:39:03 +0000</pubDate><guid>https://blog2.michael.gr/post/2025-06-build-configurations/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2025-06-build-configurations/images/ChatGPT-Image-Jun-11,-2025,-12_31_08-PM---fixed.jpg"
width="1536"
height="1024"
srcset="https://blog2.michael.gr/post/2025-06-build-configurations/images/ChatGPT-Image-Jun-11,-2025,-12_31_08-PM---fixed_hu_2251c0dc0f1c3d7e.jpg 480w, https://blog2.michael.gr/post/2025-06-build-configurations/images/ChatGPT-Image-Jun-11,-2025,-12_31_08-PM---fixed_hu_91d84ae5696b1498.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
&gt;
&lt;/p&gt;
&lt;h3 id="abstract"&gt;Abstract
&lt;/h3&gt;&lt;p&gt;The popular practice of having only two different kinds of builds (&lt;em&gt;Debug&lt;/em&gt; and &lt;em&gt;Release&lt;/em&gt;) is shown to be inadequate. Three to four different kinds of builds are proposed instead, allowing more thorough error checking during development, better performance of the final system on production, and potentially better performance when running tests on a build server.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id="the-issue"&gt;The Issue
&lt;/h3&gt;&lt;p&gt;In software development we often want our creations to have different characteristics under different circumstances; for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Optimizations:
&lt;ul&gt;
&lt;li&gt;While developing we usually do not want them, because they interfere with debugging.&lt;/li&gt;
&lt;li&gt;On the final shipped product we want them, because they make it run faster.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Preconditions, assertions, and other kinds of runtime checks:
&lt;ul&gt;
&lt;li&gt;While developing we want them, because they help us catch bugs.&lt;/li&gt;
&lt;li&gt;On the final shipped product we do not want them, because they slow it down.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="the-history"&gt;The History
&lt;/h3&gt;&lt;p&gt;In C and C++, different behavior has historically been achieved by means of compiler options controlling optimization, and preprocessor macros controlling conditional compilation. The standard stipulates an NDEBUG macro which, if defined, causes assertions to compile to nothing. This means that software systems written in C and C++ generally have two builds: a &lt;em&gt;Debug&lt;/em&gt; build, for use while debugging, and a &lt;em&gt;Release&lt;/em&gt; build, for shipping or deploying to production.&lt;/p&gt;
&lt;p&gt;When Java came along, it was decided that a single build should be good for everyone: conditional compilation was abolished&lt;sup id="fnref:1"&gt;&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref"&gt;1&lt;/a&gt;&lt;/sup&gt;, all optimization-related choices were delegated to the Just-In-Time compiler (JITter,) assertions were made to always compile into the binaries, and the &lt;code&gt;enableassertions&lt;/code&gt; switch was added to the virtual machine for controlling during runtime, rather than during compilation, whether assertions should be executing or not. This essentially gives Java developers the ability to choose between a &lt;em&gt;debug &lt;strong&gt;run&lt;/strong&gt;&lt;/em&gt; or a &lt;em&gt;release &lt;strong&gt;run&lt;/strong&gt;&lt;/em&gt;, as opposed to a debug build or a release build.&lt;/p&gt;
&lt;p&gt;C# has brought back a compiler option for controlling optimization, and conditional compilation by means of a simplified version of the preprocessor macros (called &amp;quot;define constants&amp;quot; in C#) and the &lt;code&gt;Conditional&lt;/code&gt; attribute. Two different kinds of builds (called &lt;em&gt;&lt;strong&gt;Build Configurations&lt;/strong&gt;&lt;/em&gt;) are predefined: &lt;code&gt;Debug&lt;/code&gt; and &lt;code&gt;Release&lt;/code&gt;. The build system offers great flexibility in defining additional build configurations, but C# developers rarely bother with that.&lt;/p&gt;
&lt;h3 id="the-problem"&gt;The Problem
&lt;/h3&gt;&lt;p&gt;Since developers rarely bother with defining any build configurations besides the predefined ones, the vast majority of dotnet projects use only the two predefined ones: 'Debug' and 'Release'. (Many projects actually use only 'Debug', but let us pretend we never heard of them.) Thus all different needs and usage scenarios are being shoe-horned to fit into one of those two options. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There is only one configuration that can be tested, namely the &lt;code&gt;Debug&lt;/code&gt; configuration, which means that this configuration is used not only for running tests on a developer's computer, but also for running tests on the build server.&lt;/li&gt;
&lt;li&gt;There is only one configuration of a library that can be published, namely the 'Release' configuration, which means that this configuration is used not only in production scenarios, but also in development scenarios, where software is being developed that is making use of a published library.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is problematic because:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It slows down test runs on build servers.&lt;/p&gt;
&lt;p&gt;The 'Debug' configuration is unoptimized, to avoid interference with debugging; however, by common practice, the same 'Debug' configuration is used for running tests on the build server, because that is the only configuration that can be tested; thus, the world is full of build servers executing unoptimized tests, exercising unoptimized code.&lt;/p&gt;
&lt;p&gt;If the tests and the code they are exercising are long-running and computationally expensive, lack of optimization will make them run even slower.&lt;/p&gt;
&lt;p&gt;However, virtually nothing ever gets debugged on a build server, so there is virtually never a need to have it running unoptimized code.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It slows down the software on production.&lt;/p&gt;
&lt;p&gt;When a library is published as a package, the configuration that gets packaged is, by common practice, the 'Release' configuration. This configuration executes preconditions, since it may be referenced by a project under development; however, at some point, that project together with the library are released to production, where the library is still executing preconditions.&lt;/p&gt;
&lt;p&gt;This amounts to nothing but a waste of clock cycles, because:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;By the time the software using the library gets shipped to production, it has been tested and can be reasonably assumed to be invoking the library only in valid ways.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Even if the software did happen to make invalid use of the library on production, it makes very little difference whether the resulting catastrophic failure would be signaled by a precondition failure or by some index out of range exception further down.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Many preconditions are omitted in the name of performance.&lt;/p&gt;
&lt;p&gt;Library programmers often refrain from asserting certain preconditions, if they suspect them to be even slightly expensive, in light of the fact that preconditions in a library will always be executing, even on production.&lt;/p&gt;
&lt;p&gt;An extreme example to illustrate this scenario is the binary search function, which should, in principle, be enforcing the precondition that the array to search must be sorted. Yes, this means guarding a &lt;strong&gt;O(log&lt;sub&gt;2&lt;/sub&gt;(N))&lt;/strong&gt; operation with a &lt;strong&gt;O(N)&lt;/strong&gt; operation. This is fine during development, because we test with small amounts of data anyway, but is a terrible thing to be doing on production; thus, there is virtually no library in existence with such a precondition in it, despite the fact that it is necessary.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="the-solution"&gt;The Solution
&lt;/h3&gt;&lt;p&gt;From the description of the problem it becomes evident that preconditions must be controlled separately from assertions, and both of those must be controlled separately from optimizations. Therefore, four different build configurations can be thought of:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;A 'Debug' configuration&lt;/p&gt;
&lt;p&gt;Everyone is more or less already familiar with this. It is meant for use by a developer when testing and debugging software on their local computer. Assertions are enabled, preconditions are enabled, and optimizations are disabled, because they interfere with debugging.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;An 'Optimized' configuration&lt;/p&gt;
&lt;p&gt;This is the same as Debug except that optimizations are enabled. It is meant to run on the build server, where we do not usually debug, so there is no reason to be running unoptimized software. Note that this configuration is only useful for projects that suffer from long-running, computationally expensive tests; projects that do testing right, with very short and lightweight tests, are likely to see a performance degradation from this configuration, due to the additional JITting overhead &lt;sup id="fnref:2"&gt;&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref"&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A 'Develop' configuration&lt;/p&gt;
&lt;p&gt;This configuration is only applicable to libraries, not to applications. It is identical to what was previously understood as the Release configuration, where optimizations are enabled, assertions are disabled, and preconditions are enabled; however, it is only meant to be used when developing software that makes use of the library, not for shipping to production, because we do not want to be executing preconditions on production.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A 'Release' configuration&lt;/p&gt;
&lt;p&gt;This is similar to the Develop configuration, except that preconditions are also disabled. It is the configuration which is meant for shipping to production. Note that the benefit of using this configuration is not just maximum performance on production; it is also the freedom to add as many preconditions as necessary to the library, knowing that they cost nothing on production.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here is the feature matrix:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: right"&gt;&lt;/th&gt;
&lt;th style="text-align: center"&gt;Debug&lt;/th&gt;
&lt;th style="text-align: center"&gt;Optimized&lt;/th&gt;
&lt;th style="text-align: center"&gt;Develop&lt;/th&gt;
&lt;th style="text-align: center"&gt;Release&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: right"&gt;Optimizations disabled&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚úÖ&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚¨ú&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚¨ú&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚¨ú&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: right"&gt;Assertions enabled&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚úÖ&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚úÖ&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚¨ú&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚¨ú&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: right"&gt;Overflow checking&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚úÖ&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚úÖ&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚¨ú&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚¨ú&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: right"&gt;Preconditions enabled&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚úÖ&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚úÖ&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚úÖ&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚¨ú&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: right"&gt;Code analysis&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚úÖ&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚úÖ&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚¨ú&lt;/td&gt;
&lt;td style="text-align: center"&gt;‚¨ú&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here is an excerpt from a &lt;code&gt;.csproj&lt;/code&gt; file implementing the above matrix, assuming that we have defined our own set of assertion functions, dependent upon an &lt;code&gt;ASSERTIONS&lt;/code&gt; define-constant, and our own set of precondition functions, dependent upon a &lt;code&gt;PRECONDITIONS&lt;/code&gt; define-constant.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt; 1
&lt;/span&gt;&lt;span class="lnt"&gt; 2
&lt;/span&gt;&lt;span class="lnt"&gt; 3
&lt;/span&gt;&lt;span class="lnt"&gt; 4
&lt;/span&gt;&lt;span class="lnt"&gt; 5
&lt;/span&gt;&lt;span class="lnt"&gt; 6
&lt;/span&gt;&lt;span class="lnt"&gt; 7
&lt;/span&gt;&lt;span class="lnt"&gt; 8
&lt;/span&gt;&lt;span class="lnt"&gt; 9
&lt;/span&gt;&lt;span class="lnt"&gt;10
&lt;/span&gt;&lt;span class="lnt"&gt;11
&lt;/span&gt;&lt;span class="lnt"&gt;12
&lt;/span&gt;&lt;span class="lnt"&gt;13
&lt;/span&gt;&lt;span class="lnt"&gt;14
&lt;/span&gt;&lt;span class="lnt"&gt;15
&lt;/span&gt;&lt;span class="lnt"&gt;16
&lt;/span&gt;&lt;span class="lnt"&gt;17
&lt;/span&gt;&lt;span class="lnt"&gt;18
&lt;/span&gt;&lt;span class="lnt"&gt;19
&lt;/span&gt;&lt;span class="lnt"&gt;20
&lt;/span&gt;&lt;span class="lnt"&gt;21
&lt;/span&gt;&lt;span class="lnt"&gt;22
&lt;/span&gt;&lt;span class="lnt"&gt;23
&lt;/span&gt;&lt;span class="lnt"&gt;24
&lt;/span&gt;&lt;span class="lnt"&gt;25
&lt;/span&gt;&lt;span class="lnt"&gt;26
&lt;/span&gt;&lt;span class="lnt"&gt;27
&lt;/span&gt;&lt;span class="lnt"&gt;28
&lt;/span&gt;&lt;span class="lnt"&gt;29
&lt;/span&gt;&lt;span class="lnt"&gt;30
&lt;/span&gt;&lt;span class="lnt"&gt;31
&lt;/span&gt;&lt;span class="lnt"&gt;32
&lt;/span&gt;&lt;span class="lnt"&gt;33
&lt;/span&gt;&lt;span class="lnt"&gt;34
&lt;/span&gt;&lt;span class="lnt"&gt;35
&lt;/span&gt;&lt;span class="lnt"&gt;36
&lt;/span&gt;&lt;span class="lnt"&gt;37
&lt;/span&gt;&lt;span class="lnt"&gt;38
&lt;/span&gt;&lt;span class="lnt"&gt;39
&lt;/span&gt;&lt;span class="lnt"&gt;40
&lt;/span&gt;&lt;span class="lnt"&gt;41
&lt;/span&gt;&lt;span class="lnt"&gt;42
&lt;/span&gt;&lt;span class="lnt"&gt;43
&lt;/span&gt;&lt;span class="lnt"&gt;44
&lt;/span&gt;&lt;span class="lnt"&gt;45
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-xml" data-lang="xml"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nt"&gt;&amp;lt;Choose&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;When&lt;/span&gt; &lt;span class="na"&gt;Condition=&lt;/span&gt;&lt;span class="s"&gt;&amp;#34;&amp;#39;$(Configuration)&amp;#39;==&amp;#39;Debug&amp;#39;&amp;#34;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;PropertyGroup&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;Optimize&amp;gt;&lt;/span&gt;False&lt;span class="nt"&gt;&amp;lt;/Optimize&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;DefineConstants&amp;gt;&lt;/span&gt;$(DefineConstants);PRECONDITIONS;ASSERTIONS&lt;span class="nt"&gt;&amp;lt;/DefineConstants&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;CheckForOverflowUnderflow&amp;gt;&lt;/span&gt;True&lt;span class="nt"&gt;&amp;lt;/CheckForOverflowUnderflow&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;EnableNETAnalyzers&amp;gt;&lt;/span&gt;True&lt;span class="nt"&gt;&amp;lt;/EnableNETAnalyzers&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;DebugType&amp;gt;&lt;/span&gt;Full&lt;span class="nt"&gt;&amp;lt;/DebugType&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;/PropertyGroup&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;/When&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;When&lt;/span&gt; &lt;span class="na"&gt;Condition=&lt;/span&gt;&lt;span class="s"&gt;&amp;#34;&amp;#39;$(Configuration)&amp;#39;==&amp;#39;Optimized&amp;#39;&amp;#34;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;PropertyGroup&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;Optimize&amp;gt;&lt;/span&gt;True&lt;span class="nt"&gt;&amp;lt;/Optimize&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;DefineConstants&amp;gt;&lt;/span&gt;$(DefineConstants);PRECONDITIONS;ASSERTIONS&lt;span class="nt"&gt;&amp;lt;/DefineConstants&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;CheckForOverflowUnderflow&amp;gt;&lt;/span&gt;True&lt;span class="nt"&gt;&amp;lt;/CheckForOverflowUnderflow&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;EnableNETAnalyzers&amp;gt;&lt;/span&gt;True&lt;span class="nt"&gt;&amp;lt;/EnableNETAnalyzers&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;DebugType&amp;gt;&lt;/span&gt;Full&lt;span class="nt"&gt;&amp;lt;/DebugType&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;OutputPath&amp;gt;&lt;/span&gt;bin\$(Configuration)\&lt;span class="nt"&gt;&amp;lt;/OutputPath&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;/PropertyGroup&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;/When&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;When&lt;/span&gt; &lt;span class="na"&gt;Condition=&lt;/span&gt;&lt;span class="s"&gt;&amp;#34;&amp;#39;$(Configuration)&amp;#39;==&amp;#39;Develop&amp;#39;&amp;#34;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;PropertyGroup&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;Optimize&amp;gt;&lt;/span&gt;True&lt;span class="nt"&gt;&amp;lt;/Optimize&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;DefineConstants&amp;gt;&lt;/span&gt;$(DefineConstants);PRECONDITIONS&lt;span class="nt"&gt;&amp;lt;/DefineConstants&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;CheckForOverflowUnderflow&amp;gt;&lt;/span&gt;False&lt;span class="nt"&gt;&amp;lt;/CheckForOverflowUnderflow&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;EnableNETAnalyzers&amp;gt;&lt;/span&gt;False&lt;span class="nt"&gt;&amp;lt;/EnableNETAnalyzers&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;DebugType&amp;gt;&lt;/span&gt;Portable&lt;span class="nt"&gt;&amp;lt;/DebugType&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;OutputPath&amp;gt;&lt;/span&gt;bin\$(Configuration)\&lt;span class="nt"&gt;&amp;lt;/OutputPath&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;/PropertyGroup&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;/When&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;When&lt;/span&gt; &lt;span class="na"&gt;Condition=&lt;/span&gt;&lt;span class="s"&gt;&amp;#34;&amp;#39;$(Configuration)&amp;#39;==&amp;#39;Release&amp;#39;&amp;#34;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;PropertyGroup&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;Optimize&amp;gt;&lt;/span&gt;True&lt;span class="nt"&gt;&amp;lt;/Optimize&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;DefineConstants&amp;gt;&lt;/span&gt;$(DefineConstants)&lt;span class="nt"&gt;&amp;lt;/DefineConstants&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;CheckForOverflowUnderflow&amp;gt;&lt;/span&gt;False&lt;span class="nt"&gt;&amp;lt;/CheckForOverflowUnderflow&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;EnableNETAnalyzers&amp;gt;&lt;/span&gt;False&lt;span class="nt"&gt;&amp;lt;/EnableNETAnalyzers&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;DebugType&amp;gt;&lt;/span&gt;Portable&lt;span class="nt"&gt;&amp;lt;/DebugType&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;Deterministic&amp;gt;&lt;/span&gt;True&lt;span class="nt"&gt;&amp;lt;/Deterministic&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;DeterministicSourcePaths&amp;gt;&lt;/span&gt;True&lt;span class="nt"&gt;&amp;lt;/DeterministicSourcePaths&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;/PropertyGroup&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;/When&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;Otherwise&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; ...
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;/Otherwise&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nt"&gt;&amp;lt;/Choose&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;If we follow this build configuration scheme, then each time we publish a library we must generate two packages: the 'Develop' package, and the 'Release' package.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The 'Develop' package is to be referenced by software under development.&lt;/li&gt;
&lt;li&gt;The 'Release' package is to be referenced by software that is being shipped to production.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The generation of two different packages for a single library can be accomplished by building twice, once for each configuration, and constructing the assembly name as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-xml" data-lang="xml"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;AssemblyName&amp;gt;&lt;/span&gt;$(MSBuildProjectName)-$(Configuration)&lt;span class="nt"&gt;&amp;lt;/AssemblyName&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;This way, instead of a single package called &lt;code&gt;MyPackage&lt;/code&gt; we create two packages: &lt;code&gt;MyPackage-Develop&lt;/code&gt; and &lt;code&gt;MyPackage-Release&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;There may be a better way to build a library, so that only one package gets generated, containing both the develop and release builds, and the right binaries somehow end up in the right output directory; however, I have not been able to figure that out yet. If you know how to do it, please let me know.&lt;/p&gt;
&lt;p&gt;For any build configuration of a certain module, (either an application or a library,) the build configuration of the libraries it uses can be determined using the following table:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;Build configuration of&lt;br&gt;module using library&lt;/th&gt;
&lt;th style="text-align: center"&gt;Build configuration of&lt;br&gt;library&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;'Debug'&lt;/td&gt;
&lt;td style="text-align: center"&gt;'Develop'&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;'Optimized'&lt;/td&gt;
&lt;td style="text-align: center"&gt;'Develop'&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;'Develop'&lt;/td&gt;
&lt;td style="text-align: center"&gt;'Develop'&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;'Release'&lt;/td&gt;
&lt;td style="text-align: center"&gt;'Release'&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note that the 'Develop' configuration of a module could, in theory, make use of the better-performing 'Release' configuration of a library, instead of the 'Develop' configuration; however, that can only work if the module does not expose the library, or if there is no other module in the solution that uses the 'Develop' configuration of the library. Otherwise, there are going to be build errors saying that a certain type exists in both the develop and release configuration of a certain library.&lt;/p&gt;
&lt;p&gt;Here is an excerpt of a .csproj file implementing the above table:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;span class="lnt"&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-xml" data-lang="xml"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nt"&gt;&amp;lt;PropertyGroup&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;PackagesConfiguration&lt;/span&gt; &lt;span class="na"&gt;Condition=&lt;/span&gt;&lt;span class="s"&gt;&amp;#34;&amp;#39;$(Configuration)&amp;#39;==&amp;#39;Debug&amp;#39;&amp;#34;&lt;/span&gt; &lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;Develop&lt;span class="nt"&gt;&amp;lt;/PackagesConfiguration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;PackagesConfiguration&lt;/span&gt; &lt;span class="na"&gt;Condition=&lt;/span&gt;&lt;span class="s"&gt;&amp;#34;&amp;#39;$(Configuration)&amp;#39;==&amp;#39;Optimized&amp;#39;&amp;#34;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;Develop&lt;span class="nt"&gt;&amp;lt;/PackagesConfiguration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;PackagesConfiguration&lt;/span&gt; &lt;span class="na"&gt;Condition=&lt;/span&gt;&lt;span class="s"&gt;&amp;#34;&amp;#39;$(Configuration)&amp;#39;==&amp;#39;Develop&amp;#39;&amp;#34;&lt;/span&gt; &lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;Develop&lt;span class="nt"&gt;&amp;lt;/PackagesConfiguration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;PackagesConfiguration&lt;/span&gt; &lt;span class="na"&gt;Condition=&lt;/span&gt;&lt;span class="s"&gt;&amp;#34;&amp;#39;$(Configuration)&amp;#39;==&amp;#39;Release&amp;#39;&amp;#34;&lt;/span&gt; &lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;Release&lt;span class="nt"&gt;&amp;lt;/PackagesConfiguration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="nt"&gt;&amp;lt;/PropertyGroup&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Then, packages can be referenced as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-xml" data-lang="xml"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;lt;PackageReference&lt;/span&gt; &lt;span class="na"&gt;Include=&lt;/span&gt;&lt;span class="s"&gt;&amp;#34;MyPackage-$(PackagesConfiguration)&amp;#34;&lt;/span&gt; &lt;span class="na"&gt;Version=&lt;/span&gt;&lt;span class="s"&gt;&amp;#34;...&amp;#34;&lt;/span&gt; &lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id="conclusions"&gt;Conclusions
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;An 'Optimized' build configuration has been proposed, for cutting in half the time it takes to run slow, computationally expensive tests on build servers. (Not needed by projects with small, fast tests.)&lt;/li&gt;
&lt;li&gt;A 'Develop' build configuration for libraries has been proposed, intended for use during development of software using the libraries, but not for shipping to production. It has preconditions enabled, in order to catch bugs in the software using the libraries.&lt;/li&gt;
&lt;li&gt;A 'Release' build configuration for libraries has been proposed, intended for shipping to production. It improves performance by not executing preconditions.&lt;/li&gt;
&lt;li&gt;Under the proposed schema, preconditions in libraries do not incur a performance penalty on production anymore, so programmers can apply them more liberally, leading to more robust software.&lt;/li&gt;
&lt;li&gt;Under the proposed schema, when a library is published, two packages should be generated: the 'Develop' package, for developing software that uses the library, and the 'Release' package, for shipping to production.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Cover image generated by ChatGPT, and then retouched by michael.gr. The prompt used was: &amp;quot;Please give me an image conveying the concept of highly complex and highly technical software development. Make it in landscape format, of photographic quality, with warm colors&amp;quot; and then &amp;quot;Please make the programmer look more senior&amp;quot;.&lt;/p&gt;
&lt;div class="footnotes" role="doc-endnotes"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;The creators of Java made it so that the generation of code within an &lt;code&gt;if()&lt;/code&gt; statement controlled by a compile-time constant is suppressed if that constant evaluates to &lt;code&gt;false&lt;/code&gt;, but they intentionally deprived developers from the ability to specify the value of a compile-time constant via external means, such as the command-line of the compiler. They defended this choice by saying that there is inherent merit in being able to guarantee that in Java every compilation unit has one and only one set of semantics. The usefulness of this merit is debatable. It can be argued that this is simply Java treating developers the same way that Apple has been treating users: as idiots.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink"&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;In C# most optimizations are performed by the Just-In-Time compiler (JITter), and people say that the optimizations performed by the language compiler do not make much of a difference. However, my experiments have shown otherwise: computation-intensive code tends to run twice as fast when optimizations are enabled than when not, and this difference can be observed on a build server, so it is unaffected by any optimization choices that the JITter might make due to a debugger being attached or not. I suspect that this is happening because the language compiler saves the &amp;quot;optimize&amp;quot; flag in the binary, and the JITter subsequently observes this flag.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink"&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description></item><item><title>Testana: A better way of running tests</title><link>https://blog2.michael.gr/post/2024-10-testana/</link><pubDate>Sat, 26 Oct 2024 10:58:59 +0000</pubDate><guid>https://blog2.michael.gr/post/2024-10-testana/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2024-10-testana/media/testana-logo.svg"
loading="lazy"
&gt;
&lt;/p&gt;
&lt;h3 id="abstract"&gt;Abstract
&lt;/h3&gt;&lt;p&gt;A software testing tool is presented, which uses &lt;em&gt;&lt;strong&gt;dependency analysis&lt;/strong&gt;&lt;/em&gt; to greatly optimize the process of running tests.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id="what-is-testana"&gt;What is Testana?
&lt;/h3&gt;&lt;p&gt;Testana is a console application that you launch when you want to run your tests. So far, I have created two implementations of Testana:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A Java implementation, supporting JUnit 4 annotations in Maven-based projects.&lt;/li&gt;
&lt;li&gt;A C# implementation, supporting MSTest attributes in MSBuild solutions.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="what-does-testana-achieve-that-existing-tools-do-not"&gt;What does Testana achieve that existing tools do not?
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Testana &lt;em&gt;&lt;strong&gt;runs only the subset of test modules that actually need to run&lt;/strong&gt;&lt;/em&gt;, based on the last successful run time of each test module, and whether it, or any of its dependencies, have changed.&lt;/li&gt;
&lt;li&gt;Testana &lt;em&gt;&lt;strong&gt;always considers all test modules in your entire code base as candidates for running&lt;/strong&gt;&lt;/em&gt;, so you never have to manually select a subset of the tests to run in the interest of saving time.&lt;/li&gt;
&lt;li&gt;Testana &lt;em&gt;&lt;strong&gt;runs test modules by order of dependency&lt;/strong&gt;&lt;/em&gt;, meaning that tests of modules that have no dependencies run first, tests of modules that depend on those run next, and so on.&lt;/li&gt;
&lt;li&gt;Testana &lt;em&gt;&lt;strong&gt;runs test methods in Natural Method Order,&lt;/strong&gt;&lt;/em&gt; which is the order in which the methods appear in the source file. (This is the norm in C#, but not in Java, where extra measures are necessary to accomplish.)&lt;/li&gt;
&lt;li&gt;Testana &lt;em&gt;&lt;strong&gt;runs test methods in ascending order of inheritance&lt;/strong&gt;&lt;/em&gt;, meaning that test methods in the base-most test class run first, and test methods in derived test classes run afterwards.&lt;/li&gt;
&lt;li&gt;Testana &lt;em&gt;&lt;strong&gt;discovers and reports mistakes&lt;/strong&gt;&lt;/em&gt; in the formulation of test methods, instead of ignoring the mistakes, which is what most other test frameworks do. (Silent failure.)&lt;/li&gt;
&lt;li&gt;Testana &lt;em&gt;&lt;strong&gt;does not catch any exceptions when debugging&lt;/strong&gt;&lt;/em&gt;, thus allowing your debugger to stop on the source line that threw the exception. (Testana will catch and report exceptions when not debugging, as the case is when running on a continuous build server.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="how-does-testana-work"&gt;How does Testana work?
&lt;/h3&gt;&lt;p&gt;Testana begins by constructing the dependency graph of your software system. Since this process is expensive, Testana cashes the dependency graph in a file, and recalculates it only when the structure of the system changes. The cache is stored in a text file, which is located at the root of the source tree, and is meant to be excluded from source control.&lt;/p&gt;
&lt;p&gt;Then:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Testana locates the modules that depend on nothing else within the system, and runs the tests of those modules.&lt;/li&gt;
&lt;li&gt;Once these tests are done, Testana finds modules that depend only on modules that have already been tested, and runs their tests.&lt;/li&gt;
&lt;li&gt;Testana keeps repeating the previous step, until all tests have been run.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Testana keeps a diary where it records the last successful run time of each test module. This diary is also stored in a text file, which is also located
at the root of the source tree, and is also meant to be excluded from source control.&lt;/p&gt;
&lt;p&gt;Next time Testana runs, it considers the last successful run time of each test module, versus the last modification time of that module and its dependencies. Testana then refrains from running the test module if neither it, nor any of its dependencies, have changed.&lt;/p&gt;
&lt;h3 id="why-should-i-care-about-running-only-the-tests-that-need-to-run"&gt;Why should I care about running only the tests that need to run?
&lt;/h3&gt;&lt;p&gt;The usual situation with large code bases is that tests take an unreasonably long time to run, so developers tend to take shortcuts in running them. One approach some developers take is that they simply commit code without running any tests, leaving it up to the continuous build server to run the tests and notify them of any test failures. This has multiple disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It causes repeated interruptions in the workflow, due to the slow turnaround of the continuous build, which is often of the order of an hour, sometimes longer, and even in the fastest cases, always longer than a normal person's attention span. (This is so by definition; if it was not, then there would be no problem with quickly running all tests locally before committing.)&lt;/li&gt;
&lt;li&gt;The failed tests require additional commits to fix, and each commit requires a meaningful commit message, which increases the overall level of bureaucracy in the development process.&lt;/li&gt;
&lt;li&gt;The commit history becomes bloated with commits that were done in vain and should never be checked out because they contain bugs that are fixed in later commits.&lt;/li&gt;
&lt;li&gt;Untested commits that contain bugs are regularly being made to branches in the repository; these bugs stay there while the continuous build does its thing; eventually the tests fail, the developers take notice, and commit fixes. This whole process takes time, during which other unsuspecting developers might pull from those branches, thus receiving the bugs. Kind of like &lt;em&gt;Continuous Infection&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Testana solves the above problems by figuring out which tests need to run based on what has changed, and only running those tests. This cuts down the time it takes to run tests to a tiny fraction of what it is when blindly running all tests, which means that running the tests now becomes piece of cake and can usually be done real quick before committing, as it should.&lt;/p&gt;
&lt;p&gt;Also, running the tests real quick right after each pull from source control now becomes feasible, so a developer can avoid starting to work on source code on which the tests are failing. (How often have you found yourself in a situation where you pull from source control, change something, run the tests, the tests fail, and you are now wondering whether they fail due to the changes you just made, or due to changes you pulled from the repository?)&lt;/p&gt;
&lt;h3 id="why-should-i-care-about-considering-all-test-modules-in-my-entire-code-base-as-candidates-for-running"&gt;Why should I care about considering all test modules in my entire code base as candidates for running?
&lt;/h3&gt;&lt;p&gt;Another approach taken by some developers, in the interest of saving time, is manually choosing which tests to run, based on their knowledge of what may have been affected by the changes they just made.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One simple reason why this is problematic is that it requires cognitive effort to figure out which tests might need running, and manual work to launch them individually; it is not as easy as pressing a single button that stands for &amp;quot;run whatever tests need to run in response to the changes I just made.&amp;quot;&lt;/li&gt;
&lt;li&gt;A far bigger problem is that in manually selecting the tests to run, the developer is making assumptions about the dependencies of the code that they have modified. In complex systems, dependency graphs can be difficult to grasp, and as systems evolve, the dependencies keep changing. This often leads to situations where no single developer in the house has a complete grasp of the dependency graph of the entire system. Unfortunately, unknown or not-fully-understood dependencies are a major source of bugs, and yet by hand-selecting what to test based on our assumptions about the dependencies, it is precisely the not-fully-understood dependencies that are likely to not be tested. This is a recipe for disaster.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Testana solves the above problems by always considering all test modules as candidates for running. It does not hurt to do that, because the tests that do not actually need to run will not be run by Testana anyway.&lt;/p&gt;
&lt;h3 id="why-should-i-care-about-running-test-modules-in-order-of-dependency"&gt;Why should I care about running test modules in order of dependency?
&lt;/h3&gt;&lt;p&gt;Existing test frameworks do not do anything intelligent in the direction of automatically figuring out some order of test execution that has any purpose or merit. The order tends to be arbitrary, and not configurable. In the best case it is alphabetic, but this is still problematic, because our criteria for naming test modules usually have nothing to do with the order in which we would like to see them executing.&lt;/p&gt;
&lt;p&gt;For example, it is very common for a code base to contain a module called &amp;quot;Utilities&amp;quot;, which most other modules depend on; Since it is a highly dependent-upon module, it should be tested first, but since its name begins with a &amp;quot;U&amp;quot;, it tends to be tested last.&lt;/p&gt;
&lt;p&gt;Testana executes test modules in order of dependency. This means that modules with no dependencies are tested first, modules that depend upon them are tested next, and so on until everything has been tested. Thus, the first test failure is guaranteed to point at the most fundamental problem; there is no need to look further down in case some other test failure indicates a more fundamental problem. Subsequently, Testana stops executing tests after the first failure, so it saves even more time.&lt;/p&gt;
&lt;p&gt;For more information about this way of testing, see &lt;a
href="https://blog2.michael.gr/post/2022-10-incremental-integration-testing/"
&gt;Incremental Integration Testing&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="why-should-i-care-about-running-test-methods-in-natural-order"&gt;Why should I care about running test methods in natural order?
&lt;/h3&gt;&lt;p&gt;Test frameworks in the C# world tend to run test methods in natural order, which is great, but in the Java world, the JUnit framework runs test methods in random order, which is at best useless, and arguably treacherous.&lt;/p&gt;
&lt;p&gt;One reason for wanting the test methods to run in the order in which they appear in the source file is because we usually test fundamental operations of our software before we test operations that depend upon them. (Note: it is the operations of the components under test that depend upon each other, not the tests themselves that depend upon each other!) So, if a fundamental operation fails, we want that to be the very first error that gets reported.&lt;/p&gt;
&lt;p&gt;Tests of operations that rely upon an operation whose test has failed might as well be skipped, because they can all be expected to fail. Reporting those failures before the failure of the more fundamental operation is an act of sabotage against the developer, because it is sending us looking for problems in places where there are no problems to be found, and it is making it more difficult for us to locate the real problem, which typically lies in the test that failed first &lt;em&gt;&lt;strong&gt;in the source file&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;To give an example, suppose I am developing some kind of data store with insert and find functionality, and I am writing tests to make sure this functionality works. The find-item-in-store test necessarily involves insertion before finding, so I am likely to precede it with an insert-item-to-store test. In such a scenario, it is counter-productive to be told that my find-item-in-store test failed, sending me to troubleshoot the find function, and only later to be told that my insert-item-to-store test failed, which obviously means that it was in fact the insert function that needed troubleshooting; if insert-item-to-store fails, it is game over; no other operation on this store can possibly succeed, so there is no point in running any other tests on it, just as there is no point in beating a dead horse.&lt;/p&gt;
&lt;p&gt;Finally, another very simple, very straightforward, and very important reason for wanting the test methods to be executed in natural order is because seeing the test methods listed in any other order is &lt;em&gt;&lt;strong&gt;brainfuck&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;A related rant can be found here: &lt;a
href="https://blog2.michael.gr/post/2018-04-random-order-of-tests/"
&gt;On JUnit's random order of test method execution&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="why-should-i-care-for-running-test-methods-in-ascending-order-of-inheritance"&gt;Why should I care for running test methods in ascending order of inheritance?
&lt;/h3&gt;&lt;p&gt;This feature of Testana might be irrelevant to you if you never use inheritance in test classes, but I do, and I consider it very important. I also consider the typical behavior of existing test frameworks on this matter very annoying, because they tend to do the exact opposite of what is useful.&lt;/p&gt;
&lt;p&gt;Inheritance in test classes can help to achieve great code coverage while reducing the total amount of test code. Suppose you have a collection hierarchy to test: you have an ArrayList class and a HashSet class, and you also have their corresponding test classes: ArrayListTest and HashSetTest. Now, both ArrayList and HashSet inherit from Collection, which means that lots of tests are going to be identical between ArrayListTest and HashSetTest. One way to eliminate duplication is to have a CollectionTest abstract base class, which tests only Collection methods, and then have both ArrayListTest and HashSetTest inherit from CollectionTest and provide additional tests for functionality that is specific to ArrayList and HashSet respectively. Under this scenario, when ArrayListTest or HashSetTest runs, we want the methods of CollectionTest to be executed first, because they are testing the fundamental (more general) functionality.&lt;/p&gt;
&lt;p&gt;To make the example more specific, CollectionTest is likely to add an item to the collection and then check whether the collection contains the item. If this test fails, there is absolutely no point in proceeding with tests of ArrayListTest which will, for example, add multiple items to the collection and check to make sure that IndexOf() returns the right results.&lt;/p&gt;
&lt;p&gt;Again, existing test frameworks tend to handle this in a way which is exactly the opposite of what we would want: they execute the descendant (more specialized) methods first, and the ancestor (more general) methods last.&lt;/p&gt;
&lt;p&gt;Testana corrects this by executing ancestor methods first, descendant methods last.&lt;/p&gt;
&lt;h3 id="what-additional-error-checking-does-testana-perform"&gt;What additional error checking does Testana perform?
&lt;/h3&gt;&lt;p&gt;While running tests, Testana will warn the programmer if it discovers any method that has been declared as a test method but fails to meet the requirements for a test method.&lt;/p&gt;
&lt;p&gt;Usually, test frameworks require that a test method must be a public instance method, must accept no parameters, and must return nothing; however, when these frameworks encounter a method that is declared as a test and yet fails to meet those requirements, (for example, a test method declared static,) they fail to report the mistake.&lt;/p&gt;
&lt;p&gt;Testana does not fail to report such mistakes.&lt;/p&gt;
&lt;h3 id="can-testana-be-fooled-by-inversion-of-control"&gt;Can Testana be fooled by Inversion of Control?
&lt;/h3&gt;&lt;p&gt;No. In a scenario where class A receives and invokes interface I without having a dependency on class B which implements I, the test of A still has to instantiate both A and B in order to supply A with the I interface of B, so the test depends on both A and B, which means that Testana will run the test if there is a change in either A or B.&lt;/p&gt;
&lt;h3 id="can-testana-be-fooled-by-the-use-of-mocks"&gt;Can Testana be fooled by the use of mocks?
&lt;/h3&gt;&lt;p&gt;Yes, Testana can be fooled by mocks, because that is what mocks do: they make a mockery out of the software testing process. In a scenario where class A receives and invokes interface I without having a dependency on class B which implements I, and the test of A also refrains from depending on B by just mocking I, Testana will of course not run the test of A when there is a change in B. This, however, should not be a problem, because you should not be using mocks anyway; for more information, see &lt;a
href="https://blog2.michael.gr/post/2023-01-14-mocking/"
&gt;If you are using mock objects you are doing it wrong&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="can-testana-be-fooled-by-the-use-of-fakes"&gt;Can Testana be fooled by the use of fakes?
&lt;/h3&gt;&lt;p&gt;No, as long as you do your testing properly. A test that utilizes a fake will be run by Testana only when there is a change in the fake, not when there is a change in the real thing; however, you should have a separate test which ensures that the behavior of the fake is identical to the behavior of the real thing in all aspects that matter. This test will be run by Testana when you modify either the fake, or the real thing, or both. Thus:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you make a breaking change to the real thing, then your tests will show you that you need to make the corresponding change to the fake; the change in the fake will in turn cause Testana to run the tests that utilize the fake.&lt;/li&gt;
&lt;li&gt;If you make a non-breaking change to the real thing, then the fake will remain unchanged, and this is what gives you the luxury of not having to re-run tests utilizing the fake when you make a change that only affects the real thing.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information, see &lt;a
href="https://blog2.michael.gr/post/2022-10-testing-with-fakes/"
&gt;Testing with Fakes instead of Mocks&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="what-about-undiscoverable-dependencies-due-to-weak-typing-the-use-of-rest-etc"&gt;What about undiscoverable dependencies due to weak typing, the use of REST, etc?
&lt;/h3&gt;&lt;p&gt;The following &amp;quot;hip&amp;quot; and &amp;quot;trendy&amp;quot; practices of the modern day are not supported by Testana, and there is no plan to ever support them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Squandering dependencies via &lt;em&gt;&lt;strong&gt;weak typing&lt;/strong&gt;&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Obscuring dependencies via &lt;em&gt;&lt;strong&gt;duck-typing&lt;/strong&gt;&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Denaturing dependencies via &lt;em&gt;&lt;strong&gt;stringly-typing.&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Disavowing dependencies via &lt;em&gt;&lt;strong&gt;configuration files&lt;/strong&gt;&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Abnegating dependencies via &lt;em&gt;&lt;strong&gt;non-programmatic interfaces&lt;/strong&gt;&lt;/em&gt; such as REST.&lt;/li&gt;
&lt;li&gt;Fragmenting dependencies via &lt;em&gt;&lt;strong&gt;cross-language invocations&lt;/strong&gt;&lt;/em&gt; (following the &lt;em&gt;&lt;strong&gt;polyglot craze&lt;/strong&gt;&lt;/em&gt;.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Seriously, stop all this fuckery and use a single, &lt;em&gt;&lt;strong&gt;real&lt;/strong&gt;&lt;/em&gt; programming language, (that is, a programming language with &lt;em&gt;&lt;strong&gt;strong typing&lt;/strong&gt;&lt;/em&gt;,) encode your dependencies via the type system, and everything will be fine. For more information, see &lt;a
href="https://blog2.michael.gr/post/2017-05-on-scripting-languages/"
&gt;On Scripting Languages&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="how-compatible-is-testana-with-what-i-already-have"&gt;How compatible is Testana with what I already have?
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;The Java implementation of Testana:
&lt;ul&gt;
&lt;li&gt;Works with maven projects (pom.xml files.)&lt;/li&gt;
&lt;li&gt;Supports JUnit 4.
&lt;ul&gt;
&lt;li&gt;Supports only the basic, minimum viable subset of JUnit 4 functionality, namely the @Test, @Before, @After, and @Ignore annotations, without any parameters.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The C# implementation of Testana:
&lt;ul&gt;
&lt;li&gt;Works with MSBuild projects (.sln and .csproj files)&lt;/li&gt;
&lt;li&gt;Supports MSTest.
&lt;ul&gt;
&lt;li&gt;Supports only the basic, minimum viable subset of MSTest functionality, namely the [TestClass], [TestMethod], [ClassInitialize], [ClassCleanup], and [Ignore] attributes, without any parameters.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Support for more languages, more project formats, more test frameworks, and more functionality may be added in the future.&lt;/p&gt;
&lt;h3 id="how-is-it-like-using-testana"&gt;How is it like using Testana?
&lt;/h3&gt;&lt;p&gt;You run Testana every time you want to run your tests. You launch it at the root of your source tree, without any command-line arguments, and its default behavior is to figure out everything by itself and do the right thing.&lt;/p&gt;
&lt;p&gt;Note that the first time you run Testana, there may be a noticeable delay while information is being collected; the information is cached, so this delay will not be there next time you run Testana.&lt;/p&gt;
&lt;p&gt;The first time you run Testana, it will run all tests.&lt;/p&gt;
&lt;p&gt;If you immediately re-run Testana, it will not run any tests, because nothing will have changed.&lt;/p&gt;
&lt;p&gt;If you touch one of your source files, build your project, and re-run Testana, it will only run tests that either directly or indirectly depend on the
changed file. If you run Testana with --help it will give you a rundown of the command-line arguments it supports.&lt;/p&gt;
&lt;h3 id="where-can-i-find-testana"&gt;Where can I find Testana?
&lt;/h3&gt;&lt;p&gt;The Java implementation of Testana is here:
&lt;a class="external"
href="https://github.com/mikenakis/Public/tree/master/testana" target="_blank"
&gt;https://github.com/mikenakis/Public/tree/master/testana&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The C# implementation of Testana is coming soon. (As soon as I turn it into an independent solution, because currently it is a project within a larger solution.)&lt;/p&gt;
&lt;h3 id="notes"&gt;Notes
&lt;/h3&gt;&lt;p&gt;In episode 167 of the Software Engineering Podcast (&lt;a class="external"
href="https://se-radio.net/2010/09/episode-167-the-history-of-junit-and-the-future-of-testing-with-kent-beck/" target="_blank"
&gt;SE Radio 167: The History of JUnit and the Future of Testing with Kent Beck&lt;/a&gt;) at about 40':00'' Kent Beck says that recently failed tests have the highest probability of failing again in the near future, so he suggests using this statistical fact at as a heuristic for picking which tests to run first. Testana optimizes the testing process deterministically, so there is no need to resort to heuristics.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: The Testana logo, &lt;em&gt;profile of a crash test dummy&lt;/em&gt; by michael.gr. Based on &lt;a class="external"
href="https://thenounproject.com/term/crash-test-dummy/401583/" target="_blank"
&gt;original work by Wes Breazell&lt;/a&gt; and &lt;a class="external"
href="https://thenounproject.com/term/woman/129498/" target="_blank"
&gt;Alexander Skowalsky&lt;/a&gt;. Used under &lt;a class="external"
href="https://creativecommons.org/licenses/by/3.0/us/" target="_blank"
&gt;CC BY License.&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Simplification of triple-choice prompts to dual-choice</title><link>https://blog2.michael.gr/post/2024-05-simplification-of-triple-choice-prompts/</link><pubDate>Fri, 31 May 2024 09:53:03 +0000</pubDate><guid>https://blog2.michael.gr/post/2024-05-simplification-of-triple-choice-prompts/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2024-05-simplification-of-triple-choice-prompts/images/image.png"
width="400"
height="132"
srcset="https://blog2.michael.gr/post/2024-05-simplification-of-triple-choice-prompts/images/image_hu_f5edf689a035ac41.png 480w, https://blog2.michael.gr/post/2024-05-simplification-of-triple-choice-prompts/images/image_hu_c6205dafb643c637.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="303"
data-flex-basis="727px"
&gt;
&lt;/p&gt;
&lt;p&gt;I have a lot to say about the modern trend in graphical user interface design which aims to achieve an impossibly clean look at the expense of usability, but this is going to be the subject of another blog post. In this post, I want to talk about simplifying the user interface when the simplification is clearly a win, both from a usability point of view and, incidentally, from an aesthetics point of view. Specifically, I want to show how a yes/no/cancel prompt can be reduced to just a yes/cancel prompt.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;A typical example of such a prompt is when an application asks the user what to do when the user tries to quit the application while a file is unsaved.&lt;/p&gt;
&lt;p&gt;We have two boolean variables:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;To save or not to save.&lt;/li&gt;
&lt;li&gt;To quit or not to quit.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Since there are two boolean variables, there is a total of four conceivable options:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Save and quit.&lt;/li&gt;
&lt;li&gt;Quit without saving.&lt;/li&gt;
&lt;li&gt;Save without quitting.&lt;/li&gt;
&lt;li&gt;Do not save and do not quit.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The very first programmers of interactive applications did not fail to notice that saving without quitting is not particularly useful, so in fact we only need three options, and this has given us the traditional triple-choice yes / no / cancel prompt, variations of which you see in almost all applications out there. One of the variations is as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Save the file before quitting? [Yes] / [No] / [Cancel]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Needless to say, presenting the user with an application-modal prompt containing not one, not two, but three options is terrible. (If you think that
&amp;quot;terrible&amp;quot; is a harsh word for such a low-impact problem, then please read &lt;a
href="https://blog2.michael.gr/post/2024-05-incident-impact-calculation/"
&gt;Incident Impact Calculation Formula&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;Note that the replacement of a generic &amp;quot;Yes&amp;quot; / &amp;quot;No&amp;quot; / &amp;quot;Cancel&amp;quot; prompt with a more specific &amp;quot;Save and exit&amp;quot; / &amp;quot;Exit without saving&amp;quot; / &amp;quot;Do not exit&amp;quot; prompt is probably an improvement, but this is not what I am discussing here. I would like to reduce the number of choices to less than three; once the number of choices has been reduced, finding some better wording for the remaining choices is all the better.&lt;/p&gt;
&lt;p&gt;Also note that the best solution to multiple choice application-modal prompts is of course to restructure software, to rethink software from scratch if need be, so that they can be completely eliminated. For example, all prompts about saving before quitting could be a thing of the past if we were to abandon the notion of saving, or even the notion of quitting. However, such exotic approaches are off-topic in this discussion.&lt;/p&gt;
&lt;p&gt;A blog author who has also examined the problem of triple-choice prompts, and explains it better than me, is &lt;a class="external"
href="https://martin.kleppmann.com/2007/07/19/yes-no-cancel-causes-aspirin-sales-to-soar.html" target="_blank"
&gt;Martin Kleppmann in &amp;quot;Yes/No/Cancel causes Aspirin sales to soar&amp;quot;&lt;/a&gt;. Interestingly enough, Martin Kleppmann follows a thought process which is similar to mine, but does not present a proposal as to what to do instead.&lt;/p&gt;
&lt;p&gt;So, here is my contribution to the subject:&lt;/p&gt;
&lt;p&gt;Quite often, a triple choice prompt can be simplified to a dual-choice prompt!&lt;/p&gt;
&lt;p&gt;We can eliminate the option to save and quit because we offer the option to not quit, which, if chosen, makes saving or not saving irrelevant: for as long as the application is still running, the user can always achieve saving and quitting by simply saving, and then quitting. (Duh!)&lt;/p&gt;
&lt;p&gt;Thus, we can offer the following simplified prompt:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Quit without saving? [Yes] / [Cancel]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The only way in which this could be further simplified would be to tell the user that they cannot quit because they have unsaved changes, and only show an [OK] button, but that would be annoying.&lt;/p&gt;
&lt;p&gt;The traditional triple-choice prompt may have been invented for the benefit of users who are in the habit of quitting while having unsaved changes that they intend to keep, but I hope that we can all agree that this is not a healthy habit worth facilitating, certainly not if facilitating it would add the slightest bit of inconvenience to other, more legitimate, (and I suspect more frequently occurring,) use cases:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The user quits intending to revert changes.&lt;/li&gt;
&lt;li&gt;The user attempts to quit while unaware that they have made changes.&lt;/li&gt;
&lt;li&gt;The user does not intend to quit, but issues the quit command accidentally.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Special workflows can be facilitated by separate commands that specially target such workflows. For example, saving every single unmodified file can be accomplished with a &amp;quot;Save All&amp;quot; command, and this has the benefits of:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Being useful at any time, not only when quitting, and&lt;/li&gt;
&lt;li&gt;Sparing the user from having to do one click per unmodified file.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To summarize:&lt;/p&gt;
&lt;p&gt;Presenting the user with only two choices is immensely better than presenting the user with three choices, when the missing choice can be trivially accomplished by the user, in a way which is intuitively obvious to the user.&lt;/p&gt;</description></item><item><title>Artificial Code Coverage</title><link>https://blog2.michael.gr/post/2024-03-codecoverage/</link><pubDate>Tue, 26 Mar 2024 15:01:55 +0000</pubDate><guid>https://blog2.michael.gr/post/2024-03-codecoverage/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2024-03-codecoverage/images/patrick-robert-doyle-UrHNIeIjoE4-unsplash.jpg"
width="3258"
height="1890"
srcset="https://blog2.michael.gr/post/2024-03-codecoverage/images/patrick-robert-doyle-UrHNIeIjoE4-unsplash_hu_d19487727715a135.jpg 480w, https://blog2.michael.gr/post/2024-03-codecoverage/images/patrick-robert-doyle-UrHNIeIjoE4-unsplash_hu_15abe3b3c0c4821e.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="172"
data-flex-basis="413px"
&gt;
&lt;/p&gt;
&lt;h3 id="abstract"&gt;Abstract
&lt;/h3&gt;&lt;p&gt;In this paper I put forth the proposition that contrary to popular belief, 100% code coverage can be a very advantageous thing to have, and I discuss a technique for achieving it without excessive effort.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id="the-problem"&gt;The problem
&lt;/h3&gt;&lt;p&gt;Conventional wisdom says that 100% code coverage is unnecessary, or even undesirable, because achieving it requires an exceedingly large amount of effort &lt;em&gt;&lt;strong&gt;not&lt;/strong&gt;&lt;/em&gt; for the purpose of asserting correctness, but instead for the sole purpose of achieving coverage. In other words, it is often said that 100% code coverage has no business value.&lt;/p&gt;
&lt;p&gt;Let me tell you why this is wrong, and why 100% code coverage can indeed be a very good thing to have.&lt;/p&gt;
&lt;p&gt;If you don't have 100% code coverage, then by definition, you have some lower percentage, like 87.2%, or 94.5%. The remaining 12.8%, or 5.5% is uncovered. I call this &lt;em&gt;&lt;strong&gt;the worrisome percentage.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;As you keep working on your code base, the worrisome percentage fluctuates:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;one day you might add a test for some code that was previously uncovered, so the worrisome percentage decreases;&lt;/li&gt;
&lt;li&gt;another day you may add some code with no tests, so the percentage increases;&lt;/li&gt;
&lt;li&gt;yet another day you may add some more code along with tests, so even though the number of uncovered lines has not changed, it now represents a smaller percentage;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;... and it goes on like that.&lt;/p&gt;
&lt;p&gt;If the worrisome percentage is high, then you know for sure that you are doing a bad job, but if it is low, it does not mean that you are doing a good job, because some very important functionality may be left uncovered, and you just do not know. To make matters worse, modern programming languages offer constructs that achieve great terseness of code, meaning that a few uncovered lines may represent a considerable amount of uncovered functionality.&lt;/p&gt;
&lt;p&gt;So, each time you look at the worrisome percentage, you have to wonder what is in there: are all the important lines covered? are the uncovered lines okay to be left uncovered?&lt;/p&gt;
&lt;p&gt;In order to answer this question, you have to go over every single line of code in the worrisome percentage, and examine it to determine whether it is okay that it is being left uncovered. What you find is, more often than not, the usual suspects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Some &lt;code&gt;ToString()&lt;/code&gt; function which is only used for diagnostics;&lt;/li&gt;
&lt;li&gt;Some &lt;code&gt;Equals()&lt;/code&gt; and &lt;code&gt;HashCode()&lt;/code&gt; functions of some value type which does not currently happen to be used as a key in a hash-map;&lt;/li&gt;
&lt;li&gt;Some &lt;code&gt;default&lt;/code&gt; &lt;code&gt;switch&lt;/code&gt; clause which can never be reached, and if it was to ever be reached it would throw;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;... etc.&lt;/p&gt;
&lt;p&gt;So, your curiosity is satisfied, your worries are allayed, and you go back to your usual software development tasks.&lt;/p&gt;
&lt;p&gt;A couple of weeks later, the worrisome percentage has changed again, prompting the same question: what is being left uncovered now?&lt;/p&gt;
&lt;p&gt;Each time you need to have this question answered, you have to re-examine every single line of code in the worrisome percentage. As you do this, you discover that in the vast majority of cases, the lines that you are examining now are the exact same lines that you were examining the previous time you were going through this exercise. After a while, this starts getting tedious. Eventually, you quit looking. Sooner or later, everyone in the shop quits looking.&lt;/p&gt;
&lt;p&gt;The worrisome percentage has now become &lt;em&gt;&lt;strong&gt;terra incognita&lt;/strong&gt;&lt;/em&gt;: literally anything could be in there; nobody knows, and nobody wants to know, because finding out is such a dreary chore.&lt;/p&gt;
&lt;p&gt;That is not a particularly nice situation to be in.&lt;/p&gt;
&lt;h3 id="the-solution"&gt;The solution
&lt;/h3&gt;&lt;p&gt;So, here is a radical proposition: If you always keep your code coverage at 100%, then the worrisome percentage is always zero, so there is nothing to worry about!&lt;/p&gt;
&lt;p&gt;When the worrisome percentage is never zero, then no matter how it fluctuates, it never represents an appreciable change in the situation: it always goes from some non-zero number to some other non-zero number, meaning that we used to have some code uncovered, and we still have some code uncovered. No matter what happens, there is no actionable item.&lt;/p&gt;
&lt;p&gt;On the other hand, if the worrisome percentage is normally zero, then each time it rises above zero it represents a definite change in the situation: you used to have everything covered, and now you have something uncovered. This signifies a clear call to action: the code that is now being left uncovered needs to be examined, and dealt with.&lt;/p&gt;
&lt;p&gt;By dealing with uncovered code as soon as it gets introduced, you bring the worrisome percentage back to zero, thus achieving two things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You ensure that next time the worrisome percentage becomes non-zero, it will represent a new call to action.&lt;/li&gt;
&lt;li&gt;You never find yourself in the unpleasant situation of re-examining code that has been examined before; so, the examination does not feel like a dreary chore.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The conventional understanding of how to deal with uncovered code is to write a test for it, and that is why achieving 100% code coverage is regarded as onerous; however, there exist alternatives that are much easier. For any given piece of uncovered code, you have three options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Option #1: Write a test for the code.&lt;/p&gt;
&lt;p&gt;This is of course the highest quality option, but it does not always represent the best value for money, and it is not even always possible. You only need to do it if the code is important enough to warrant testing, and you can only do it if the code is in fact testable. If you write a test, you can still minimize the effort of doing so, by utilizing certain techniques that I talk about in other posts, such as &lt;a
href="https://blog2.michael.gr/post/2024-04-audit-testing/"
&gt;Audit Testing&lt;/a&gt;, &lt;a
href="https://blog2.michael.gr/post/2022-10-testing-with-fakes/"
&gt;Testing with Fakes instead of Mocks&lt;/a&gt;, and &lt;a
href="https://blog2.michael.gr/post/2022-10-incremental-integration-testing/"
&gt;Incremental Integration Testing&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Option #2: Exclude the code from code coverage.&lt;/p&gt;
&lt;p&gt;Code that is not testable, or not important enough to warrant testing, can be moved into a separate module which does not participate in coverage analysis. Alternatively, if your code coverage analysis tool supports it, you may be able to exclude individual methods without having to move them to another module. In the DotNet world, this can be accomplished by marking a method with &lt;a class="external"
href="https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.codeanalysis.excludefromcodecoverageattribute" target="_blank"
&gt;the &lt;code&gt;ExcludeFromCodeCoverage&lt;/code&gt; attribute&lt;/a&gt;, found in the &lt;code&gt;System.Diagnostics.CodeAnalysis&lt;/code&gt; namespace. In the Java world, IntelliJ IDEA offers a setting for specifying what annotation we want to use for marking methods to be excluded from code coverage, so you can use any annotation you like. (See &lt;a
href="https://blog2.michael.gr/post/2022-12-intellij-idea-can-now-exclude-methods/"
&gt;IntelliJ IDEA can now exclude methods from code coverage&lt;/a&gt;.) Various different code coverage analyzers support additional ways of excluding code from coverage.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Option #3: Artificially cover the code.&lt;/p&gt;
&lt;p&gt;With the previous two options you should be able to bring the worrisome percentage down to a very small number, like 1 or 2 percent. What remains is code which should really be excluded from coverage, but it cannot, due to limitations in available tooling: although code coverage analyzers generally allow excluding entire functions from coverage analysis, they generally do not offer any means of excluding individual lines of code, such as the unreachable &lt;code&gt;default&lt;/code&gt; clause of some &lt;code&gt;switch&lt;/code&gt; statement. You can try moving that line into a separate function, and excluding that function, but you cannot exclude the call to that function, so the problem remains.&lt;/p&gt;
&lt;p&gt;The solution in these cases is to cause the uncovered code to be invoked during testing, &lt;em&gt;&lt;strong&gt;not&lt;/strong&gt;&lt;/em&gt; in order to test it, but simply in order to have it covered. This might sound like cheating, but it is not, because the stated objective was not to test the code, it was to exclude it from coverage. You would have excluded that line from coverage if the tooling supported doing so, but since it does not, the next best thing, (and the only option you are left with,) is to artificially include it in the code coverage.&lt;/p&gt;
&lt;p&gt;Here is a (hopefully exhaustive) list of all the different reasons due to which code might be left uncovered, and what to do in each case:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The code should really be covered, but you forgot to write tests for it, or you have plans to write tests in the future.&lt;/p&gt;
&lt;p&gt;Go with Option #1: write tests for it. Not in the future, &lt;em&gt;&lt;strong&gt;now&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The code is not used and there is no plan to use it.&lt;/p&gt;
&lt;p&gt;This is presumably code which exists for historical reasons, or for reference, or because it took some effort to write it and you do not want to admit that the effort was a waste by throwing away the code.&lt;/p&gt;
&lt;p&gt;Go with Option #2 and exclude it from coverage.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The code is only used for diagnostics.&lt;/p&gt;
&lt;p&gt;The prime example of this is &lt;code&gt;ToString()&lt;/code&gt; methods that are not normally invoked in a production environment, but give informative
descriptions of our objects while debugging.&lt;/p&gt;
&lt;p&gt;Go with Option #2: Exclude such methods from coverage.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The code is not normally reachable, but it is there in case something unexpected happens.&lt;/p&gt;
&lt;p&gt;The prime example of this is C# &lt;code&gt;switch&lt;/code&gt; statements that cover all possible cases and yet also contain a &lt;code&gt;default&lt;/code&gt; clause just in case an unexpected value somehow manages to creep in.&lt;/p&gt;
&lt;p&gt;Go with Option #3: Artificially cover such code. This may require a bit of refactoring to make it easier to cause the problematic &lt;code&gt;switch&lt;/code&gt; statement to be invoked with an invalid value. The code most likely throws, so catch the exception and swallow it. You can also assert that the expected exception was thrown, in which case it becomes more like Option #1: a test.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The code is reachable but not currently being reached.&lt;/p&gt;
&lt;p&gt;This is code which is necessary for completeness, and it just so happens that it is not currently being used, but nothing prevents it from being used at any moment. A prime example of this is the &lt;code&gt;Equals()&lt;/code&gt; and &lt;code&gt;HashCode()&lt;/code&gt; functions of value types: without those functions, a value type is incomplete; however, if the value type does not currently happen to be used as a key in a hash-map, then those functions are almost certainly unused.&lt;/p&gt;
&lt;p&gt;In this case, you can go with any of the three options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You can go with Option #1 and write a proper test.&lt;/li&gt;
&lt;li&gt;You can go with Option #2 and exclude the code.&lt;/li&gt;
&lt;li&gt;You can go with Option #3 and artificially cover the code.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The code is not important enough to have a test for it.&lt;/p&gt;
&lt;p&gt;Say you have a function which takes a tree data structure and converts it to text using &lt;a class="external"
href="https://en.wikipedia.org/wiki/Box-drawing_character" target="_blank"
&gt;&lt;em&gt;box-drawing characters&lt;/em&gt;&lt;/a&gt; so as to be able to print it nicely as a tree on the console. Since the function receives text and emits text, it is certainly testable, but is it really worth testing? If it ever draws something wrongly, you will probably notice, and if you do not notice, then maybe it did not matter anyway.&lt;/p&gt;
&lt;p&gt;In this case you can go either with Option #2 and exclude such functions, or Option #3 and artificially cover them.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The code is literally or practically untestable.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If your application has a Graphical User Interface (GUI), you can write automated tests for all of your application logic, but the only practical way to ascertain the correctness of the GUI is to have human eyes staring at the screen. (There exist tools for testing GUIs, but I assess them as &lt;em&gt;woefully impractical and acutely ineffective&lt;/em&gt;.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If your application controls some hardware, you may have a hardware abstraction layer with two implementations, one which emulates the hardware, and one which interacts with the actual hardware. The emulator will enable you to test all of your application logic without having the actual hardware in place; however, the implementation which interacts with the actual hardware is practically untestable by software alone.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you have a piece of code that queries the endianness of the hardware architecture and operates slightly differently depending on it, the only path you can truly cover is the one for the endianness of the hardware architecture you are actually using. (You can fake the endianness query, and pretend that your hardware has the opposite endianness, but you still have no guarantees as to whether the bit-juggling that you do in that path is right for the opposite endianness.)&lt;/p&gt;
&lt;p&gt;In all of the above cases, and in all similar cases, we have no option but #2: exclude the code from coverage.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id="conclusion"&gt;Conclusion
&lt;/h4&gt;&lt;p&gt;If testing has business value, then 100% code coverage has business value, too.&lt;/p&gt;
&lt;p&gt;A code coverage percentage of 100% is very useful, not for bragging, but for maintaining certainty that everything that ought to be tested is in fact being tested.&lt;/p&gt;
&lt;p&gt;Achieving a code coverage percentage of 100% does require some effort, but with techniques such as Artificial Coverage the effort can be reduced to manageable levels.&lt;/p&gt;
&lt;p&gt;Ideally, Artificial Coverage should never be necessary, but it is a practical workaround for the inability of coverage tools to exclude individual lines of code from analysis.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image by &lt;a class="external"
href="https://unsplash.com/@teapowered" target="_blank"
&gt;Patrick Robert Doyle from Unsplash&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Audit Testing</title><link>https://blog2.michael.gr/post/2024-04-audit-testing/</link><pubDate>Fri, 09 Feb 2024 14:55:40 +0000</pubDate><guid>https://blog2.michael.gr/post/2024-04-audit-testing/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2024-04-audit-testing/images/audit-testing.svg"
loading="lazy"
&gt;
&lt;/p&gt;
&lt;h4 id="abstract"&gt;Abstract
&lt;/h4&gt;&lt;p&gt;An automated software testing technique is presented which spares us from having to stipulate our expectations in test code, and from having to go fixing test code each time our expectations change.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id="the-problem"&gt;The Problem
&lt;/h3&gt;&lt;p&gt;The most common scenario in automated software testing is ensuring that given specific input, a component-under-test produces expected output. The conventional way of achieving this is by feeding the component-under-test with a set of predetermined parameters, obtaining the output of the component-under-test, comparing the output against an instance of known-good output which has been hard-coded within the test, and failing the test if the two are not equal.&lt;/p&gt;
&lt;p&gt;This approach works, but it is inefficient, because during the development and evolution of a software system we often make changes to the production code fully anticipating the output of certain components to change. Unfortunately, each time we do this, the tests fail, because they are still expecting the old output. So, each change in the production code must be followed by a round of fixing tests to make them pass.&lt;/p&gt;
&lt;p&gt;Note that under Test-Driven Development things are not any better: first we modify the tests to start expecting the new output, then we observe them fail, then we modify the components to produce the new output, then we watch the tests pass. We still have to stipulate our expectations in test code, and we still have to change test code each time our expectations change, which is inefficient.&lt;/p&gt;
&lt;p&gt;This imposes a considerable burden on the software development process. As a matter of fact, it often happens that programmers refrain from making needed changes to their software because they dread the prospect of having to fix all the tests that will break as a result of those changes.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Audit Testing&lt;/strong&gt;&lt;/em&gt; is a technique for automated software testing which aims to correct all this.&lt;/p&gt;
&lt;h3 id="the-solution"&gt;The Solution
&lt;/h3&gt;&lt;p&gt;Under Audit Testing, the assertions that verify the correctness of the output of the component-under-test are abolished, and replaced with code that simply saves the output to a text file. This file is known as the &lt;em&gt;&lt;strong&gt;Audit File&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The test may still fail if the component-under-test encounters an error while producing output, in which case we follow a conventional test-fix-repeat workflow, but if the component-under-test manages to produce output, then the output is saved in the Audit File and the test completes successfully &lt;em&gt;&lt;strong&gt;without examining it.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The trick is that the Audit File is saved right next to the source code file of the test, which means that it is kept under Version Control. In the most common case, each test run produces the exact same audit output as the previous run, so nothing changes, meaning that all is good. If a test run produces different audit output from a previous test run, then the tooling alerts the developer to that effect, and the Version Control System additionally indicates that the Audit File has been modified and is in need of committing. Thus, the developer cannot fail to notice that the audit output has changed.&lt;/p&gt;
&lt;p&gt;The developer can then utilize the &amp;quot;Compare with unmodified&amp;quot; feature of the Version Control System to see the differences between the audit output that was produced by the modified code, and the audit output of the last known-good test run. By visually inspecting these differences, the developer can decide whether they are as expected or not, according to the changes they made in the code.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the observed differences are not as expected, then the developer needs to keep working on their code until they are.&lt;/li&gt;
&lt;li&gt;If the observed differences are as expected, then the developer can simply commit the new code, along with the new Audit File, &lt;em&gt;&lt;strong&gt;and they are done.&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This way, we eliminate the following burdens:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Having to hard-code into the tests the output expected from the component-under-test.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Having to assert, in each test, that the output of the component-under-test matches the expected output.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Having to go fixing test code each time there is a (fully expected) change in the output of the component-under-test.&lt;/p&gt;
&lt;p&gt;The eliminated burdens are traded for the following much simpler responsibilities:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The output of the component-under-test must be converted to text and written to an audit file.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When the version control system shows that an audit file changed after a test run, the differences must be reviewed, and a decision must be made as to whether they are as expected or not.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tests and production code must be written with some noise reduction concerns in mind. (More on that further down.)&lt;/p&gt;
&lt;p&gt;This represents a considerable optimization of the software development process.&lt;/p&gt;
&lt;p&gt;Note that the arrangement is also convenient for the reviewer, who can see both the changes in the code and the resulting changes in the Audit Files.&lt;/p&gt;
&lt;p&gt;As an added safety measure, the continuous build pipeline can deliberately fail the tests if an unclean working copy is detected after running the tests, because that would mean that the tests produced different results from what was expected, or that someone failed to commit some updated audit file.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="noise-reduction"&gt;Noise reduction
&lt;/h3&gt;&lt;p&gt;For Audit Testing to work effectively, all audit output must be completely free of noise. By noise we mean:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Two test runs of the exact same code producing different audit output.&lt;/li&gt;
&lt;li&gt;A single change in the code producing wildly different audit output.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example, if a test emits the username of the current user into the audit output, then the audit file generated by that test will be different for every user that runs it, even if the user does not modify any code.&lt;/p&gt;
&lt;p&gt;Noise is undesirable, because:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Needlessly modified audit files are a false cause of alarm.&lt;/li&gt;
&lt;li&gt;Examining changes in audit files only to discover that they are due to noise is a waste of time.&lt;/li&gt;
&lt;li&gt;A change that might be important to notice can be lost in the noise.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Noise in audit files is most commonly caused by various sources of non-determinism, such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Wall-clock time.&lt;/p&gt;
&lt;p&gt;As the saying goes, the arrow of time is always moving forward. This means that the &amp;quot;current&amp;quot; time coordinate is always different from test run to test run, and this in turn means that if any wall-clock timestamps find their way into the audit output, the resulting audit file will always be different from the previous run. So, for example, if your software generates a log, and you were thinking of using the log as your audit output, then you will have to either remove the timestamps from the log, or fake them. Faking the clock for the purpose of testing is a well-known best practice anyway, regardless of audit testing. To accomplish this, create a &amp;quot;Clock&amp;quot; interface, and propagate it to every place in your software that needs to know the current time. Create two implementations of that interface: one for production, which queries the actual wall-clock time from the operating environment, and one for testing, which starts from some fixed, known origin and increments by a fixed amount each time it is queried.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Random number generation.&lt;/p&gt;
&lt;p&gt;Random number generators are usually pseudo-random, and we tend to make them practically random by seeding them with the wall-clock time. This can be easily fixed for the purpose of testing by seeding them with a known fixed value instead. Some pseudo-random generators seed themselves with the wall-clock time without allowing us to override this behavior; this is deplorable. Such generators must be faked in their entirety for the purpose of testing. This extends to any other constructs that employ random number generation, such as GUIDs/UUIDs: they must also be faked when testing, using deterministic generators.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multi-threading.&lt;/p&gt;
&lt;p&gt;Multiple threads running in parallel tend to exhibit unpredictable timing irregularities, and result in a chaotically changing order of events. If these threads affect audit output, then the ordering of the content of the audit file will be changing on every test run. For this reason, multi-threading must either be completely avoided when testing, or additional mechanisms (queuing, sorting, etc.) must be employed to guarantee a consistent ordering of audit output.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Floating-point number imprecision.&lt;/p&gt;
&lt;p&gt;Floating-point calculations can produce slightly different results depending on whether optimizations are enabled or not. To ensure that the audit file is unaffected, any floating point values emitted to the audit file must be rounded to as few digits as necessary. At the very least, they must be rounded to one digit less than their full precision.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Other external factors.&lt;/p&gt;
&lt;p&gt;User names, computer names, file creation times, IP addresses resolved from DNS, etc must either be prevented from finding their way into the audit output, or they must be faked when running tests. Fake your file-system; fake The Internet if necessary. For more information about faking stuff, see &lt;a
href="https://blog2.michael.gr/post/2022-10-testing-with-fakes/"
&gt;Testing with Fakes instead of Mocks&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In short, anything that would cause &lt;a class="external"
href="https://ell.stackexchange.com/a/299395/129530" target="_blank"
&gt;flakiness&lt;/a&gt; in software tests will cause noisiness in Audit Testing.&lt;/p&gt;
&lt;p&gt;Additionally, the content of audit files can be affected by some constructs that are fully deterministic in their nature. These constructs will never result in changed audit files without any changes in the code, but may produce drastically different audit files as a result of only minute changes in the code. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Hash Table Rehashing.&lt;/p&gt;
&lt;p&gt;A hash table may decide to re-hash itself as a result of a single key addition, if that addition happens to cause some internal load factor
threshold to be exceeded. Exactly when and how this happens depends on the implementation of the hash table and we usually have no control over it. After re-hashing, the order in which the hash table enumerates its keys is drastically different, and if the keys are emitted to audit output, then the audit file will be drastically different. To avoid this, replace plain hash tables with hash tables that retain the order of key insertion.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Insufficient Sorting Keys.&lt;/p&gt;
&lt;p&gt;When sorting data, the order of items with identical keys is undefined. It is still deterministic, but the addition or removal of a single item can cause all items with the same sorting key to be arbitrarily rearranged. To avoid this, always use a full set of sorting keys when sorting data, so as to give every item a specific unique order. Introduce additional sorting keys if necessary, even if you would not normally have a use for them.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Noise reduction aims to ensure that we will never see changes in the audit files unless there have been changes in the code, and that for every unique change in the code we will see a specific expected set of changes in the audit output, instead of a large number of irrelevant changes. This ensures that the single change that matters will not be lost in the noise, and makes it easier to determine that the modifications we made to the code have exactly the intended consequences and not any unintended consequences.&lt;/p&gt;
&lt;p&gt;Note that in some cases, noise reduction can be implemented in the tests rather than in the production code. For example, instead of replacing a plain hash table with an ordered hash table in production code, our test can obtain the contents of the plain hash table and sort them before writing them to the audit file. However, this may not be possible in cases where the hash table is several transformations away from the auditing. Thus, replacing a plain hash table with an ordered hash table may sometimes be necessary in production code.&lt;/p&gt;
&lt;p&gt;Noise reduction in production code can be either always enabled, or only enabled during testing. The most performant choice is to only have it enabled during testing, but the safest choice is to have it always enabled.&lt;/p&gt;
&lt;h3 id="failure-testing"&gt;Failure Testing
&lt;/h3&gt;&lt;p&gt;Failure Testing is the practice of deliberately supplying the component-under-test with invalid input and ensuring that the component-under-test detects the error and throws an appropriate exception. Such scenarios can leverage Audit Testing by simply catching exceptions and serializing them, as text, into the audit output.&lt;/p&gt;
&lt;h3 id="applicability"&gt;Applicability
&lt;/h3&gt;&lt;p&gt;Audit Testing is most readily useful when the Component Under Test produces results as text, or results that are directly translatable to text. With a bit of effort, any kind of output can be converted to text, so Audit Testing is universally applicable.&lt;/p&gt;
&lt;h3 id="must-audit-files-be-committed"&gt;Must Audit Files be committed?
&lt;/h3&gt;&lt;p&gt;It is in theory possible to refrain from storing Audit Files in the source code repository, but doing so would have the following disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It would deprive the code reviewer from the convenience of being able to see not only the changes in the code, but also the differences that these changes have introduced in the audit output of the test.&lt;/li&gt;
&lt;li&gt;It would require the developer to always remember to immediately run the tests each time they pull from the source code repository, so as to have the unmodified Audit Files produced locally, before proceeding to make modifications to the code which would further modify the Audit Files.&lt;/li&gt;
&lt;li&gt;It would make it more difficult for the developer to take notice when the Audit Files change.&lt;/li&gt;
&lt;li&gt;It would make it more difficult for the developer to see diffs between the modified Audit Files and the unmodified ones.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course all of this could be taken care of with some extra tooling. What remains to be seen is whether the effort of developing such tooling can be justified by the mere benefit of not having to store Audit Files in the source code repository.&lt;/p&gt;
&lt;h4 id="conclusion"&gt;Conclusion
&lt;/h4&gt;&lt;p&gt;Audit Testing is a universally applicable technique for automated software testing which can significantly reduce the effort of writing and maintaining tests by sparing us from having to stipulate our expectations in test code, and from having to go fixing test code each time our expectations change.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: &amp;quot;Audit Testing&amp;quot; by michael.gr.&lt;/p&gt;</description></item><item><title>Types of dependencies</title><link>https://blog2.michael.gr/post/2024-01-types-of-dependencies/</link><pubDate>Thu, 11 Jan 2024 17:33:42 +0000</pubDate><guid>https://blog2.michael.gr/post/2024-01-types-of-dependencies/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2024-01-types-of-dependencies/images/dependency0.png"
width="1861"
height="1046"
srcset="https://blog2.michael.gr/post/2024-01-types-of-dependencies/images/dependency0_hu_616f75dcb058bc68.png 480w, https://blog2.michael.gr/post/2024-01-types-of-dependencies/images/dependency0_hu_55cc59d1b7857d37.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="177"
data-flex-basis="426px"
&gt;
&lt;/p&gt;
&lt;p&gt;The term &amp;quot;dependency&amp;quot; is used very often in software engineering, but depending on context, it may mean slightly different things. To avoid confusion, here are the different meanings of the term, and their explanations.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Compile-time (static) dependency:&lt;/strong&gt; When module &lt;strong&gt;A&lt;/strong&gt; makes use of a symbol which is defined in module &lt;strong&gt;B&lt;/strong&gt;, we say that &lt;strong&gt;A&lt;/strong&gt; has a compile-time dependency on &lt;strong&gt;B&lt;/strong&gt;. (Or that &lt;strong&gt;B is a compile-time dependency of A.&lt;/strong&gt;) This happens not only when module &lt;strong&gt;A&lt;/strong&gt; contains a hard-coded invocation to module &lt;strong&gt;B&lt;/strong&gt;, but also when &lt;strong&gt;A&lt;/strong&gt; makes use of some definition from &lt;strong&gt;B&lt;/strong&gt;, such as referring to a constant, implementing an interface, or instantiating a type defined in &lt;strong&gt;B&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Runtime (dynamic) dependency:&lt;/strong&gt; When module &lt;strong&gt;A&lt;/strong&gt; is given, at runtime, a reference to invoke module &lt;strong&gt;B&lt;/strong&gt;, then we have a runtime dependency between &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt;. Runtime dependencies can be further divided in two sub-categories:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Assembly-time (semi-dynamic) dependency:&lt;/strong&gt; This is a runtime dependency which is realized during system assembly, and remains unchanged throughout the lifetime of the system.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Post-assembly-time (fully dynamic) dependency:&lt;/strong&gt; This is a runtime dependency which may be realized or changed at any moment, by having one module programmatically pass a callback to another module.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we are to take the &lt;a class="external"
href="https://en.wikipedia.org/wiki/Dependency_inversion_principle" target="_blank"
&gt;Dependency Inversion Principle (DIP)&lt;/a&gt; for granted in software architecture, (and we should,) then software architecture is not concerned with static dependencies. This is because the DIP states that concrete modules should never statically depend on other concrete modules; instead, concrete modules may statically depend only on abstractions. Thus, the DIP is advising us to build our concrete modules so that they have no knowledge of each other. Instead, they should be making outgoing invocations to interfaces, and these invocations should be wired to concrete modules implementing those interfaces. Interfaces are abstractions, so it is okay for a concrete module to have compile-time dependencies on modules defining such abstractions.&lt;/p&gt;
&lt;p&gt;Assembly-time dependencies are what software architecture is mostly concerned with. The architecture of a software system specifies how to wire interface invocations between components. The wiring prescribed by the design is normally performed during system assembly, which is part of system deployment. Thus, the wires constitute assembly-time dependencies, and the graph of these dependencies is essentially the call graph of the system as defined by the architecture.&lt;/p&gt;
&lt;p&gt;Post-assembly-time dependencies do not affect the topology of a design, because every post-assembly time dependency requires an existing assembly-time dependency through which the callback can be communicated. Thus, post-assembly-time dependencies constitute implementation details of the modules that supply and invoke callbacks. As such, they are of only limited interest in software architecture.&lt;/p&gt;</description></item><item><title>Call Graph Acyclicity</title><link>https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/</link><pubDate>Wed, 27 Dec 2023 12:08:24 +0000</pubDate><guid>https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic0.png"
width="1860"
height="1122"
srcset="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic0_hu_5c4a1077d5a1af0.png 480w, https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic0_hu_bc6ab53ae2d39e03.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="165"
data-flex-basis="397px"
&gt;
&lt;/p&gt;
&lt;h3 id="abstract"&gt;Abstract
&lt;/h3&gt;&lt;p&gt;In technical design of software systems as conventionally practiced, call graphs often contain cycles. We show that cyclic call graphs are highly problematic for a number of reasons, the most important being that they require careful handling on a case-by-case basis by custom-written code, thus preventing the standardization, and therefore the automation, of system assembly. We discuss refactoring strategies for systematically eliminating call cycles, including a universally applicable technique for trivially eliminating a certain common type of call cycle. We conclude that since call cycles can be avoided or eliminated, they can be comprehensively disallowed, thus paving the way for the automation of system assembly.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id="what-is-a-cycle-in-a-call-graph"&gt;What is a cycle in a call graph
&lt;/h3&gt;&lt;p&gt;When component &lt;strong&gt;A&lt;/strong&gt; invokes component &lt;strong&gt;B&lt;/strong&gt;, and component &lt;strong&gt;B&lt;/strong&gt; also invokes component &lt;strong&gt;A&lt;/strong&gt;, we say that the call graph contains a &lt;em&gt;direct&lt;/em&gt; cycle. If &lt;strong&gt;A&lt;/strong&gt; invokes &lt;strong&gt;B&lt;/strong&gt;, which invokes &lt;strong&gt;C&lt;/strong&gt;, which in turn invokes &lt;strong&gt;A&lt;/strong&gt;, we say that the call graph contains an &lt;em&gt;indirect&lt;/em&gt; cycle. If &lt;strong&gt;A&lt;/strong&gt; invokes itself, we say that the call graph contains a self-loop, or a buckle, which is a special case of a cycle. In general, if a component diagram contains any path of invocations starting at a certain component and arriving back at the same component, the call graph contains a cycle.&lt;/p&gt;
&lt;p&gt;As an example, let us consider the simplest possible scenario, consisting of just two components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A temperature sensor component, whose job is to obtain a temperature value from some piece of hardware, and make that value available within the software system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A temperature indicator component, whose job is to display a temperature on the screen.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic1.png"
width="1860"
height="686"
srcset="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic1_hu_bb41670c7de8d3cb.png 480w, https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic1_hu_2dad1d21c6ed7e3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="271"
data-flex-basis="650px"
&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this diagram, each component has &lt;em&gt;&lt;strong&gt;inputs&lt;/strong&gt;&lt;/em&gt; and &lt;strong&gt;outputs&lt;/strong&gt;, collectively known as &lt;em&gt;&lt;strong&gt;pins&lt;/strong&gt;&lt;/em&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An input is an endpoint for receiving incoming interface invocations; it represents an interface exposed by a component for invocation by other components. It is signified by an arrow pointing into the component.&lt;/li&gt;
&lt;li&gt;An output is an endpoint through which a component places outgoing interface invocations; it represents an interface that a component wants to invoke. It is signified by an arrow pointing out of the component.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For those familiar with UML component diagrams, an input is a &lt;em&gt;&lt;strong&gt;provided&lt;/strong&gt;&lt;/em&gt; interface in UML, and an output is a &lt;em&gt;&lt;strong&gt;required&lt;/strong&gt;&lt;/em&gt; interface in UML. In this paper we use arrows to show the direction of invocations from output to input, instead of the socket-and-lollipop notation of UML.&lt;/p&gt;
&lt;p&gt;Each input and output has a name and a type. Obviously, an output can be connected to an input only if their types match.&lt;/p&gt;
&lt;p&gt;The temperature sensor:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Has an input called &lt;em&gt;&lt;strong&gt;Reading&lt;/strong&gt;&lt;/em&gt;, of type &lt;em&gt;&lt;strong&gt;ReadonlyFloat&lt;/strong&gt;&lt;/em&gt;, which can be invoked by some other component to obtain the current value of the temperature.&lt;/li&gt;
&lt;li&gt;Has an output called &lt;em&gt;&lt;strong&gt;Changed&lt;/strong&gt;&lt;/em&gt;, of type &lt;em&gt;&lt;strong&gt;Procedure0&lt;/strong&gt;&lt;/em&gt; (same thing as the &amp;quot;Runnable&amp;quot; of Java or the &amp;quot;Action&amp;quot; of C#) that it invokes in order to indicate that the value of the temperature has changed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The temperature indicator:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Has an output which is called &lt;em&gt;&lt;strong&gt;Reading&lt;/strong&gt;&lt;/em&gt;, of type &lt;em&gt;&lt;strong&gt;ReadonlyFloat&lt;/strong&gt;&lt;/em&gt;, that it invokes in order to obtain the current value of the temperature.&lt;/li&gt;
&lt;li&gt;Has an input called &lt;em&gt;&lt;strong&gt;Refresh&lt;/strong&gt;&lt;/em&gt;, of type &lt;em&gt;&lt;strong&gt;Procedure0&lt;/strong&gt;&lt;/em&gt;, which can be invoked to cause the indicator to re-display the current temperature value.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the diagram, the &lt;em&gt;&lt;strong&gt;Reading&lt;/strong&gt;&lt;/em&gt; output of the indicator has been connected to the &lt;em&gt;&lt;strong&gt;Reading&lt;/strong&gt;&lt;/em&gt; input of the sensor, and the &lt;em&gt;&lt;strong&gt;Changed&lt;/strong&gt;&lt;/em&gt; output of the sensor has been connected to the &lt;em&gt;&lt;strong&gt;Refresh&lt;/strong&gt;&lt;/em&gt; input of the indicator. Note that this design has a call cycle in it: The indicator invokes the sensor to obtain the current temperature, but the sensor also invokes the indicator to tell it that the current temperature has changed.&lt;/p&gt;
&lt;h3 id="dependencies"&gt;Dependencies
&lt;/h3&gt;&lt;p&gt;In &lt;a
href="https://blog2.michael.gr/post/2024-01-types-of-dependencies/"
&gt;Types of dependencies&lt;/a&gt; I differentiate between &lt;strong&gt;compile-time (static)&lt;/strong&gt; dependencies, &lt;strong&gt;assembly-time (semi-dynamic)&lt;/strong&gt; dependencies, and &lt;strong&gt;post-assembly-time (fully dynamic)&lt;/strong&gt; dependencies.&lt;/p&gt;
&lt;p&gt;Compile-time dependencies have already been given a lot of consideration and the general consensus is that they better not be cyclic. Most build systems prohibit static dependency cycles between build modules; for example, in the Java world, Maven artifacts cannot circularly depend on each other; similarly, in the dotnet world, MSBuild projects cannot circularly depend on each other. However, programming languages usually allow compile-time dependency cycles within program code: if classes &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt; are defined within the same build module, it is usually possible to have &lt;strong&gt;A&lt;/strong&gt; contain a hard-coded invocation to a method of &lt;strong&gt;B&lt;/strong&gt;, and for &lt;strong&gt;B&lt;/strong&gt; to also contain a hard-coded invocation to a method of &lt;strong&gt;A&lt;/strong&gt;. Nonetheless, software architecture is not concerned with hard-coded invocations; therefore, in this paper the term &amp;quot;dependency&amp;quot; does &lt;em&gt;&lt;strong&gt;not&lt;/strong&gt;&lt;/em&gt; refer to compile-time (static) dependencies.&lt;/p&gt;
&lt;p&gt;Assembly-time dependencies are what software architecture is mostly concerned with, and as such, this is the sense in which the term &amp;quot;dependency&amp;quot; is used in this paper.&lt;/p&gt;
&lt;p&gt;Post-assembly-time dependencies are useful, as we will see, in certain techniques for eliminating call cycles; however, they do not affect the topology of a design, (they are implementation details which are not representable in a component diagram,) and as such these are not the kind of dependencies that we are referring to when we speak of dependencies in this paper.&lt;/p&gt;
&lt;h3 id="are-call-cycles-common"&gt;Are call cycles common?
&lt;/h3&gt;&lt;p&gt;In software design as conventionally practiced, cycles in the call graph are a frequent phenomenon. Software architects often have no qualms about producing a design where &lt;strong&gt;A&lt;/strong&gt; calls &lt;strong&gt;B&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt; also calls &lt;strong&gt;A&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In the literature we find statements endorsing this practice. For example, in the seminal paper &lt;a class="external"
href="https://c2.com/doc/oopsla89/paper.html" target="_blank"
&gt;&amp;quot;A Laboratory For Teaching Object-Oriented Thinking&amp;quot;&lt;/a&gt;&lt;a class="external"
href="https://c2.com/doc/oopsla89/paper.html" target="_blank"
&gt;(1989)&lt;/a&gt; by &lt;a class="external"
href="https://en.wikipedia.org/wiki/Kent_Beck" target="_blank"
&gt;Kent Beck&lt;/a&gt; and &lt;a class="external"
href="https://en.wikipedia.org/wiki/Ward_Cunningham" target="_blank"
&gt;Ward Cunningham&lt;/a&gt;, the authors acknowledge that many components act as servers &amp;quot;with little regard or even awareness of [their] client&amp;quot;, but also find it perfectly normal for some components to be &amp;quot;near-equals&amp;quot; in a &amp;quot;symmetric relation&amp;quot;. That paper introduced the term &amp;quot;collaborator&amp;quot;, which became a staple term in the software engineering discipline, specifically in order to allow for bidirectional interaction between components, as opposed to the already-existing term &amp;quot;dependency&amp;quot;, which implies a one-way interaction. (For more on this, see &lt;a
href="https://blog2.michael.gr/post/2023-01-16-collaborator/"
&gt;Definition: Collaborator&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id="the-problem-with-cyclic-call-graphs"&gt;The problem with cyclic call graphs
&lt;/h3&gt;&lt;p&gt;Cyclic call graphs constitute &lt;a class="external"
href="https://en.wikipedia.org/wiki/Tight_coupling?redirect=no" target="_blank"
&gt;tight coupling&lt;/a&gt;. This in turn has a severe negative effect on the understandability and maintainability of software. Wikipedia &lt;a class="external"
href="https://en.wikipedia.org/wiki/Coupling_%28computer_programming%29" target="_blank"
&gt;lists some specific disadvantages of tight coupling&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A change in one module usually forces a ripple effect of changes in other modules.&lt;/li&gt;
&lt;li&gt;Assembly of modules might require more effort and/or time due to the increased inter-module dependency.&lt;/li&gt;
&lt;li&gt;A particular module might be harder to reuse and/or test because dependent modules must be included.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The second point might be a bit vague, but it is very important, so it is worth examining it in more depth. The term &amp;quot;assembly of modules&amp;quot; refers to the process of instantiating each component that makes up the system, and wiring the components together so that the system can start running. In this paper, we call this process &lt;em&gt;&lt;strong&gt;system assembly&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The simplest approach to system assembly is to pass to each component all of its dependencies as constructor parameters when instantiating it, so that immediately upon construction the component is ready to start performing its duties. However, this approach is not viable if the call graph contains cycles, because circular dependencies introduce a chicken-and-egg problem: If each component requires all of its dependencies to be passed as constructor parameters, and if components &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt; depend on each other, then &lt;strong&gt;A&lt;/strong&gt; can only be constructed if &lt;strong&gt;B&lt;/strong&gt; has already been constructed, but &lt;strong&gt;B&lt;/strong&gt; cannot be constructed unless &lt;strong&gt;A&lt;/strong&gt; has been constructed first.&lt;/p&gt;
&lt;p&gt;This problem is pervasive, but it has not received much attention because we are resigned to software development being a largely unstandardized, labor-intensive process where copious amounts of custom-written code provide ad-hoc solutions to long-standing problems on a case by case basis. During system assembly, developers tend to wire as many components as they can during construction, and when a certain wire turns out to form a call cycle, they make a special case and refactor the components involved so as to postpone the wiring of that particular call until after construction. (This often leads to order-of-initialization bugs, which require painstaking effort to troubleshoot and fix.)&lt;/p&gt;
&lt;p&gt;As the system evolves, and wires between components are added or removed, developers try to keep components unchanged by re-arranging the order in which they are instantiated, and when this is not enough, they further refactor components, turning more construction-time wiring into post-construction-time wiring, and vice versa. (Invariably resulting in &lt;em&gt;more&lt;/em&gt; order-of-initialization bugs, and &lt;em&gt;more&lt;/em&gt; painstaking effort to troubleshoot and fix them.)&lt;/p&gt;
&lt;p&gt;Conventional software development practices often utilize &lt;a class="external"
href="https://en.wikipedia.org/wiki/Dependency_injection#Frameworks" target="_blank"
&gt;&lt;em&gt;&lt;strong&gt;dependency injection frameworks&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt; to handle the wiring of components. Such frameworks work as if by magic, which is by some schools of thought undesirable by definition; they also represent substantial runtime overhead, so they are unsuitable for certain classes of applications, e.g. for embedded systems. Some dependency injection frameworks do not solve the problem of circular dependencies, because they simply prohibit them, whereas others attempt to solve the problem by transparently creating proxy objects, which postpone wiring until some post-construction moment, and are therefore doubly magical. The problem with proxy objects is that they tend to fail if invoked from within a constructor, and when this happens it is extremely difficult to troubleshoot and fix. Most importantly, dependency injection frameworks tend to hide dependencies from view, while the goal of software architecture is precisely the opposite: to keep dependencies into view.&lt;/p&gt;
&lt;p&gt;The promise of authoritative technical software design, where the end-system is automatically generated from the design with no human intervention, requires us to stop writing custom code which wires components together in ad-hoc ways, and to replace it with a universally applicable, fully automated mechanism for assembling a system. In order for this mechanism to be fully automated, it must be fully standardized. If we were to try to standardize system assembly while allowing call cycles, we might for a moment imagine that we could accomplish our goal with a three-phase approach:&lt;/p&gt;
&lt;p&gt;(Note: I am not actually recommending this! It will not work!)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Construction:&lt;/strong&gt; All components are instantiated in an unconnected state.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wiring:&lt;/strong&gt; Now that all components exist, each component receives its dependencies.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Showtime:&lt;/strong&gt; A special event is broadcast to all components, letting them know that wiring is complete, so they can now perform their
initialization and start performing their duties.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This three-phase approach imposes a number of bureaucratic requirements on each component:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Each component must support some means of receiving references to its dependencies after construction. This constitutes incidental complexity.&lt;/li&gt;
&lt;li&gt;Each component must support some means of receiving the showtime event, so that it can perform the initialization that it would have otherwise performed in its constructor. This also constitutes incidental complexity.&lt;/li&gt;
&lt;li&gt;The requirement for components to be able to receive their dependencies after construction and to respond to the &amp;quot;showtime&amp;quot; event necessitates the introduction of some &lt;code&gt;IComponent&lt;/code&gt; interface, which must be implemented by all components. This ties all components to the framework which defines &lt;code&gt;IComponent&lt;/code&gt; and knows what to do with it.&lt;/li&gt;
&lt;li&gt;The member fields in which a component stores the references to its dependencies are initialized after construction, and therefore must be
declared as mutable, even though in principle they ought to be immutable. Similarly, the initialization performed during the showtime event often generates information that needs to be stored in member fields for later use. These member fields are also initialized after construction, so they must also be declared as mutable, even though in principle many of them ought to be immutable. Thus, any notion of immutability goes out the window. Many components might still be &lt;em&gt;effectively immutable&lt;/em&gt;, but all of them are very mutable as far as any code analysis tool can tell.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Most importantly, the three-phase approach does not solve the chicken-and-egg problem that we mentioned earlier, it only postpones it in time: When an event is triggered, the order in which event handlers are invoked is undefined. This means that during the processing of the showtime event a component may attempt to invoke another component which has not yet received the event, and therefore has not yet performed its initialization.&lt;/p&gt;
&lt;p&gt;Even if we were to further complicate things by introducing some additional mechanism that would give programmers control over the order in which components process the showtime event, the problem still remains: The presence of cycles in the call graph always leaves open the possibility that some components will be invoked before they have been initialized. It should by now be evident that cyclic call graphs are highly problematic, and that if they are to be allowed then there is no way to standardize system assembly. It remains to be shown whether call cycles can be systematically avoided or eliminated, and thus disallowed.&lt;/p&gt;
&lt;h3 id="solving-the-trivial-case"&gt;Solving the trivial case
&lt;/h3&gt;&lt;p&gt;If our goal is to eliminate the cycle in the call graph of the earlier example with the temperature sensor and the temperature indicator, we can trivially accomplish it by applying the &lt;a class="external"
href="https://en.wikipedia.org/wiki/Observer_pattern" target="_blank"
&gt;Observer Pattern&lt;/a&gt;, as shown in the following figure:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic2.png"
width="1861"
height="587"
srcset="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic2_hu_47aa25ae2d1ea891.png 480w, https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic2_hu_1fd4268ef71dec79.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="317"
data-flex-basis="760px"
&gt;
&lt;/p&gt;
&lt;p&gt;Note that the sensor does not invoke the indicator anymore; instead, the indicator invokes the sensor not only to read the current temperature but also to register an observer for temperature change notifications. The fact that the sensor will then be invoking that observer is an implementation detail which does not affect the topology of the design; thus, this design is free of cycles.&lt;/p&gt;
&lt;p&gt;Practically, the use of the observer pattern means that the sensor cannot invoke the indicator before the indicator has registered its observable, and this in turn means that the indicator can never be invoked before its initialization is complete.&lt;/p&gt;
&lt;p&gt;By eliminating the call cycle between the sensor and the indicator, we end up with a system that has a specific, computable order of initialization which is guaranteed to be free of problems: the sensor does not depend on the indicator anymore, so it can always be constructed first. The indicator, which depends on the sensor, can always be constructed after the sensor, so it can receive its dependencies as constructor parameters.&lt;/p&gt;
&lt;p&gt;As a result, each component can store all of its dependencies in immutable member variables. The only interface that needs to be stored in a mutable member variable is the callback that the observable receives from the observer, and this is in line with the nature of the observer pattern, where registration and de-registration of callbacks necessarily involves mutation.&lt;/p&gt;
&lt;p&gt;Pins of type &lt;code&gt;Observable&amp;amp;lt;T&amp;amp;gt;&lt;/code&gt; are bound to occur so often in software designs, that they warrant some special notation in order to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simplify their representation.&lt;/li&gt;
&lt;li&gt;Make them more conspicuous.&lt;/li&gt;
&lt;li&gt;Save space in the diagram.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following figure shows an example of what this notation could look like:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic3.png"
width="1860"
height="590"
srcset="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic3_hu_720b9cdf7430d0df.png 480w, https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic3_hu_3aca30d589c5dd57.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="315"
data-flex-basis="756px"
&gt;
&lt;/p&gt;
&lt;p&gt;In the above diagram, the following changes have been made to pins of type &lt;code&gt;Observable&amp;amp;lt;T&amp;amp;gt;&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The generics notation (&lt;code&gt;Observable&amp;amp;lt;T&amp;amp;gt;&lt;/code&gt;) has been replaced with tilde notation (&lt;code&gt;~T&lt;/code&gt;). The tilde indicates that the type of the pin is not really of type &lt;code&gt;T&lt;/code&gt;, it is of type &lt;code&gt;Observable&amp;amp;lt;T&amp;amp;gt;&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The arrows of the observable pins have been replaced with slightly larger circles containing slightly smaller arrows pointing in the opposite direction.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The encircled arrows are not pointing from the output to the input as normal arrows do; instead, the encircled arrows are showing the direction of callback invocations, so they are pointing from the input to the output. Essentially, a circle signifies inversion of the direction of invocations, so an encircled arrow corresponds to a normal arrow of the opposite direction.&lt;/p&gt;
&lt;p&gt;If the callback interface does not contain any methods that return information, (as the case is with all notification interfaces,) the above design can be improved even more.&lt;/p&gt;
&lt;p&gt;First, note that the refactoring of an input-output pair to an observer-output-observable-input pair results in components that violate the &lt;a class="external"
href="https://en.wikipedia.org/wiki/Single_responsibility_principle" target="_blank"
&gt;&lt;strong&gt;Single Responsibility Principle&lt;/strong&gt; (&lt;strong&gt;SRP&lt;/strong&gt;)&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Instead of simply exposing a &lt;em&gt;&lt;strong&gt;Changed&lt;/strong&gt;&lt;/em&gt; output, the sensor now has to implement the functionality of an event manager, so as to offer the same notification as an observable input.&lt;/li&gt;
&lt;li&gt;Similarly, instead of simply exposing a &lt;em&gt;&lt;strong&gt;Refresh&lt;/strong&gt;&lt;/em&gt; input, the indicator now has to contain a few more lines of code to register a callback in order to receive the same notification as an observer.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The above may not represent a lot of work, but it is nonetheless a refactoring which must be applied to the code in order to support the needs of the design; however, in a different design, the observer pattern might be unnecessary, so why should the components be hard-coded to support it?&lt;/p&gt;
&lt;p&gt;To solve this problem, let us revisit our first design, where we had a temperature sensor with a simple &lt;em&gt;&lt;strong&gt;Changed&lt;/strong&gt;&lt;/em&gt; output and a temperature indicator with a simple &lt;em&gt;&lt;strong&gt;Refresh&lt;/strong&gt;&lt;/em&gt; input, and hence a call cycle. Let us us now introduce two new components into the design, where one is a &lt;em&gt;&lt;strong&gt;General-Purpose Observable&lt;/strong&gt;&lt;/em&gt; and the other is a &lt;em&gt;&lt;strong&gt;General-Purpose Observer&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic4.png"
width="1860"
height="888"
srcset="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic4_hu_4b6ccb9e601811aa.png 480w, https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic4_hu_3226eae63daffbb9.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="209"
data-flex-basis="502px"
&gt;
&lt;/p&gt;
&lt;p&gt;The job of the observer is simply to register a callback via its &lt;em&gt;&lt;strong&gt;Registration&lt;/strong&gt;&lt;/em&gt; output during construction, and from that moment on to keep echoing each invocation of the callback to its &lt;em&gt;&lt;strong&gt;Trigger&lt;/strong&gt;&lt;/em&gt; output.&lt;/p&gt;
&lt;p&gt;The job of the observable is to receive an observer registration via its &lt;em&gt;&lt;strong&gt;Registration&lt;/strong&gt;&lt;/em&gt; input, and to keep echoing invocations coming into its &lt;em&gt;&lt;strong&gt;Trigger&lt;/strong&gt;&lt;/em&gt; input to the registered observer, if any.&lt;/p&gt;
&lt;p&gt;Note that with this arrangement, the call cycle is still eliminated, and at the same time we have managed to retain the sensor and indicator components in their original form, with no code refactoring necessary, since the refactoring has now been applied to the design. Also note that the SRP is being nicely upheld.&lt;/p&gt;
&lt;p&gt;I postulate that the combination of a general-purpose observer and a general-purpose observable will be occurring quite frequently, to the point where it might be worth simplifying their representation using some special notation. For this purpose, I propose an &lt;em&gt;&lt;strong&gt;air-gap pseudo-component&lt;/strong&gt;&lt;/em&gt;. With the use of an air-gap, the previous figure turns into the following:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic5.png"
width="1860"
height="835"
srcset="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic5_hu_684347aa7e465dfc.png 480w, https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic5_hu_c30de23a51830a7c.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="222"
data-flex-basis="534px"
&gt;
&lt;/p&gt;
&lt;p&gt;Note that the symbol for the air-gap component has been borrowed from electronics, where it stands for a capacitor. An electronic capacitor is also, in a sense, an air gap; however, the similarity is superficial, and it is only meant to serve as a mnemonic: In software, an air-gap pseudo-component does not maintain any charge, nor does it act as some kind of high-pass filter, etc.; it just allows us to pick a wire that takes part in a call cycle, and trivially make that wire break the cycle.&lt;/p&gt;
&lt;p&gt;Also note that the air-gap is not a real component, it is a pseudo-component. This means that it is simply a notation, which represents an underlying pair of actual components: a general-purpose observer, and a general-purpose observable. This is necessary because these two components will invariably need to be constructed at different times during system assembly. In the sensor-indicator example, construction would take place in the following order:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The general-purpose observable is constructed first because it does not depend on anything else.&lt;/li&gt;
&lt;li&gt;Then, the sensor is constructed, which depends on the general-purpose observable.&lt;/li&gt;
&lt;li&gt;Then, the indicator is constructed, which depends on the sensor.&lt;/li&gt;
&lt;li&gt;Finally, the general-purpose observer is constructed, which depends on both the indicator and the general-purpose observable.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, during system assembly, each air-gap pseudo-component is decomposed into an observer and an observable, so that all components can be instantiated and wired in the order dictated by their dependency graph.&lt;/p&gt;
&lt;h3 id="solving-non-trivial-cases"&gt;Solving non-trivial cases
&lt;/h3&gt;&lt;p&gt;The application of the observer pattern is a good first step in the direction of being able to express any software design acyclically; however, it does not cover all cases. Specifically, the observer pattern cannot be used under the following circumstances:&lt;/p&gt;
&lt;p&gt;The observable expects information to be returned back from the observer, and it is incapable of handling the case where no observer is registered, and therefore no results can be returned. (For example, the observable needs to invoke the observer and receive information back from the observer during the observable's construction, at which point the observer cannot possibly have registered yet.)&lt;/p&gt;
&lt;p&gt;The simple &lt;em&gt;&lt;strong&gt;Changed&lt;/strong&gt;&lt;/em&gt; notification of the temperature-sensor-and-indicator example does not fall under these circumstances because it is in the nature of notifications that they never return any information; however, in other scenarios, these circumstances can arise. Thus, it remains to be shown how call cycles can be eliminated when the observer pattern is inapplicable.&lt;/p&gt;
&lt;h3 id="strategy-fusion"&gt;Strategy: Fusion
&lt;/h3&gt;&lt;p&gt;The presence of a call cycle between components &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt; might indicate that perhaps they should not be separate components, and that we might be better off by fusing &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt; into a single component. In doing so, we remove the cycle from the topology of the design by turning it
into an implementation detail of the new component. The following figure illustrates this:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic6.png"
width="1860"
height="426"
srcset="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic6_hu_b070ad42c31ba5da.png 480w, https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic6_hu_b38442f141ba6f20.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="436"
data-flex-basis="1047px"
&gt;
&lt;/p&gt;
&lt;p&gt;Clearly, the left diagram contains a cycle, whereas the right diagram does not.&lt;/p&gt;
&lt;p&gt;Needless to say, this strategy is only marginally useful, and it should not be considered unless all else fails, because the goal of software architecture is to distribute functionality into as many components as possible, so that each component can be as simple as possible, instead of conglomerating functionality into monolithic components. The fusion strategy is mentioned here only for the sake of completeness.&lt;/p&gt;
&lt;h3 id="strategy-plain-fission"&gt;Strategy: Plain Fission
&lt;/h3&gt;&lt;p&gt;The presence of a call cycle between components &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt; might indicate that at least one of the two components violates the &lt;a class="external"
href="https://en.wikipedia.org/wiki/Single_responsibility_principle" target="_blank"
&gt;&lt;strong&gt;Single Responsibility Principle&lt;/strong&gt; (&lt;strong&gt;SRP&lt;/strong&gt;)&lt;/a&gt;. In this case, one of the responsibilities can be extracted into a separate component which only exposes inputs, thus breaking the cycle, as the following figure illustrates:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic7.png"
width="1861"
height="722"
srcset="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic7_hu_f6ae600ec9ba0180.png 480w, https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic7_hu_f26f68362306158c.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="257"
data-flex-basis="618px"
&gt;
&lt;/p&gt;
&lt;p&gt;In this diagram, component &lt;strong&gt;A&lt;/strong&gt; has been split into &lt;strong&gt;A1&lt;/strong&gt; and &lt;strong&gt;A2&lt;/strong&gt;. Both &lt;strong&gt;A1&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt; invoke &lt;strong&gt;A2&lt;/strong&gt;, but &lt;strong&gt;A2&lt;/strong&gt; does not invoke anything, so there is no cycle.&lt;/p&gt;
&lt;p&gt;This can happen, for example, if component &lt;strong&gt;A&lt;/strong&gt; contains both a data model and some logic acting upon the data model. If &lt;strong&gt;A&lt;/strong&gt; is incapable of fully encapsulating the data model, it may have to expose not only an output for interacting with the rest of the system, but also an input for the rest of the system to interact with the data model. With the fission refactoring, component &lt;strong&gt;A&lt;/strong&gt; has been split into one component for the logic (&lt;strong&gt;A1&lt;/strong&gt;) and a separate component for the data model (&lt;strong&gt;A2&lt;/strong&gt;).&lt;/p&gt;
&lt;h3 id="strategy-observable-fission"&gt;Strategy: Observable Fission
&lt;/h3&gt;&lt;p&gt;The astute reader might notice that in the plain fission example, components &lt;strong&gt;A1&lt;/strong&gt; and &lt;strong&gt;A2&lt;/strong&gt; are not exactly equivalent to component &lt;strong&gt;A&lt;/strong&gt;: In the original diagram &lt;strong&gt;A&lt;/strong&gt; used to be able to take notice of incoming calls from &lt;strong&gt;B&lt;/strong&gt; intended for the data model, and could therefore take action in response to those calls, whereas in the refactored diagram &lt;strong&gt;A1&lt;/strong&gt; is oblivious to any calls that &lt;strong&gt;B&lt;/strong&gt; makes to &lt;strong&gt;A2&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;If &lt;strong&gt;A1&lt;/strong&gt; needs to be aware of such calls, this can be very easily accomplished by having &lt;strong&gt;A2&lt;/strong&gt; issue change notifications, and wiring these notifications back to &lt;strong&gt;A1&lt;/strong&gt;. This new wire does not introduce a call cycle, because as we have already shown when describing the trivial case, notifications can always be air-gapped.&lt;/p&gt;
&lt;p&gt;The following figure illustrates the application of the observable fission strategy:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic8.png"
width="1861"
height="722"
srcset="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic8_hu_c298426430891ac6.png 480w, https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/images/acyclic8_hu_701e420d6dc70bd6.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="257"
data-flex-basis="618px"
&gt;
&lt;/p&gt;
&lt;h4 id="conclusion"&gt;Conclusion
&lt;/h4&gt;&lt;p&gt;We have shown that cyclic call graphs prevent the standardization, and therefore the automation, of system assembly.&lt;/p&gt;
&lt;p&gt;We have discussed refactoring strategies for systematically eliminating call cycles, including a universally applicable technique for trivially eliminating the most common call cycles.&lt;/p&gt;
&lt;p&gt;We conclude that since call cycles can be avoided or eliminated, they can be comprehensively disallowed, thus paving the way for the automation of system assembly.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;TO DO:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Change the cover image to make the cycle look nicer.&lt;/li&gt;
&lt;li&gt;Show a diagram where the observable and observer interfaces are fully spelled out before showing the diagram in which the notation has been simplified.&lt;/li&gt;
&lt;li&gt;Redo the placement and wiring of A1 and A2 to more clearly show that they used to be A.&lt;/li&gt;
&lt;li&gt;Mention that the air-gap pseudo-component does not need to incorporate an actual multicast observable component; a unicast observable will suffice.&lt;/li&gt;
&lt;li&gt;Provide a better example of a situation where an air-gap cannot be used.&lt;/li&gt;
&lt;li&gt;Most importantly: Introduce a distinction between &amp;quot;early&amp;quot; outputs, which may be invoked during construction, and &amp;quot;late&amp;quot; outputs, which may only be invoked after construction. Show that late wires can be air-gapped too, even if they are two-way.&lt;/li&gt;
&lt;li&gt;Use a polarized capacitor symbol for one-way interface air-gaps and a non-polarized capacitor symbol for two-way interface air-gaps.&lt;/li&gt;
&lt;li&gt;Possibly introduce diode notation for one-way pins.&lt;/li&gt;
&lt;li&gt;Possibly introduce bar-plus-arrow notation for early pins.&lt;/li&gt;
&lt;li&gt;Possibly introduce not-gate notation for inverted pins.&lt;/li&gt;
&lt;li&gt;Possibly represent an observatory as a not-gate and an observer as the opposite (a triangle with a bubble on its flat side.)&lt;/li&gt;
&lt;li&gt;Note the following:
&lt;ul&gt;
&lt;li&gt;One-way interfaces: can always be inverted.&lt;/li&gt;
&lt;li&gt;Two-way interfaces: can only be inverted if late, and one-to-one.&lt;/li&gt;
&lt;li&gt;Normal two-way interfaces: multiple outputs can connect to one input.&lt;/li&gt;
&lt;li&gt;Normal one-way interfaces: multiple outputs can connect to multiple inputs. (With the help of a distributor.)&lt;/li&gt;
&lt;li&gt;Inverted one-way interfaces: one output can connect to multiple inputs.&lt;/li&gt;
&lt;li&gt;Inverted two-way interfaces: one output connects to one input. (And must be late.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Towards Authoritative Software Design</title><link>https://blog2.michael.gr/post/2023-12-09-authoritative-technical-design/</link><pubDate>Sat, 09 Dec 2023 19:16:05 +0000</pubDate><guid>https://blog2.michael.gr/post/2023-12-09-authoritative-technical-design/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2023-12-09-authoritative-technical-design/media/blueprint.jpg"
width="5000"
height="2740"
srcset="https://blog2.michael.gr/post/2023-12-09-authoritative-technical-design/media/blueprint_hu_97e76780ef2663b9.jpg 480w, https://blog2.michael.gr/post/2023-12-09-authoritative-technical-design/media/blueprint_hu_44b86b65f3bab1f7.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="182"
data-flex-basis="437px"
&gt;
&lt;/p&gt;
&lt;h3 id="abstract"&gt;Abstract
&lt;/h3&gt;&lt;p&gt;This paper examines the long-standing need within the software engineering discipline for technical design that is &lt;em&gt;&lt;strong&gt;authoritative&lt;/strong&gt;&lt;/em&gt;. A design process is authoritative if there exist technical means of materializing the design document as a working product, thus guaranteeing that the end result is indeed as described by the design. We notice the scarcity and inadequacy of existing solutions for software design, we look at solutions in other engineering disciplines, and we conclude with realizations on what it would take to come up with a solution that works for software.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id="prior-art"&gt;Prior art
&lt;/h3&gt;&lt;p&gt;Through the decades, plenty of tools and methodologies have been developed with the aim of aiding the software design process. A common pattern among them is that they try to make some aspect of development more visual rather than textual. They fall into one of the following categories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Visual Implementation tools (For example: &lt;a class="external"
href="https://en.wikipedia.org/wiki/Visual_programming_language" target="_blank"
&gt;&lt;em&gt;Visual Programming Languages&lt;/em&gt;&lt;/a&gt; like &lt;em&gt;Snap!&lt;/em&gt;, &lt;em&gt;Scratch&lt;/em&gt;, &lt;em&gt;EduBlocks&lt;/em&gt;, &lt;em&gt;Blockly&lt;/em&gt;, etc.,) - They are indeed visual, and they do indeed produce runnable software, but their structure and level of detail is identical to the structure and level of detail of program code in the form of text, so they express implementations rather than designs.&lt;/li&gt;
&lt;li&gt;Visualization tools (For example: class diagrams, dependency diagrams, call trees, etc.) - They are restricted to the visualization, exploration, and documentation, but not the editing of existing software, nor the design of new software. As such, they are reverse engineering tools, not design tools.&lt;/li&gt;
&lt;li&gt;Niche tools (For example: &lt;a class="external"
href="https://en.wikipedia.org/wiki/Web_Services_Description_Language" target="_blank"
&gt;&lt;em&gt;Web Services Description Language (WSDL)&lt;/em&gt;&lt;/a&gt;, &lt;a class="external"
href="https://en.wikipedia.org/wiki/Business_Process_Execution_Language" target="_blank"
&gt;*Business Process Execution Language (BPEL)&lt;/a&gt;, etc.) - They are exclusively focused on specific domains such as web services, business processes, etc., and cannot be used for software design at large.&lt;/li&gt;
&lt;li&gt;&amp;quot;Look ma, no code&amp;quot; tools (For example: &lt;a class="external"
href="https://en.wikipedia.org/wiki/Rapid_application_development" target="_blank"
&gt;&lt;em&gt;Rapid Application Development (RAD) tools&lt;/em&gt;&lt;/a&gt;, &lt;a class="external"
href="https://en.wikipedia.org/wiki/No-code_development_platform" target="_blank"
&gt;&lt;em&gt;No-Code Development Platforms (NCDPs)&lt;/em&gt;&lt;/a&gt;, and &lt;a class="external"
href="https://en.wikipedia.org/wiki/Low-code_development_platform" target="_blank"
&gt;&lt;em&gt;Low-Code Development Platforms (LCDPs)&lt;/em&gt;&lt;/a&gt;) - They impose limitations on what can be done; they impose the use of a massive vendor-specific platform; they do not scale; they are aimed at non-programmers, allowing easy creation of simple user-interface-centric applications to quickly (and usually haphazardly) meet specific narrow business needs.&lt;/li&gt;
&lt;li&gt;Modelling tools (For example: &lt;a class="external"
href="https://en.wikipedia.org/wiki/Microsoft_Visio" target="_blank"
&gt;&lt;em&gt;Microsoft Visio&lt;/em&gt;&lt;/a&gt;, &lt;a class="external"
href="https://en.wikipedia.org/wiki/Modeling_language" target="_blank"
&gt;&lt;em&gt;Modelling Languages&lt;/em&gt;&lt;/a&gt; such as &lt;a class="external"
href="https://en.wikipedia.org/wiki/Unified_Modeling_Language" target="_blank"
&gt;&lt;em&gt;Unified Modeling Language (UML)&lt;/em&gt;&lt;/a&gt;, The &lt;a class="external"
href="https://en.wikipedia.org/wiki/C4_model" target="_blank"
&gt;&lt;em&gt;C4 model&lt;/em&gt;&lt;/a&gt;, etc.) - They are restricted to modelling, so they produce designs that bear no necessary relationship to reality. They aim to constrain what is supposed to be included in a design, but these constrains exist only in theory, because they are not enforced by any technical means.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For a more detailed look at prior art, see &lt;a
href="https://blog2.michael.gr/post/2025-08-the-state-of-affairs-in-computer-aided/"
&gt;The state of affairs in computer-aided software design&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Of all the technologies listed above, only modelling tools can legitimately be said to be of any potential usefulness in the software design process at large.&lt;/p&gt;
&lt;h3 id="the-unsuitability-of-modelling"&gt;The unsuitability of modelling
&lt;/h3&gt;&lt;p&gt;Modelling tools allow designs that bear no relationship to reality: they are not informed via any technical means about the actual components available for incorporation in a design, nor about valid ways of interconnecting them. Consequently, modelling tools are nothing more than fancy whiteboards: they cannot guarantee, via any technical means, the feasibility of a design. (This is so by definition; otherwise, it would not be modelling, it would be engineering.)&lt;/p&gt;
&lt;p&gt;Essentially, modelling tools are &lt;em&gt;&lt;strong&gt;non-authoritative&lt;/strong&gt;&lt;/em&gt;: no matter how sophisticated the model is, the authoritative source of truth for the structure of the system remains the source code, not the model.&lt;/p&gt;
&lt;p&gt;The source code should ideally constitute a faithful implementation of the model, but there are no technological safeguards to guarantee that it does, and as a matter of fact it usually cannot, because the model is almost never feasible as designed to begin with.&lt;/p&gt;
&lt;p&gt;For these reasons, modelling is of severely limited value, and programmers largely regard it as loathsome double book-keeping.&lt;/p&gt;
&lt;p&gt;For a list of ways in which modelling as a means of design fails the software engineering discipline, please see &lt;a
href="https://blog2.michael.gr/post/2025-08-the-perils-of-whiteboards/"
&gt;The perils of whiteboards&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="other-engineering-disciplines"&gt;Other engineering disciplines
&lt;/h3&gt;&lt;p&gt;In long-established engineering disciplines such as mechanical, electrical, civil, etc., for several decades now, design work has been facilitated by &lt;a class="external"
href="https://en.wikipedia.org/wiki/Computer-aided_design" target="_blank"
&gt;Computer-Aided Design (CAD)&lt;/a&gt; tools and &lt;a class="external"
href="https://en.wikipedia.org/wiki/Computer-aided_engineering" target="_blank"
&gt;&lt;em&gt;Computer-Aided Engineering (CAE)&lt;/em&gt;&lt;/a&gt; tools.&lt;/p&gt;
&lt;p&gt;Mechanical engineers use CAD tools to create documents describing complicated three-dimensional structures with detailed information about materials, dimensions, and tolerances. The tools perform various forms of analysis to verify the validity and feasibility of the design. Based on the results, the engineers can edit the design to optimize it, and repeat the analysis as necessary. Eventually, the design document is sent to a shop where &lt;a class="external"
href="https://en.wikipedia.org/wiki/Computer_numerical_control" target="_blank"
&gt;&lt;em&gt;CNC machining&lt;/em&gt;&lt;/a&gt; or &lt;a class="external"
href="https://en.wikipedia.org/wiki/3D_printing" target="_blank"
&gt;&lt;em&gt;3D-printing&lt;/em&gt;&lt;/a&gt; is used to create the parts with minimal human intervention.&lt;/p&gt;
&lt;p&gt;In electronic engineering, which is the discipline from which most parallels can be drawn to software engineering, virtually all design work since the 1980s is being done using &lt;a class="external"
href="https://en.wikipedia.org/wiki/Electronic_design_automation" target="_blank"
&gt;&lt;em&gt;Electronic Design Automation (EDA) / Electronic Computer-Aided Design (ECAD) tools&lt;/em&gt;&lt;/a&gt;. These tools have revolutionized electronic design by using a standardized notation to not only describe, analyze, and optimize products, but also to manufacture them.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Electronic schematic diagrams use a standard notation which is understood by all electronic engineers. A new hire begins their first day at work by studying the schematics, and before the end of the day they are often able to pick up the soldering iron and start doing productive work. Contrast this with software engineering, where a new hire usually cannot be productive before spending weeks studying source code and documentation, and having numerous knowledge transfer meetings with senior engineers who know the system.&lt;/li&gt;
&lt;li&gt;Most importantly, ECAD tools bridge the gap from the physical world to the design, and from the design back to the physical world. The tools have libraries of electronic components available for inclusion in a design, and electronic manufacturing has long ago advanced to the point where an electronic design document can be turned into a functioning circuit board with nearly zero human intervention. Thus, electronic design documents today are &lt;em&gt;&lt;strong&gt;authoritative&lt;/strong&gt;&lt;/em&gt;: the end products are accurately described by their designs.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="the-problem-with-software"&gt;The problem with software
&lt;/h3&gt;&lt;p&gt;Unfortunately, thus far, the software engineering discipline has been following a very different path from other engineering disciplines: technical software design documents are scarce, and &lt;em&gt;authoritative&lt;/em&gt; technical software design documents are completely non-existent.&lt;/p&gt;
&lt;p&gt;This situation has been allowed to go on for so long, partly because in software we already have a certain other kind of document which is authoritative, and this is the source code. However, source code is an implementation, or at best a detailed technical description, but not a technical design. To say that the technical design of a software system is a listing of the lines of source code that make up that software system is equivalent to saying that the technical design of the Great Wall of China is a list of all the bricks that make up the Great Wall of China.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;img src="https://blog2.michael.gr/post/2023-12-09-authoritative-technical-design/media/the-great-wall-by-hao-wei.jpg"
width="4606"
height="3071"
srcset="https://blog2.michael.gr/post/2023-12-09-authoritative-technical-design/media/the-great-wall-by-hao-wei_hu_d1eba4a46b4d1881.jpg 480w, https://blog2.michael.gr/post/2023-12-09-authoritative-technical-design/media/the-great-wall-by-hao-wei_hu_4d46a82415ff1bad.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="149"
data-flex-basis="359px"
&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;(A tiny part of) the Great Wall of China &lt;a class="external"
href="https://commons.wikimedia.org/w/index.php?curid=351725" target="_blank"
&gt;by Hao Wei, CC BY 2.0&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;A technical design is supposed to list operative components, and to show how they are interconnected, but not to delve past the level of detail of the component. Unfortunately, we do not have that for software, at least not in an authoritative form.&lt;/p&gt;
&lt;p&gt;It is a great paradox of our times that the software engineering discipline is bereft of authoritative design tools, when such tools are the bread and butter of the long-established engineering disciplines.&lt;/p&gt;
&lt;p&gt;In lieu of authoritative tools, software design today is practiced using conventional, non-authoritative means, such as box-and-arrow drawing applications, which, as explained earlier, are only capable of modelling, and therefore amount to nothing more than fancy whiteboards.&lt;/p&gt;
&lt;p&gt;The end-result of all this is the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Software systems do not match their designs.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Even if the technical design happens to describe a software system that could actually be built as described, there are no technological safeguards to guarantee that it will: the software engineers and the operations engineers are free to build and deploy a system that deviates from the design, and neither the architects, nor the management, have any way of knowing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Software systems diverge from their designs over time.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Even if the deployed software system initially matches its design, the system is bound to evolve. The design should ideally evolve in tandem, but it rarely does, again because there are no technological safeguards to enforce this: the engineers are free to modify and redeploy the system without updating the design document, and in fact they usually do, because it saves them from double book-keeping. Thus, over time, the design bears less and less relationship to reality.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If, due to the above reasons, you suspect that your technical design document is counterfactual, and you would like to know exactly what it is that you have actually deployed and running out there, you have to begin by asking questions to the software engineers and the operations engineers.&lt;/p&gt;
&lt;p&gt;In order to answer your questions, the engineers will in turn have to examine source code, version control histories, build scripts, configuration files, server provisioning scripts, and launch scripts, because the truth is scattered in all those places. In some cases they might even have to try and remember specific commands that were once typed on a terminal to bring the system to life.&lt;/p&gt;
&lt;p&gt;If this sounds a bit like it is held together by shoestrings, it is because it is in fact held together by shoestrings.&lt;/p&gt;
&lt;p&gt;Thus, the information that you will receive will hardly be usable, and even if you manage to collect it all, make sense out of it, and update the design document with it, by the time you are done, the deployed system may have already changed, which means that your design document is already obsolete.&lt;/p&gt;
&lt;p&gt;As a result, it is generally impossible at any given moment to know the actual technical design of any non-trivial software system in existence.&lt;/p&gt;
&lt;p&gt;This is a very sorry state of affairs for the entire software industry to be in.&lt;/p&gt;
&lt;h3 id="towards-a-solution"&gt;Towards a solution
&lt;/h3&gt;&lt;p&gt;If we consider all the previously listed problems that plague software design as conventionally practiced, and if we look at how the corresponding problems have been solved in long-established engineering disciplines, we inescapably arrive at the following realization:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;The technical design of a system can only be said to accurately describe that system if there exist technical means of having the system automatically created from the design.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In order to automatically create a system from its design, the design must be semantically valid. This brings us to a second realization:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;The semantic validity of a technical design can only be guaranteed if there exist technical means of informing the design with components available for incorporation and restricting the design to only valid ways of interconnecting them.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The above statements define a design process as &lt;em&gt;&lt;strong&gt;authoritative&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;An authoritative software design document is an &lt;strong&gt;essential engineering instrument&lt;/strong&gt; instead of an abstract work of art:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The design document contains all the information necessary for provisioning target environments with software components, instantiating the components, and wiring them together; this information not only need not, but in fact must not be encoded anywhere else in the source code; this eliminates double book-keeping, which is considered by developers as another layer of red tape which is preventing them from getting things done, and is the complaint most often heard from developers about conventional software design.&lt;/li&gt;
&lt;li&gt;The design document is the only means through which the system can be re-deployed after making a change to either the code, or the design, or both; this guarantees that the deployed system will always be exactly as described by the design, so there is no possibility of the design ever becoming outdated, which is the complaint most often heard from architects about programmers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Any attempt to introduce authoritative design in the software engineering discipline would necessarily have to borrow concepts from the electronic engineering discipline. This means that the solution must lie within the realm of &lt;a class="external"
href="https://en.wikipedia.org/wiki/Component-based_software_engineering" target="_blank"
&gt;&lt;em&gt;Component-Based Software Engineering (CBSE)&lt;/em&gt;&lt;/a&gt;, where systems consist of well-defined components, connectable via specific interfaces, using well-defined connectivity rules.&lt;/p&gt;
&lt;p&gt;What we need is a toolset that implements such a paradigm for software. The toolset must have knowledge of available components, knowledge of the interfaces exposed by each component, and rules specifying valid ways of connecting those interfaces. The toolset must then be capable of materializing the design into a running software system.&lt;/p&gt;
&lt;p&gt;The toolset must not repeat the mistakes and suffer from the drawbacks of previous attempts at component-based software engineering. Thus, the toolset must meet the following goals:&lt;/p&gt;
&lt;h4 id="facilitate-any-programming-language"&gt;Facilitate any programming language.
&lt;/h4&gt;&lt;p&gt;By this we do not mean that it should be possible to freely mix C++ components with Java components; what we mean is that it should be possible to express in one place a C++ subsystem containing C++ components interconnected via C++ interfaces, and in another place a Java subsystem containing Java components interconnected via Java interfaces, and at a higher scope to have each of these subsystems represented as an individual opaque component, where connections between the two components are made via language-agnostic interfaces (e.g. REST) or cross-language interfaces (e.g. JNI, JNA, etc.)&lt;/p&gt;
&lt;h4 id="facilitate-any-level-of-scale-from-embedded-systems-to-network-clouds"&gt;Facilitate any level of scale, from embedded systems to network clouds.
&lt;/h4&gt;&lt;p&gt;This means that the nature of a component and the nature of an interface must not be restricted, so that they can be realized in different ways at different levels of scale. For example, at the embedded/C++ level of scale, a component might be defined as a C++ class exposing C++ interfaces, whereas at the internet level of scale a component is likely to be defined as a (physical or virtualized) network host exposing TCP interfaces.&lt;/p&gt;
&lt;h4 id="guarantee-type-safety-at-any-scale"&gt;Guarantee type-safety at any scale.
&lt;/h4&gt;&lt;p&gt;Type safety can be carried across different levels of scale by means of parametric polymorphism (generic interfaces.) For example, a type-safe interface between a client and a server in a network can be described with a construct like Tcp&amp;lt;Rest&amp;lt;AcmeShopping&amp;gt;&amp;gt; which stands for a TCP connection through which we are exchanging REST transactions according to a schema which corresponds to some programmatic interface called &amp;quot;AcmeShopping&amp;quot;.&lt;/p&gt;
&lt;h4 id="require-minimal-extra-baggage"&gt;Require minimal extra baggage.
&lt;/h4&gt;&lt;p&gt;Components should not be required to include a lot of extra overhead to facilitate their inclusion in a design. Especially at the embedded level, components should ideally include zero overhead.&lt;/p&gt;
&lt;p&gt;This means that a C++ class which accepts as constructor parameters interfaces to invoke and exposes interfaces for invocation by virtue of simply implementing them should ideally be usable in s design as-is.&lt;/p&gt;
&lt;p&gt;The extra functionality necessary for representing the component during design-time, provisioning a target environment with it, instantiating it, and wiring it should be provided by a separate companion module, which acts as a plugin to the design toolset, and exists only during design-time and deployment-time, but not during run-time**.**&lt;/p&gt;
&lt;h4 id="support-automatic-deployment"&gt;Support automatic deployment.
&lt;/h4&gt;&lt;p&gt;The toolset must be capable of deploying a software system of arbitrary complexity to a production environment of arbitrary complexity, and it must be capable of doing so with no human intervention other than the pressing of a &amp;quot;Deploy&amp;quot; button. To this end, toolset must support components representing various different kinds of environments such as network hosts, isolated devices, operating systems, virtual machines, etc. and each of these components must be configurable with everything necessary in order to provision a certain environment with the corresponding part of the design.&lt;/p&gt;
&lt;h4 id="support-iterative-development"&gt;Support iterative development.
&lt;/h4&gt;&lt;p&gt;Once a system has been designed, coded, and deployed, it is a fact of life that it will keep evolving. The design toolset must support re-deploying after modifying the code, or the design, or both.&lt;/p&gt;
&lt;h4 id="support-automatic-wiring"&gt;Support automatic wiring.
&lt;/h4&gt;&lt;p&gt;Once an execution environment has been provisioned with software components, the components must be wired together in order to start running. Traditionally, the wiring of freshly instantiated components is done by carefully hand-crafted code, to account for circular dependency issues between components. If we are to have fully automated deployment, the wiring cannot be done by hand-crafted code anymore; it must be automated, therefore it must be standardized. This in turn means that certain connectivity rules are necessary in order to guarantee that software designs do not suffer from circular dependency issues that would require custom handling. For more on this, see &lt;a
href="https://blog2.michael.gr/post/2023-12-27-call-graph-acyclicity/"
&gt;Call Graph Acyclicity&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id="facilitate-incremental-adoption"&gt;Facilitate incremental adoption.
&lt;/h4&gt;&lt;p&gt;It should be possible to express, via an authoritative design document, the structure of a small subsystem within a larger system whose structure has not (yet) been expressed authoritatively.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In systems of medium scale and above, this may be handled by making the core deployment and wiring engine of the toolset available on demand, during runtime, to quickly materialize a small subsystem within the larger system.&lt;/li&gt;
&lt;li&gt;In embedded-scale systems, it should be possible to utilize code generation to do the instantiation and the wiring, so as to avoid having the core engine present in the target environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="utilize-a-text-based-document-format"&gt;Utilize a text-based document format.
&lt;/h4&gt;&lt;p&gt;In software we make heavy use of version control systems, which work best with text files, so the design documents must be text-based. The text format would essentially be a system description language, so it must be programmer-friendly in order to facilitate editing using a text editor or an IDE. A graphical design tool would read text of this language into data structures, allow the visual editing of such data structures, and save them back as text.&lt;/p&gt;
&lt;h4 id="facilitate-dynamic-software-systems"&gt;Facilitate dynamic software systems.
&lt;/h4&gt;&lt;p&gt;Every non-trivial system has the ability to vary, at runtime, the number of instances of some components in response to changing computation needs, and to choose to instantiate different types of components to handle different needs. Therefore, a toolset aiming to be capable of expressing any kind of design must be capable of expressing, at a minimum, the following dynamic constructs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Plurality: Multiple instantiation of a certain component, where the number of instances is decided at runtime.&lt;/li&gt;
&lt;li&gt;Polymorphism: Fulfilling a certain role by instantiating one of several different types of components capable of fulfilling that role, where the choice of which component type to instantiate is made at runtime.&lt;/li&gt;
&lt;li&gt;Polymorphic plurality: A combination of the previous two: A runtime-variable array of components where each component can be of a different, runtime-decidable type.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="facilitate-multiple-alternative-configurations-layers"&gt;Facilitate multiple alternative configurations (layers).
&lt;/h4&gt;&lt;p&gt;In virtually every software development endeavor there is a core system design which is materialized in a number of variations to cover different needs. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Debug vs. release&lt;/li&gt;
&lt;li&gt;Testing vs. production&lt;/li&gt;
&lt;li&gt;With instrumentation or without&lt;/li&gt;
&lt;li&gt;With hardware emulation vs. a targeting the actual hardware&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The bulk of the components and the wires of the design exist in all configurations, but some configurations prescribe additional components and slightly different wiring.&lt;/p&gt;
&lt;p&gt;Therefore, the toolset must facilitate the expression of alternative configurations so that each configuration can be defined authoritatively.&lt;/p&gt;
&lt;p&gt;To facilitate this, the toolset must support design layers, similar to drawing layers found in drawing applications like Photoshop. Note that design layers are unrelated to the architectural layers found in layered architectures, although it is possible that people will figure out ways to represent architectural layers using design layers.&lt;/p&gt;
&lt;p&gt;The details of how layers are going to work in order to support configurations are to be decided, but one preliminary idea is to have one or more base layers where the bulk of the components are laid out, and a few mutually exclusive configuration layers on top of them. A configuration layer combines with one or more base layers to form a complete system, and is deployable, whereas base layers do not describe complete systems and are therefore not deployable by themselves.&lt;/p&gt;
&lt;h4 id="be-extensible"&gt;Be extensible.
&lt;/h4&gt;&lt;p&gt;The design document must support the inclusion of arbitrary metadata to be used by various tools, which can be either separate applications, or plugins to the graphical editor. Examples of metadata:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Keeping track of documentation of interest to different stakeholders, for example &lt;a class="external"
href="https://en.wikipedia.org/wiki/Architectural_decision" target="_blank"
&gt;Architectural Decisions&lt;/a&gt; &lt;sup id="fnref:1"&gt;&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref"&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Keeping track of &lt;em&gt;Team Architecture&lt;/em&gt;, i.e. which development teams are responsible for building and/or maintaining different parts of the design. &lt;sup id="fnref:2"&gt;&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Recording various technical characteristics, such as data flow. (Every interface can be associated with a direction of data flow with respect to the direction of invocation: when invoked, some interfaces only pull data, some only push data, and some perform bi-directional transfer of data.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Recording, either manually or automatically, various metrics such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Technical debt estimations&lt;/li&gt;
&lt;li&gt;Threat modelling&lt;/li&gt;
&lt;li&gt;Compliance considerations and responsibilities&lt;/li&gt;
&lt;li&gt;Test code coverage results&lt;/li&gt;
&lt;li&gt;Performance statistics&lt;/li&gt;
&lt;li&gt;Frequency of change statistics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Using such metadata and plugins, the graphical editor may allow switching between views to visualize various aspects of the system overlaid on the component diagram, such as, for example, data flow instead of control flow, a heat map of technical debt, a heat map of test code coverage, a heat map of frequency of change, etc.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="be-accessible-and-attractive"&gt;Be accessible and attractive.
&lt;/h4&gt;&lt;p&gt;The extent and speed by which a new software development technology is adopted greatly depends on how accessible and attractive the technology is. To this end:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The core toolset must be free and open source software. (Profit may be made from additional, optional tools, such as a visual editor.) This also means that the toolset must be a cross-platform, installable software package rather than a cloud offering.&lt;/li&gt;
&lt;li&gt;A clear distance must be kept from unattractive technologies like UML, XML, etc.&lt;/li&gt;
&lt;li&gt;The literature around the toolset must avoid wooden language and alienating terms such as &amp;quot;enterprise architecture&amp;quot;, &amp;quot;standards committee&amp;quot;, &amp;quot;industry specifications consortium&amp;quot;, etc&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="efficiently-manage-complexity"&gt;Efficiently manage complexity.
&lt;/h4&gt;&lt;p&gt;Software designs can become formidably complicated. One of the major goals of a design methodology is to manage complexity and to reduce clutter. Therefore, the toolset must support the following constructs:&lt;/p&gt;
&lt;p&gt;Containers&lt;/p&gt;
&lt;p&gt;Some systems are so large that expressing them in a single diagram may be inconvenient to the point of being unworkable. To address this, the
toolset must facilitate hierarchical system composition by means of container components. A container encapsulates an entire separately-editable diagram and exposes some of the interfaces of the contained components as interfaces of its own. Thus, containers can be used to abstract away entire sub-designs into opaque black-boxes within greater designs. Container components moust be boundlessly nestable.&lt;/p&gt;
&lt;p&gt;Vias&lt;/p&gt;
&lt;p&gt;Large numbers of wires traveling long distances within a diagram can have a detrimental effect on the intelligibility of the diagram. For this reason, the concept of the &amp;quot;via&amp;quot; will be borrowed from electronic design. A via is a named circle into which a wire may terminate and thus vanish from view. All vias with the same name are implicitly connected without having to show the wires between them. This is especially useful for wires of interfaces representing cross-cutting concerns, which are ubiquitous, and therefore do not need to be shown everywhere.&lt;/p&gt;
&lt;p&gt;A via is strongly typed like any pin; when the first pin is wired to a via, the via implicitly takes the type of that pin. Vias are to be drawn as little circles.&lt;/p&gt;
&lt;p&gt;Ribbons&lt;/p&gt;
&lt;p&gt;Sometimes there may be multiple parallel wires that travel over long distances on a diagram. Some of them might even go in opposite directions.&lt;/p&gt;
&lt;p&gt;To reduce clutter, the toolset must make it possible to group such wires together in a ribbon. At each end of a ribbon is a connector, which breaks the ribbon into individual pins and shows the name and type of each pin, so that individual wires can be drawn from there to component pins.&lt;/p&gt;
&lt;p&gt;Ribbons and connectors are pseudo-elements, in the sense that they only exist in the design diagram and have no counterpart in code. Ribbons are to be drawn as two parallel hairlines with a slanted hash between them. The shape of connectors is to be determined, but it will probably be borrowed from electronic design. Ribbons can also be routed in and out of vias. Ribbon vias are to be slightly bigger than single-wire vias.&lt;/p&gt;
&lt;h4 id="establish-a-universal-notation"&gt;Establish a universal notation.
&lt;/h4&gt;&lt;p&gt;To ensure that every developer can easily understand a design document that they see for the first time, the toolset must standardize the notation used in software diagrams, the same way that electronic schematic diagrams follow a standard notation which is universally understood by all electronic engineers.&lt;/p&gt;
&lt;p&gt;The details are to be decided, but some preliminary ideas about styling and conventions are as follows:&lt;/p&gt;
&lt;p&gt;(Need to show an illustration here.)&lt;/p&gt;
&lt;p&gt;Diagrams are drawn using nothing but monochrome lines. (Black lines on a white background, or white lines on a blue background, etc.) This is because color opens up too many possibilities for distractions and for non-standard representations. The use of color should be reserved for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Distinguishing between different layers when multiple layers are drawn superimposed.&lt;/li&gt;
&lt;li&gt;Transient concepts such as:
&lt;ul&gt;
&lt;li&gt;Mouse-over in the graphical editor&lt;/li&gt;
&lt;li&gt;Selection in the graphical editor&lt;/li&gt;
&lt;li&gt;Validation errors&lt;/li&gt;
&lt;li&gt;Visualization of statistics (especially heat maps)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Nonetheless, people will probably figure out that they can present a design in a colorful way by placing different components on different layers, choosing a different color for each layer, and having all layers displayed simultaneously. However, should they decide to do that, they are on their own: the toolset will not offer any features specifically intended to facilitate this.&lt;/p&gt;
&lt;p&gt;Wires are to be drawn using hairlines.&lt;/p&gt;
&lt;p&gt;Pins are also to be drawn using hairlines. Outputs will be triangular arrows pointing out of a component, inputs will be triangular arrows pointing into a component. The name and type of each pin is to be drawn outside the shape of the component, allowing components to be relatively small and requiring a lot of empty space around them to fit the names of the pins. The pin name is to be drawn with a bigger font than for the pin type.&lt;/p&gt;
&lt;p&gt;Wires may bend only in right angles. When two wires cross, this means that they are isolated from each other. When multiple outputs converge into a single input, a small but discernible dot at the point of convergence indicates that the wires are connected.&lt;/p&gt;
&lt;p&gt;At various points along a wire there can be tiny skinny arrows to remind the viewer of the direction of the wire (always from the output to the input.)&lt;/p&gt;
&lt;p&gt;Component shapes are to be drawn using thick lines. The default shape for every component type is a plain rectangle, with the name and type of the component rendered in the center. The component name is to be drawn using a bigger font than the component type.&lt;/p&gt;
&lt;p&gt;Some component types perform simple and standard functions, which can usually be inferred from their pins, for example adapters from one interface to another, or converters that transform data from one form to another. For such simple components, there is merit in refraining from displaying their name and type, and instead displaying them with special shape, thereby making them occupy less space in the design, and making the design more expressive. The toolset will initially offer a few special shapes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A triangular component shape intended for component types that act as converters.&lt;/li&gt;
&lt;li&gt;An AND-gate component shape for component types that play the role of adapters.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Over time, more component types that perform simple and standard functions will inevitably be identified. This will lead to a demand to introduce additional component shapes, bearing some resemblance to electronic or flowchart symbols, to represent those components; however, the intention is to be conservative in this, and only introduce new shapes if the demand for them is strong and widespread.&lt;/p&gt;
&lt;p&gt;The preferred placement of pins on the perimeter of a component shall be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Inputs along the left and top edges&lt;/li&gt;
&lt;li&gt;Outputs along the right and bottom edges&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The convention for pin placement shall be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;General-purpose and cross-cutting concern interfaces:
&lt;ul&gt;
&lt;li&gt;inputs along the top edge&lt;/li&gt;
&lt;li&gt;outputs along the bottom edge.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Application-specific interfaces:
&lt;ul&gt;
&lt;li&gt;inputs along the left edge.&lt;/li&gt;
&lt;li&gt;outputs along the right edge.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This arrangement is analogous to electronic design, where the convention is that signals flow from left to right and voltages from top to bottom.&lt;/p&gt;
&lt;div class="footnotes" role="doc-endnotes"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;See &lt;a class="external"
href="https://thinkrelevance.com/blog/2011/11/15/documenting-architecture-decisions" target="_blank"
&gt;Architectural Decision Records by Michael Nygard&lt;/a&gt;-&amp;gt; link is dead, &lt;a class="external"
href="https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions" target="_blank"
&gt;new link here&lt;/a&gt;. For ADRs as a vehicle of engagement between architects and developers instead of documentation, see &lt;a class="external"
href="https://www.youtube.com/watch?v=n6G5qtJHmgw" target="_blank"
&gt;Mark Richards - The Intersection of Architecture and Implementation - DDD Europe&lt;/a&gt;.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink"&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;See the concept of &amp;quot;Team Architecture&amp;quot; in &lt;a class="external"
href="https://youtu.be/BNTt2aLB1tg?t=464" target="_blank"
&gt;Practical (a.k.a. Actually Useful) Architecture by Stefan Tilkov, GOTO 2023, section 2, &amp;quot;Explicitly architect your team setup&amp;quot;&lt;/a&gt; -- Related term: &lt;em&gt;Team Topologies.&lt;/em&gt;&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink"&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description></item><item><title>If you are using mock objects you are doing it wrong</title><link>https://blog2.michael.gr/post/2023-01-14-mocking/</link><pubDate>Sat, 14 Jan 2023 14:13:37 +0000</pubDate><guid>https://blog2.michael.gr/post/2023-01-14-mocking/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2023-01-14-mocking/images/mocking.svg"
loading="lazy"
&gt;
&lt;/p&gt;
&lt;h4 id="abstract"&gt;Abstract:
&lt;/h4&gt;&lt;p&gt;The practice of using Mock Objects in automated software testing is examined from a critical point of view and found to be highly problematic. Opinions of some well known industry speakers are cited. The supposed benefits of Mock Objects are shown to be either no real benefits, or achievable via alternative means.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id="introduction"&gt;Introduction
&lt;/h3&gt;&lt;p&gt;The automated software testing technique which is predominant in the industry today is Unit Testing. The goal of Unit Testing is to achieve defect localization, and to this effect it requires each component to be tested in strict isolation from its collaborators.&lt;/p&gt;
&lt;p&gt;Testing components in isolation from each other poses certain challenges:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;While being tested, the component-under-test makes invocations to collaborator interfaces; since the collaborator components are not present, some kind of substitute must be there to implement the collaborator interfaces and receive those invocations.&lt;/li&gt;
&lt;li&gt;For each invocation that the component-under-test makes to a collaborator, it expects to receive back some result; therefore, the substitute receiving the invocation must be capable of generating a result that matches the result that would be generated by the real collaborator.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The technique which is predominant in the industry today for providing the component-under-test with substitutes of its collaborators is &lt;em&gt;&lt;strong&gt;Mock Objects&lt;/strong&gt;&lt;/em&gt;, or just mocks.&lt;/p&gt;
&lt;h3 id="how-do-mocks-work"&gt;How do mocks work?
&lt;/h3&gt;&lt;p&gt;Mocks are based on the premise that the real work done by collaborators in a production environment is irrelevant during testing, and all that the component-under-test really needs from them is the results that they return when invoked. A test exercises the component-under-test in a specific way, therefore the component-under-test is expected to invoke its collaborators in ways which are known in advance; thus, regardless of how the real collaborators would work, the mocks which replace them do not need to contain any functionality; all they need to do is to yield the same results that the real collaborators would have returned, which are also known in advance.&lt;/p&gt;
&lt;p&gt;To this effect, each test dynamically creates and configures as many mocks as necessary to substitute each one of the collaborators of the component-under-test, with the help of some mocking framework. These frameworks are so popular that there exists a proliferation of them: JMock, EasyMock, Mockito, NMock, Moq, JustMock, and the list goes on.&lt;/p&gt;
&lt;p&gt;A mock object is configured to expose the same interface as the real collaborator that it substitutes, and to expect specific methods of this interface to be invoked, with specific argument values, sometimes even in a specific order of invocation. If anything goes wrong, such as an unexpected method being invoked, or a parameter having an unexpected value, the mock fails the test. A very common practice is to also fail the test if an expected method is &lt;em&gt;not&lt;/em&gt; invoked.&lt;/p&gt;
&lt;p&gt;For each one of the expected methods, the mock is configured to yield a prefabricated result which is intended to match the result that the real collaborator would have produced if it was being used, and if it was working exactly according to its specification.&lt;/p&gt;
&lt;p&gt;Or at least, that is the intention.&lt;/p&gt;
&lt;h4 id="drawbacks-of-mocks"&gt;Drawbacks of Mocks
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Complex and laborious&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;In each test it is not enough to invoke the component-under-test to perform a computation and check the results; we also have to configure a mock for each one of the collaborators of the component, to anticipate every single call that the component will be making to them while performing the computation, and for each call to fabricate a result which matches the result that the real collaborator would have returned from that call.&lt;/li&gt;
&lt;li&gt;Luckily, mocking frameworks lessen the amount of code necessary to accomplish this, but no matter how terse the mocking code is, the fact still remains that it constitutes substantial additional functionality which represents considerable additional complexity.&lt;/li&gt;
&lt;li&gt;One of the well-known caveats of software testing is that a test failure does not necessarily indicate a defect in the production code; it always indicates a defect either in the production code or in the test itself, and the only way to know is to troubleshoot. Thus, the more code we put in tests, and the more complex this code is, the more time we end up wasting in chasing and fixing bugs in the tests themselves rather than in the code that they are meant to test.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Over-specified&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;By anticipating every single call that the component-under-test makes to its collaborators, we are claiming to have detailed knowledge of the inner workings of the component-under-test, and we are concerned not only with what it accomplishes, but also with every little detail about how it goes on about accomplishing it. Essentially, we are implementing all of our application logic twice: once with production code expressing the logic in imperative mode, and once more with testing code expressing the same logic in expectational mode. In both cases, we write copious amounts of code describing what should happen in excruciatingly meticulous detail.&lt;/li&gt;
&lt;li&gt;Note that over-specification might not even be a goal in and of itself in some cases, but with mocking it is unavoidable in all cases: Each request that the component-under-test sends to its collaborators could conceivably be ignored, but the component-under-test still needs to receive some meaningful result in response to that request, so as to continue functioning during the remainder of the test; unfortunately, the only way that mocks can fabricate individual responses is by anticipating individual requests, even if the intention of the test is not to verify whether the requests are being made.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Presumptuous&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;When using mocks we are claiming to not only have detailed knowledge of the calls that the component-under-test makes to its collaborators, but also detailed knowledge of the results that would be returned by the real collaborators in a production environment.&lt;/li&gt;
&lt;li&gt;Furthermore, the results returned by a collaborator depend on the state that the collaborator is in, which in turn depends on previous calls made to it, but a mock is by its nature incapable of emulating state, so when using mocks we are also claiming to have knowledge of the state transitions that the real collaborators undergo in a production environment, and of the effect that these state transitions have on the results that they return.&lt;/li&gt;
&lt;li&gt;Such exorbitant presumptuousness might be okay if we are building high-criticality software, where each collaborator is likely to have requirements and specification that are well-defined and unlikely to change; however, in all other software, which is regular, commercial, non-high-criticality software, things are a lot less strict: not only the requirements and specifications change all the time, but also, by established practice, both the requirements, and the specification, and even the documentation, tend to be the code itself, and the code changes every time a new commit is made to the source code repository. Thus, the only way to know exactly how a collaborator behaves tends to be to actually invoke it and see what it does, while the mechanism which ensures that it does what it is supposed to do is the tests of that collaborator itself, which are unrelated to the tests of components that invoke it.&lt;/li&gt;
&lt;li&gt;As a result of all this, the practice of mocking often places us in the all too familiar situation where our Unit Tests all pass with flying colors, but our Integration Tests miserably fail because the behavior of the real collaborators turns out to be different from what the mocks assumed it would be.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fragile&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;By its nature, a mock object has no option but to fail the test if the interactions between the component under test and its collaborators deviate from what it expects. However, these interactions may legitimately change as software evolves. This may happen due to the application of a bug-fix, due to refactoring, or simply because as we write new code we invariably have to also modify existing code to interact with the new code that we are adding. Thus, when using mocks, every time we change the behavior of production code, we also have to fix tests to expect the new behavior. (Not only do we have to write all of our application logic twice, we also have to perform all of its maintenance twice.)&lt;/li&gt;
&lt;li&gt;The original promise of Automated Software Testing was to enable us to continuously evolve our software without fear of breaking it. The idea is that whenever you modify the production code, you can re-run the tests to ensure that everything still works. When using mocks this does not work, because every time you change the slightest thing in the production code, the tests break. As a result, many programmers are hesitant to make needed changes to production code because of all the changes in testing code that would be required. The understanding is growing within the software engineering community that mock objects actually hinder software development instead of facilitating it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Non-reusable&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Mocks exercise the implementation of a component rather than its interface. Thus, when using mocks, it is impossible to reuse the same testing code to validate multiple different components that implement the same public interface but employ different collaborators. For example:
&lt;ul&gt;
&lt;li&gt;It is impossible to completely rewrite the component and reuse the old tests to make sure that the new implementation works exactly as the old one did.&lt;/li&gt;
&lt;li&gt;It is impossible to use a single test suite to exercise both a real component and its fake.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Unenlightening&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Ideally, a set of tests for a certain component should act as sample code demonstrating usage scenarios of that component. A programmer who is not familiar with a particular component should be able to read the tests of that component and gain a fairly good idea of what it can do, what it cannot do, and how to write production code that interacts with it.&lt;/li&gt;
&lt;li&gt;Unfortunately, when using mocks, the tests are full of cryptic mock-related jabber, which obscures the actual usage of the component-under-test, and so the enlightening bits are lost in the noise.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="what-do-others-say"&gt;What do others say?
&lt;/h4&gt;&lt;p&gt;I am certainly not the only one to voice dissatisfaction with mocks. People have been noticing that although automated software testing is intended to facilitate refactoring by ensuring that the code still works after each change that we make, the use of mocks often hinders refactoring, because the tests are so tied to the implementation that you cannot change anything without breaking the tests.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the video &lt;em&gt;Thoughtworks - TW Hangouts: Is TDD dead?&lt;/em&gt; (&lt;a class="external"
href="https://www.youtube.com/watch?v=z9quxZsLcfo" target="_blank"
&gt;youtube&lt;/a&gt;, &lt;a class="external"
href="https://martinfowler.com/articles/is-tdd-dead/" target="_blank"
&gt;text digest&lt;/a&gt;) at 21':10'' Kent Beck states &amp;quot;My personal practice is I mock almost nothing.&amp;quot;&lt;/li&gt;
&lt;li&gt;In the same video, at 23':56'' Martin Fowler adds &amp;quot;I'm with Kent, I hardly ever use mocks.&amp;quot;&lt;/li&gt;
&lt;li&gt;In the &lt;em&gt;Fragile Test&lt;/em&gt; section of his book &lt;em&gt;xUnit Test Patterns: Refactoring Test Code&lt;/em&gt; (&lt;a class="external"
href="https://xunitpatterns.com/" target="_blank"
&gt;xunitpatterns.com&lt;/a&gt;) author Gerard Meszaros admits that &amp;quot;extensive use of Mock Objects causes overcoupled tests.&amp;quot;&lt;/li&gt;
&lt;li&gt;In his presentation &lt;em&gt;TDD, where did it all go wrong?&lt;/em&gt; (&lt;a class="external"
href="https://www.infoq.com/presentations/tdd-original/" target="_blank"
&gt;InfoQ&lt;/a&gt;, &lt;a class="external"
href="https://www.youtube.com/watch?v=EZ05e7EMOLM" target="_blank"
&gt;YouTube&lt;/a&gt;) at 49':32'' Ian Cooper states &amp;quot;I argue quite heavily against mocks because they are overspecified.&amp;quot;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that in an attempt to avoid sounding too blasphemous, these people refrain from suggesting that mocks should be abolished; however, it is evident that 3 out of 4 of them are strongly against mocks, and we do not need to read much between the lines to figure out that they would probably be calling for the complete abolition of mocks if they had a viable and universally applicable alternative to propose.&lt;/p&gt;
&lt;h4 id="so-if-not-mocking-then-what"&gt;So, if not mocking, then what?
&lt;/h4&gt;&lt;p&gt;Mocking has been such a great hit with the software industry because it achieves multiple different goals at once. Here is a list of the supposed benefits of mocking, and for each one of them an explanation of why it is not really a benefit, or how it can be achieved without mocking:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mocking achieves defect localization by eliminating collaborators from the picture and allowing components to be tested in strict isolation from each other.
&lt;ul&gt;
&lt;li&gt;Defect localization is useful, but it is not an absolute necessity, and it does not have to be done to absolute perfection as mocking aims to do; we can achieve more than good enough defect localization by testing each component in integration with its collaborators, simply by arranging the order in which tests are executed to ensure that by the time a component gets tested, all of its collaborators have already passed their tests. See &lt;a
href="https://blog2.michael.gr/post/2022-10-incremental-integration-testing/"
&gt;Incremental Integration Testing&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mocking allows a component to be tested without the performance overhead of instantiating and invoking its real collaborators.
&lt;ul&gt;
&lt;li&gt;The performance overhead of instantiating and invoking the real collaborators is not always prohibitive, or even noticeable, so in many cases it is perfectly fine to test a component in integration with its real collaborators. See &lt;a
href="https://blog2.michael.gr/post/2022-10-incremental-integration-testing/"
&gt;Incremental Integration Testing&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;In the limited number of cases where the performance overhead is indeed prohibitive, it can be avoided with the use of Fakes instead of Mocks. See &lt;a
href="https://blog2.michael.gr/post/2022-10-testing-with-fakes/"
&gt;Testing with Fakes instead of Mocks&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mocking allows us to examine invocations being made by the component-under-test to its collaborators, to ensure that they are issued exactly as expected.
&lt;ul&gt;
&lt;li&gt;In most cases, examining the invocations made by the component-under-test to its collaborators is in fact bad practice, because it constitutes white-box testing. The only reason why this is being widely practiced in the industry is because mocking does not work otherwise, so in this regard mocking contains a certain element of a self-serving paradigm.&lt;/li&gt;
&lt;li&gt;In those rare cases where examining the invocations is in fact necessary, it is still bad practice to do so programmatically, because it results in tests that are over-specified and fragile.&lt;/li&gt;
&lt;li&gt;What we can do instead is to record the interactions during each test run, visually compare the latest recording with that of the last known good run, and decide whether the differences match our expectations; if they do not match, then we must keep working on our code; but if they do match, then we are done without the need to go fixing any tests. See &lt;a
href="https://blog2.michael.gr/post/2024-04-audit-testing/"
&gt;Audit Testing&lt;/a&gt; and &lt;a
href="https://blog2.michael.gr/post/2023-01-06-collaboration-monitoring/"
&gt;Collaboration Monitoring&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mocking allows us to fabricate the results returned from a collaborator to the component-under-test, so as to guarantee that they are free from defects that could be caused by bugs in the implementation of the real collaborator.
&lt;ul&gt;
&lt;li&gt;Fabricating the results that would have been returned by a real collaborator is in fact bad practice, because it will not magically make any bugs go away, (in this sense it can be likened to ostrich policy,) and because as I have already explained, it is highly presumptuous. The definitive authority on what results are returned by a certain collaborator is the real implementation of that collaborator, or a fake thereof, which in turn necessitates integration testing. See &lt;a
href="https://blog2.michael.gr/post/2022-10-incremental-integration-testing/"
&gt;Incremental Integration Testing&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mocking allows us to verify the correctness of components that generate their output by means of forwarding results to collaborators rather than by returning results from invocations.
&lt;ul&gt;
&lt;li&gt;Even in this case, &lt;em&gt;Collaboration Monitoring&lt;/em&gt; can be used instead of mocking, to verify that the results are generated as expected without having to programmatically describe what the results should be and without having to go fixing tests each time we modify the component under test and deliberately change something about the results it generates. See &lt;a
href="https://blog2.michael.gr/post/2024-04-audit-testing/"
&gt;Audit Testing&lt;/a&gt; and &lt;a
href="https://blog2.michael.gr/post/2023-01-06-collaboration-monitoring/"
&gt;Collaboration Monitoring&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mocking allows us to start testing a component while one or more of its collaborators are not ready yet for integration because they are still in development, and no fakes of them are available either.
&lt;ul&gt;
&lt;li&gt;This is true, but once the collaborators (or fakes thereof) become available, it is best to integrate them in the tests, and to unceremoniously throw away the mocks. See &lt;a
href="https://blog2.michael.gr/post/2022-10-incremental-integration-testing/"
&gt;Incremental Integration Testing&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mocking allows us to develop a component without depending on factors that we have no control over, such as the time of delivery of collaborators, the quality of their implementation, and the quality of their testing. With the use of Mocks we can claim that our component is complete and fully tested, based on nothing but the specification of its collaborators, and we can claim that it should work fine in integration with its collaborators when they happen to be delivered, and if they happen to work according to spec.
&lt;ul&gt;
&lt;li&gt;True, but this implies a very bureaucratic way of working, and utter lack of trust towards the developers of the collaborators; it is best if it never comes to that.&lt;/li&gt;
&lt;li&gt;We can still avoid the use of mocks by creating fakes of the collaborators ourselves. See &lt;a
href="https://blog2.michael.gr/post/2022-10-testing-with-fakes/"
&gt;Testing with Fakes instead of Mocks&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To summarize, mocks can always be replaced with one or more of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fakes (see &lt;a
href="https://blog2.michael.gr/post/2022-10-testing-with-fakes/"
&gt;Testing with Fakes instead of Mocks&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Incremental Integration Testing (see &lt;a
href="https://blog2.michael.gr/post/2022-10-incremental-integration-testing/"
&gt;Incremental Integration Testing&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Audit Testing (see &lt;a
href="https://blog2.michael.gr/post/2024-04-audit-testing/"
&gt;Audit Testing&lt;/a&gt;) and Collaboration Monitoring (see &lt;a
href="https://blog2.michael.gr/post/2023-01-06-collaboration-monitoring/"
&gt;Collaboration Monitoring&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="conclusion"&gt;Conclusion
&lt;/h4&gt;&lt;p&gt;As we have shown, the practice of using Mock Objects in automated software testing is laborious, over-specified, presumptuous, and leads to tests that are fragile and non-reusable, while each of the alleged benefits of using mocks is either not a real benefit, or can be realized by other means, which we have named.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;img src="https://blog2.michael.gr/post/2023-01-14-mocking/images/grumpy-cat-mock-objects.jpg"
width="797"
height="1024"
srcset="https://blog2.michael.gr/post/2023-01-14-mocking/images/grumpy-cat-mock-objects_hu_8156248a341d61af.jpg 480w, https://blog2.michael.gr/post/2023-01-14-mocking/images/grumpy-cat-mock-objects_hu_5b4ff396469f2342.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="77"
data-flex-basis="186px"
&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;Mandatory grumpy cat meme - &amp;quot;Mock objects - they are horrible&amp;quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: &amp;quot;Mocking&amp;quot; by michael.gr, based on &lt;a class="external"
href="https://thenounproject.com/icon/mock-2657532/" target="_blank"
&gt;'mock' by 'Iconbox' from the noun project.&lt;/a&gt;&lt;/p&gt;</description></item><item><title>On messages and message-passing</title><link>https://blog2.michael.gr/post/2022-12-messages-and-message-passing/</link><pubDate>Sun, 18 Dec 2022 08:59:25 +0000</pubDate><guid>https://blog2.michael.gr/post/2022-12-messages-and-message-passing/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2022-12-messages-and-message-passing/media/message-passing.png"
width="2673"
height="1494"
srcset="https://blog2.michael.gr/post/2022-12-messages-and-message-passing/media/message-passing_hu_cac0be91696add81.png 480w, https://blog2.michael.gr/post/2022-12-messages-and-message-passing/media/message-passing_hu_4c50d0e4091ea6ab.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="178"
data-flex-basis="429px"
&gt;
&lt;/p&gt;
&lt;p&gt;Over the decades, numerous software system architectures have emerged which require invocations across subsystems to be done via message-passing instead of programmatic interface method calls. Such architectures are so common that many programmers have come to regard message-passing as an end in and of itself, oblivious of the fact that it is nothing but a (poor) technical mechanism for accomplishing a certain architectural goal.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;The architectural goal is to be able to perform general-purpose operations on invocations, for example routing the invocations according to configuration, or queuing the invocations for delivery on a different thread. In order to be able to do things like that, the invocations must first be expressed in a general-purpose form.&lt;/p&gt;
&lt;p&gt;Message-passing is simply the only general-purpose form that could be imagined by the pioneers who built the first asynchronous event-driven systems, or perhaps the only form that could readily be implemented using the programming languages available back then. However, in succeeding decades our thinking and our tools have advanced considerably, to the point where we now have much better ways of achieving things technically, so it might be worth taking a moment to re-examine the concept of message-passing.&lt;/p&gt;
&lt;p&gt;Here is a list of problems with message passing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Custom message classes have to be written and maintained, usually in large numbers, constituting nothing but incidental complexity which steers focus away from the class hierarchy of the problem domain, and towards the class hierarchy of the overelaborate inter-module communication apparatus.&lt;/li&gt;
&lt;li&gt;For each invocation, a message class needs to be instantiated, filled, and submitted, requiring several lines of custom-written code. This is also nothing but incidental complexity, diverting the attention of programmers from solving the problem at hand to negotiating the trifling technicalities of placing invocations.&lt;/li&gt;
&lt;li&gt;On the receiving end, each message must be examined in order to determine what kind of message it is, usually by means of an unwieldy switch statement, and its contents have to be extracted before any useful work can be done. Again, this is all incidental complexity, contributing nothing towards the end-goal of the software system; its sole purpose is to serve the message-passing bureaucracy.&lt;/li&gt;
&lt;li&gt;In order to reduce the total number of different message classes that need to be defined, programmers often reuse message classes for different purposes, filling different parts according to each purpose. This habit further increases the total amount of incidental complexity both at the sending and at the receiving end, and very often leads to bugs due to wrongly packed or wrongly unpacked messages.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, message-passing exists for the sole purpose of expressing invocations in a general-purpose form, but as it turns out, its use is laborious, and it tends to flood systems with debilitating amounts of incidental complexity.&lt;/p&gt;
&lt;p&gt;The most natural, simple, convenient, straightforward, robust, maintainable, and self-documenting paradigm for making and receiving invocations, which facilitates problem-solving instead of hindering it, is programmatic interface method calls. Unfortunately, interfaces are not general-purpose in and of themselves, because each interface constitutes a unique type, requiring custom-written code to place calls to it and custom-written code to receive calls for it, thus preventing us from applying general-purpose operations on it. So, we have two separate and seemingly conflicting concerns:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How to express invocations in the most convenient way&lt;/li&gt;
&lt;li&gt;How to perform general-purpose operations on the invocations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ideally, separate concerns should not be mixed; the need to somehow apply general-purpose operations on invocations should not be dictating how we write code, and it should certainly not be making our job harder. Therein lies perhaps the biggest objection to message-passing: they are an onerous contrivance that programmers by themselves would never opt to use out of their own free will, but usually gets imposed on them by software architects who do not actually have to write code using this contrivance.&lt;/p&gt;
&lt;p&gt;Message-passing has enjoyed widespread use mainly due to the historical inability of application programmers to think in terms of abstractions: it is always possible, even in systems that require message-passing, to write all application code so that it never deals with any messages at all, and uses nothing but application-specific programmatic interfaces instead; the trick is to create packaging and unpackaging adaptors, where on the sending side we are simply invoking a programmatic interface which is implemented by a packaging adaptor that creates messages, packs them, and sends them off to be enqueued, while on the receiving side a corresponding unpackaging adaptor is fed with messages from the queue, unpacks them, and calls the corresponding implementation of the interface. Alas, this arrangement requires a modicum of abstract thinking, and application programmers are generally not into that sort of thing.&lt;/p&gt;
&lt;p&gt;Furthermore, if we bother creating such packaging and unpackaging adaptors, the realization quickly starts to sink-in that all the message classes are irrelevant; there is no need to define a special message class containing a separate field for each parameter of each method, because the only code that would ever deal with such a class would be the corresponding pair of packaging and unpackaging adaptors; so, the adaptors might as well use a single universal message class which simply stores all parameters in an array of object, and voila, the entire menagerie of message classes becomes entirely unnecessary.&lt;/p&gt;
&lt;p&gt;Thus, it becomes evident that what we are really after is not message-passing per se; it is some general-purpose form of expressing invocations, so that general-purpose operations can be performed on them, and some mechanism for converting back and forth between this general-purpose form and the natural form, which is programmatic interface method calls, so that we can write code naturally. Ideally, the conversion mechanism would be automatic and transparent, so that we do not even have to write those adaptors. Messages have only existed due to the historical absence of such an automatic and transparent mechanism.&lt;/p&gt;
&lt;p&gt;Fortunately, with modern reflecting, intermediate-code-based, just-in-time compiled programming languages, today we have at our disposal all that is necessary to build such mechanisms. For more information see &lt;a
href="https://blog2.michael.gr/post/2022-12-intertwine/"
&gt;Intertwine&lt;/a&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;img src="https://blog2.michael.gr/post/2022-12-messages-and-message-passing/media/grumpy-cat-message-passing.jpg"
width="493"
height="555"
srcset="https://blog2.michael.gr/post/2022-12-messages-and-message-passing/media/grumpy-cat-message-passing_hu_292667b1799fe58a.jpg 480w, https://blog2.michael.gr/post/2022-12-messages-and-message-passing/media/grumpy-cat-message-passing_hu_6ad615b796b41427.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="88"
data-flex-basis="213px"
&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;Mandatory grumpy cat meme: &amp;quot;Message-Passing: it's awful&amp;quot; by michael.gr&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: Conceptual illustration of message-passing, by michael.gr, based on original art by Youmena and Made from the Noun Project.&lt;/p&gt;</description></item><item><title>Intertwine</title><link>https://blog2.michael.gr/post/2022-12-intertwine/</link><pubDate>Sun, 11 Dec 2022 16:18:00 +0000</pubDate><guid>https://blog2.michael.gr/post/2022-12-intertwine/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2022-12-intertwine/media/intertwine-logo.svg"
loading="lazy"
&gt;
&lt;/p&gt;
&lt;h3 id="abstract"&gt;Abstract
&lt;/h3&gt;&lt;p&gt;A mechanism is described for automatically converting method invocations of any programmatic interface into a single-method &lt;em&gt;&lt;strong&gt;normal form&lt;/strong&gt;&lt;/em&gt; and converting back to invocations of the original interface, so that general-purpose operations can be performed on the normal form without explicit knowledge of the interface being invoked. Implementations are provided for C# and for Java.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id="the-problem"&gt;The Problem
&lt;/h3&gt;&lt;p&gt;When creating software systems of nontrivial complexity we often need to be able to apply certain operations on the invocations that are being made between certain components. Examples of such operations are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Logging:&lt;/strong&gt; Recording information about each invocation being made.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multicasting:&lt;/strong&gt; Delivering a single invocation to multiple recipients.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Remoting:&lt;/strong&gt; Placing invocations across machine boundaries.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Desynchronization:&lt;/strong&gt; Queuing invocations for later execution, possibly on a different thread.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Synchronization:&lt;/strong&gt; Obtaining and holding a lock for the duration of the invocation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transformation:&lt;/strong&gt; Converting between invocation formats, e.g. method calls to REST and back.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ordinarily, the components doing the invocations are application-specific, and the interfaces between them are also application-specific, but the operators that we want to interject between them are general-purpose, so they need to remain agnostic of the application-specific details of the invocations, in a way analogous to how a general-purpose sorting algorithm is agnostic of the application-specific format of the data it sorts.&lt;/p&gt;
&lt;p&gt;Therefore, we need some way of expressing application-specific invocations in a general-purpose form.&lt;/p&gt;
&lt;h3 id="prior-art"&gt;Prior Art
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Messages and message-passing:&lt;/strong&gt; The mechanism historically used for expressing invocations in a general-purpose form is message-passing. Unfortunately, its use is laborious, and it floods systems with debilitating amounts of incidental complexity. For details, see &lt;a
href="https://blog2.michael.gr/post/2022-12-messages-and-message-passing/"
&gt;On messages and message-passing&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Parameterless lambdas:&lt;/strong&gt; Application-specific method calls can be wrapped inside parameterless lambdas, and since all parameterless lambdas look the same, they can be handled by general-purpose code which may for example add them to a queue, and later dequeue and invoke them.
Unfortunately:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The wrapping of each application-specific method call inside a parameterless lambda must happen at each call site, which is cumbersome and reveals details about the underlying invocation delivery mechanism.&lt;/li&gt;
&lt;li&gt;The evaluation of the parameters that are passed to the application-specific method happens at the moment that the lambda makes the call, not at the moment that the lambda is constructed, which can lead to insidious bugs even if the evaluations have no side-effects. (And &lt;em&gt;woe to you on earth and sea&lt;/em&gt; if they do have side-effects.)&lt;/li&gt;
&lt;li&gt;The parameterless lambda completely hides the values of the parameters that are being passed to the application-specific method, as well as the identity of the method being invoked. Thus, parameterless lambdas cannot be used in scenarios that require information about each call being made.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Dynamic Proxies:&lt;/strong&gt; Both in Java and in C# there exist mechanisms that can be used to convert application-specific invocations to a general-purpose form, but not the other way around. These are &lt;code&gt;java.lang.reflect.Proxy&lt;/code&gt; for Java, and various libraries like Castle's and LinFu for C#. The reverse operation can be achieved using reflection, but this involves a round-trip to native-land, which incurs a heavy performance penalty. Furthermore, these mechanisms suffer from additional issues, such as messing with exceptions, doing more work than necessary, etc.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="the-solution"&gt;The Solution
&lt;/h3&gt;&lt;p&gt;In order to be able to perform general-purpose operations on application-specific invocations we need a mechanism for converting application-specific invocations into a general-purpose form and back, so that the operators can act upon the general-purpose form. What follows is a description of such a mechanism, which I call &lt;em&gt;&lt;strong&gt;Intertwine&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Intertwine introduces a general-purpose form for expressing invocations, which is called &lt;em&gt;&lt;strong&gt;the normal form of invocations&lt;/strong&gt;&lt;/em&gt;, and is represented by a single method of the following signature:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Object&lt;/span&gt; &lt;span class="n"&gt;AnyCall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;MethodKey&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Object&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;arguments&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;In C#, &lt;code&gt;AnyCall&lt;/code&gt; would be a &lt;em&gt;delegate.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;In Java, &lt;code&gt;AnyCall&lt;/code&gt; would be a &lt;em&gt;single-method interface&lt;/em&gt;, otherwise known as a &lt;em&gt;functional interface&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This method signature represents the fact that every conceivable interface method call can be fully described in terms of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A return value, of the common denominator type &lt;code&gt;Object&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;A unique key which identifies which method of the interface is being invoked.&lt;/li&gt;
&lt;li&gt;An array containing arguments, of the common denominator type &lt;code&gt;Object&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please note that the method identifier is &lt;code&gt;MethodKey&lt;/code&gt; in the Java implementation, but &lt;code&gt;int selector&lt;/code&gt; in the C# implementation. This is because the Java implementation was made a considerable time after the C# implementation, and is therefore a bit more advanced.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;MethodKey&lt;/code&gt; used in the Java implementation allows the caller and the callee to unambiguously identify methods even in situations where binary compatibility between the caller and the callee is not guaranteed, and therefore an integer method index does not necessarily refer to the same method on both the caller and the callee.&lt;/p&gt;
&lt;p&gt;The Java implementation of intertwine provides efficient means of converting back and forth between a &lt;code&gt;MethodKey&lt;/code&gt; and any of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The reflection &amp;quot;Method&amp;quot; object of the method. (This is &lt;code&gt;java.lang.reflect.Method&lt;/code&gt; in Java, or &lt;code&gt;System.Reflection.MethodInfo&lt;/code&gt; in C#.)&lt;/li&gt;
&lt;li&gt;The string representation of the prototype of the method.&lt;/li&gt;
&lt;li&gt;The zero-based method index of the method.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The sample code that follows was written for C#, so it uses an &lt;code&gt;int selector&lt;/code&gt; instead of &lt;code&gt;MethodKey key&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For methods of &lt;code&gt;void&lt;/code&gt; return type the value returned by AnyCall is unspecified. (It will in all likelihood be &lt;code&gt;null&lt;/code&gt;, but nobody should rely on this.)&lt;/li&gt;
&lt;li&gt;Value types (primitives) are boxed and unboxed as necessary.&lt;/li&gt;
&lt;li&gt;Certain features such as the &lt;code&gt;ref&lt;/code&gt; and &lt;code&gt;out&lt;/code&gt; parameters in C#, receive special handling.&lt;/li&gt;
&lt;li&gt;Other features such as properties, indexers, virtual events, etc. are nothing but syntactic sugar which is implemented using regular method calls under the hood, so they require no special handling.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, the problem can now be restated as follows:&lt;/p&gt;
&lt;p&gt;How to convert any interface method invocation to an invocation of an AnyCall method, and how to convert back from an invocation of an AnyCall method to an invocation of the original interface method.&lt;/p&gt;
&lt;p&gt;For this, Intertwine introduces two new concepts: &lt;em&gt;&lt;strong&gt;Entwiners&lt;/strong&gt;&lt;/em&gt; and &lt;em&gt;&lt;strong&gt;Untwiners&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An Entwiner of interface &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt; is a class which exposes (implements) interface &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt; and delegates to an instance of &lt;em&gt;AnyCall&lt;/em&gt;. It can also be thought of as a &lt;em&gt;normalizer&lt;/em&gt; or &lt;em&gt;generalizer&lt;/em&gt; or &lt;em&gt;multiplexer.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;An Untwiner of interface &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt; is a class which exposes an &lt;em&gt;AnyCall&lt;/em&gt; method and delegates to an instance of &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt;. It can also be thought of as a &lt;em&gt;denormalizer&lt;/em&gt; or &lt;em&gt;specializer&lt;/em&gt; or &lt;em&gt;demultiplexer.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More specifically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The entwiner of &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt; does the following:
&lt;ul&gt;
&lt;li&gt;Accepts an instance of &lt;code&gt;Anycall&lt;/code&gt; as a constructor parameter and stores it in a &lt;code&gt;final&lt;/code&gt;/&lt;code&gt;readonly&lt;/code&gt; field.&lt;/li&gt;
&lt;li&gt;Implements each method of &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt; as follows:
&lt;ul&gt;
&lt;li&gt;Packs the parameters that were passed to the method into an array of &lt;code&gt;Object&lt;/code&gt;, performing any boxing necessary.&lt;/li&gt;
&lt;li&gt;Invokes anyCall passing it a key that uniquely identifies the method, and the array of parameters.&lt;/li&gt;
&lt;li&gt;Returns, possibly after unboxing, whatever was returned by the invocation of anyCall.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The untwiner of &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt; performs the opposite and complementary operation of the entwiner, namely:
&lt;ul&gt;
&lt;li&gt;Accepts an instance of &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt; as a constructor parameter and stores it in a &lt;code&gt;final&lt;/code&gt;/&lt;code&gt;readonly&lt;/code&gt; field.&lt;/li&gt;
&lt;li&gt;Implements the &lt;code&gt;anycall&lt;/code&gt; method of the &lt;code&gt;Anycall&lt;/code&gt; interface as follows:&lt;/li&gt;
&lt;li&gt;It uses the supplied &lt;code&gt;MethodKey&lt;/code&gt; to determine which method of &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt; is being invoked, and for each method it does the
following:
&lt;ul&gt;
&lt;li&gt;Unpacks the parameters from the array of &lt;code&gt;Object&lt;/code&gt;, performing any unboxing necessary.&lt;/li&gt;
&lt;li&gt;Invokes the method of &lt;em&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/em&gt;, passing it the unpacked parameters.&lt;/li&gt;
&lt;li&gt;Returns, possibly after boxing, whatever was returned by the method, or &lt;code&gt;null&lt;/code&gt; if the method was of &lt;code&gt;void&lt;/code&gt; return type.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="a-hand-crafted-implementation"&gt;A hand-crafted implementation
&lt;/h3&gt;&lt;p&gt;Before we look at the automatic creation of entwiners and untwiners, let us take a look at an example of how we would implement an entwiner and untwiner for a certain interface if we were to do it by hand.&lt;/p&gt;
&lt;p&gt;Let us consider the following interface:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;interface&lt;/span&gt; &lt;span class="nc"&gt;IFooable&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="n"&gt;Moo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="n"&gt;Boo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kt"&gt;string&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;And let us consider the following class implementing that interface:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;FooImplementation&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;IFooable&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="n"&gt;IFooable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Moo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;Console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;WriteLine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="s"&gt;&amp;#34;i: &amp;#34;&lt;/span&gt; &lt;span class="p"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="n"&gt;IFooable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Boo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kt"&gt;string&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;Console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;WriteLine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="s"&gt;&amp;#34;s: &amp;#34;&lt;/span&gt; &lt;span class="p"&gt;+&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="p"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;#34;, b: &amp;#34;&lt;/span&gt; &lt;span class="p"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;And then let us consider the following method which invokes the interface:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="n"&gt;InvokeFoo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;IFooable&lt;/span&gt; &lt;span class="n"&gt;fooable&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;fooable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Moo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="m"&gt;42&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;fooable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Boo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="s"&gt;&amp;#34;fubar!&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;The InvokeFoo method can be directly hooked up to an instance of the implementing class in a completely conventional way as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="n"&gt;Run1&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;IFooable&lt;/span&gt; &lt;span class="n"&gt;fooable&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;FooImplementation&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;InvokeFoo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;fooable&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Now, an entwiner for our IFooable interface could be hand-crafted as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;span class="lnt"&gt;6
&lt;/span&gt;&lt;span class="lnt"&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;EntwinerForFooable&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;IFooable&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="k"&gt;readonly&lt;/span&gt; &lt;span class="n"&gt;AnyCall&lt;/span&gt; &lt;span class="n"&gt;AnyCall&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Constructor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;AnyCall&lt;/span&gt; &lt;span class="n"&gt;anycall&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;AnyCall&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;anycall&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="n"&gt;IFooable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Moo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;AnyCall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="kt"&gt;object&lt;/span&gt;&lt;span class="p"&gt;[]{&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="n"&gt;IFooable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Boo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kt"&gt;string&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;AnyCall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="kt"&gt;object&lt;/span&gt;&lt;span class="p"&gt;[]{&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Whereas an untwiner for IFooable could be hand-crafted as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt; 1
&lt;/span&gt;&lt;span class="lnt"&gt; 2
&lt;/span&gt;&lt;span class="lnt"&gt; 3
&lt;/span&gt;&lt;span class="lnt"&gt; 4
&lt;/span&gt;&lt;span class="lnt"&gt; 5
&lt;/span&gt;&lt;span class="lnt"&gt; 6
&lt;/span&gt;&lt;span class="lnt"&gt; 7
&lt;/span&gt;&lt;span class="lnt"&gt; 8
&lt;/span&gt;&lt;span class="lnt"&gt; 9
&lt;/span&gt;&lt;span class="lnt"&gt;10
&lt;/span&gt;&lt;span class="lnt"&gt;11
&lt;/span&gt;&lt;span class="lnt"&gt;12
&lt;/span&gt;&lt;span class="lnt"&gt;13
&lt;/span&gt;&lt;span class="lnt"&gt;14
&lt;/span&gt;&lt;span class="lnt"&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;UntwinerForFooable&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="k"&gt;readonly&lt;/span&gt; &lt;span class="n"&gt;IFooable&lt;/span&gt; &lt;span class="n"&gt;Target&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="n"&gt;Constructor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;IFooable&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;Target&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;object&lt;/span&gt; &lt;span class="n"&gt;AnyCall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;selector&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;object&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;switch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;selector&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Target&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Moo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Target&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Boo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;default&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;throw&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;InvalidOperationException&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;With the above classes, we can now write the following piece of awesomeness:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;span class="lnt"&gt;6
&lt;/span&gt;&lt;span class="lnt"&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="n"&gt;Run2&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;IFooable&lt;/span&gt; &lt;span class="n"&gt;fooable&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;FooImplementation&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;var&lt;/span&gt; &lt;span class="n"&gt;untwiner&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;UntwinerForFooable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;fooable&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;var&lt;/span&gt; &lt;span class="n"&gt;entwiner&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;EntwinerForFooable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;untwiner&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;AnyCall&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;InvokeFoo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;entwiner&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Note that &lt;code&gt;Run2()&lt;/code&gt; has exactly the same end-result as &lt;code&gt;Run1()&lt;/code&gt;, but there is a big difference in what goes on under the hood: all outbound interface method calls from the &lt;code&gt;InvokeFoo&lt;/code&gt; function are now arriving at the entwiner, which converts them to &lt;code&gt;AnyCall&lt;/code&gt; invocations, which are then forwarded to the untwiner, which converts them back to &lt;code&gt;IFooable&lt;/code&gt; calls, which are then forwarded to our &lt;code&gt;FooImplementation&lt;/code&gt; object. This means that if we wanted to, we could interject a chain of objects between the entwiner and the untwiner, each one of these objects implementing an &lt;code&gt;AnyCall&lt;/code&gt; delegate and invoking another &lt;code&gt;AnyCall&lt;/code&gt; delegate, thus enabling us to perform any conceivable operation upon those invocations without having any built-in knowledge of the &lt;code&gt;IFooable&lt;/code&gt; interface.&lt;/p&gt;
&lt;p&gt;As the complexity of the interface increases, and as additional subtleties come into the picture, such as parameters passed with ref or out, coding entwiners and untwiners by hand can become very tedious and error-prone, so, obviously, we would like to have it automated.&lt;/p&gt;
&lt;h3 id="automating-it-with-reflection"&gt;Automating it with reflection
&lt;/h3&gt;&lt;p&gt;It is possible to write a general-purpose untwiner that does its job using reflection, but reflection is slow, so the result is going to suffer performance-wise. For the sake of completeness, here is a possible implementation for a general-purpose reflecting untwiner using reflection:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt; 1
&lt;/span&gt;&lt;span class="lnt"&gt; 2
&lt;/span&gt;&lt;span class="lnt"&gt; 3
&lt;/span&gt;&lt;span class="lnt"&gt; 4
&lt;/span&gt;&lt;span class="lnt"&gt; 5
&lt;/span&gt;&lt;span class="lnt"&gt; 6
&lt;/span&gt;&lt;span class="lnt"&gt; 7
&lt;/span&gt;&lt;span class="lnt"&gt; 8
&lt;/span&gt;&lt;span class="lnt"&gt; 9
&lt;/span&gt;&lt;span class="lnt"&gt;10
&lt;/span&gt;&lt;span class="lnt"&gt;11
&lt;/span&gt;&lt;span class="lnt"&gt;12
&lt;/span&gt;&lt;span class="lnt"&gt;13
&lt;/span&gt;&lt;span class="lnt"&gt;14
&lt;/span&gt;&lt;span class="lnt"&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ReflectingUntwiner&lt;/span&gt; &lt;span class="c1"&gt;//WARNING: SLOW AS MOLASSES&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="k"&gt;readonly&lt;/span&gt; &lt;span class="kt"&gt;object&lt;/span&gt; &lt;span class="n"&gt;Target&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="k"&gt;readonly&lt;/span&gt; &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Reflection&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MethodInfo&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;Methodinfos&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="n"&gt;Constructor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;Type&lt;/span&gt; &lt;span class="n"&gt;twinee&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;object&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Target&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Methodinfos&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;twinee&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GetMethods&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;BindingFlags&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Public&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;BindingFlags&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NonPublic&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="n"&gt;BindingFlags&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Instance&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;object&lt;/span&gt; &lt;span class="n"&gt;AnyCall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;selector&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;object&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;arguments&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Methodinfos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;selector&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;Invoke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;Target&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arguments&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Note that untwiner creation could be optimized by caching the MethodInfos of frequently used types, but that's not the problem; the real bottleneck is the &lt;code&gt;MethodInfo.Invoke()&lt;/code&gt; call. If you put a breakpoint on the target and examine the stack, you will see that between the &lt;code&gt;AnyCall&lt;/code&gt; frame and the target frame there will be a managed-to-native transition and a native-to-managed transition, which is something to be avoided at all costs.&lt;/p&gt;
&lt;p&gt;Also note: it is impossible to write a reflecting entwiner.&lt;/p&gt;
&lt;h3 id="automating-it-with-intertwine"&gt;Automating it with Intertwine
&lt;/h3&gt;&lt;p&gt;The Intertwine library will automatically generate for us a pair of optimally-performing entwiner and untwiner classes for any interface. These classes are generated at runtime, so no extra build step is needed. To accomplish this, the C# implementation of Intertwine generates MSIL and creates assemblies from it; the Java Implementation generates bytecode and creates classes from it.&lt;/p&gt;
&lt;p&gt;The following method of the &lt;code&gt;Intertwine.Factory&lt;/code&gt; class creates an entwiner:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="n"&gt;NewEntwiner&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;(&lt;/span&gt; &lt;span class="n"&gt;AnyCall&lt;/span&gt; &lt;span class="n"&gt;anycall&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;For &lt;code&gt;T&lt;/code&gt; we give the type of our interface, and for &lt;code&gt;anycall&lt;/code&gt; we give a delegate of ours that will be receiving calls. This method returns a reference to an implementation of our interface, provided by an Entwiner-derived class that has been dynamically generated specifically for our interface, and instantiated to work with the given &lt;code&gt;AnyCall&lt;/code&gt; instance. For every call received through a method of our interface, this special entwiner will be marshalling the arguments and forwarding the call to our &lt;code&gt;AnyCall&lt;/code&gt; delegate.&lt;/p&gt;
&lt;p&gt;The following method of the &lt;code&gt;Intertwine.Factory&lt;/code&gt; class creates an untwiner:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="n"&gt;AnyCall&lt;/span&gt; &lt;span class="n"&gt;NewUntwiner&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;(&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;For target we give an implementation of our interface, and what we get is a reference to an &lt;code&gt;AnyCall&lt;/code&gt; delegate implemented by an Untwiner-derived class that was dynamically generated specifically for our interface, and instantiated to work with the given target instance. For every call received through the &lt;code&gt;AnyCall&lt;/code&gt; delegate, this special untwiner will be unmarshalling the arguments and forwarding the call to the appropriate method of our target interface.&lt;/p&gt;
&lt;p&gt;So, with the dynamically generated entwiners and untwiners we can now do the following epicness:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;span class="lnt"&gt;6
&lt;/span&gt;&lt;span class="lnt"&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="n"&gt;Run3&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;IFooable&lt;/span&gt; &lt;span class="n"&gt;fooable&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;FooImplementation&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;AnyCall&lt;/span&gt; &lt;span class="n"&gt;untwiner&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Intertwine&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Factory&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NewUntwiner&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;IFooable&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;(&lt;/span&gt; &lt;span class="n"&gt;fooable&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;IFooable&lt;/span&gt; &lt;span class="n"&gt;entwiner&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Intertwine&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Factory&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NewEntwiner&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;IFooable&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;(&lt;/span&gt; &lt;span class="n"&gt;untwiner&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;InvokeFoo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;entwiner&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;The actual implementation of &lt;code&gt;Intertwine.Factory&lt;/code&gt; is pretty straightforward, so there is not much to talk about. As one might expect, the generated types are cached. A static factory method is generated with each generated type, for instantiating the type, so as to avoid having to call &lt;code&gt;Activator.CreateInstance()&lt;/code&gt;, because that method uses reflection. The static factory method is invoked using &lt;code&gt;Delegate.Invoke()&lt;/code&gt;, which does not use reflection. You will find the code-generating code choke-full of comments, explaining exactly what each emitted opcode does.&lt;/p&gt;
&lt;p&gt;Intertwine for C#:
&lt;a class="external"
href="https://github.com/mikenakis/IntertwineCSharp" target="_blank"
&gt;https://github.com/mikenakis/IntertwineCSharp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Intertwine for Java:
&lt;a class="external"
href="https://github.com/mikenakis/Public/tree/master/intertwine" target="_blank"
&gt;https://github.com/mikenakis/Public/tree/master/intertwine&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="appendix-an-example-interface-multicasts-events-in-c"&gt;Appendix: An example: Interface multicasts (events) in C#
&lt;/h3&gt;&lt;p&gt;If you are still with me you may be thinking that it is about time for a demonstration. What follows is not just an example, but actually a complete and useful application of intertwine which you may be able to start utilizing in your projects right away.&lt;/p&gt;
&lt;p&gt;The C# language has built-in support for multicasts (events) but only delegates can be used as event observers. There are many cases, however, where interfaces would be more suitable. Java does not even have built-in support for multicasts, so programmers generally have to write their own, using single-method (functional) interfaces. In either language, if you want to achieve multicasting on multi-method interfaces, you have to rewrite the multicasting code for every single method of every single interface.&lt;/p&gt;
&lt;p&gt;Consider the following interface:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;span class="lnt"&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;interface&lt;/span&gt; &lt;span class="nc"&gt;ITableNotification&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="n"&gt;RowInserted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;Fields&lt;/span&gt; &lt;span class="n"&gt;fields&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="n"&gt;RowDeleted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;Key&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="n"&gt;RowUpdated&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;Key&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Fields&lt;/span&gt; &lt;span class="n"&gt;fields&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;And consider the following hypothetical (not actually possible) way of using it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;event&lt;/span&gt; &lt;span class="n"&gt;ITableNotification&lt;/span&gt; &lt;span class="n"&gt;tableNotificationEvent&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;tableNotificationEvent&lt;/span&gt; &lt;span class="p"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;my_observer&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;tableNotificationEvent&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RowUpdated&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fields&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;The above does not work because events in C# work only with delegates, not with interfaces. However, with Intertwine, the next best thing is actually possible:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;var&lt;/span&gt; &lt;span class="n"&gt;tableNotificationEventManager&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;InterfaceEventManager&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;ITableNotifcation&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;tableNotificationEventManager&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Source&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RegisterObserver&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;my_observer&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;tableNotificationEventManager&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Trigger&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RowUpdated&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fields&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;This approach is self-explanatory, and the amount of code you have to write in order to use it is optimal; you do not need to deal with anything more than what is necessary, and if you ever add a notification, it will be a new interface method, so all existing implementations of that interface will automatically be flagged by the compiler as incomplete. With the help of Intertwine, this event manager is implemented in just 150 lines of code, including extensive comments.&lt;/p&gt;
&lt;h3 id="end-notes"&gt;End-notes
&lt;/h3&gt;&lt;p&gt;Back in 2011 I posted a question on stackoverflow.com, titled &lt;a class="external"
href="https://stackoverflow.com/questions/6154205/multiplexing-interface-method-calls-into-a-single-delegate-and-demultiplexing" target="_blank"
&gt;Multiplexing interface method calls into a single delegate and demultiplexing&lt;/a&gt; asking if anyone knows of anything like Intertwine, but nobody did, so I built it myself.&lt;/p&gt;
&lt;p&gt;This post supersedes the original post from 2011: &lt;a
href="https://blog2.michael.gr/post/2011-10-16-intertwine-normalizing-interface/"
&gt;Intertwine: Normalizing Interface Invocations&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: The Intertwine Logo, by michael.gr&lt;/p&gt;</description></item><item><title>So the "master" branch is not kosher anymore</title><link>https://blog2.michael.gr/post/2022-12-master-branch-not-kosher/</link><pubDate>Fri, 27 May 2022 09:12:37 +0000</pubDate><guid>https://blog2.michael.gr/post/2022-12-master-branch-not-kosher/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2022-12-master-branch-not-kosher/media/slavery-cropped.jpg"
width="2775"
height="1684"
srcset="https://blog2.michael.gr/post/2022-12-master-branch-not-kosher/media/slavery-cropped_hu_8ae04781ddc88246.jpg 480w, https://blog2.michael.gr/post/2022-12-master-branch-not-kosher/media/slavery-cropped_hu_58a6348cfbae9cec.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="164"
data-flex-basis="395px"
&gt;
&lt;/p&gt;
&lt;p&gt;The origins of the debate go so far back that they are lost in the mists of time, but a good starting point (which contains references to prior debate) is an Internet Draft from 2018 titled &lt;em&gt;&lt;a class="external"
href="https://datatracker.ietf.org/doc/draft-knodel-terminology/" target="_blank"
&gt;Terminology, Power, and Inclusive Language in Internet-Drafts and RFCs&lt;/a&gt;&lt;/em&gt;. Some especially &lt;a class="external"
href="https://www.urbandictionary.com/define.php?term=woke" target="_blank"
&gt;woke&lt;/a&gt; communities like the Python community had already started applying some of the recommendations in this draft as early as 2019, but things really picked up steam in 2020, with &lt;a class="external"
href="https://en.wikipedia.org/wiki/Murder_of_George_Floyd" target="_blank"
&gt;the murder of George Floyd&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Programmers all over the world, the overwhelming majority of whom are white boys, wanted to feel like they are doing something about the whole &lt;a class="external"
href="https://en.wikipedia.org/wiki/Black_Lives_Matter" target="_blank"
&gt;Black Lives Matter&lt;/a&gt; thing, but killing cops is a bit difficult, let alone messy, not to mention risky, and what if there is one good cop in the USA and we kill him? -- so they resorted to the next best thing: &lt;em&gt;using more sensitive language&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Naturally, every company that caters to &lt;a class="external"
href="https://www.urbandictionary.com/define.php?term=Wokey" target="_blank"
&gt;wokeys&lt;/a&gt; needed to show that they are more woke than the next one, and changing terminology is such a cheap and easy thing to do compared to the amount of good publicity it generates that it is actually a bargain; thus, all mega-corporations were suddenly competing on who will revise more politically incorrect terms faster. This involved the identification of politically incorrect terms that we were previously unaware of, and in some cases even the invention of some.&lt;/p&gt;
&lt;p&gt;The 2018 Internet Draft about inclusive language says nothing about the master branch; it suggests, among other things, to rename the term master/slave to something else, e.g. primary/secondary. This change is arguably worth making; not so much because of its inherent merit, (it has very little of that,) but because we have to acknowledge the possibility that we are unable to put ourselves in the shoes of people who might be hurt by the use of the term. Rumor has it that if you ask actual black people about this issue, they are likely to tell you that they don't give a damn, but this is destined to slide by. Making this change also presupposes that we feel compelled to go out of our way to ease the pain of people who for whatever reasons feel hurt by various things, but that can also arguably be regarded as a reasonable thing to do.&lt;/p&gt;
&lt;p&gt;I am worried that one day people might start feeling hurt by the fact that I am sporting a beard, due to the unbearably toxic masculinity that it exudes and what not, but I guess I will deal with that when the day comes.&lt;/p&gt;
&lt;p&gt;Now, if the abolition of master/slave hardly had any real grounds to stand on, the abolition of the master branch is absolutely groundless, because in this case the word &amp;quot;master&amp;quot; is used in the sense of &amp;quot;original&amp;quot;, as in &amp;quot;master recording&amp;quot;. (See&lt;a class="external"
href="https://en.wiktionary.org/wiki/master" target="_blank"
&gt;&amp;quot;master&amp;quot; in wiktionary.org&lt;/a&gt;.) However, if we acknowledge someone the right to be offended by master/slave, then who are we to take away their right to also be offended by master branch? After all, don't forget that we have already established that we are incapable of putting ourselves in their shoes, right?&lt;/p&gt;
&lt;p&gt;So, once the abolition of &amp;quot;master/slave&amp;quot; was unanimously agreed upon, the master branch was naturally next. It was just a matter of &lt;em&gt;the innocent paying along with the guilty&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;After some debate, (see &lt;a class="external"
href="https://git.github.io/rev_news/2020/07/29/edition-65/" target="_blank"
&gt;Git Rev News: Edition 65&lt;/a&gt;) both git and GitHub announced in 2020 that they were moving in the direction of renaming the default branch from &amp;quot;master&amp;quot; to main. In October of that year, GitHub &lt;a class="external"
href="https://github.com/github/renaming" target="_blank"
&gt;proceeded with the change&lt;/a&gt;. Lots of other mega-corporations followed suit. One article which skips the whys and the why-nots and just talks about the technical aspects of this transition is &lt;a class="external"
href="https://www.biteinteractive.com/of-git-and-github-master-and-main/" target="_blank"
&gt;&lt;em&gt;Of Git and GitHub, Master and Main&lt;/em&gt; by Matt Neuburg, 2021&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So, we shall all rename our &amp;quot;master&amp;quot; branches to &amp;quot;main&amp;quot;. You might &lt;em&gt;think&lt;/em&gt; that you can get away with using &amp;quot;main&amp;quot; only for new projects and leaving old projects alone, but that will not quite cut it, because then you will be left with eternal confusion since you will have different projects with different default branch names and you will have to always remember which is which. Trying to remember things is the stuff mistakes are made of, and mistakes with branches tend to have very severe consequences. So, all master branches will have to be renamed to main everywhere.&lt;/p&gt;
&lt;p&gt;Is it silly? Yes. Is it a waste of time? Yes. Is it giving in to &lt;a class="external"
href="https://www.urbandictionary.com/define.php?term=Wokeism" target="_blank"
&gt;wokeism&lt;/a&gt;? Yes. But you have to pick your battles. You have to question whether you want to engage in an argument with a broader cause that you are already in alignment with anyway. As a manager, it is easier to suffer the small technical pain of transitioning from &amp;quot;master&amp;quot; to main&amp;quot; than to spend valuable time debating the whole silly thing, and running the risk of appearing as a bigot in the process.&lt;/p&gt;
&lt;p&gt;Having said all that, let me state that on the broad picture, I am completely with Bill Maher on this: the liberal world is going mad with political correctness, sense of entitlement, &lt;a class="external"
href="https://www.urbandictionary.com/define.php?term=snowflakeism" target="_blank"
&gt;snowflakeism&lt;/a&gt;, and &lt;a class="external"
href="https://www.urbandictionary.com/define.php?term=wokeness" target="_blank"
&gt;wokeness&lt;/a&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;img src="https://blog2.michael.gr/post/2022-12-master-branch-not-kosher/media/grumpy-cat-wokeness.jpg"
width="843"
height="565"
srcset="https://blog2.michael.gr/post/2022-12-master-branch-not-kosher/media/grumpy-cat-wokeness_hu_bfd19a0acccbf67b.jpg 480w, https://blog2.michael.gr/post/2022-12-master-branch-not-kosher/media/grumpy-cat-wokeness_hu_6dd0e5589091004e.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="149"
data-flex-basis="358px"
&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;Mandatory grumpy cat meme: Wokeness? How About NO.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</description></item><item><title>Incremental Integration Testing</title><link>https://blog2.michael.gr/post/2022-10-incremental-integration-testing/</link><pubDate>Tue, 14 Dec 2021 09:07:09 +0000</pubDate><guid>https://blog2.michael.gr/post/2022-10-incremental-integration-testing/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2022-10-incremental-integration-testing/media/incremental_integration_testing.svg"
loading="lazy"
&gt;
&lt;/p&gt;
&lt;h3 id="abstract"&gt;Abstract
&lt;/h3&gt;&lt;p&gt;A new method for &lt;em&gt;&lt;strong&gt;Automated Software Testing&lt;/strong&gt;&lt;/em&gt; is presented as an alternative to &lt;em&gt;&lt;strong&gt;Unit Testing&lt;/strong&gt;&lt;/em&gt;. The new method retains the benefit of Unit Testing, which is &lt;em&gt;&lt;strong&gt;Defect Localization&lt;/strong&gt;&lt;/em&gt;, but eliminates white-box testing and mocking, thus greatly lessening the effort of writing and maintaining tests.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id="summary"&gt;Summary
&lt;/h3&gt;&lt;p&gt;Unit Testing aims to achieve Defect Localization by replacing the collaborators of the Component Under Test with Mocks. As we will show, the use of Mocks is laborious, complicated, over-specified, presumptuous, and constitutes testing against the implementation, not against the interface, thus leading to brittle tests that hinder refactoring rather than facilitating it.&lt;/p&gt;
&lt;p&gt;To avoid these problems, &lt;em&gt;&lt;strong&gt;Incremental Integration Testing&lt;/strong&gt;&lt;/em&gt; allows each component to be tested in integration with its collaborators, (or with Fakes thereof,) thus completely abolishing Mocks. Defect Localization is achieved by arranging the order in which tests are executed so that the collaborators of a component get tested before the component gets tested, and stopping as soon as a defect is encountered.&lt;/p&gt;
&lt;p&gt;Thus, when a test discovers a defect, we can be sufficiently confident that the defect lies in the component being tested, and not in any of its collaborators, because by that time, the collaborators have passed their tests.&lt;/p&gt;
&lt;h3 id="the-problem"&gt;The problem
&lt;/h3&gt;&lt;p&gt;The goal of automated software testing in general, regardless of what kind of testing it is, is to exercise a software system under various usage scenarios to ensure that it meets its requirements and that it is free from defects. The most simple and straightforward way to achieve this is to set up some input, invoke the system to perform a certain job, and then examine the output to ensure that it is what it is expected to be.&lt;/p&gt;
&lt;p&gt;Unfortunately, this approach only really works in the &amp;quot;sunny day&amp;quot; scenario: if no defects are discovered by the tests, then everything is fine; however, if defects are discovered, we are faced with a problem: the system consists of a large network of collaborating software components, and the test is telling us that there is a defect somewhere, but it is unclear in which component the problem lies. Even if we divide the system into subsystems and try to test each subsystem separately, each subsystem may still consist of many components, so the problem remains.&lt;/p&gt;
&lt;p&gt;What it ultimately boils down to is that each time we test a component, and a defect is discovered, it is unclear whether the defect lies in the component being tested, or in one or more of its collaborators.&lt;/p&gt;
&lt;p&gt;Ideally, we would like each test to be conducted in such a way as to detect defects specifically in the component that is being tested, instead of extraneous defects in its collaborators; in other words, we would like to achieve &lt;em&gt;Defect Localization&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id="the-existing-solution-unit-testing"&gt;The existing solution: Unit Testing
&lt;/h3&gt;&lt;p&gt;&lt;a class="external"
href="https://en.wikipedia.org/wiki/Unit_testing" target="_blank"
&gt;Unit Testing&lt;/a&gt; was invented specifically in order to achieve defect localization. It takes an extremely drastic approach: if the use of collaborators introduces uncertainties, one way to eliminate those uncertainties is to eliminate the collaborators. Thus, Unit Testing aims to test each component in strict isolation. Hence, its name.&lt;/p&gt;
&lt;p&gt;To achieve this remarkably ambitious goal, Unit Testing refrains from supplying the component under test with the actual collaborators that it would normally receive in a production environment; instead, it supplies the component under test with specially crafted &lt;em&gt;&lt;strong&gt;substitutes&lt;/strong&gt;&lt;/em&gt; of its collaborators, otherwise known as &lt;em&gt;&lt;strong&gt;test doubles&lt;/strong&gt;&lt;/em&gt;. There exist a few different kinds of substitutes, but by far the most widely used kind is &lt;em&gt;&lt;strong&gt;Mocks.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Each Mock must be hand-written for every individual test that is performed; it exposes the same interface as the real collaborator that it substitutes, and it expects specific methods of that interface to be invoked by the component-under-test, with specific argument values, sometimes even in a specific order of invocation. If anything goes wrong, such as an unexpected method being invoked, an expected method &lt;em&gt;not&lt;/em&gt; being invoked, or a parameter having an unexpected value, the Mock fails the test. When the component-under-test invokes one of the methods that the Mock expects to be invoked, the Mock does nothing of the sort that the real collaborator would do; instead, the Mock is hard-coded to yield a fabricated response which is intended to exactly match the response that the real collaborator would have produced if it was being used, and if it was working exactly according to its specification.&lt;/p&gt;
&lt;p&gt;Or at least, that is the intention.&lt;/p&gt;
&lt;h3 id="drawbacks-of-unit-testing"&gt;Drawbacks of Unit Testing
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Complex and laborious&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;In each test it is not enough to simply set up the input, invoke the component, and examine the output; we also have to anticipate every single call that the component will make to its collaborators, and for each call we have to set up a mock, expecting specific parameter values, and producing a specific response aiming to emulate the real collaborator under the same circumstances. Luckily, mocking frameworks lessen the amount of code necessary to accomplish this, but no matter how terse the mocking code is, the fact still remains that it implements a substantial amount of functionality which represents considerable complexity.&lt;/li&gt;
&lt;li&gt;One of the well-known caveats of software testing at large (regardless of what kind of testing it is) is that a test failure does not necessarily indicate a defect in the production code; it always indicates a defect either in the production code, or in the test itself. The only way to know is to troubleshoot. Thus, the more code we put in tests, and the more complex this code is, the more time we end up wasting in chasing and fixing bugs in the tests themselves rather than in the code that they are meant to test.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Over-specified&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Unit Testing is concerned not only with what a component accomplishes, but also with every little detail about how the component goes on about accomplishing it. This means that when we engage in Unit Testing we are essentially expressing all of our application logic twice: once with production code expressing the logic in imperative mode, and once more with testing code expressing the same logic in expectational mode. In both cases, we write copious amounts of code describing what should happen in excruciatingly meticulous detail.&lt;/li&gt;
&lt;li&gt;Note that with Unit Testing, over-specification might not even be goal in and of itself in some cases, but it is unavoidable in all cases. This is due to the elimination of the collaborators: the requests that the component under test sends to its collaborators could conceivably be routed into a black hole and ignored, but in order for the component under test to continue working so as to be tested, it still needs to receive a meaningful response to each request; thus, the test has to expect each request in order to produce each needed response, even if the intention of the test was not to know how, or even whether, the request is made.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Presumptuous&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Each Unit Test claims to have detailed knowledge of not only how the component-under-test invokes its collaborators, but also how each real collaborator would respond to each invocation in a production environment, which is a highly presumptuous thing to do.&lt;/li&gt;
&lt;li&gt;Such presumptuousness might be okay if we are building high-criticality software, where each collaborator is likely to have requirements and specification that are well-defined and unlikely to change; however, in all other software, which is regular, commercial, non-high-criticality software, things are a lot less strict: not only the requirements and specifications change all the time, but also quite often, the requirements, the specification, even the documentation, is the code itself, and the code changes every time a new commit is made to the source code repository. This might not be ideal, but it is pragmatic, and it is established practice. Thus, the only way to know exactly how a component behaves tends to be to actually invoke the latest version of that component and see how it responds, while the mechanism which ensures that these responses are what they are supposed to be is the tests of that component itself, which are unrelated to the tests of components that depend on it.&lt;/li&gt;
&lt;li&gt;As a result of this, Unit Testing often places us in the all too familiar situation where our Unit Tests all pass with flying colors, but our Integration Tests miserably fail because the behavior of the real collaborators turns out to be different from what the mocks assumed it would be.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fragile&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;During Unit Testing, if the interactions between the component under test and its collaborators deviate even slightly from our expectations, the test fails. However, these interactions may legitimately change as software evolves. This may happen due to the application of a bug-fix, due to refactoring, or due to the fact that whenever new code is added to implement new functionality, preexisting code must almost always be modified to accommodate the new code. With Unit Testing, every time we change the inner workings of production code, we have to go fixing all related tests to expect the new inner workings of that code.&lt;/li&gt;
&lt;li&gt;The original promise of Automated Software Testing was to enable us to continuously evolve software without fear of breaking it. The idea is that whenever you make a modification to the software, you can re-run the tests to ensure that everything still works as before. With Unit Testing this does not work, because every time you change the slightest thing in the production code you have to also change the tests, and you have to do this even for changes that are only internal. The understanding is growing within the software engineering community that Unit Testing with mocks actually hinders refactoring instead of facilitating it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Non-reusable&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Unit Testing exercises the implementation of a component rather than its interface. As such, the Unit Test of a certain component can only be used to test that component and nothing else. Thus, with Unit Testing the following things are impossible:
&lt;ul&gt;
&lt;li&gt;Completely rewrite a piece of production code and then reuse the old tests to make sure that the new implementation works exactly as the old one did.&lt;/li&gt;
&lt;li&gt;Reuse the same test to test multiple different components that implement the same interface.&lt;/li&gt;
&lt;li&gt;Use a single test to test multiple different implementations of a certain component, created by independently working development teams taking different approaches to solving the same problem.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The above disadvantages of Unit Testing are direct consequences of the fact that it is White-Box Testing by nature. What we need to be doing instead is Black-Box testing, which means that Unit Testing should be avoided, despite the entire Software Industry's addiction to it.&lt;/p&gt;
&lt;p&gt;Note that I am not the only one to voice dissatisfaction with Unit Testing with Mocks. People have been noticing that although tests are intended to facilitate refactoring by ensuring that the code still works after refactoring, tests often end up hindering refactoring, because they are so tied to the implementation that you can't refactor anything without breaking the tests. This problem has been identified by renowned personalities such as Martin Fowler and Ian Cooper, and even by Ken Beck, the inventor of Test-Driven Development (TDD).&lt;/p&gt;
&lt;p&gt;In the video &lt;em&gt;Thoughtworks - TW Hangouts: Is TDD dead?&lt;/em&gt; (&lt;a class="external"
href="https://www.youtube.com/watch?v=z9quxZsLcfo" target="_blank"
&gt;youtube&lt;/a&gt;) at 21':10'' Kent Beck says &amp;quot;My personal practice is I mock almost nothing&amp;quot; and at 23':56'' Martin Fowler says &amp;quot;I'm with Kent, I hardly ever use mocks&amp;quot;.&lt;/p&gt;
&lt;p&gt;In the &lt;em&gt;Fragile Test&lt;/em&gt; section of his book &lt;em&gt;xUnit Test Patterns: Refactoring Test Code&lt;/em&gt; (&lt;a class="external"
href="https://xunitpatterns.com/" target="_blank"
&gt;xunitpatterns.com&lt;/a&gt;) author Gerard Meszaros states that extensive use of Mock Objects causes overcoupled tests.&lt;/p&gt;
&lt;p&gt;In his presentation &lt;em&gt;TDD, where did it all go wrong?&lt;/em&gt; (&lt;a class="external"
href="https://www.infoq.com/presentations/tdd-original/" target="_blank"
&gt;InfoQ&lt;/a&gt;, &lt;a class="external"
href="https://www.youtube.com/watch?v=EZ05e7EMOLM" target="_blank"
&gt;YouTube&lt;/a&gt;) at 49':32'' Ian Cooper says &amp;quot;I argue quite heavily against mocks because they are overspecified.&amp;quot;&lt;/p&gt;
&lt;p&gt;Note that in an attempt to avoid sounding too blasphemous, none of these people calls for the complete abolition of mocks, they only warn against the excessive use of mocks. Furthermore, do not seem to be isolating the components under test, and yet they seem to have little, if anything, to say about any alternative means of achieving defect localization.&lt;/p&gt;
&lt;h3 id="a-new-solution-incremental-integration-testing"&gt;A new solution: Incremental Integration Testing
&lt;/h3&gt;&lt;p&gt;If we were to abandon Unit Testing with mocks, then one might ask what should we be doing instead. Obviously, we must somehow continue testing our software, and it would be nice if we can continue to be enjoying the benefits of defect localization.&lt;/p&gt;
&lt;p&gt;As it turns out, eliminating the collaborators is just one way of achieving defect localization; another, more pragmatic approach is as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Allow each component to be tested in integration with its collaborators, but only after each of the collaborators has undergone its own testing, and has successfully passed it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Thus, any observed malfunction can be attributed with a high level of confidence to the component being tested, and not to any of its collaborators, because the collaborators have already been tested.&lt;/p&gt;
&lt;p&gt;I call this &lt;em&gt;&lt;strong&gt;Incremental Integration Testing&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;An alternative way of arriving at the idea of Incremental Integration Testing begins with the philosophical observation that strictly speaking, there is no such thing as a Unit Test; there always exist collaborators which by established practice we never mock and invariably integrate in Unit Tests without blinking an eye; these are, for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Many of the external libraries that we use.&lt;/li&gt;
&lt;li&gt;Most of the functionality provided by the Runtime Environment in which our software runs.&lt;/li&gt;
&lt;li&gt;Virtually all of the functionality provided by the Runtime Library of the language we are using.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Nobody mocks standard collections such as array-lists, linked-lists, hash-sets, and hash-maps; very few people bother with mocking filesystems; nobody would mock a math library, a serialization library, and the like; even if one was so paranoid as to mock those, at the extreme end, nobody mocks the MUL and DIV instructions of the CPU; so clearly, there are always some things that we take for granted, and we allow ourselves the luxury of taking these things for granted because we believe that they have been sufficiently tested by their respective creators and can be reasonably assumed to be free of defects.&lt;/p&gt;
&lt;p&gt;So, why not also take our own creations for granted once we have tested them? Are we testing them sufficiently or not?&lt;/p&gt;
&lt;h3 id="prior-art"&gt;Prior Art
&lt;/h3&gt;&lt;p&gt;An internet search for &amp;quot;Incremental Integration Testing&amp;quot; does yield some results. An examination of those results reveals that they refer to some strategy for integration testing which is meant to be performed manually by human testers, constitutes an alternative to big-bang integration testing, and requires full Unit Testing of the traditional kind to have already taken place. I am hereby appropriating this term, so from now on it shall mean what I intend it to mean. If a context ever arises where disambiguation is needed, the terms &amp;quot;automated&amp;quot; vs. &amp;quot;manual&amp;quot; can be used.&lt;/p&gt;
&lt;p&gt;The first hints to Incremental Integration Testing can actually be found in the classic 1979 book &lt;em&gt;The Art of Software Testing&lt;/em&gt; by Glenford Myers. In chapter 5 &amp;quot;Module (Unit) Testing&amp;quot; the author plants the seeds of what later became white-box testing with mocks by writing:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[‚Ä¶] since module B calls module E, something must be present to receive control when B calls E. A stub module, a special module given the name &amp;quot;E&amp;quot; that must be coded to simulate the function of module E, accomplishes this.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;then, the author proceeds to write:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The alternative approach is incremental testing. Rather than testing each module in isolation, the next module to be tested is first combined with the set of modules &lt;em&gt;&lt;strong&gt;that have already been tested.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(emphasis mine.)&lt;/p&gt;
&lt;p&gt;Back in 1979, Glen Myers envisioned these approaches to testing as being carried out by human testers, manually launching tests and receiving printouts of results to examine. He even envisioned employing multiple human testers to perform multiple tests in parallel. In the last several decades we have much better ways of doing all of that.&lt;/p&gt;
&lt;h3 id="implementing-the-solution-the-poor-mans-approach"&gt;Implementing the solution: the poor man's approach
&lt;/h3&gt;&lt;p&gt;As explained earlier, Incremental Integration Testing requires that when we test a component, all of its collaborators must have already been tested. Thus, Incremental Integration Testing necessitates exercising control over the order in which tests are executed.&lt;/p&gt;
&lt;p&gt;Most testing frameworks execute tests in alphanumeric order, so if we want to change the order of execution all we have to do is to appropriately name the tests, and the directories in which they reside.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;p&gt;Let us suppose that we have the following modules:&lt;/p&gt;
&lt;p&gt;com.acme.alpha_depends_on_bravo&lt;br&gt;
com.acme.bravo_depends_on_nothing&lt;br&gt;
com.acme.charlie_depends_on_alpha&lt;/p&gt;
&lt;p&gt;Note how the modules are listed alphanumerically, but they are not listed in order of dependency.&lt;/p&gt;
&lt;p&gt;Let us also suppose that we have one test suite for each module. By default, the names of the test suites follow the names of the modules that they test, so again, a listing of the test suites in alphanumeric order does not match the order of dependency of the modules that they test:&lt;/p&gt;
&lt;p&gt;com.acme.alpha_depends_on_bravo_&lt;strong&gt;tests&lt;/strong&gt;&lt;br&gt;
com.acme.bravo_depends_on_nothing_&lt;strong&gt;tests&lt;/strong&gt;&lt;br&gt;
com.acme.charlie_depends_on_alpha_&lt;strong&gt;tests&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To achieve Incremental Integration Testing, we add a suitably chosen prefix to the name of each test suite, as follows:&lt;/p&gt;
&lt;p&gt;com.acme.&lt;strong&gt;T02&lt;/strong&gt;_alpha_depends_on_bravo_tests&lt;br&gt;
com.acme.&lt;strong&gt;T01&lt;/strong&gt;_bravo_depends_on_nothing_tests&lt;br&gt;
com.acme.&lt;strong&gt;T03&lt;/strong&gt;_charlie_depends_on_alpha_tests&lt;/p&gt;
&lt;p&gt;Note how the prefixes have been chosen in such a way as to establish a new alphanumerical order for the tests. Thus, an alphanumeric listing of the test suites now lists them in order of dependency of the modules that they test:&lt;/p&gt;
&lt;p&gt;com.acme.T01_bravo_depends_on_nothing_tests&lt;br&gt;
com.acme.T02_alpha_depends_on_bravo_tests&lt;br&gt;
com.acme.T03_charlie_depends_on_alpha_tests&lt;/p&gt;
&lt;p&gt;At this point Java developers might object that this is impossible, because in Java, the tests always go in the same module as the production code, directory names must match package names, and test package names always match production package names. Well, I have news for you: they don't have to. The practice of doing things this way is very widespread in the Java world, but there are no rules that require it: the tests do not in fact have to be in the same module, nor in the same package as the production code. The only inviolable rule is that directory names must match package names, but you can call your test packages whatever you like, and your test directories accordingly.&lt;/p&gt;
&lt;p&gt;Java developers tend to place tests in the same module as the production code simply because the tools (maven) have a built-in provision for this, without ever questioning whether there is any actual benefit in doing so. Spoiler: there isn't. As a matter of fact, in the DotNet world there is no such provision, and nobody complains. Furthermore, Java developers tend to place tests in the same package as the production code for no purpose other than to make package-private entities of their production code accessible from their tests, but this is testing against the implementation, not against the interface, and therefore, as I have already explained, it is misguided.&lt;/p&gt;
&lt;p&gt;So, I know that this is a very hard thing to ask from most Java developers, but trust me, if you would only dare to take a tiny step off the beaten path, if you would for once do something in a certain way for reasons other than &amp;quot;everyone else does it this way&amp;quot;, you can very well do the renaming necessary to achieve Incremental Integration Testing.&lt;/p&gt;
&lt;p&gt;Now, admittedly, renaming tests in order to achieve a certain order of execution is not an ideal solution. It is awkward, it is thought-intensive since we have to figure out the right order of execution by ourselves, and it is error-prone because there is nothing to guarantee that we will get the order right. That's why I call it &amp;quot;the poor man's approach&amp;quot;. Let us now see how all of this could be automated.&lt;/p&gt;
&lt;h3 id="implementing-the-solution-the-automated-approach"&gt;Implementing the solution: the automated approach
&lt;/h3&gt;&lt;p&gt;Here is an algorithm to automate Incremental Integration Testing:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Begin by building a model of the dependency graph of the entire software system.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;This requires system-wide static analysis to discover all components in our system, and all dependencies of each component. I did not say it was going to be easy.&lt;/li&gt;
&lt;li&gt;The graph should not include external dependencies, since they are presumed to have already been tested by their respective creators.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Test each leaf node in the model.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;A leaf node in the dependency graph is a node which has no dependencies; at this level, a Unit Test is indistinguishable from an Integration Test, because there are no dependencies to either integrate or mock.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;If any malfunction is discovered during step 2, then stop as soon as step 2 is complete.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;If a certain component fails to pass its test, it is counter-productive to proceed with the tests of components that depend on it. Unit Testing seems to be completely oblivious to this little fact; Incremental Integration Testing fixes this.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Remove the leaf nodes from the model of the dependency graph.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Thus removing the nodes that were previously tested in step 2, and obtaining a new, smaller graph, where a different set of nodes are now the leaf nodes.&lt;/li&gt;
&lt;li&gt;The dependencies of the new set of leaf nodes have already been successfully tested, so they are of no interest anymore: they are as good as external dependencies now.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Repeat starting from step 2, until there are no more nodes left in the model.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Allowing each component to be tested in integration with its collaborators, since they have already been tested.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;No testing framework that I know of (JUnit, MSTest, etc.) is capable of doing the above; for this reason, I have developed a utility which I call &lt;em&gt;&lt;strong&gt;Testana&lt;/strong&gt;&lt;/em&gt;, that does exactly that.&lt;/p&gt;
&lt;p&gt;Testana will analyze a system to discover its structure, will analyze modules to discover dependencies and tests, and will run the tests in the right order so as to achieve Incremental Integration Testing. It will also do a few other nice things, like keep track of last successful test runs, and examine timestamps, so as to refrain from running tests whose dependencies have not changed since the last successful test run. For more information, see &lt;a
href="https://blog2.michael.gr/post/2024-10-testana/"
&gt;Testana: A better way of running tests&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="what-if-my-dependencies-are-not-discoverable"&gt;What if my dependencies are not discoverable?
&lt;/h3&gt;&lt;p&gt;Some very trendy practices of our modern day and age include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using scripting languages, where there is no notion of types, and therefore no way of discovering dependencies via static analysis.&lt;/li&gt;
&lt;li&gt;Breaking up systems into disparate source code repositories, so there is no single system on which to perform system-wide static analysis to discover dependencies.&lt;/li&gt;
&lt;li&gt;Incorporating multiple different programming languages in a single system, (following the polyglot craze,) thus hindering system-wide static analysis, since it now needs to be performed on multiple languages and across language barriers.&lt;/li&gt;
&lt;li&gt;Making modules interoperate not via normal programmatic interfaces, but instead via various byzantine mechanisms such as REST, whose modus operandi is binding by name, thus making dependencies undiscoverable.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you are following any of the above trendy practices, then you cannot programmatically discover dependencies, so you have no way of automating Incremental Integration Testing, so you will have to manually specify the order in which your tests will run, and you will have to keep maintaining this order manually.&lt;/p&gt;
&lt;p&gt;Sorry, but silly architectural choices do come with consequences.&lt;/p&gt;
&lt;h3 id="what-about-performance"&gt;What about performance?
&lt;/h3&gt;&lt;p&gt;One might argue that Incremental Integration Testing does not address one very important issue which is nicely taken care of by Unit Testing with Mocks, and that issue is performance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When collaborators are replaced with Mocks, the tests tend to be fast.&lt;/li&gt;
&lt;li&gt;When actual collaborators are integrated, such as file systems, relational database management systems, messaging queues, and what not, the tests can become very slow.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To address the performance issue I recommend the use of &lt;em&gt;&lt;strong&gt;Fakes&lt;/strong&gt;&lt;/em&gt;, not Mocks. For an explanation of what Fakes are, and why they are incontestably preferable over Mocks, please read &lt;a
href="https://blog2.michael.gr/post/2022-10-testing-with-fakes/"
&gt;Testing with Fakes instead of Mocks&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;By supplying a component under test with a Fake instead of a Mock we benefit from great performance, while utilizing a collaborator which has already been tested by its creators and can be reasonably assumed to be free of defects. In doing so, we continue to avoid White-Box Testing and we keep defects localized.&lt;/p&gt;
&lt;p&gt;Furthermore, nothing prevents us from having our CI/CD server run the test of each component twice:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Once in integration with Fakes&lt;/li&gt;
&lt;li&gt;Once in integration with the actual collaborators&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This will be slow, but CI/CD servers generally do not mind. The benefit of doing this is that it gives further guarantees that everything works as intended.&lt;/p&gt;
&lt;h3 id="benefits-of-incremental-integration-testing"&gt;Benefits of Incremental Integration Testing
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;It greatly reduces the effort of writing and maintaining tests, by eliminating the need for mocking code in each test.&lt;/li&gt;
&lt;li&gt;It allows our tests to engage in Black-Box Testing instead of White-Box Testing. For an in-depth discussion of what is wrong with White-Box Testing, see &lt;a
href="https://blog2.michael.gr/post/2021-12-white-box-vs-black-box-testing/"
&gt;White-Box vs. Black-Box Testing&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;It makes tests more effective and accurate, by eliminating assumptions about the behavior of the real collaborators.&lt;/li&gt;
&lt;li&gt;It simplifies our testing operations by eliminating the need for two separate testing phases, one for Unit Testing and one for Integration Testing.&lt;/li&gt;
&lt;li&gt;It is unobtrusive, since it does not dictate how to construct the tests, it only dictates the order in which the tests should be executed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="arguments-and-counter-arguments"&gt;Arguments and counter-arguments
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Argument: Incremental Integration Testing assumes that a component which has been tested is free of defects.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A well-known caveat of software testing is that it cannot actually prove that software is free from defects, because it necessarily only checks for defects that we have anticipated and tested for. As Edsger W. Dijkstra famously put it, &amp;quot;program testing can be used to show the presence of bugs, but never to show their absence!&amp;quot;&lt;/p&gt;
&lt;p&gt;Counter-arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I am not claiming that once a component has been tested, it has been proven to be free from defects; all I am saying is that it can reasonably be assumed to be free from defects. Incremental Integration Testing is not meant to be a perfect solution; it is meant to be a pragmatic solution.&lt;/li&gt;
&lt;li&gt;The fact that testing cannot prove the absence of bugs does not mean that everything is futile in this vain world, and that we should abandon all hope in despair: testing might be imperfect, but it is what we can do, and it is in fact what we do, and practical, real-world observations show that it is quite effective.&lt;/li&gt;
&lt;li&gt;Most importantly: Any defects in an insufficiently tested component will not magically disappear if we mock that component in the tests of its dependents.
&lt;ul&gt;
&lt;li&gt;In this sense, the practice of mocking collaborators can arguably be likened to &lt;a class="external"
href="https://en.wikipedia.org/wiki/Ostrich_policy" target="_blank"
&gt;&lt;em&gt;Ostrich policy&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;On the contrary, continuing to integrate that component in subsequent tests gives us incrementally more opportunities to discover defects in it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Argument: Incremental Integration Testing fails to achieve complete defect localization.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If a certain component has defects which were not detected when it was being tested, these defects may cause tests of collaborators of that component to fail, in which case it will be unclear where the defect lies.&lt;/p&gt;
&lt;p&gt;Counter-arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is true that Incremental Integration Testing may fall short of achieving defect localization when collaborators have defects despite having already been tested. It is also true that Unit Testing with Mocks does not suffer from that problem when collaborators have defects; but then again, neither does it detect those defects. For that, it is necessary to always follow a round of Unit Testing with a round of Integration Testing. However, when the malfunction is finally observed during Integration Testing, we are facing the exact same problem that we would have faced if we had done a single round of Incremental Integration Testing instead: a malfunction is being observed which is not due to a defect in the root component of the integration, but instead due to a defect in some unknown collaborator. The difference is that Incremental Integration Testing gets us there faster.&lt;/li&gt;
&lt;li&gt;Let us not forget that the primary goal of software testing is to guarantee that software works as intended, and that defect localization is an important but nonetheless secondary goal. Incremental Integration Testing goes a long way towards achieving defect localization, but it may not achieve it perfectly, in favor of other conveniences, such as making it far more easy to write and maintain tests. So, it all boils down to whether Unit Testing represents overall more or less convenience than Incremental Integration Testing. I assert that Incremental Integration Testing is unquestionably far more convenient than Unit Testing.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Argument: Incremental Integration Testing only tests behavior; it does not check what is going on under the hood.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;With Unit Testing, you can ensure that a certain module not only produces the right results, but also that it follows an expected sequence of steps to produce those results. With Incremental Integration Testing you cannot observe the steps, you can only check the results. Thus, the internal workings of a component might be slightly wrong, or less than ideal, and you would never know.&lt;/p&gt;
&lt;p&gt;Counter-arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This is true, and this is why Incremental Integration Testing might be unsuitable for high-criticality software, where White-Box Testing is the explicit intention, since it is necessary to ensure not only that the software produces correct results, but also that its internals are working exactly according to plan. However, Incremental Integration Testing is not being proposed as a perfect solution, it is being proposed as a pragmatic solution: the vast majority of software being developed in the world is regular, commercial-grade, non-high-criticality software, where Black-Box Testing is appropriate and sufficient, since all that matters is that the requirements be met. Essentially, Incremental Integration Testing represents the realization that in the general case, tests which worry not only about the behavior, but also about the inner workings of a component, constitute over-engineering. For a more in-depth discussion about this, please read &lt;a
href="https://blog2.michael.gr/post/2021-12-white-box-vs-black-box-testing/"
&gt;White-Box vs. Black-Box Testing&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;In order to make sure that everything is happening as expected under the hood, you do not have to stipulate in excruciating detail what should be happening, you do not have to fail the tests at the slightest sign of deviation from what was expected, and you do not have to go fixing tests each time the expectations change. Another way of ensuring the same thing is to simply:
&lt;ul&gt;
&lt;li&gt;Gain visibility into what is happening under the hood.&lt;/li&gt;
&lt;li&gt;Be notified when something different starts happening.&lt;/li&gt;
&lt;li&gt;Visually examine what is now different.&lt;/li&gt;
&lt;li&gt;Vouch for the differences being as expected.
For more details about this, see &lt;a
href="https://blog2.michael.gr/post/2023-01-06-collaboration-monitoring/"
&gt;Collaboration Monitoring&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Argument: Incremental Integration Testing prevents us from picking a single test and running it.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;With Unit Testing, we can pick any individual test and run it. With Incremental Integration Testing, running an individual test of a certain component is meaningless unless we first run the tests of the collaborators of that component.&lt;/p&gt;
&lt;p&gt;Counter-arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Picking an individual test and running it is meaningless under all scenarios. It is usually done in the interest of saving time, but it is based on the assumption that we know what tests have been affected by the changes we just made to the source code. This is never a safe assumption to make.&lt;/li&gt;
&lt;li&gt;Instead of picking an individual test and running it, we need a way to automatically run all tests that have been affected by the changes we just made, which requires knowledge of the dependency graph of the system.&lt;/li&gt;
&lt;li&gt;If you are unsure as to exactly what you just changed, and exactly what depends on it, then consider using a tool like Testana, which figures all this out for you. See &lt;a
href="https://blog2.michael.gr/post/2024-10-testana/"
&gt;Testana: A better way of running tests&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Argument: Incremental Integration Testing requires additional tools.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Incremental Integration Testing is not supported by any of the popular testing frameworks, which means that in order to start practicing it, new tools are necessary. Obtaining such tools might be very difficult, if not impossible, and creating such tools might be difficult, because they would have to do advanced stuff like system-wide static analysis to discover the dependency graph of a system.&lt;/p&gt;
&lt;p&gt;Counter-arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;My intention is to show the way; if people see the way, the tools will come.&lt;/li&gt;
&lt;li&gt;I have already built such a tool which is compatible with some combinations of programming languages, build systems, and testing frameworks; see &lt;a
href="https://blog2.michael.gr/post/2024-10-testana/"
&gt;Testana: A better way of running tests&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Even in lack of tools, it is possible to start experimenting with Incremental Integration Testing today by following the poor-man's approach, which consists of simply naming the tests, and the directories in which they reside, in such a way that your existing testing framework will run them in the right order. This is described in the &amp;quot;poor man's approach&amp;quot; section of this paper.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="conclusion"&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;Unit Testing was invented in order to achieve defect localization, but as we have shown, it constitutes White-Box Testing, so it is laborious, over-complicated, over-specified, and presumptuous. Furthermore, it is not even, strictly speaking, necessary. Incremental Integration Testing is a pragmatic approach which achieves almost the same degree of defect localization but without the use of mocks, and in so doing it greatly reduces the effort of developing and maintaining tests.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: &lt;em&gt;Incremental Integration Testing&lt;/em&gt; by michael.gr&lt;/p&gt;</description></item><item><title>So, what is a Microservice, anyway?</title><link>https://blog2.michael.gr/post/2021-10-so-what-is-microservice-anyway/</link><pubDate>Thu, 14 Oct 2021 17:39:23 +0000</pubDate><guid>https://blog2.michael.gr/post/2021-10-so-what-is-microservice-anyway/</guid><description>&lt;p&gt;This article attempts to shed some light on what a microservice really is; it
is meant as support material for other posts of mine that discuss
microservices, mainly
&lt;a
href="https://blog2.michael.gr/post/2021-10-14-the-stateful-microservice/"
&gt;The Stateful Microservice&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2021-10-so-what-is-microservice-anyway/media/microservices.svg"
loading="lazy"
&gt;
&lt;/p&gt;
&lt;h3 id="what-is-a-microservice"&gt;What is a microservice?
&lt;/h3&gt;&lt;p&gt;If you go looking for information on what a microservice is, you will find
many different descriptions, exhibiting considerable difference of opinion.
Most claims about microservices are non-technical rather than technical, for
example the allegedly &amp;quot;independent&amp;quot; software development style around
microservices, or some alleged organization of microservices &amp;quot;around business
capabilities&amp;quot;. Even when the claims do stick within the technical realm, they
are often unwarranted; for example, I have seen statements to the effect that
a microservice is supposed to live in its very own source code repository,
that microservices must communicate with each other via nothing but REST, etc.
My favorite one is that they must necessarily be stateless. This paper is a
first step in dispelling the statelessness myth.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;To clear up the confusion a little bit, I would like to propose a purely
technical definition of a microservice which is brief and to the point:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;From a purely technical standpoint, a microservice is a scalable module.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, what I am proposing here is that the only fundamental technical
requirement for a microservice is scalability, and that all other purported
characteristics mentioned in the literature are either non-technical, or they
are byproducts of this fundamental technical requirement.&lt;/p&gt;
&lt;p&gt;You see, there was a time back in the late 1990s to early 2000s when users
were joining websites at exponential rates, and servers running monolithic web
apps were reaching capacity and could not deliver service anymore; the
business people were asking the technologists to fix this, because they were
losing money, and the technologists were saying that they could not do
anything, because they already had the biggest, most expensive server that
money could buy. The business people would na?vely say &amp;quot;well, add more
servers!&amp;quot; to which the technologists would (equally na?vely) reply &amp;quot;you don't
understand, that's impossible!&amp;quot; Later on the technologists started realizing
that it is in fact possible, it just requires a radical change in their way of
thinking, and a radical redesign of all their systems. When the sums of money
at stake were high enough to justify redoing everything from scratch, scalable
systems started appearing, and are commonplace today.&lt;/p&gt;
&lt;p&gt;The new software development paradigm that was allowing web sites to achieve
scalability received a name quite some time after it first started being put
to use; the naming happened some time in the mid 2000s, and it was
&lt;em&gt;microservices&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Then of course came the evangelists. Unfortunately, when people become
salespersons of a cause, for some reason they never seem to be satisfied with
simply mentioning the one real, game-changing advantage that their product has
over the alternatives; instead, they feel compelled to throw as much as
possible at the customer, inventing advantages if possible. That's how all the
fictitious characteristics of microservices came to be. However, the truth
remains that there was one and only one thing that business needed which could
not be achieved otherwise, and therefore business was willing to pay for it
limitlessly, and that one thing was scalability, nothing else. (1)&lt;/p&gt;
&lt;p&gt;Business could not care less whether the software gets deployed in pieces or
in a big bang; business could not care less whether development is done by
autonomous teams or by all the programmers shouting at each other in one big
room; business could not care less whether the software communicates via REST
or via pheromone secretion. Things were getting done before, and things would
continue getting done, regardless of those alleged &amp;quot;advantages&amp;quot; of
microservices. Scalability was the only thing that was impossible before
microservices and was made possible by microservices.&lt;/p&gt;
&lt;p&gt;Of course, you might not agree with this definition; if not, then please take
it as nothing but a working definition, and only for the purpose of these
papers about statelessness.&lt;/p&gt;
&lt;p&gt;There is one more characteristic of microservices which is not really fundamental, because it is a direct
consequence of the first, but it is so
important that it deserves mentioning as a requirement, and this is resilience.&lt;/p&gt;
&lt;p&gt;You see, scalable architectures are not magically capable of performing better
than monolithic ones; in fact, quite the opposite is true: in terms of raw
throughput per unit of hardware, scalable architectures perform much worse
than monolithic ones. In order to accommodate the same workload that you used
to have with a single server running a monolithic application, you might need several
servers running microservices. The benefit of the scalable architecture is
that you can in fact now throw more hardware at the problem, instead of being
stuck with a single piece of hardware. So, given enough money to buy enough
hardware you can end up with a higher sum of throughput despite the worse
throughput per unit of hardware. Thus, when we are talking about scalability, we
are usually talking about a lot of hardware. And by this I mean &lt;em&gt;an awful lot&lt;/em&gt; of hardware.&lt;/p&gt;
&lt;p&gt;Now, it just so happens that hardware, being necessarily bound to the
constraints of the &lt;em&gt;physical world?&lt;/em&gt;, has this inconvenient
characteristic called &amp;quot;Mean Time Before Failure&amp;quot; (MTBF) which is of a somewhat
statistical nature: the more pieces of hardware you have, the higher the
chances are that any one of them will fail at any given moment. Furthermore,
as these pieces age, their individual chances of failure at any given moment
increase. The result of all this is that hardware failure in server farms
becomes not just something that there is a high risk of; not even just
something that is inevitable; it actually becomes a regularly occurring
phenomenon. As such, hardware failure cannot be addressed on an as-needed
basis via crisis management responses; it must be addressed systematically, as
a normal part of the operation of the system. This means that the software
that runs on that hardware must be capable of continuing to function as if
nothing happened despite pieces of the hardware randomly failing and being
replaced all the time.&lt;/p&gt;
&lt;p&gt;A software system that manages to continue functioning despite parts of it
ceasing to work is called a resilient software system. If we want to add the
resilience concern into our definition, then this is what we are left with:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;From a purely technical standpoint, a microservice is a scalable and resilient
module.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Further reading: &lt;a
href="https://blog2.michael.gr/post/2021-10-on-stateless-microservices/"
&gt;On Stateless Microservices&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;(1) According to Neal Ford, this started with Pets.com; see &lt;a class="external"
href="https://youtu.be/fYWvTYFmVYs?t=2156" target="_blank"
&gt;Neal Ford: &amp;quot;Stories Every Developer Should Know&amp;quot; at YOW! 2018, starting at 35:56&lt;/a&gt;&lt;/p&gt;</description></item><item><title>The Stateful Microservice</title><link>https://blog2.michael.gr/post/2021-10-14-the-stateful-microservice/</link><pubDate>Thu, 14 Oct 2021 16:58:10 +0000</pubDate><guid>https://blog2.michael.gr/post/2021-10-14-the-stateful-microservice/</guid><description>&lt;p&gt;I did a quick search for the term and did not find anything concrete, so I
thought I might as well publicly document my thoughts.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2021-10-14-the-stateful-microservice/media/elephants.jpg"
width="2048"
height="1365"
srcset="https://blog2.michael.gr/post/2021-10-14-the-stateful-microservice/media/elephants_hu_cfac862bf8819bb5.jpg 480w, https://blog2.michael.gr/post/2021-10-14-the-stateful-microservice/media/elephants_hu_6c0c09c376128914.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
&gt;
&lt;/p&gt;
&lt;p&gt;(Useful pre-reading:
&lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Almost everyone doing microservices today will tell you that microservices
need to be stateless. In another post of mine I explain that statelessness is
not an end in and of itself; instead, it is just a means to an end. The
desired technical ends are scalability and resilience, and statelessness is just one way of achieving them. Furthermore, I explain that statelessness
in particular is a very cowardly solution from an engineering standpoint, and
it performs very badly. For details, please see
&lt;a
href="https://blog2.michael.gr/post/2021-10-on-stateless-microservices/"
&gt;On Stateless Microservices&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What remains to be shown is whether there exists an alternative.&lt;/p&gt;
&lt;p&gt;Obviously, an alternative to the stateless microservice would be the stateful
microservice, so what we are about to examine here is what a stateful
microservice could possibly be, and how it would compare to a stateless
microservice.&lt;/p&gt;
&lt;h4 id="what-is-a-stateful-microservice"&gt;What is a stateful microservice
&lt;/h4&gt;&lt;p&gt;A stateful microservice maintains state for the purpose of expediting the
processing of incoming requests, reducing overall server load, (trading memory
for processing power and data storage traffic,) and achieving certain things
that are difficult to achieve otherwise, such as server-initiated client
updates.&lt;/p&gt;
&lt;p&gt;The state kept by a stateful microservice can include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;State that has been obtained from the main data store and has possibly
undergone expensive transformations. The benefit of maintaining such
transient state within the microservice is that the data store does not
need to be re-queried, and the possibly expensive transformations do not
need to be repeated, with each incoming request; the loading and
processing of the data only needs to happen once when the microservice
starts, and to be repeated only in response to a notification from the
system's messaging backbone that the original data in the main data store
has changed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;State that does not exist in the main data store, and does not need to,
because it is of a transient nature, for example information that is only
needed during user's visit to a web site and can be dismissed afterwards.
This can include information necessary for maintaining a session, such as
the session token, and view-related information, such as which page (or
pages) of the web site the user is currently viewing. View-related
information may be useful for the server to have for various reasons, for
example for the purpose of sending server-initiated client updates that
are specific to the web page(s) that are being viewed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;State that may eventually be entered into the main data store but has not
yet been entered due to various workflow demands or optimization concerns.
For example, the user may be sequentially visiting each page of a wizard
workflow, and entering information on each page, but this information
should not be merged into the main data store unless the user first
reaches the last page of the wizard workflow and confirms their actions.&lt;/p&gt;
&lt;p&gt;From the above it should be obvious that a stateful microservice is
necessarily session-oriented, meaning that it requires a specific client to
talk to. Session-agnostic stateful microservices already exist, and we do not
think of them as anything special; they are microservices that implement
caches, containing information that is pertinent to not just one client, but
to all clients. These microservices are already scalable and resilient because
a cache can be trivially duplicated to an arbitrary degree and it can also be
destroyed and trivially re-created from scratch.&lt;/p&gt;
&lt;p&gt;We now need to show how a stateful microservice can still be called a
microservice.&lt;/p&gt;
&lt;p&gt;In a previous post of mine I examined what a microservice really is, and I
came to the conclusion that from a purely technical standpoint, it is simply a scalable and resilient module. (See
&lt;a
href="https://blog2.michael.gr/post/2021-10-so-what-is-microservice-anyway/"
&gt;So, what is a Microservice, anyway?&lt;/a&gt;) Even if you disagree with this definition, and you regard microservices as
necessarily more than that, I hope you will at least agree that the purpose of
statelessness in microservices is precisely to achieve scalability and
resilience, so the definition of a microservice as a scalable and resilient
module can serve as a working definition for the purposes of this discussion.&lt;/p&gt;
&lt;p&gt;So, we need to show how stateful microservices can be scalable and resilient,
just as their stateless counterparts are.&lt;/p&gt;
&lt;p&gt;Scalability in stateful microservices can be achieved by means of a
header-inspecting, session-aware, load balancing gateway which routes new
session requests to the least busy server, and from that moment on keeps
routing requests of that same session to the same server. Under such a
scenario, rebalancing of the server farm can be achieved simply by killing
microservices on overloaded servers and letting the resilience mechanism
described next make things right.&lt;/p&gt;
&lt;p&gt;Resilience can be achieved by having each instance of a stateful microservice
continuously persisting its transient state in an efficient manner into a
high-performance backup store which is accessible by all servers in the farm.
Thus, if a microservice unexpectedly ceases to exist, it can be reconstructed
from that backup on any other server. The trick, as we shall see, is that the
backup is taken very efficiently, and in the event that the microservice needs
to be reconstructed, the restoration from the backup is also done very
efficiently.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In more detail, it works as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When a client initially connects to the server farm, no session has been
established yet, so the first request that it sends is sessionless.&lt;/li&gt;
&lt;li&gt;The sessionless request arrives at the load-balancing gateway, which routes
it to the least busy server in the farm. This mostly takes care of
scalability, since we can always add more servers, which will initially be
idle, but as requests for new sessions keep arriving, they are routed to the
idle servers instead of the busy ones, so over time, the load distribution
evens out.&lt;/li&gt;
&lt;li&gt;The server that receives the sessionless request creates a new instance of a
stateful microservice to handle that request, and the session is established
between that microservice and the client.&lt;/li&gt;
&lt;li&gt;From that moment on, any further incoming requests for that same session are
routed by the gateway to the same server, and the server delegates them to
the same instance of the stateful microservice. (Alternatively, the
microservice and the client may negotiate a direct persistent connection
between the two, thus bypassing any middlemen from that moment on.)&lt;/li&gt;
&lt;li&gt;The newly spawned stateful microservice registers with the messaging
backbone of the system to receive notifications about system-wide events, so
as to be able to keep its state always up to date.&lt;/li&gt;
&lt;li&gt;The newly spawned stateful microservice loads whatever state it is going to
need, and keeps that state in memory.&lt;/li&gt;
&lt;li&gt;The microservice processes the request and sends back a response.
&lt;ul&gt;
&lt;li&gt;Possibly also changing its own transient state.&lt;/li&gt;
&lt;li&gt;Possibly also updating the main data store with information that must
always be globally available and up to date, and issuing system-wide
notifications about these changes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The microservice takes a backup of itself.
&lt;ul&gt;
&lt;li&gt;The microservice serializes the entirety of its state into a binary blob&lt;/li&gt;
&lt;li&gt;The blob is written into a persistent key-value store, using the session
id as the key.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt;This persistent key-value store is used as a backup, meaning that it is
written often, but it is never read unless something bad happens.
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Continuous persistence of stateful microservices is not expected to pose a
performance problem, because:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Serialization to and from a binary format performs much better than
general-purpose serialization into a textual markup like JSON or XML.&lt;/li&gt;
&lt;li&gt;The size of the blob is expected to be relatively small. (Of the order of
kilobytes.)&lt;/li&gt;
&lt;li&gt;Key-value stores tend to have very high performance characteristics.&lt;/li&gt;
&lt;li&gt;The backup store can be physically separate from the main data store,
(even on a different network,) thus avoiding contention.&lt;/li&gt;
&lt;li&gt;The act of serializing an in-memory data structure into a single in-memory
blob and then sending that blob as one piece into persistent storage is
bound to perform far better than a series of operations to update a
structured data store. (For one thing, there are no index updates.)&lt;/li&gt;
&lt;li&gt;Persisting the blob can be done asynchronously and in parallel to the
sending of the response to the client, so it does not contribute to
user-perceived latency.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For as long as the session does not expire, the stateful microservice can
remain alive, continuing to serve requests efficiently, taking advantage of
the transient state that it contains and keeps up-to-date. Contrast this
with the stateless microservice approach, which requires that any request
can be handled by any server, therefore each microservice must contain no
state at all:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The processing of each request begins with zero knowledge of the state of
the system, so persistent storage must always be queried to obtain state.&lt;/li&gt;
&lt;li&gt;These queries represent overhead, and this overhead must be suffered in
full before the request can be serviced, thus manifesting as latency to
the user.&lt;/li&gt;
&lt;li&gt;The results of these queries may not be cached, because they may at any
moment be rendered out-of-date by any other microservice in the system.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;An instance of a stateful microservice may prematurely cease to exist due to
a number of reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The microservice may be terminated on demand in order to rebalance the
server farm.&lt;/li&gt;
&lt;li&gt;The server hosting the microservice may become unavailable due to hardware
failure.&lt;/li&gt;
&lt;li&gt;The microservice may fall victim to the whim of the chaos monkey.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If for whatever reason a microservice ceases to exist, the gateway discovers
this either on its own, or when the next request arrives from the client.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The gateway routes the request to the least busy server in the farm.&lt;/li&gt;
&lt;li&gt;The server that receives the request sees that there is no microservice to
handle requests for that session, so it creates a new one.&lt;/li&gt;
&lt;li&gt;The newly instantiated microservice checks, whether the key-value store
contains a backup for the current session, and discovers that it does.&lt;/li&gt;
&lt;li&gt;The microservice restores its state from the backup.&lt;/li&gt;
&lt;li&gt;Operation continues from that moment on as if nothing happened.&lt;/li&gt;
&lt;li&gt;Between the moment in time that a certain microservice instance
prematurely ceases to exist, and the moment in time that a new incarnation
of that microservice is ready for showtime on a freshly assigned server,
some events from the messaging backbone may be lost. To avoid
inconsistencies in the state of the microservice, we must utilize a
messaging backbone which is capable of replaying events. For example, if
we use Kafka, then the stateful microservice can make sure to include
among its persistent state what is known in Kafka terminology as the
&amp;quot;consumer offset&amp;quot;. Thus, when the microservice gets reconstructed, it asks
Kafka for events starting at that offset, so Kafka replays any missed
events before it starts sending new ones. Thus, we ensure that the state
of the microservice is always up to date, even in the case of termination
and reconstruction.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thus, stateful microservices can achieve not only scalability but also
resilience.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: Photo of two elephants friendly interacting with each other, from
&lt;a class="external"
href="https://www.scientificamerican.com/article/elephants-never-forget/" target="_blank"
&gt;The Scientific American: &lt;em&gt;Fact or Fiction?: Elephants Never Forget&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;</description></item><item><title>On Stateless Microservices</title><link>https://blog2.michael.gr/post/2021-10-on-stateless-microservices/</link><pubDate>Thu, 14 Oct 2021 10:53:38 +0000</pubDate><guid>https://blog2.michael.gr/post/2021-10-on-stateless-microservices/</guid><description>&lt;p&gt;This post discusses the stateless microservice design pattern; it is meant as
support material for other posts of mine that discuss microservices, mainly
&lt;a
href="https://blog2.michael.gr/post/2021-10-14-the-stateful-microservice/"
&gt;The Stateful Microservice&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2021-10-on-stateless-microservices/media/8.png"
width="1378"
height="2048"
srcset="https://blog2.michael.gr/post/2021-10-on-stateless-microservices/media/8_hu_48b7be9e0748ac79.png 480w, https://blog2.michael.gr/post/2021-10-on-stateless-microservices/media/8_hu_56b2bd321fd1677a.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="67"
data-flex-basis="161px"
&gt;
&lt;/p&gt;
&lt;h4 id="is-statelessness-a-requirement-for-a-microservice"&gt;Is statelessness a requirement for a microservice?
&lt;/h4&gt;&lt;p&gt;In another post (see
&lt;a
href="https://blog2.michael.gr/post/2021-10-so-what-is-microservice-anyway/"
&gt;So, what is a Microservice, anyway?&lt;/a&gt;) I examine what a microservice really is, and I come to the conclusion that from a purely technical standpoint, a working definition could be
as simple as this:&lt;/p&gt;
&lt;p&gt;A microservice is a scalable and resilient module.&lt;/p&gt;
&lt;p&gt;Even if you disagree with the terseness of this definition, and you regard
microservices as necessarily more than that, I hope you will at least agree
that it is precisely scalability and resilience that statelessness in microservices aims to address, so this definition serves its
purpose at least in the context of this series of posts.&lt;/p&gt;
&lt;p&gt;There are many who will try to convince you that in order to build a scalable
and resilient system, you need statelessness; so much so, that microservices
have almost come to be regarded as synonymous with statelessness. This post
examines whether this is that in fact so, and what is the cost of doing things
this way.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;If we take a step back for a moment and examine the issue from a somewhat
distanced point of view, we notice that there is no such thing as a stateless
software system. If there was such a thing, it would not be capable of
performing any function worth speaking of, and it would necessarily be less
useful than a brick, because a brick has physical existence, so you can, at
the very least, throw it at someone.&lt;/p&gt;
&lt;p&gt;If there is one thing that a software system necessarily has, it is state, so
there is no word that is more unsuitable to go with the word &amp;quot;software&amp;quot; than
the word &amp;quot;stateless&amp;quot;. (By the way, that is also a little something that
functional programming aficionados should perhaps take a moment to
philosophically ponder about.)&lt;/p&gt;
&lt;p&gt;What this all means is that even if you build a system using so-called
stateless microservices, that system will still have state; for example, if it
is a web shop, it will very conveniently remember me when I come to visit
again, and if I order any goods during my visit, it will very inconveniently
&lt;em&gt;not&lt;/em&gt; forget to send me an invoice. That is all happening due to state, which is
stored in the database system of the web shop. So, when people speak of
microservices with no state what they actually mean is microservices with no
&lt;em&gt;transient&lt;/em&gt; state. The state is definitely there, the system just does
not rely on any microservice remembering any of it. Each microservice
refrains from keeping any state in memory for any longer than it absolutely
has to; it always begins the processing of every single transaction by
querying the database for all necessary state, and it makes sure to persist
any changed state into the database before proclaiming the transaction
complete.&lt;/p&gt;
&lt;p&gt;Stateless microservices were invented because statelessness is an easy way of
achieving scalability and resilience: if a module does not keep any state, then an
indefinite number of copies of that module can be created to process requests in
parallel; any request arriving at the server farm can be serviced by any
instance of that module, and any subset of copies of the module can be destroyed at any moment,
without depriving the system from its ability to function.&lt;/p&gt;
&lt;p&gt;That's great, but statelessness is not an end in and of itself; it is a means
to an end; it is just one way of achieving scalability and
resilience. This is proven by the fact that the database systems upon which
stateless microservice architectures are built are most certainly not
stateless at all, and yet they do somehow manage to be scalable and resilient.
Obviously, they are doing something differently.&lt;/p&gt;
&lt;h4 id="what-is-wrong-with-statelessness"&gt;What is wrong with statelessness?
&lt;/h4&gt;&lt;p&gt;When building a system which needs to be scalable and resilient, and also
needs to be very stateful as a whole, one has to begin with a scalable and
resilient data layer as a foundation. Luckily, there exist various
commercially available products that accomplish this. On top of that
foundation, one has to build their application-specific logic in a way that is
also scalable and resilient. Stateless microservices will achieve this, but
they are one of the &lt;strong&gt;worst performing&lt;/strong&gt;, and from an engineering
standpoint most &lt;em&gt;&lt;strong&gt;cowardly&lt;/strong&gt;&lt;/em&gt; ways of achieving scalability and
resilience. Choosing the stateless microservices approach is like saying the
following:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;State is hard; we do not have the slightest clue as to how we can maintain
state and at the same time remain scalable and resilient; but look, the
creators of our database system are very smart folks, they seem to have
figured it all out! So, here is what we will do: we will delegate the entire
task of maintaining state to them!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That is how we arrived at the stateless microservice model, which I like to
call the &amp;quot;Dory&amp;quot; model, after the fish that suffered from amnesia in the
&lt;em&gt;Finding Nemo&lt;/em&gt; movie.&lt;/p&gt;
&lt;p&gt;In the Dory model, every single incoming transaction gets processed by a
microservice that is drawing a complete blank. Upon receiving the request, the
microservice starts with very basic questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Who am I, and what is this strange place I am running in?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Who are these folks sending me requests, and why?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Should I respond to them, or should I four-oh-three them away?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Let's start by authenticating them...&lt;/p&gt;
&lt;p&gt;...and it goes on like that. For every single request, there are multiple
round-trips to the database while the microservice is discovering more and more
about what it is being requested to do and whether it should in fact do it,
and even more round-trips to retrieve the information that will go into the
response, including very basic information that hardly ever changes, such as
the name of the visitor on whose behalf the request was sent, and in multi-tenancy scenarios even
the name of the tenant on whose behalf the website is being served.&lt;/p&gt;
&lt;p&gt;When the transaction is nearing completion, the stateless microservice will
meticulously store every single little piece of changed state in its exact
right place in the database, as if it is making notes to itself, lest it
forgets.&lt;/p&gt;
&lt;p&gt;Finally, once the transaction is completed, the microservice will proceed to
deliberately forget absolutely everything that it learned during the
processing of the transaction, before it starts to wait for the next
transaction.&lt;/p&gt;
&lt;p&gt;I am not going to say that this is preposterously inefficient, but
it is &lt;em&gt;&lt;strong&gt;preposterously inefficient.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Incidentally, the magnificent inefficiency of stateless microservices makes
them to a certain extent a self-serving paradigm: in order to scale up you
might think you need them, but once you have them, they will perform so badly,
that boy oh boy, are you going to need to scale up!&lt;/p&gt;
&lt;p&gt;Another problem with stateless microservices is that they cannot take any
initiative of their own, they are restricted to only responding to incoming
requests. This poses a problem with server-initiated client updates, which in
certain circles are known as &amp;quot;push notifications&amp;quot;. A server-initiated client
update happens when the server decides to send some data to the client at an
arbitrary moment in time, as a result of some event occurring on the server,
without the client first having to request that data.&lt;/p&gt;
&lt;p&gt;Actually, the very term &amp;quot;push notification&amp;quot; seems to have originated from
system designs in which such sending of data is a difficult task, as if the
developers have to put their shoulders against the notification and push it
all together to make it straddle the great divide between the server and the
client. In other designs, where asynchronous bi-directional communication is
the default mode of operation, there is no need for such laboriousness;
server-initiated client updates are just part of the normal way things work.
Alas, you cannot have that with stateless microservices, because
bi-directional communication requires the notion of a session, which in turn
implies a notion of state, which is a no-no.&lt;/p&gt;
&lt;p&gt;Consequently, software systems that utilize the stateless microservice design
pattern address the problem of server-initiated client updates in various
wacky hacky ways:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Some opt to not have any; if the user wants to see what has changed, let
them refresh the page. This can cause serious problems in systems where
multiple clients may edit the same data, since the system has no way of
alerting a client that the data they are editing is also being edited by
another client at the same time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Some use polling, meaning that each client keeps sending requests to the
server at regular intervals asking whether there are any updates. This is wasteful, because each of these requests represents work that needs to
be done, but very few of them will result in anything useful happening. At
the same time, in order to reduce server load, the polling cannot be too
frequent, which in turn means that there will always be a time
lapse between the moment that an event occurs on the server and the moment
that the clients take notice.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Some opt to have special stateful modules working side by side with the
stateless microservices to handle the push notifications in a completely
separate way, under the assumption that notifications are a kind of optional, &amp;quot;nice to have&amp;quot; thing anyway, so if performance suffers due to lack
of scaling, or if service is interrupted due to lack of resilience, it will
not hurt too much. On top of being clunky, this approach is also
short-sighted because from the entire broad topic of server-initiated client
updates it only considers the narrow case of updates being used for the sole
purpose of on-screen notifications.&lt;/p&gt;
&lt;p&gt;Further reading: &lt;a
href="https://blog2.michael.gr/post/2021-10-14-the-stateful-microservice/"
&gt;The Stateful Microservice&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: &lt;em&gt;Dory&lt;/em&gt;, the yellow-blue fish (a &lt;em&gt;Royal Blue Tang&lt;/em&gt;) that
suffered from amnesia in the 2003 movie &lt;em&gt;Finding Nemo&lt;/em&gt; by Pixar.&lt;/p&gt;</description></item><item><title>White-Box vs. Black-Box Testing</title><link>https://blog2.michael.gr/post/2021-12-white-box-vs-black-box-testing/</link><pubDate>Wed, 22 Sep 2021 13:47:17 +0000</pubDate><guid>https://blog2.michael.gr/post/2021-12-white-box-vs-black-box-testing/</guid><description>&lt;p&gt;&lt;a class="external"
href="https://blogger.googleusercontent.com/img/a/AVvXsEjW7YbG075F9q253nTW0xSWiTzN9msG1BuZ2TgZO-mztpIBkgk9or5PoE2z-KhAx_WmfsT86Z5y6NFntAxir_gDF9PE3CCPaGQDmtx6ypfaffZirjHodfq1rM5SP8ONNI7AUmT3xHoijMhReRWmeHJZKjyPtZuyhHPAFJ6MrPUuPE7BXsGJ4gFWE36yyg=s1000" target="_blank"
&gt;&lt;img src="https://blog2.michael.gr/post/2021-12-white-box-vs-black-box-testing/media/tag-blogger.com,1999-blog-3494795920779884230.post-69667484864678488091.jpg"
width="640"
height="256"
srcset="https://blog2.michael.gr/post/2021-12-white-box-vs-black-box-testing/media/tag-blogger.com,1999-blog-3494795920779884230.post-69667484864678488091_hu_f50f246ab2524aaf.jpg 480w, https://blog2.michael.gr/post/2021-12-white-box-vs-black-box-testing/media/tag-blogger.com,1999-blog-3494795920779884230.post-69667484864678488091_hu_cde10918de1bcfd0.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="250"
data-flex-basis="600px"
&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I have something blasphemous to tell you.&lt;/p&gt;
&lt;p&gt;Unit Testing is wrong.&lt;/p&gt;
&lt;p&gt;There, I said it.&lt;/p&gt;
&lt;p&gt;I know I just insulted most people's sacred cow.&lt;/p&gt;
&lt;p&gt;Sorry, not sorry.&lt;/p&gt;
&lt;p&gt;I will explain, bear with me.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h4 id="so-what-is-unit-testing-anyway"&gt;So, what is Unit Testing anyway?
&lt;/h4&gt;&lt;p&gt;Unit Testing, according to its definition, aims to examine a module in
isolation, to make sure that it behaves as expected without uncertainties
introduced by the behavior of other modules that it interacts with. These
other modules are known as dependencies. To achieve this, the test refrains
from connecting the module with its dependencies, and instead emulates the
behavior of the dependencies. That is what makes it a Unit Test, as opposed to
an Integration Test.&lt;/p&gt;
&lt;p&gt;The emulation of the dependencies is meant to be done in a very
straightforward and inexpensive way, because if it was complicated, then it
would introduce uncertainties of its own. So, if we were to imagine for a
moment that the math library is a dependency of the module under test, (just
for the sake of the example,) when the module under test asks for the cosine
of an angle, the Unit Test does not want to invoke the actual math library to perform the cosine
computation; instead, the Unit Test makes sure beforehand to supply the module
under test with such inputs that will cause the module to work with a known
angle of say 60 degrees, so the Unit Test can anticipate that the module will ask for the cosine of a 60 degree
angle, at which point the Unit Test will supply the module under test with a hard-coded value of 0.5,
which is known to be the cosine of 60 degrees. The Unit Test then proceeds to
make sure that the module does the right thing with that 0.5 and produces the
right results.&lt;/p&gt;
&lt;p&gt;In doing so, the Unit Test expects the module under test to interact with each of its
dependencies in a strictly predetermined way: a specific set of calls is
expected to be made, in a specific order, with specific arguments. Thus, the
unit test has knowledge of exactly how the module is implemented: not only the
outputs of the module must be according to spec, but also every single little
detail about the inner workings of the module must go exactly as expected.
Therefore, Unit Testing is white-box testing by nature.&lt;/p&gt;
&lt;h4 id="what-is-wrong-with-white-box-testing"&gt;What is wrong with White-Box Testing
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;White-box testing is not agnostic enough.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Just as users tend to test software in ways that the developer never
thought of, (the well known &amp;quot;works for me but always breaks in the hands
of the user&amp;quot; paradox,) software tests written by developers who maintain
an agnostic stance about the inner workings of the production code are
likely to test for things that were never considered by those who wrote
the production code.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;White-box testing is a laborious endeavor.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The amount of test code that has to be written and maintained often far
exceeds the amount of production code that is being tested.&lt;/li&gt;
&lt;li&gt;Each modification to the inner workings of production code requires corresponding modifications to the testing code, even if the interface and behavior of
the production code remains unchanged.&lt;/li&gt;
&lt;li&gt;With respect to procedural logic within the module under test, the Unit Test has to make sure
that every step of each workflow is followed, so the test essentially has to anticipate
every single decision that the module will make. This means that the test
duplicates all of the knowledge embodied within the module, and
essentially constitutes a repetition of all of the procedural logic of the
module, expressed in a different way. This problem has also been identified by others, and it is sometimes called the &amp;quot;over-specified tests problem&amp;quot;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;White-box testing suffers from &lt;em&gt;The Fragile Test Problem&lt;/em&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A bug fix in the production code more often than not causes tests to
break, which then have to be fixed. Note that this often happens even if we first write a test for the bug, which is expected to initially fail, and to start passing once the bug fix is applied: other previously existing tests will break. Unfortunately, it is often unclear to
what extent the tests are wrong, and to what extent the tests are right
but the production code suffers from other, dormant bugs, that keep
causing the tests to fail. When fixing tests as a result of bug fixes in
production, the general assumption is that the production is now correct,
therefore the test must be wrong, so the test is often hastily modified to make it pass
the existing production code. This often results in tests that &amp;quot;test
around&amp;quot; pre-existing bugs, meaning that the tests only pass if the bugs
are there.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;White-box tests are not re-usable.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It should be possible to completely rewrite a piece of production code and
then reuse the old tests to make sure that the new code works exactly as
the old one did. This is impossible with white-box testing.&lt;/li&gt;
&lt;li&gt;It should be possible to write a test once and use it to test multiple
different implementations of a certain module, created by independently working
development teams taking different approaches to solving the same problem.
This is also impossible with white-box testing.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;White-box testing hinders refactoring.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Quite often, refactorings which would affect the entire code base are unattainable because they would necessitate rewriting all unit tests, even if the refactorings themselves would have no effect on the behavior of the module, and would only require limited and harmless modifications to the production code, such as the case is when replacing one third-party library with another.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;White-box testing is highly presumptuous.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;White-box testing claims to have knowledge of exactly how the dependencies behave,
which may not be accurate. As an extreme example, the cosine of 60 is 0.5 only if that 60 is in degrees; if the cosine function of the actual math library used in production works with radians instead of degrees, then the result will
be something completely different, and the Unit Test will be achieving
nothing but ensuring that the module will only pass the test if it
severely malfunctions. In real-world scenarios the wrongful assumptions are much more subtle than a degrees vs radians discrepancy, making them a lot harder to detect and troubleshoot.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the preface of the book &lt;em&gt;&lt;strong&gt;The Art of Unit Testing&lt;/strong&gt;&lt;/em&gt; (Manning,
2009) by &lt;strong&gt;Roy Osherove&lt;/strong&gt;, the author admits to having participated in a
project which failed to a large part due to the tremendous development
burden imposed by badly designed unit tests which had to be maintained
throughout the duration of the development effort. The author does not go
into details about the design of those unit tests and what was so bad about
it, but I would dare to postulate that it was simply the fact that they were...
Unit Tests.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="is-white-box-testing-good-for-anything"&gt;Is white-box testing good for anything?
&lt;/h4&gt;&lt;p&gt;If you are sending humans to space, or developing any other high-criticality
system, then fine, go ahead and do white-box testing, as well as inside-out
testing, and upside-down testing, and anything else that you can think of,
because in high-criticality software, there is no amount of testing that
constitutes too much testing. However, the vast majority of software written
in the world today is not high criticality software, it is just plain normal,
garden variety, commercial software. Applying space-grade practices in the
development of commercial software does not make business sense, because
space-grade practices tend to be much more expensive than
commercial practices.&lt;/p&gt;
&lt;p&gt;In high criticality, it is all about safety; in commercial, it is all about
cost effectiveness.&lt;/p&gt;
&lt;p&gt;In high criticality, it is all about leaving nothing to chance; in commercial,
it is all about meeting the requirements.&lt;/p&gt;
&lt;h4 id="what-about-leaving-nothing-to-chance"&gt;What about leaving nothing to chance?
&lt;/h4&gt;&lt;p&gt;It is true that if you do black-box testing you
cannot be absolutely sure that absolutely everything goes absolutely as
intended. For example, you may be testing a module to ensure that given a
certain input, a certain record is written to the database.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you do white-box testing, you can ensure not only that the record has the correct content,
but also that the record is written once and only once.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you do black-box
testing, all you care is that at the end of the day, a record with the correct content can be found
in the database; there may be a bug which inadvertently
causes the record to be written twice, and you would not know.&lt;/p&gt;
&lt;p&gt;So, at this point some might argue that in promoting black-box testing I am
actually advocating imperfect software. Well, guess what: in the commercial sector, there is no such
thing as perfect software; there is only software that meets its requirements,
and software that does not. If the requirements are met, then some record being written twice is just a performance concern. Furthermore, it is a performance concern not only in the sense of the performance of the running software system, but also in the sense of the performance of your development process: By established practice, it is perfectly fine to knowingly allow a record to be written twice if eliminating this duplication would require too much development work to be worth it, so how is this any different from following an efficient development methodology which might allow that record to be written twice?&lt;/p&gt;
&lt;p&gt;This is in line with the observation that nobody aims to write software that is free from imperfections. Virtually
every single method that returns a collection in all of Java code written
since the dawn of time makes a safety copy of that collection; these safety
copies are almost always unnecessary, and yet people keep making them, because
they do not want to be concerned with what is safe and what is not safe on a
case by case basis; case-by-case addressing of safety concerns is the stuff
that bugs are made of. Software that is free of bugs is software that meets
the requirements, and that's all that counts.&lt;/p&gt;
&lt;p&gt;(Note: personally, I never make safety copies of collections; I use special
unmodifiable collection interfaces instead; but that's a different story.)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="conclusion"&gt;Conclusion
&lt;/h4&gt;&lt;p&gt;In the book
&lt;em&gt;&lt;strong&gt;Design Patterns: Elements of Reusable Object-Oriented Software&lt;/strong&gt;&lt;/em&gt;
(Addison-Wesley, 1994) by &lt;em&gt;&lt;strong&gt;The Gang of Four&lt;/strong&gt;&lt;/em&gt; (Erich Gamma, Richard
Helm, Ralph Johnson, and John Vlissides) one of the principles listed is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Program against the interface, not against the implementation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Virtually all software engineers agree with this self-evident maxim, and
nobody in their right mind would take issue with it. To program against the
implementation rather than the interface is universally considered a misguided
practice.&lt;/p&gt;
&lt;p&gt;In the context of testing, the corollary to this maxim is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Test against the interface, not against the implementation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In other words, do black-box testing, not white-box testing.&lt;/p&gt;
&lt;p&gt;This is not a unique idea of my own, others have had the same idea before, and have similar things to say. Ian Cooper in his &amp;quot;TDD, where did it all go wrong&amp;quot; talk states that in TDD a Unit Test is defined as a test that runs in isolation from other tests, not a test that isolates the unit under test from other units. In other words, the unit of isolation is the test, not the unit under test. Some excerpts from the talk are here: &lt;a class="external"
href="https://www.youtube.com/watch?v=HNjlJpuA5kQ" target="_blank"
&gt;Build Stuff '13: Ian Cooper - TDD, where did it all go wrong&lt;/a&gt; and the full talk is here: &lt;a class="external"
href="https://www.youtube.com/watch?v=EZ05e7EMOLM" target="_blank"
&gt;TDD, Where Did It All Go Wrong (Ian Cooper, 2017)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Other references:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class="external"
href="https://eng.libretexts.org/Bookshelves/Computer_Science/Programming_and_Computation_Fundamentals/Book%3A_Object-Oriented_Reengineering_Patterns_%28Demeyer_Ducasse_and_Nierstrasz%29/06%3A_Tests__Your_Life_Insurance/6.05%3A_Test_the_Interface_Not_the_Implementation" target="_blank"
&gt;Object-Oriented Reengineering Patterns (Demeyer, Ducasse, and Nierstrasz) - Tests - Your Life Insurance - 6.05 - Test the Interface Not the Implementation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="external"
href="https://web.archive.org/web/20180825215727/http://www.richardlord.net/blog/tdd/test-the-interface-not-the-implementation.html" target="_blank"
&gt;Richard Lord - Test the interface, not the implementation&lt;/a&gt; (via archive.org)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="if-not-unit-testing-then-what"&gt;If not Unit Testing, then what?
&lt;/h4&gt;&lt;p&gt;So, one might ask: if Unit Testing is wrong, then what should we be doing
instead? The original impetus behind the invention of Unit Testing still
remains: when we test a module we want to make sure that the observed behavior
is not affected by potential malfunction in its dependencies. How can we avoid that?&lt;/p&gt;
&lt;p&gt;The way I have been handling this in recent years is by means of a method that
I call &lt;em&gt;Incremental Integration Testing&lt;/em&gt;. You can read about it here: &lt;a
href="https://blog2.michael.gr/post/2022-10-incremental-integration-testing/"
&gt;Incremental Integration Testing&lt;/a&gt;.&lt;/p&gt;</description></item><item><title>The MVVM architectural design pattern</title><link>https://blog2.michael.gr/post/2021-01-the-mvvm-architectural-design-pattern/</link><pubDate>Sat, 16 Jan 2021 14:47:04 +0000</pubDate><guid>https://blog2.michael.gr/post/2021-01-the-mvvm-architectural-design-pattern/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2021-01-the-mvvm-architectural-design-pattern/media/mvvm.png"
width="800"
height="242"
srcset="https://blog2.michael.gr/post/2021-01-the-mvvm-architectural-design-pattern/media/mvvm_hu_8fa849595e07c30f.png 480w, https://blog2.michael.gr/post/2021-01-the-mvvm-architectural-design-pattern/media/mvvm_hu_400ee7376db477fb.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="330"
data-flex-basis="793px"
&gt;
&lt;/p&gt;
&lt;p&gt;This is a brief technical explanation of MVVM, with enough detail (borrowed from its WPF implementation) and examples to allow the reader to grasp how it actually works.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;MVVM&lt;/em&gt; is an architectural design pattern for building interactive applications. Its aim is to achieve complete decoupling of application logic from presentation logic.&lt;/li&gt;
&lt;li&gt;MVVM is not something new, and it was not even new at the time that it became popular. It was named by &lt;a class="external"
href="https://docs.microsoft.com/en-us/archive/blogs/johngossman/introduction-to-modelviewviewmodel-pattern-for-building-wpf-apps" target="_blank"
&gt;John Gossman in 2005&lt;/a&gt;, who states that it is the same as the &lt;em&gt;Presentation Model&lt;/em&gt; pattern named by &lt;a class="external"
href="https://martinfowler.com/eaaDev/PresentationModel.html" target="_blank"
&gt;Martin Fowler in 2004&lt;/a&gt;, who in turn states that it was previously known as the &lt;em&gt;Application Model&lt;/em&gt; pattern in &lt;a class="external"
href="https://en.wikipedia.org/wiki/VisualWorks" target="_blank"
&gt;certain Smalltalk circles&lt;/a&gt; as early as in the 1980s, and that's where we lose track of it: for all we know, it may have originated in Ancient Egypt.&lt;/li&gt;
&lt;li&gt;The acronym stands for &lt;em&gt;Model&lt;/em&gt;, &lt;em&gt;View&lt;/em&gt;, &lt;em&gt;Viewmodel&lt;/em&gt;.
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;/em&gt; refers to the main &lt;em&gt;estate&lt;/em&gt; data model of our application; it is optional and largely irrelevant, so it will only be mentioned a couple of times here.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;View&lt;/strong&gt;&lt;/em&gt; refers to the user interface.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;Viewmodel&lt;/strong&gt;&lt;/em&gt; is the secret sauce, but in essence it refers to the application logic.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Application logic is placed in objects known as viewmodels. A viewmodel does the following:
&lt;ul&gt;
&lt;li&gt;Publicly exposes state, part of which is publicly mutable.&lt;/li&gt;
&lt;li&gt;Issues notifications about any mutation of its state.&lt;/li&gt;
&lt;li&gt;Responds to state mutations with behavior, such as querying and updating data stores, issuing events in some messaging backbone, etc.&lt;/li&gt;
&lt;li&gt;Manifests its behavior by means of further modifying its own state, which in turn generates more state mutation notifications.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;This allows the following very simple workflow:
&lt;ul&gt;
&lt;li&gt;When the presentation layer modifies a property of a viewmodel, the viewmodel takes notice and exhibits its behavior.&lt;/li&gt;
&lt;li&gt;When a viewmodel modifies one of its own properties, the presentation layer takes notice and updates the screen.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Thus, a viewmodel essentially implements a fully interactive and yet completely abstract (i.e. not graphical) user interface, with mutable properties instead of editable controls. The viewmodel is free from presentation concerns such as where on the screen the properties may be shown, what user interface controls may be used to show them, etc.
&lt;ul&gt;
&lt;li&gt;Note: GUI pushbuttons, which have no state, are implemented as special &amp;quot;Command&amp;quot; objects that are exposed by a viewmodel besides its properties, but they could also be implemented as Boolean properties, where a transition from say, true to false triggers behavior. Command objects make viewmodels more self-documenting and more usable, but they are nothing but a nice-to-have feature: in principle, everything could work with just properties.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If we wanted to allow the user to edit a &lt;code&gt;Customer&lt;/code&gt; entity in a modal dialog box:
&lt;ul&gt;
&lt;li&gt;There will be a viewmodel for this dialog box, which exposes:
&lt;ul&gt;
&lt;li&gt;One property for each editable field of &lt;code&gt;Customer&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;One command for the 'OK' button&lt;/li&gt;
&lt;li&gt;One boolean property which stands for the 'enabled' state of the 'OK' button.&lt;/li&gt;
&lt;li&gt;One command for the 'Cancel' button, presumed to be always enabled.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The viewmodel may set the enabled state of the 'OK' command to true only once the user has made changes to the fields.&lt;/li&gt;
&lt;li&gt;When the 'OK' command is triggered, the viewmodel performs validation.&lt;/li&gt;
&lt;li&gt;If validation fails, the viewmodel instantiates another viewmodel which stands for an error message, and the view chooses how to show it, e.g. with a modal dialog box or with a temporary &amp;quot;toast&amp;quot;.&lt;/li&gt;
&lt;li&gt;If validation succeeds, the viewmodel persists the entered information in the data store.&lt;/li&gt;
&lt;li&gt;If the user opts to cancel, then the viewmodel discards the edited information.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Viewmodels are so agnostic of presentation concerns that they can in fact be instantiated without any user interface at all. This allows us to test the entirety of the behavior of our application logic without a user interface and without having to examine any of its private implementation details such as its data store. Our application logic tests simply modify the public state of viewmodels and examine how the viewmodels further modify their public state in response.&lt;/li&gt;
&lt;li&gt;The presentation layer consists of views.
&lt;ul&gt;
&lt;li&gt;In a desktop application, views are user-defined controls, panels, windows, dialogs, etc.&lt;/li&gt;
&lt;li&gt;In a web application, views would be HTML fragments.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Each view type is specific to a particular viewmodel type, and contains bindings, which describe how each property of the viewmodel is bound to each property of a control within the view.
&lt;ul&gt;
&lt;li&gt;So, a &lt;code&gt;CustomerForm&lt;/code&gt; view which is meant to display a &lt;code&gt;Customer&lt;/code&gt; viewmodel has a binding which specifies that the &lt;code&gt;Name&lt;/code&gt; property of the customer should be bound to the &lt;code&gt;Text&lt;/code&gt; property of a certain &lt;code&gt;TextBox&lt;/code&gt; control within the view.&lt;/li&gt;
&lt;li&gt;Note that these associations are purely declarative, and they reference nothing but statically available information, (data types and their members,) which means that they can be described using a markup language, i.e. without the need to write any application-specific code to build up the user interface.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A viewmodel may contain a property which is in turn another viewmodel. Let us call that a child viewmodel. In this case, the view can do one of two things:
&lt;ul&gt;
&lt;li&gt;Specify a particular child view type to display that particular child viewmodel.&lt;/li&gt;
&lt;li&gt;Specify a mapping table which defines what type of child view to use for displaying any different possible type of child viewmodel.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Views are resolved at runtime, based on the actual type of the child viewmodel, which can be more derived than the advertised type of the child viewmodel property; so, if a viewmodel exposes a &lt;code&gt;Customer&lt;/code&gt; child viewmodel property which can be either of type &lt;code&gt;Customer&lt;/code&gt; or of a more derived type &lt;code&gt;WholesaleCustomer&lt;/code&gt;, the mapping table can specify a different child view type for each of these child viewmodel types, and the right child view will be instantiated at runtime depending on the actual type of the child viewmodel.&lt;/li&gt;
&lt;li&gt;Any child view can in turn contain its own mapping table which defines more associations, or redefines existing associations, so that for example:
&lt;ul&gt;
&lt;li&gt;In the scope of an &lt;code&gt;AllCustomers&lt;/code&gt; view, the &lt;code&gt;Customer&lt;/code&gt; viewmodel can be associated with a &lt;code&gt;CustomerRow&lt;/code&gt; view, so as to present the customer as a row in a tabular control.&lt;/li&gt;
&lt;li&gt;In the scope of a &lt;code&gt;CustomerDetails&lt;/code&gt; view, the same &lt;code&gt;Customer&lt;/code&gt; viewmodel can be associated with a &lt;code&gt;CustomerForm&lt;/code&gt; view, to present the customer using individual fields laid out on a surface.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Note that again, this mapping table consists of nothing but statically available information, (view types and viewmodel types,) so everything is still achievable in markup.&lt;/li&gt;
&lt;li&gt;A child viewmodel property can be optional or nullable, thus allowing the application logic to control whether an entire section of the user interface is available or not at any given moment.&lt;/li&gt;
&lt;li&gt;A child viewmodel property can be a collection of viewmodels, allowing for a corresponding child view which is a list control or a tab control. Viewmodel type mapping still applies, so if the collection contains viewmodels of different types at runtime, the resulting list control will consist of different kinds of rows, or the resulting tab control will consist of different kinds of tabs.&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Object Lifetime Awareness</title><link>https://blog2.michael.gr/post/2020-12-27-object-lifetime-awareness/</link><pubDate>Sun, 27 Dec 2020 10:46:17 +0000</pubDate><guid>https://blog2.michael.gr/post/2020-12-27-object-lifetime-awareness/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2020-12-27-object-lifetime-awareness/images/le-penseur.jpg"
width="3648"
height="5472"
srcset="https://blog2.michael.gr/post/2020-12-27-object-lifetime-awareness/images/le-penseur_hu_9d5b056aaaccb843.jpg 480w, https://blog2.michael.gr/post/2020-12-27-object-lifetime-awareness/images/le-penseur_hu_c19a599b08f288b2.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="66"
data-flex-basis="160px"
&gt;
&lt;/p&gt;
&lt;h4 id="abstract"&gt;Abstract
&lt;/h4&gt;&lt;p&gt;Garbage collectors have given us a false sense of security with respect to what happens to an object once we stop thinking about it. The assumption is that it will be magically taken care of, but this does not always go as hoped, resulting in memory leaks and bugs due to failure to perform necessary cleanup. Tools for troubleshooting such problems are scarce, and not particularly helpful, so finding and fixing such problems is notoriously difficult.&lt;/p&gt;
&lt;p&gt;A methodology is presented, which differs from current widespread practices, for maintaining awareness of, and exercising full deterministic control over, the lifetime of certain objects in a garbage-collected environment. We issue hard errors in the event of misuse, and accurate diagnostic messages in the event of omissions, thus improving the robustness of software and lessening the troubleshooting burden.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h4 id="definition"&gt;Definition
&lt;/h4&gt;&lt;p&gt;An object can be said to have a concept of lifetime if at some point it must perform some cleanup actions, after which it must never be accessed again.&lt;/p&gt;
&lt;h4 id="a-first-look-at-the-problem"&gt;A first look at the Problem
&lt;/h4&gt;&lt;p&gt;One of the original promises of garbage collectors was that we should not have to worry about the lifetime of objects; however, there exist various known situations where objects do, by their very nature, have an inherent notion of lifetime, so we do have to worry about it; for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Objects that model real-world processes with an inherent concept of lifetime, such as:
&lt;ul&gt;
&lt;li&gt;A user's visit to a web site, represented by a web session which at some moment expires.&lt;/li&gt;
&lt;li&gt;The printing of a document, represented by a print job which at some moment completes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Objects implementing application behaviors with a clearly defined end, such as:
&lt;ul&gt;
&lt;li&gt;A dialog window which at some moment gets dismissed and ceases to exist.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additionally, there exist certain programmatic constructs which require a notion of lifetime; for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An event observer which must at some point unregister from the event source that it had previously registered with.&lt;/li&gt;
&lt;li&gt;A database transaction which must at some point end, either by committing it or rolling it back.&lt;/li&gt;
&lt;li&gt;Generally, any situation where:
&lt;ul&gt;
&lt;li&gt;We must remember to undo something which was previously done.&lt;/li&gt;
&lt;li&gt;Some initialization must be balanced by some corresponding cleanup.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Furthermore, any object which contains an object that has a notion of lifetime needs to have a notion of its own lifetime, so as to be in a position of controlling the lifetime of the contained object. Thus, there tends to be a need for objects with a notion of lifetime to form a containment hierarchy whose root is the main application object.&lt;/p&gt;
&lt;p&gt;Unfortunately, in garbage collected environments, object lifetime is not given as much attention as it deserves. Software architectures tend to underestimate its importance, give it only a partial treatment, and invariably do it in ad-hoc ways, without any clearly defined methodology or aiding infrastructure. All to often, an object with an inherent notion of lifetime is built without explicit knowledge of it; instead, its lifetime is treated only implicitly. Thus, the software design has no knowledge of, and no control over, the lifetime of that object, and relies on the garbage collector to magically take care of it.&lt;/p&gt;
&lt;p&gt;Once we leave an object up to the garbage collector to take care of, we completely relinquish control over what happens next: there are no guarantees as to when the object will be collected, or even as to whether it will in fact be collected; there will be nothing to inform us of the outcome, and we have no way of influencing the outcome. Thus, when object-lifetime related trouble happens, it is by its nature very difficult to troubleshoot, diagnose, and fix; nonetheless, most programmers try to avoid dealing with object lifetime if they can, and each time problems pop up, they try to fix them on an as needed basis.&lt;/p&gt;
&lt;p&gt;The following kinds of trouble are common:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Direct failure to perform necessary cleanup:&lt;/strong&gt; the false sense of security offered by the garbage collector sometimes makes programmers forget that it only reclaims unused memory, it does not do any other cleanup for us, such as unregistering observers from event sources. This usually needs to be done manually, and it requires that the observer must have a notion of lifetime. An event source could in theory be asserting that every single observer did eventually remember to deregister; however, such a technique would require not only observers to have a notion of lifetime, but also the event source itself. Thus, there is no widespread use of such a technique, because there is no widespread use of object lifetime awareness in the first place.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memory leaks:&lt;/strong&gt; in an ideal world, the magic of the garbage collector would always be strong and true, but in practice it is not, due to subtle human error such as inadvertently keeping around a reference to an object, thus preventing it from being garbage collected. Lack of object lifetime awareness only exacerbates this problem.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Troubleshooting in the dark:&lt;/strong&gt; an object with a notion of lifetime can either be alive or dead. If the lifetime of the object is explicit, we can always inspect that state with the debugger. If not, then we never know whether the object that we are looking at is meant to be alive or not.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inability to detect misuse:&lt;/strong&gt; a very common mistake is continuing to access an object even after its lifetime is over. When the object has no explicit knowledge of its own lifetime, it cannot assert against such mistakes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="existing-mechanisms"&gt;Existing mechanisms
&lt;/h4&gt;&lt;p&gt;Garbage collectors and their associated execution environments do provide some machinery which is related to the topic of object lifetime management, namely &lt;em&gt;&lt;strong&gt;finalization&lt;/strong&gt;&lt;/em&gt;, &lt;em&gt;&lt;strong&gt;disposal&lt;/strong&gt;&lt;/em&gt;, &lt;em&gt;&lt;strong&gt;&amp;quot;automatic&amp;quot; disposal&lt;/strong&gt;&lt;/em&gt;, and &lt;em&gt;&lt;strong&gt;weak references&lt;/strong&gt;&lt;/em&gt;, but as we shall see this machinery alone is woefully inadequate.&lt;/p&gt;
&lt;h3 id="finalization"&gt;Finalization
&lt;/h3&gt;&lt;p&gt;In Java we have the &lt;code&gt;Object.finalize()&lt;/code&gt; method, and in C# we have &amp;quot;destructors&amp;quot;, which are actually not destructors at all, they are finalizers, too. &lt;sup id="fnref:1"&gt;&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref"&gt;1&lt;/a&gt;&lt;/sup&gt; The garbage collector will invoke the finalizer of an object right before reclaiming the memory occupied by it, so that the object can in theory perform some cleanup at that moment. Unfortunately, this mechanism is notoriously unreliable:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An object will not be finalized unless it first becomes eligible for collection, and in order for that to happen, it must first become unreachable. However, the object may remain reachable due to subtle mistakes such as unknowingly keeping a reference to it in some list, thus resulting in objects which never get finalized.&lt;/li&gt;
&lt;li&gt;When an object does become eligible for collection, the moment that it will actually be collected largely depends upon the whim of the garbage-collector, which is non-deterministic, both according to the documentation and as observed by experimentation. There are no guarantees as to when an object will be collected, or even as to whether it will ever be collected, despite being eligible.
&lt;ul&gt;
&lt;li&gt;If the garbage collector works in aggressive mode, (common in servers,) the object will be collected sooner rather than later, but how soon depends on variables that we practically have no control over, such as at what rate existing objects are becoming eligible for collection, how many objects are pending to be finalized, etc. So:
&lt;ul&gt;
&lt;li&gt;Even though the object may be finalized within milliseconds, there are no guarantees as to how many milliseconds, and also please note that &amp;quot;milliseconds&amp;quot; is still a far cry from &amp;quot;now&amp;quot;.&lt;/li&gt;
&lt;li&gt;Even if the object gets finalized as quickly as possible, this is still going to happen in a separate thread, so finalization will always be desynchronized from the set of instructions which rendered the object eligible for finalization. If these instructions are followed by another set of instructions that in any way rely on finalization having already taken place, the second set of instructions will almost always fail.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If the garbage collector works in non-aggressive mode, (common in desktop and console applications,) then:
&lt;ul&gt;
&lt;li&gt;The object might not be collected unless the virtual machine starts running out of memory, which is at an entirely unknown and usually distant time in the future.&lt;/li&gt;
&lt;li&gt;The object may still not be collected at all if our software completes before exhausting its available memory. If we are only dealing with unmanaged resources that belong to the current process, they will be automatically reclaimed upon process termination, so all will be good, but if we are dealing with resources that are external to our process, (e.g. controlling a peripheral,) these resources will not be released.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The garbage collector orchestrates collection and finalization according to memory availability concerns, but not according to other concerns which it has no knowledge of; consequently, if we are acquiring instances of a certain scarce resource at a high rate, the garbage collector will not hasten collection and finalization in response to the scarcity of that resource, because it has no knowledge of that scarcity. However, if that resource only gets recycled when collection and finalization occurs, and if we do not happen to be allocating and freeing memory fast enough to trigger frequent enough collection and finalization, then we will be consuming the resource faster than it is being recycled, so we will run out of it, despite everything seemingly being done right.&lt;/li&gt;
&lt;li&gt;Finalization is unordered and does not respect containment hierarchy, which means that when the finalizer is invoked on an object, a random subset of the objects contained in this object may have already been finalized. This is a completely chaotic situation which makes it impossible to get anything non-trivial done within a finalizer.&lt;/li&gt;
&lt;li&gt;The chaotic and non-deterministic conditions under which the finalizer executes make it virtually impossible to test any code that you put in a finalizer, so virtually all finalizers are written on a best-effort basis: if it seems to work as written, it will hopefully keep working, fingers crossed.&lt;/li&gt;
&lt;li&gt;Finalization is documented as having a high performance cost, so the standing advice is that it is best to minimize its use, or avoid it altogether if possible.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Therefore, relying on finalization does not give us control over anything, on the contrary it takes control away from us. The official literature of both Microsoft DotNet and the Java Virtual Machine recommends using finalization for the purpose of releasing unmanaged resources, which is not just unhelpful but actually wrongful advice to give. The entire software industry has been blindly following this advice without first questioning its correctness, which has resulted in lots of buggy software out there.&lt;/p&gt;
&lt;h3 id="disposal"&gt;Disposal
&lt;/h3&gt;&lt;p&gt;In Java we have the &lt;code&gt;Closeable&lt;/code&gt; interface, and in C# we have the &lt;code&gt;IDisposable&lt;/code&gt; interface. The benefit of using these interfaces is that they allow explicit (i.e. deterministic and synchronous) triggering of cleanup, instead of relying on finalization to trigger it.&lt;/p&gt;
&lt;p&gt;A C#-only note: In the C# world there is an understanding that &lt;code&gt;IDisposable&lt;/code&gt; may also be used for performing regular cleanup at the end of an object's lifetime; however, its primary reason of existence is still regarded as being the release of unmanaged resources, so people are trying to use it for both purposes. At the same time, the releasing of unmanaged resources is still regarded as something that must always be attempted during finalization, so people are trying to write disposal methods which must work both when explicitly invoked during normal program flow, and when invoked by the finalizer. Needless to say, the complexity of this task is daunting, and the result is incredible amounts of confusion. The &lt;a class="external"
href="https://docs.microsoft.com/en-us/dotnet/standard/garbage-collection/implementing-dispose" target="_blank"
&gt;&lt;code&gt;Dispose(bool)&lt;/code&gt; pattern&lt;/a&gt; has been invented to help manage the chaos, but the result is still preposterously complicated, it suffers from boilerplate code on every single object that implements the pattern, it is largely untestable, and what is most disappointing is that absolutely no thinking seems to have gone in the direction of avoiding all this chaos in the first place.&lt;/p&gt;
&lt;p&gt;Overall, the problem with disposal is that it is very easy to accidentally omit, and when it is omitted there is usually nothing to tell us that we did something wrong, other than performance degradation and inexplicable malfunction. As a matter of fact, the designers of both Java and C# anticipated the inevitability of such omissions, so they invented finalization as a fallback mechanism which is hoped to save the day despite the omissions. However, since finalization is notoriously unreliable, it is not a solution either; it is more like implementing an insurance policy by purchasing lottery tickets.&lt;/p&gt;
&lt;p&gt;Unfortunately, the availability of finalization, and its deceitful promise of making everything right by magic, has steered programmers to regard disposal as largely optional, while in reality it is essential. All that disposal needs in order to be actually useful is a mechanism that will warn us when we forget to perform it, instead of a mechanism that will try to magically fix our omissions.&lt;/p&gt;
&lt;h3 id="automatic-disposal"&gt;&amp;quot;Automatic&amp;quot; disposal
&lt;/h3&gt;&lt;p&gt;Both Java and C# provide special &amp;quot;automatic&amp;quot; disposal constructs, namely the &lt;code&gt;try-with-resources&lt;/code&gt; statement of java, and the &lt;code&gt;using&lt;/code&gt; keyword of C#, both of which implicitly invoke the disposal method even if an exception is thrown. However:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The only thing that is automatic about these constructs is that if you remember to use them, then they will save you from having to write some code that disposes an object; unfortunately,
&lt;ul&gt;
&lt;li&gt;You may very easily forget to use them.&lt;/li&gt;
&lt;li&gt;You may very easily forget that your object requires disposal and therefore be unaware of the fact that you should have used them.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;These constructs can only be used in the simplistic scenario where the lifetime of an object is fully contained within the scope of a single method; unfortunately, in all but the most trivial situations what we actually have is objects which are contained within other objects and live for a prolonged time, so the method that creates them is different from the method that destroys them. In all these cases, the automatic disposal constructs are of no use whatsoever, and the programmer must remember to do everything right.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="weak-references"&gt;Weak References
&lt;/h3&gt;&lt;p&gt;A weak reference is an object which receives special treatment by the execution environment, to achieve something which is not normally possible. It contains a reference to a target object, which is disregarded by the garbage collector when determining whether the target object is accessible. Therefore, if there are no other references to the target object, then the target object is allowed to be garbage-collected, at which point the reference inside the weak reference object is replaced with null.&lt;/p&gt;
&lt;p&gt;Weak references do not actually help us manage the lifetime of objects, but they have been suggested as a mechanism that can help us design things so that there is no need to manage the lifetime of objects. The idea is that we can implement the observer pattern using weak references, so that observers do not need to remember to unregister themselves from the event source; instead, they can simply be allowed to become garbage-collected, and the event source will subsequently forget them.&lt;/p&gt;
&lt;p&gt;This approach suffers from a number of drawbacks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Weak references might save us from having to worry about the lifetime of event observers, but they do nothing for a wide range of other situations that require cleanup at the end of an object's lifetime.&lt;/li&gt;
&lt;li&gt;Weak observers run the danger of being prematurely garbage-collected. When this happens, it is very difficult to troubleshoot, and the fix tends to require tricks and hacks.&lt;/li&gt;
&lt;li&gt;Weak references are a bit too low level, a bit too esoteric, and a bit like magic, so suggesting their widespread use by the average programmer is a bit of a tough proposition.&lt;/li&gt;
&lt;li&gt;The use of weak references represents a step backwards from the stated goal of gaining more control over the inner workings of our software.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="a-deeper-look-at-the-problem"&gt;A deeper look at the problem
&lt;/h4&gt;&lt;p&gt;In a language like C++, which has proper destructors, the lifetime of an object is well defined, and the compiler does all the work necessary to guarantee that this lifetime will end at the exact right moment, as long as we are using either local storage or smart pointers. However, in garbage-collected languages we have none of that; the lifetime of objects is not well defined by the language, so there is virtually nothing that the compiler can do for us. (As we have already shown, the &lt;code&gt;try-with-resources&lt;/code&gt; statement of Java and the &lt;code&gt;using&lt;/code&gt; keyword of C# are of very limited usefulness.)&lt;/p&gt;
&lt;p&gt;In order to implement necessary cleanup at the end of an object's lifetime in garbage-collected languages, programmers either rely on finalization, or explicitly invoke objects to let them know that their lifetime is over. As we have already shown, finalization is asynchronous and non-deterministic, so it is unsuitable for basing any essential function of our software upon it, which means that explicit object lifetime termination is the only viable option.&lt;/p&gt;
&lt;p&gt;Unfortunately, explicit object lifetime termination suffers from its own range of problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There is usually nothing in the code to give us a hint that we should place a call to end the lifetime of an object.&lt;/li&gt;
&lt;li&gt;When we forget to end the lifetime of an object, there is never any immediate error to tell us that we forgot.&lt;/li&gt;
&lt;li&gt;The problems that subsequently occur tend to be subtle, so we often do not notice them until a considerable time after the fact. For example, forgetting to unregister an observer from an event source turns the observing object into a memory leak, and causes the observing method to keep being needlessly invoked by the event source, to perform actions that in the best case only waste clock cycles without any value or effect, and in the non-best case cause malfunction.&lt;/li&gt;
&lt;li&gt;When the malfunction does get noticed, it often seems inexplicable and does not tend to point to the source of the problem.&lt;/li&gt;
&lt;li&gt;Even when we discover that a certain malfunction is due to the lifetime of an object not having been ended, it is usually difficult to tell at which point in the code it should have been ended. Often, in order to know this, we first need to know where in the code the object was allocated, but this information is not normally available.&lt;/li&gt;
&lt;li&gt;Writing tests to catch omissions in object lifetime control is not only hard and tedious, but it also requires testing against the implementation rather than testing against the interface, which violates recommended best practices. (To test whether object A properly ends the lifetime of object B, we have to mock B and ensure that its lifetime termination method is invoked by A, but if we do this then we are by definition testing against the implementation of A.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="the-solution"&gt;The Solution
&lt;/h4&gt;&lt;p&gt;Whereas it is generally true that &amp;quot;if you do everything right there will be no problems&amp;quot;, this is a very bad rule to live by, because it completely disregards another very important rule which says &amp;quot;there will be mistakes&amp;quot;. Reliance on everything being done right tends to result in brittle software designs, because some things will inevitably go wrong. We are definitely not advocating designs that are tolerant of mistakes; however, a software design must at the very least offer means of detecting mistakes and responding to them with hard error, diagnostic messages, or both; a design which relies on mistakes not being made, and at the same time is incapable of detecting the mistakes that will nonetheless be made, is doomed to run into trouble.&lt;/p&gt;
&lt;p&gt;Object lifetime awareness is a design pattern for writing robust software. It begins by acknowledging that in garbage collected languages there tends to be widespread uncertainty with respect to the lifetime of objects, which results in bugs that are very difficult to troubleshoot and fix. While the garbage collector would ideally be taking care of a lot of things, by its nature it cannot take care of everything, and in practice it often does not even take care of things that it is expected to, due to subtle human error.&lt;/p&gt;
&lt;p&gt;The impetus behind object lifetime awareness is that we have had enough of this uncertainty, so we are taking matters into our own hands by establishing definitive knowledge of the lifetime of our objects and taking full control over it. When an object has an inherent notion of lifetime, this notion must always be made explicit, and handled in a certain structured and recognizable manner, so that when mistakes occur, we receive hard errors and diagnostic messages, allowing us to fix problems without troubleshooting in the dark.&lt;/p&gt;
&lt;p&gt;Specifically, every lifetime-aware object must do the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Encapsulate an &amp;quot;alive&amp;quot; state which:
&lt;ul&gt;
&lt;li&gt;Starts as &amp;quot;true&amp;quot;.&lt;/li&gt;
&lt;li&gt;At some moment transitions to &amp;quot;false&amp;quot;.&lt;/li&gt;
&lt;li&gt;Is not exposed.&lt;/li&gt;
&lt;li&gt;It can be asserted.&lt;/li&gt;
&lt;li&gt;Can be inspected with a debugger.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;On debug runs, the lifetime-aware object must respond with hard error to any attempt to invoke any of its public instance methods once its lifetime is over.&lt;/li&gt;
&lt;li&gt;On debug runs, the lifetime-aware object must discover any omission to end its lifetime, and generate a diagnostic message if so. (More on how to achieve this later.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please note that the definition of a &amp;quot;debug run&amp;quot; varies depending on which language you are using:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In C# it is a run of the debug build.&lt;/li&gt;
&lt;li&gt;In Java it is a run with assertions enabled.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please also note that automated test runs are usually debug runs.&lt;/p&gt;
&lt;p&gt;Luckily we do not have to add lifetime awareness to all objects, we only need to add it to objects that belong to one or more of the following categories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Objects that by their nature have a concept of lifetime, such as timers, windows, files, network connections, notification suppressors, etc.&lt;/li&gt;
&lt;li&gt;Objects that once initialized, are known to have some cleanup to do eventually.&lt;/li&gt;
&lt;li&gt;Objects with which other objects may register in some way. (To ensure that each object that registers does not forget to unregister.)&lt;/li&gt;
&lt;li&gt;Objects that contain (own) other lifetime-aware objects.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In each system the objects that can benefit from lifetime awareness tend to be relatively few, while the majority of objects can continue being blissfully unaware of their lifetime, letting the garbage collector handle it.&lt;/p&gt;
&lt;p&gt;In certain rare cases, a lifetime-aware object may control its own lifetime; however, far more often, the lifetime of an object is meant to be controlled by other objects. In these cases, the lifetime-aware object should implement the disposal interface of the language, primarily in order to document the fact that it is lifetime-aware, and secondarily so that the &amp;quot;automatic&amp;quot; disposal mechanism of the language can be used when the opportunity arises.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In Java, that would be an object implementing the &lt;code&gt;Closeable&lt;/code&gt; interface, thus allowing us to sometimes make use of the &lt;code&gt;try-with-resources&lt;/code&gt; statement.&lt;/li&gt;
&lt;li&gt;In C#, that would be the an object implementing the &lt;code&gt;IDisposable&lt;/code&gt; interface, thus allowing us to sometimes make use of the &lt;code&gt;using&lt;/code&gt; keyword.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please note that the use of these interfaces here has nothing to do with releasing unmanaged resources; The goal is object lifetime awareness, while the releasing of unmanaged resources is at best a side note and largely a red herring in this discussion. It is true that the original intention of these interfaces was to allow releasing unmanaged resources, but there is absolutely nothing, either in the interfaces themselves, or in the language specifications, or in the respective compilers, or in the respective runtime environments, which says that this has to be the only purpose of these interfaces, or the only way they should be used, or the only way they can be used. So, here we are using them for something else. Please completely disregard the issue of unmanaged resources for now, we will address them later.&lt;/p&gt;
&lt;p&gt;By making objects aware of their own lifetime, we achieve the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Any discrepancy between an object's expected alive state and its actual alive state (i.e. whether we think it should be alive vs. whether it actually is alive) can be asserted against and therefore be swiftly and infallibly detected without any need for white-box testing.&lt;/li&gt;
&lt;li&gt;The alive state of an object can be explicitly and deterministically controlled without ever having to rely on finalization to do it for us.&lt;/li&gt;
&lt;li&gt;All necessary cleanup can be done when the alive state transitions to false, thus ensuring that each initialization action is always balanced by its corresponding cleanup action. This includes ending the lifetime of any contained (owned) objects, unregistering the object from whatever it had previously registered with, etc.&lt;/li&gt;
&lt;li&gt;At the end of the object's lifetime we can take whatever extra measures are within our power to take in order to ensure that the lifetime of other objects is being correctly managed. For example, we can assert that any objects which had previously registered with this object have by now unregistered themselves.&lt;/li&gt;
&lt;li&gt;More broadly, we construct our software to be in complete control over its inner workings, instead of leaving things to chance.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=""&gt;
&lt;/h4&gt;&lt;h4 id="detecting-omissions"&gt;Detecting omissions
&lt;/h4&gt;&lt;p&gt;The main thing which makes object lifetime awareness a viable proposition is the promise of useful diagnostic messages in response to omissions to explicitly end the lifetime of objects. Without such diagnostic messages, object lifetime awareness would not be much different from existing practices.&lt;/p&gt;
&lt;p&gt;Interestingly enough, (or perversely enough, depending on how you would like to see it,) the mechanism that we leverage in order to detect such omissions is the garbage collector itself. The idea is that an object can check during finalization whether it is still alive or not: if it discovers that it is being finalized while still alive, then this means that the programmer forgot to explicitly end the lifetime of the object at an earlier moment.&lt;/p&gt;
&lt;p&gt;It is very important to note that once we detect that an object is still alive during finalization, we specifically refrain from repeating the widespread mistake of trying to correct the problem: we most certainly do not attempt to end the lifetime of the object at that moment; instead, we only generate a diagnostic message, alerting the programmer that they forgot to end the lifetime of the object at an earlier time. This is important because the checks performed during finalization are meant to be of a strictly diagnostic nature, (a quality assurance mechanism if you wish,) so they are only meant to be performed on debug runs, so our software better be working correctly without them on release runs.&lt;/p&gt;
&lt;p&gt;One might protest that an object which has accidentally become a memory leak will never be finalized, so it will never discover that its lifetime was not ended. Luckily, this can be taken care of with a bit of infrastructural support and a bit of discipline: During application shutdown we ensure that our system undergoes an orderly and thorough cleanup phase, where all remaining lifetime-aware objects are terminated. Typically, this simply means ending the lifetime of the main application object, and this should cascade throughout the entire containment hierarchy, ending the lifetime of all objects. Once this cleanup phase is complete, and if this is a debug run, we force a full garbage collection, and we wait for it to complete before exiting the application. In doing so, we ensure that all finalizers are invoked, and this includes the finalizers of any objects that were inadvertently memory-leaked. Thus, any omission to end the lifetime of an object is detectable in the worst case during application shutdown. For this to work optimally, some extra discipline is necessary, for example avoiding to directly or indirectly anchor lifetime-aware objects in static storage.&lt;/p&gt;
&lt;p&gt;In actual practice most omissions to control the lifetime of objects happen without the objects necessarily also becoming memory-leaked, so the objects do get garbage-collected, so the omissions are detected at various moments during runtime when garbage collection occurs. For this reason, it is beneficial on debug runs to introduce regular forced garbage collection, thus detecting omissions as soon as possible after they happen. The right moment to force garbage collection tends to be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On web servers, immediately after servicing each client request.&lt;/li&gt;
&lt;li&gt;On desktop applications, immediately after each application logic idle event.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(An application logic idle event is similar to the graphical user interface idle event, except that it happens less frequently, i.e. not after every single event from the input system such as a mouse move, but only after the application logic has actually had some work to do.)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On data processing systems with a main loop, at the end of each iteration of the main loop.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is worth stressing that forced garbage collection only needs to be employed as a diagnostic tool, and only on debug runs. On release runs there is never a need to force garbage collection because all object lifetime control issues are presumed to have already been addressed.&lt;/p&gt;
&lt;p&gt;Forced garbage collection can also be used as a diagnostic tool during automated software testing; however, if our tests are fine-grained, (as the case usually is with unit tests,) it is advisable to refrain from forcing garbage collection after each test, because a full run of the garbage collector tends to be expensive, so its frequent use may multiply the total run time of a test suite by a very large factor. The ideal is to perform just one forced garbage collection at the end of all tests, and if any object lifetime control failures are detected, then and only then do another run of all tests with forced garbage collection enabled after each test, to detect precisely in which tests the failures occur.&lt;/p&gt;
&lt;p&gt;In order to force garbage collection at will during testing, one needs a testing framework which supports this, and I am not aware of any, but if you do not make use of any exotic features of your existing testing framework, it is easy to write your own and take control yourself.&lt;/p&gt;
&lt;h4 id="addendum-lifeguards"&gt;Addendum: Lifeguards
&lt;/h4&gt;&lt;p&gt;For an object to be aware of its own lifetime and to issue diagnostic messages when its lifetime is not properly controlled, a certain amount of functionality is needed, and we do not want to be coding this functionality by hand in each class that we write, so we will be delegating as much of the work as possible to a separate class. An appropriate name for such a class would be &lt;code&gt;ObjectLifetimeGuard&lt;/code&gt;, but this is a mouthful, so we will simply abbreviate it to &lt;code&gt;LifeGuard&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The lifeguard exposes only 2 methods:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A lifetime-assertion method which is invoked to assert that the lifeguard is still alive.&lt;/li&gt;
&lt;li&gt;An end-of-lifetime method which is invoked to let the lifeguard know that its lifetime is over.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With the introduction of the lifeguard, each lifetime-aware class only needs to do the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Obtain during construction, and fully encapsulate, an instance of &lt;code&gt;LifeGuard&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Perform an assertion at the beginning of each public instance method, (by definition only on debug runs, since it is an assertion,) which simply delegates to the lifetime-assertion method of the lifeguard.&lt;/li&gt;
&lt;li&gt;Implement the object disposal interface of the language at hand, performing whatever cleanup actions are necessary, and then delegating to the end-of-lifetime method of the lifeguard.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The lifeguard does the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On debug runs, it encapsulates an &lt;code&gt;alive&lt;/code&gt; state which starts as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;It implements the is-alive-assertion method as follows:
&lt;ul&gt;
&lt;li&gt;On debug runs, it returns &lt;code&gt;true&lt;/code&gt; if the object is alive, and throws an exception if not.&lt;/li&gt;
&lt;li&gt;On release runs, it always throws an exception, because it is only meant to be invoked from within assertions, and assertions are not meant to execute on release runs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;It implements the end-of-lifetime method as follows:
&lt;ul&gt;
&lt;li&gt;On debug runs, it first asserts that the object is currently alive, and then transitions the alive state to false.&lt;/li&gt;
&lt;li&gt;On release runs, it does nothing.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;On debug runs it defines a finalizer which checks whether the object is still alive during finalization, and generates a diagnostic message if so.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A lifeguard is obtained by invoking a factory method instead of using the &lt;code&gt;new&lt;/code&gt; keyword, because this method will return something different depending on whether this is a debug run or a release run. The factory can come in the form of a &lt;code&gt;static&lt;/code&gt; method for simplicity, or it can come in some other form if necessary.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The interface of the lifeguard has been designed in such a way that its alive state can be asserted without being exposed. This has the effect of:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Preventing misuse&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Allowing for a high performance implementation for release runs which does not even contain that state.&lt;/li&gt;
&lt;li&gt;Still allowing the alive state to be inspected with a debugger on debug runs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lifetime-aware objects that have a need for some similar state which is queryable must implement it separately. The fact that on debug runs this state will be mirroring the &lt;code&gt;alive&lt;/code&gt; state of the lifeguard is irrelevant.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In certain environments which support asynchronous method invocations it might be impossible to guarantee that no method is ever invoked past end of lifetime; these are exceptions to the rule, which need special handling by means of &lt;code&gt;if&lt;/code&gt; statements instead of assertions. Since the lifeguard only allows asserting the alive state without exposing it, such objects will need to implement their own &lt;code&gt;alive&lt;/code&gt; state in parallel to the lifeguard.&lt;/li&gt;
&lt;li&gt;As a rule, triggering hard error is preferable over generating diagnostic messages; however, an omission to end the lifetime of an object can only be detected during finalization, and by that time it is already too late for any fail-fast measures, so what we have here is an exception to the rule: in this particular case, it is okay if we just generate a diagnostic message. If needed, extra measures can be taken to alert the programmer to not forget to look at the diagnostic messages.&lt;/li&gt;
&lt;li&gt;The diagnostic message generated in the event of an omission to end the lifetime of an object is meant to include a stack trace, complete with source filenames and line numbers, showing precisely where in the source code the object was allocated, to help us easily locate and fix the problem.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unfortunately, this stack trace needs to be collected by the lifeguard during construction, just in case it will need to be displayed during finalization, but in many environments collecting a stack trace is unreasonably expensive, so if each lifeguard instantiation was to involve collecting a stack trace, this would run the danger of slowing down our debugs runs to the point of making them unusable. (Obtaining a stack trace with source filenames and line numbers a few dozen times per second incurs a noticeable penalty on the JVM, while under DotNet the penalty is catastrophically more severe.)&lt;/p&gt;
&lt;p&gt;For this reason, a special procedure is necessary: by default, stack traces are not collected, so a lifeguard which detects an omission to end the lifetime of an object reports only enough information to help us identify the class of the containing object. Once we know the class, we can go to the source code and flip a flag which enables stack trace collection for lifeguards of that specific class only, so that we can then re-run and obtain a message which includes a stack trace. Once we have solved the problem, we put the flag back to its default value to avoid the performance hit.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Both in C# and in Java there is an established tradition which says that methods involved in the closing or disposing of things should be forgiving, in the sense that multiple invocations should be permitted with no penalty. In my opinion this practice is ill-conceived, so instead I prescribe an end-of-lifetime method which asserts that it is never invoked twice. This is in line with the overall theme of object lifetime awareness, which is to gain greater control over the inner workings of our software. I am perfectly aware of the fact that this is parting ways with a tradition cherished by the entire industry; it is perfectly fine to part ways with traditions when you know better, especially since another term for tradition is &amp;quot;capricious progress-stopper&amp;quot;.&lt;/li&gt;
&lt;li&gt;The lifeguard is designed in such a way that on release runs it contains no state and performs no action; therefore, it need not be instantiated once per lifetime-aware object; instead, it can be a singleton, and all lifetime-aware objects can receive the same reference to its one and only dummy instance. Thus, the performance cost of using the lifeguard on release runs is near zero.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An implementation of lifeguard in C# is as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt; 1
&lt;/span&gt;&lt;span class="lnt"&gt; 2
&lt;/span&gt;&lt;span class="lnt"&gt; 3
&lt;/span&gt;&lt;span class="lnt"&gt; 4
&lt;/span&gt;&lt;span class="lnt"&gt; 5
&lt;/span&gt;&lt;span class="lnt"&gt; 6
&lt;/span&gt;&lt;span class="lnt"&gt; 7
&lt;/span&gt;&lt;span class="lnt"&gt; 8
&lt;/span&gt;&lt;span class="lnt"&gt; 9
&lt;/span&gt;&lt;span class="lnt"&gt; 10
&lt;/span&gt;&lt;span class="lnt"&gt; 11
&lt;/span&gt;&lt;span class="lnt"&gt; 12
&lt;/span&gt;&lt;span class="lnt"&gt; 13
&lt;/span&gt;&lt;span class="lnt"&gt; 14
&lt;/span&gt;&lt;span class="lnt"&gt; 15
&lt;/span&gt;&lt;span class="lnt"&gt; 16
&lt;/span&gt;&lt;span class="lnt"&gt; 17
&lt;/span&gt;&lt;span class="lnt"&gt; 18
&lt;/span&gt;&lt;span class="lnt"&gt; 19
&lt;/span&gt;&lt;span class="lnt"&gt; 20
&lt;/span&gt;&lt;span class="lnt"&gt; 21
&lt;/span&gt;&lt;span class="lnt"&gt; 22
&lt;/span&gt;&lt;span class="lnt"&gt; 23
&lt;/span&gt;&lt;span class="lnt"&gt; 24
&lt;/span&gt;&lt;span class="lnt"&gt; 25
&lt;/span&gt;&lt;span class="lnt"&gt; 26
&lt;/span&gt;&lt;span class="lnt"&gt; 27
&lt;/span&gt;&lt;span class="lnt"&gt; 28
&lt;/span&gt;&lt;span class="lnt"&gt; 29
&lt;/span&gt;&lt;span class="lnt"&gt; 30
&lt;/span&gt;&lt;span class="lnt"&gt; 31
&lt;/span&gt;&lt;span class="lnt"&gt; 32
&lt;/span&gt;&lt;span class="lnt"&gt; 33
&lt;/span&gt;&lt;span class="lnt"&gt; 34
&lt;/span&gt;&lt;span class="lnt"&gt; 35
&lt;/span&gt;&lt;span class="lnt"&gt; 36
&lt;/span&gt;&lt;span class="lnt"&gt; 37
&lt;/span&gt;&lt;span class="lnt"&gt; 38
&lt;/span&gt;&lt;span class="lnt"&gt; 39
&lt;/span&gt;&lt;span class="lnt"&gt; 40
&lt;/span&gt;&lt;span class="lnt"&gt; 41
&lt;/span&gt;&lt;span class="lnt"&gt; 42
&lt;/span&gt;&lt;span class="lnt"&gt; 43
&lt;/span&gt;&lt;span class="lnt"&gt; 44
&lt;/span&gt;&lt;span class="lnt"&gt; 45
&lt;/span&gt;&lt;span class="lnt"&gt; 46
&lt;/span&gt;&lt;span class="lnt"&gt; 47
&lt;/span&gt;&lt;span class="lnt"&gt; 48
&lt;/span&gt;&lt;span class="lnt"&gt; 49
&lt;/span&gt;&lt;span class="lnt"&gt; 50
&lt;/span&gt;&lt;span class="lnt"&gt; 51
&lt;/span&gt;&lt;span class="lnt"&gt; 52
&lt;/span&gt;&lt;span class="lnt"&gt; 53
&lt;/span&gt;&lt;span class="lnt"&gt; 54
&lt;/span&gt;&lt;span class="lnt"&gt; 55
&lt;/span&gt;&lt;span class="lnt"&gt; 56
&lt;/span&gt;&lt;span class="lnt"&gt; 57
&lt;/span&gt;&lt;span class="lnt"&gt; 58
&lt;/span&gt;&lt;span class="lnt"&gt; 59
&lt;/span&gt;&lt;span class="lnt"&gt; 60
&lt;/span&gt;&lt;span class="lnt"&gt; 61
&lt;/span&gt;&lt;span class="lnt"&gt; 62
&lt;/span&gt;&lt;span class="lnt"&gt; 63
&lt;/span&gt;&lt;span class="lnt"&gt; 64
&lt;/span&gt;&lt;span class="lnt"&gt; 65
&lt;/span&gt;&lt;span class="lnt"&gt; 66
&lt;/span&gt;&lt;span class="lnt"&gt; 67
&lt;/span&gt;&lt;span class="lnt"&gt; 68
&lt;/span&gt;&lt;span class="lnt"&gt; 69
&lt;/span&gt;&lt;span class="lnt"&gt; 70
&lt;/span&gt;&lt;span class="lnt"&gt; 71
&lt;/span&gt;&lt;span class="lnt"&gt; 72
&lt;/span&gt;&lt;span class="lnt"&gt; 73
&lt;/span&gt;&lt;span class="lnt"&gt; 74
&lt;/span&gt;&lt;span class="lnt"&gt; 75
&lt;/span&gt;&lt;span class="lnt"&gt; 76
&lt;/span&gt;&lt;span class="lnt"&gt; 77
&lt;/span&gt;&lt;span class="lnt"&gt; 78
&lt;/span&gt;&lt;span class="lnt"&gt; 79
&lt;/span&gt;&lt;span class="lnt"&gt; 80
&lt;/span&gt;&lt;span class="lnt"&gt; 81
&lt;/span&gt;&lt;span class="lnt"&gt; 82
&lt;/span&gt;&lt;span class="lnt"&gt; 83
&lt;/span&gt;&lt;span class="lnt"&gt; 84
&lt;/span&gt;&lt;span class="lnt"&gt; 85
&lt;/span&gt;&lt;span class="lnt"&gt; 86
&lt;/span&gt;&lt;span class="lnt"&gt; 87
&lt;/span&gt;&lt;span class="lnt"&gt; 88
&lt;/span&gt;&lt;span class="lnt"&gt; 89
&lt;/span&gt;&lt;span class="lnt"&gt; 90
&lt;/span&gt;&lt;span class="lnt"&gt; 91
&lt;/span&gt;&lt;span class="lnt"&gt; 92
&lt;/span&gt;&lt;span class="lnt"&gt; 93
&lt;/span&gt;&lt;span class="lnt"&gt; 94
&lt;/span&gt;&lt;span class="lnt"&gt; 95
&lt;/span&gt;&lt;span class="lnt"&gt; 96
&lt;/span&gt;&lt;span class="lnt"&gt; 97
&lt;/span&gt;&lt;span class="lnt"&gt; 98
&lt;/span&gt;&lt;span class="lnt"&gt; 99
&lt;/span&gt;&lt;span class="lnt"&gt;100
&lt;/span&gt;&lt;span class="lnt"&gt;101
&lt;/span&gt;&lt;span class="lnt"&gt;102
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;namespace&lt;/span&gt; &lt;span class="nn"&gt;SomeNamespace&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="nn"&gt;Sys&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="nn"&gt;Collections&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Collections&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Generic&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="nn"&gt;System.Linq&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="nn"&gt;SysDiag&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Diagnostics&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="nn"&gt;SysComp&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Runtime&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CompilerServices&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;abstract&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;LifeGuard&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Sys&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;IDisposable&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="n"&gt;LifeGuard&lt;/span&gt; &lt;span class="n"&gt;Create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;collectStackTrace&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="c1"&gt;//&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="na"&gt; [SysComp.CallerFilePath]&lt;/span&gt; &lt;span class="kt"&gt;string?&lt;/span&gt; &lt;span class="n"&gt;callerFilePath&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="c1"&gt;//&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="na"&gt; [SysComp.CallerLineNumber]&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;callerLineNumber&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="p"&gt;!&lt;/span&gt;&lt;span class="n"&gt;DebugMode&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;ProductionLifeGuard&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Instance&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;callerFilePath&lt;/span&gt; &lt;span class="p"&gt;!=&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;collectStackTrace&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;VerboseDebugLifeGuard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;TerseDebugLifeGuard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;callerFilePath&lt;/span&gt;&lt;span class="p"&gt;!,&lt;/span&gt; &lt;span class="n"&gt;callerLineNumber&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;abstract&lt;/span&gt; &lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="n"&gt;Dispose&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;abstract&lt;/span&gt; &lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;IsAliveAssertion&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;sealed&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ProductionLifeGuard&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;LifeGuard&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="k"&gt;readonly&lt;/span&gt; &lt;span class="n"&gt;ProductionLifeGuard&lt;/span&gt; &lt;span class="n"&gt;Instance&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;ProductionLifeGuard&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="n"&gt;ProductionLifeGuard&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="c1"&gt;//nothing to do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;override&lt;/span&gt; &lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="n"&gt;Dispose&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="c1"&gt;//nothing to do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;override&lt;/span&gt; &lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;IsAliveAssertion&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;throw&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Sys&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Exception&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;//never invoke on a release build&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;DebugLifeGuard&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;LifeGuard&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;alive&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="k"&gt;readonly&lt;/span&gt; &lt;span class="kt"&gt;string&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;protected&lt;/span&gt; &lt;span class="n"&gt;DebugLifeGuard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kt"&gt;string&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;message&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;sealed&lt;/span&gt; &lt;span class="kd"&gt;override&lt;/span&gt; &lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="n"&gt;Dispose&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;alive&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;alive&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GC&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SuppressFinalize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="k"&gt;this&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;sealed&lt;/span&gt; &lt;span class="kd"&gt;override&lt;/span&gt; &lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;IsAliveAssertion&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;alive&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;protected&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;string&lt;/span&gt; &lt;span class="n"&gt;GetSourceInfo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kt"&gt;string?&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;lineNumber&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s"&gt;$&amp;#34;{filename}({lineNumber})&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;~&lt;/span&gt;&lt;span class="n"&gt;DebugLifeGuard&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;SysDiag&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Debug&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;WriteLine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="s"&gt;&amp;#34;Object still alive!&amp;#34;&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;SysDiag&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Debug&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;WriteLine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;override&lt;/span&gt; &lt;span class="kt"&gt;string&lt;/span&gt; &lt;span class="n"&gt;ToString&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;=&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;gt&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;alive&lt;/span&gt; &lt;span class="p"&gt;?&lt;/span&gt; &lt;span class="s"&gt;&amp;#34;&amp;#34;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#34;END-OF-LIFE&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;sealed&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;TerseDebugLifeGuard&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;DebugLifeGuard&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="n"&gt;TerseDebugLifeGuard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kt"&gt;string&lt;/span&gt; &lt;span class="n"&gt;callerFilePath&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;callerLineNumber&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;base&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="s"&gt;$&amp;#34; {GetSourceInfo( callerFilePath, callerLineNumber )}&amp;#34;&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;sealed&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;VerboseDebugLifeGuard&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;DebugLifeGuard&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="n"&gt;VerboseDebugLifeGuard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;framesToSkip&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;base&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;buildMessage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;framesToSkip&lt;/span&gt; &lt;span class="p"&gt;+&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;string&lt;/span&gt; &lt;span class="n"&gt;buildMessage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;framesToSkip&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="s"&gt;&amp;#34;\r\n&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;getStackFrames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;framesToSkip&lt;/span&gt; &lt;span class="p"&gt;+&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;//&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Select&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;getSourceInfoFromStackFrame&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="n"&gt;SysDiag&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;StackFrame&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;getStackFrames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;framesToSkip&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;var&lt;/span&gt; &lt;span class="n"&gt;stackTrace&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;SysDiag&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;StackTrace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;framesToSkip&lt;/span&gt; &lt;span class="p"&gt;+&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;SysDiag&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;StackFrame&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;frames&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;stackTrace&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GetFrames&lt;/span&gt;&lt;span class="p"&gt;()!;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Sys&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Type&lt;/span&gt; &lt;span class="n"&gt;type&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;frames&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;GetMethod&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;DeclaringType&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;Assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="k"&gt;typeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Sys&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;IDisposable&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;IsAssignableFrom&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;type&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;frames&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="p"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GetFileName&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;!=&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;//&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ToArray&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;private&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;string&lt;/span&gt; &lt;span class="n"&gt;getSourceInfoFromStackFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;SysDiag&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;StackFrame&lt;/span&gt; &lt;span class="n"&gt;frame&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kt"&gt;string&lt;/span&gt; &lt;span class="n"&gt;sourceInfo&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GetSourceInfo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GetFileName&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GetFileLineNumber&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s"&gt;$&amp;#34; {sourceInfo}: {frame.GetMethod().DeclaringType}.{frame.GetMethod().Name}()&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Note that in theory, &lt;code&gt;private readonly string message&lt;/code&gt; may have already been finalized by the time the destructor attempts to use it. In reality, I have never encountered this happening. If it becomes a problem, a simple &lt;code&gt;string.Intern()&lt;/code&gt; could be used to permanently anchor these strings in memory, and that is okay despite the fact that it essentially introduces a memory leak, because it is only applicable to debug runs.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;DebugMode&lt;/code&gt; is defined as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt; 1
&lt;/span&gt;&lt;span class="lnt"&gt; 2
&lt;/span&gt;&lt;span class="lnt"&gt; 3
&lt;/span&gt;&lt;span class="lnt"&gt; 4
&lt;/span&gt;&lt;span class="lnt"&gt; 5
&lt;/span&gt;&lt;span class="lnt"&gt; 6
&lt;/span&gt;&lt;span class="lnt"&gt; 7
&lt;/span&gt;&lt;span class="lnt"&gt; 8
&lt;/span&gt;&lt;span class="lnt"&gt; 9
&lt;/span&gt;&lt;span class="lnt"&gt;10
&lt;/span&gt;&lt;span class="lnt"&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;DebugMode&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;get&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#if&lt;/span&gt; &lt;span class="n"&gt;DEBUG&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#else&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cp"&gt;#endif&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;This allows us to minimize the use of &lt;code&gt;#if DEBUG&lt;/code&gt;, which is ugly and cumbersome, and often results in code rot in the &lt;code&gt;#endif&lt;/code&gt; part, which is only discoverable when trying to compile the release build.&lt;/p&gt;
&lt;h4 id="addendum-ad-hoc-alive-states"&gt;Addendum: Ad-hoc alive states
&lt;/h4&gt;&lt;p&gt;Object lifetime awareness comes with a piece of advice:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Avoid ad-hoc alive states, implement them as separate lifetime-aware objects instead.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;What this means is that a class should refrain from exposing a pair of methods for entering and exiting some special state of that class, and instead it should expose only one method which creates a new lifetime-aware object to represent that special state, and to exit the state when its lifetime is ended. Then, if the class has any methods which may only be invoked while in that special state, these methods must be moved into the special state object, so that they are not even available unless the special state has been entered.&lt;/p&gt;
&lt;p&gt;By following this advice we split the interface of our object into smaller interfaces that are more simple and intuitive, we clearly document what is going on by making use of the lifetime-awareness pattern, and we take advantage of the error-checking and diagnostic facilities of the lifetime-awareness mechanism.&lt;/p&gt;
&lt;p&gt;An example of an interface which could have benefited from this advice is the JDBC API. This interface exposes a multitude of methods for dealing with a relational database, and among them it exposes a pair of methods for beginning and ending a transaction. A better way of structuring that interface would have been to expose a single method for creating a new transaction object, which in turn ends the transaction when disposed. Then, all the data manipulation methods would be moved into that object, so that it is impossible to manipulate data unless a transaction is active.&lt;/p&gt;
&lt;h4 id="addendum-unmanaged-resources"&gt;Addendum: Unmanaged Resources
&lt;/h4&gt;&lt;p&gt;As we have shown, by leveraging hard error and diagnostic messages on debug runs and test runs, the object lifetime awareness pattern guarantees cleanup at the end of an object's lifetime.&lt;/p&gt;
&lt;p&gt;Conveniently enough, this cleanup can, and should, include the releasing of unmanaged resources.&lt;/p&gt;
&lt;p&gt;This in turn means that we never need to involve finalization for this task, not even as a fallback mechanism: unmanaged resources can be released infallibly, deterministically, and synchronously, i.e. &lt;em&gt;always right now,&lt;/em&gt; as opposed to at some unknown moment later in time, if at all. This also means that on release runs we do not need finalization at all.&lt;/p&gt;
&lt;p&gt;In essence, the releasing of unmanaged resources loses the special status that it has enjoyed so far, and becomes regular cleanup just as any other kind of cleanup. Our software sees to it that all necessary cleanup is always performed, without leaving anything to chance, and without any distinctions between really important cleanup and not-so-important cleanup.&lt;/p&gt;
&lt;p&gt;C#-only note: This also means that there is no more need for that &lt;code&gt;Dispose(bool)&lt;/code&gt; nonsense, either.&lt;/p&gt;
&lt;h4 id="further-research-and-recommendations"&gt;Further research and recommendations
&lt;/h4&gt;&lt;p&gt;Lifetime aware objects may benefit from a lifetime control service being propagated throughout the containment hierarchy so that they can register and unregister from it, thus:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Eliminating the need for a static factory of lifeguard;&lt;/li&gt;
&lt;li&gt;Allowing us to at any given moment traverse the entire graph of lifetime-aware objects to see who is still alive;&lt;/li&gt;
&lt;li&gt;Making it impossible to inadvertently construct a lifetime-aware object without having explicit knowledge of the fact that it is lifetime-aware, since the lifetime control service must be passed to its constructor.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Object lifetime awareness has the theoretic potential of completely eliminating all finalization overhead. Unfortunately, as things stand today, this potential cannot be realized, because existing runtime environments still offer essential classes that make unconditional use of finalization; e.g. classes that represent files, sockets, etc. These environments could benefit from new implementations of such essential classes that make use of the object lifetime awareness pattern so as to also avoid finalization. (While at it, please also note that these same classes could really benefit from not being needlessly multithreading-aware; when we have a use for multithreading awareness, we can add it ourselves, thank you.)&lt;/p&gt;
&lt;p&gt;Additionally, if it could be definitively established that finalization is to be used only for the purpose of generating diagnostic messages, then the entire machinery implementing finalization in runtime environments could be greatly simplified from the monster of complexity that it is today. Consider, for example, that garbage collectors are currently built to handle such preposterous situations as &amp;quot;object resurrection&amp;quot;, which is what may happen if a finalizer decides to anchor an object in memory, thus taking an object which had previously become eligible for collection and making it not eligible anymore. If finalization could be made trivial, then object resurrection could become impossible, or it could result in hard error rather than having to be handled.&lt;/p&gt;
&lt;p&gt;Also see my previous post &lt;a
href="https://blog2.michael.gr/post/2015-03-on-dispose-bool-disposing-abomination/"
&gt;Mandatory disposal vs. the 'Dispose-disposing' abomination&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Cover image: &lt;em&gt;The Thinker&lt;/em&gt; (French: &lt;em&gt;Le Penseur&lt;/em&gt;) by Auguste Rodin (From &lt;a class="external"
href="https://en.wikipedia.org/wiki/The_Thinker" target="_blank"
&gt;Wikipedia&lt;/a&gt;)&lt;/p&gt;
&lt;div class="footnotes" role="doc-endnotes"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;The language feature that C# calls &amp;quot;destructor&amp;quot; is a misnomer; it is not a destructor, it is a finalizer, and the choice of the tilde syntax to denote finalizers in C# as if they were C++ destructors has caused nothing but confusion. Microsoft has been reluctantly &lt;a class="external"
href="https://docs.microsoft.com/en-us/archive/blogs/ericlippert/whats-the-difference-between-a-destructor-and-a-finalizer" target="_blank"
&gt;acknowledging this&lt;/a&gt; and quietly &lt;a class="external"
href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/destructors" target="_blank"
&gt;correcting their terminology&lt;/a&gt; in their documentation.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink"&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description></item><item><title>Coherence: The Assertable Lock</title><link>https://blog2.michael.gr/post/2020-12-12-coherence/</link><pubDate>Sat, 12 Dec 2020 13:51:31 +0000</pubDate><guid>https://blog2.michael.gr/post/2020-12-12-coherence/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2020-12-12-coherence/media/coherence.jpg"
width="1280"
height="853"
srcset="https://blog2.michael.gr/post/2020-12-12-coherence/media/coherence_hu_774fdb15a774b77.jpg 480w, https://blog2.michael.gr/post/2020-12-12-coherence/media/coherence_hu_d8603833f9d0eb32.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
&gt;
&lt;/p&gt;
&lt;h3 id="abstract"&gt;Abstract
&lt;/h3&gt;&lt;p&gt;A Software Design Pattern for concurrent systems is presented, which makes race conditions something that can be asserted against and thus &lt;strong&gt;deterministically eliminated&lt;/strong&gt; rather than stochastically reduced or minimized.&lt;/p&gt;
&lt;h3 id="a-description-of-the-problem"&gt;A description of the problem
&lt;/h3&gt;&lt;p&gt;Every Software Engineer who has dealt with concurrency knows that it is hard. The bane of concurrency is race conditions: when a thread accesses data without taking into account the fact that the data is shared with other concurrently running threads which may alter that data at any unforeseeable moment in time.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;There exist two kinds of race conditions that I can think of, let's call them &lt;em&gt;&lt;strong&gt;physical&lt;/strong&gt;&lt;/em&gt; and &lt;em&gt;&lt;strong&gt;logical&lt;/strong&gt;&lt;/em&gt;. (I just made up these terms, perhaps they have already been studied and given other names, but I am unaware of that.)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Physical Race Conditions&lt;/strong&gt; happen due to the way the underlying hardware works. One example is trying to read a variable consisting of who machine words, thus requiring two successive read operations which are not atomic, while another thread is simultaneously writing to that variable, resulting in garbage being read. Another example is two threads simultaneously performing increment operations on the same memory location, where a memory increment is implemented by the CPU as a non-atomic sequence of read-increment-write operations, resulting in some of the increments being lost.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Logical Race Conditions&lt;/strong&gt; happen when application logic fails to account for concurrency. For example, checking whether a collection contains a value, and if not, adding the value to the collection: when two threads try to do this, it will sometimes happen that they will both find that the collection does not contain the value in question, and will both add it, resulting in a duplicate. Depending on whether the implementation of the collection allows duplicates or not, this will result either in soft malfunction, (a duplicate where it was not intended,) or in hard failure due to the collection throwing a &amp;quot;duplicate element&amp;quot; exception.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that logical race conditions can occur even if we have taken all necessary precautions (i.e. locking) to avoid physical race conditions. Incidentally, this is the reason why many of the so-called &amp;quot;concurrent&amp;quot; collections like the &amp;quot;concurrent map&amp;quot; are of very limited use: sure, they guarantee that they will not crash and burn, but they do not guarantee correct results.&lt;/p&gt;
&lt;p&gt;Race conditions exhibit a disastrous combination of unfortunate qualities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Non-deterministic:&lt;/strong&gt; you cannot reproduce them at will, they just appear to happen at random, so you can almost never use the debugger to troubleshoot them.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sensitive to troubleshooting instrumentation:&lt;/strong&gt; not only they never manifest while single-stepping through code, but if you introduce extra code to detect them, they may seemingly disappear, because they are highly dependent on timing. The moment you remove the instrumentation however, they may start manifesting again.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Elusive:&lt;/strong&gt; their effects are usually observed not at the moment that they occur but after the fact, so it is difficult to tell what happened and why it happened.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Confusing:&lt;/strong&gt; sometimes, the malfunction that they cause seems at first impossible to happen, requiring extensive troubleshooting before the realization sinks in that it must be due to a race condition.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-faced:&lt;/strong&gt; in many cases the effects of a race condition differ on each manifestation, so you are never sure whether you are chasing one issue or several issues at the same time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Untestable:&lt;/strong&gt; there is no unit test that can catch race conditions or give any assurances for their absence.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Treacherous:&lt;/strong&gt; a race condition which happens on average once every million seconds of usage may take months before it manifests in your development environment, and yet once there are a million customers using your software, there will be one customer encountering it roughly every second.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Catastrophic:&lt;/strong&gt; program state corruption tends to result in complete failure of the software.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="solutions-that-try-to-avoid-the-problem"&gt;Solutions that try to avoid the problem
&lt;/h3&gt;&lt;p&gt;Since concurrency with locks is so hard, a number of mechanisms have been invented that try to implement concurrency without locking.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Immutability (functional programming):&lt;/strong&gt; if all program state is immutable, then there is no possibility of one thread modifying some state while another thread is trying to read it, because there is no state that can be modified. Therefore, no locking is necessary.&lt;/p&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Functional programming and immutability are not ubiquitous, and it is yet to be seen whether they will ever become ubiquitous.&lt;/li&gt;
&lt;li&gt;Many implementations of Functional Programming are not purely functional, they mix mutability with immutability, so the problem remains.&lt;/li&gt;
&lt;li&gt;Functional programming is only common in high-level systems running on garbage-collecting virtual machines. It is rare in mid-level systems and virtually absent in low-level systems.&lt;/li&gt;
&lt;li&gt;Many of the data structures that give the illusion of mutability while their inner workings are immutable tend to be computationally more expensive than their straightforward mutable counterparts.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Message-passing:&lt;/strong&gt; threads never share any data, instead they only work on data that they exclusively own, and they exchange data by means of immutable messages passed through message queues. Essentially, in the entire system there is only one little piece of code which employs locking, and that is the concurrent message queue implementation. The idea is that we should be able to get at least that small part right.&lt;/p&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Performance suffers as the amount of data exchanged among threads increases.&lt;/li&gt;
&lt;li&gt;Performance also suffers since data can never be manipulated in-place, it must be placed in a message, the message must be posted into a queue, a thread context switch must usually occur for the receiving thread to process the message, and then the reverse path must be followed for the original thread to receive the result. (When manipulating data in-place, a thread context switch will only occur when attempting to obtain a lock while another thread already holds that lock, which may be a rare occurrence.)&lt;/li&gt;
&lt;li&gt;Nowadays in order to avoid the tedious creation of countless message classes you are more likely to just post a lambda into the message queue, but then you have a lambda which is declared in one thread but executed in another thread, so you still have to be extremely careful with what that lambda is allowed to touch.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Other:&lt;/strong&gt; exotic mechanisms such as the single-writer principle of the Rust programming language.&lt;/p&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;They tend to require compiler support. (So, a mechanism that can be implemented in any language would still be of value.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, avoiding race conditions when practicing concurrency by means of locking is an existing problem in need of a solution.&lt;/p&gt;
&lt;h3 id="a-deeper-look-at-the-problem"&gt;A deeper look at the problem
&lt;/h3&gt;&lt;p&gt;At the heart of the race condition problem lies the &amp;quot;to lock or not to lock&amp;quot; conundrum. The choice of what to do lies in a continuum between two absurd extremes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Ultra-fine grain locking:&lt;/strong&gt; Always lock every single little piece of mutable state when accessing it, and only while accessing it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ultra-coarse grain locking:&lt;/strong&gt; Place a global lock on the entirety of your mutable state on program start and release it on program exit.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Obviously, neither of these extreme approaches would work.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ultra-fine grain locking would result in an unreasonable amount of bloat in
all code that we write, it would suffer performance-wise, and although it
would eliminate physical race conditions, it would do nothing for
logical race conditions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ultra-coarse grain locking would not work either because increasing the
lifetime of a lock also increases the chances that other threads will be
blocked, with the absurd extreme of the lock lifetime being equal to program
runtime resulting in all threads becoming permanently blocked and no actual
sharing of any mutable state ever taking place.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, the answer to the &amp;quot;to lock or not to lock&amp;quot; conundrum always lies somewhere in-between:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Always lock for as long as necessary, but try not to lock any longer than necessary.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This leads to the number one cause of race conditions:&lt;/p&gt;
&lt;p&gt;Trying to lock for as long as necessary but to avoid locking longer than necessary means that there will always be code which is accessing mutable state without first acquiring a fine grain lock, and instead is &lt;em&gt;&lt;strong&gt;assuming&lt;/strong&gt;&lt;/em&gt; that a coarser grain lock has already been acquired by some other code higher up the call-tree. (Remember, computer science trees are upside-down.) This assumption leaves open the possibility of human error, as the programmer who wrote the code higher up the call-tree may have forgotten to lock, thus putting all code below it at risk of race conditions.&lt;/p&gt;
&lt;p&gt;This situation is so widespread that it may be hard to realize its full extent: every single time we invoke a standard runtime library mutable collection class (which is one of the most frequent things we do) we are engaging in this assumption: the collection is not concurrency aware, so it is not placing any locks, but it is manipulating mutable state, so under conditions of concurrency it will fail unless a lock is in place. Essentially, the collection class is doing its job while &lt;em&gt;praying&lt;/em&gt; that someone up the call tree has remembered to acquire the necessary lock.&lt;/p&gt;
&lt;p&gt;The grain of locks affects two things: performance and correctness.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Choosing the grain of the locks in the most performant way is more of an art than a science, requiring a master of the craft to do it right, and that is okay: experts will always be useful. If no expert is available, performance might end up being suboptimal, but the software will still run, so strictly speaking the expert is not necessary.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Choosing the grain of the locks in such a way that the program remains correct is also more of an art than a science as things stand today, so it also requires a master of the craft to do it right; however, if we want to be thinking of our profession as a science rather than an art, we cannot have software that tends to crash and burn unless a master of the craft has written it. Therefore, we need a mechanism for detecting and protecting ourselves against the human error which is practically inevitable when an apprentice rather than a master touches the code, or even when the master touches the code while having a bad day.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="restating-the-problem"&gt;Restating the problem
&lt;/h3&gt;&lt;p&gt;A very important first step in solving a problem often is to restate it
using terminology that is more conducive to solving it. The term &amp;quot;Race
Condition&amp;quot; is somewhat cumbersome because it refers to an unfortunate event
which may or may not happen, depending on non-deterministic
circumstances. The original 1954 paper by David Huffman, titled &amp;quot;The synthesis of sequential switching circuits&amp;quot;, which contains the
first known mention of the term, regards race conditions as something which
may exist when a certain instability is detected, so even the original sense referred to events that may potentially occur.&lt;/p&gt;
&lt;p&gt;However, if we care about software correctness, then we do not want to be leaving anything to chance, so the fact that the unfortunate event &lt;em&gt;&lt;strong&gt;may&lt;/strong&gt;&lt;/em&gt; happen is irrelevant: if circumstances can arise at all which would potentially allow a race condition to occur, then for all practical purposes it must be assumed that the race condition &lt;em&gt;&lt;strong&gt;will&lt;/strong&gt;&lt;/em&gt; occur. Therefore, the race conditions themselves should be of no interest to us; what should be of interest is modes of operation that allow race conditions to occur. We will call them Race Modes.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A &lt;strong&gt;Race Mode&lt;/strong&gt; is an erroneous mode of operation in which a race condition can potentially occur.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A piece of software either enters race modes, or it does not. If it does enter race modes, then race conditions may occur, and as already established, it should be presumed that they will occur. If the software never enters any race modes, then no race conditions can occur.&lt;/p&gt;
&lt;p&gt;So, the problem has been restated from &amp;quot;avoiding race conditions&amp;quot; to &amp;quot;avoiding race modes&amp;quot;. The difference may be subtle, but it is important enough to make.&lt;/p&gt;
&lt;h3 id="the-solution"&gt;The solution
&lt;/h3&gt;&lt;p&gt;In restating the problem as described above we have set ourselves a new goal: how to assert against race modes. If race modes can be asserted against, then the concurrency problem stops being subject to chance and becomes quite deterministic instead: if our software runs and no assertion failures occur, then it never enters a race mode, and therefore no race conditions are possible. (Note that the assertions are not meant to catch race conditions; the assertions are meant to catch race modes.)&lt;/p&gt;
&lt;p&gt;The mechanism that I have come up with for asserting against race modes is called &lt;em&gt;&lt;strong&gt;Coherence&lt;/strong&gt;&lt;/em&gt; and in its simplest form it can be thought of as an abstraction of an &lt;em&gt;Assertable Lock&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;There are two things you can do with coherence: enter it, and assert it. (By entering coherence we mean executing a piece of code while in coherence, so once that piece of code is done executing, coherence will be exited.) So, coherence gives us the ability to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Take measures at certain places in our code to prevent entering a race mode.&lt;/li&gt;
&lt;li&gt;Ensure in all other places in our code that the necessary measures have been taken to guarantee we are not in a race mode.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thus, coherence saves us from doing ultra-fine grain locking and from making assumptions about locking: by turning locks into something assertable, we do not have to acquire a lock every single time we touch mutable state, but we can assert that a lock has been acquired by code higher up the call tree. Since assertions can compile to nothing on the release build, this is a zero-runtime-cost solution.&lt;/p&gt;
&lt;p&gt;The name Coherence was chosen as opposed to Assertable Lock because Coherence is meant to be a high level abstraction. The use of an abstraction is necessary for two reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Coherence is meant to be asserted ubiquitously by any code that accesses mutable state, even by general purpose code such as the standard collection classes. However, general purpose code tends to be (and should remain) agnostic of concurrency, so it should not be burdened with such a low-level and concurrency-specific concept as locking.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Depending on the concurrency characteristics of the execution environment, there can be different implementations of coherence, some of which do not even involve actual locking, so using the term 'Lock' would be inaccurate and misleading.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples of possible coherence implementations depending on the concurrency characteristics of the execution environment:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In a strictly single-threaded environment, a dummy implementation is needed which never places any locks and never fails a coherence check.&lt;/li&gt;
&lt;li&gt;In a share-nothing environment, a simple implementation will suffice which never places any locks and only fails a coherence check if the currently executing thread is not the thread that owns the mutable state, i.e. the thread in which the mutable state was created.&lt;/li&gt;
&lt;li&gt;In a thread-pooled, share-nothing environment, a somewhat more elaborate implementation is needed which takes into account the fact that the thread which owns the mutable state may not necessarily be the thread that created the mutable state, since threads are picked from a pool.&lt;/li&gt;
&lt;li&gt;In a multi-threaded environment with a small amount of shared state, a singular locking implementation will suffice which enters coherence by obtaining a lock on the totality of the shared state and fails the coherence check when that lock has not been obtained. This represents a coarse grain lock, so it might result in sub-optimal performance, but it has the advantage of being simple and avoiding deadlocks.&lt;/li&gt;
&lt;li&gt;In a multi-threaded environment with a large amount of shared state and high thread contention over it, necessitating finer grain locking for good enough performance, a plural coherence implementation can be used which allows placing independent locks on independent subsets of the shared state, and fails a coherence check when the lock corresponding to a particular subset of state has not been obtained. Care must be exercised to always enter and assert the correct instance of coherence for each subset of state, and to avoid deadlocks in doing so.&lt;/li&gt;
&lt;li&gt;Regardless of the concurrency characteristics of the execution environment, when the lifetime of a certain piece of mutable state is confined within a single call tree, a simple coherence implementation will again suffice which does not place a lock and simply asserts that the current thread is the thread in which the state was created. (To guard against the mutable state somehow escaping the scope of the call tree in which it was meant to be confined.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that Coherence only allows asserting its state and purposefully disallows testing its state. In other words, you cannot have an &amp;quot;if coherence is entered then...&amp;quot; construct. This is done so as to prevent misuse and to allow for high performance coherence implementations that, on the release build, may not have explicit knowledge of whether coherence has been entered or not.&lt;/p&gt;
&lt;p&gt;Note that unlike most existing locking mechanisms, which explicitly allow a thread to obtain a lock multiple times, coherence explicitly disallows re-entrance. I have chosen to do it this way because my approach to Software Engineering is &amp;quot;leave nothing to chance&amp;quot;, so if you are unsure whether you have already obtained a lock on something, and you would like the locking mechanism to be forgiving in case you try to lock twice, then you must be doing something wrong. It is my firm belief that when a piece of framework is in a position of alerting you that you are doing something wrong, it should be alerting you that you are doing something wrong. Of course it may be that I am wrong here, and unbeknownst to me there exist legitimate reasons for having to allow coherence reentrancy; this remains to be seen.&lt;/p&gt;
&lt;h3 id="further-research"&gt;Further Research
&lt;/h3&gt;&lt;p&gt;As mentioned earlier, in multi-threaded environments with a large amount of shared state and high thread contention over it, performance concerns often necessitate dividing the state into subsets and having an individual lock for each subset, so that different subsets can be locked independently of each other.&lt;/p&gt;
&lt;p&gt;Unfortunately, when we do this, we run the danger of entering deadlocks, and as it stands, the plural coherence implementation, which is suitable for these scenarios, does not address the issue of deadlocks.&lt;/p&gt;
&lt;p&gt;Some research is necessary to determine whether the plural coherence implementation could do any of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Detect a deadlock once it happens and provide diagnostic information.&lt;/li&gt;
&lt;li&gt;Detect a deadlock once it happens and somehow take corrective measure.&lt;/li&gt;
&lt;li&gt;Detect the possibility of deadlocks and alert the programmer by means of hard error.&lt;/li&gt;
&lt;li&gt;Be structured in such a way as to make deadlocks impossible.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Cover image by reginasphotos from pixabay.com&lt;/p&gt;</description></item><item><title>Domain Oriented Programming</title><link>https://blog2.michael.gr/post/2020-06-26-domain-oriented-programming/</link><pubDate>Fri, 26 Jun 2020 18:46:47 +0000</pubDate><guid>https://blog2.michael.gr/post/2020-06-26-domain-oriented-programming/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2020-06-26-domain-oriented-programming/media/DomainOrientedProgramming.png"
width="1253"
height="783"
srcset="https://blog2.michael.gr/post/2020-06-26-domain-oriented-programming/media/DomainOrientedProgramming_hu_46f0896593c4ea4d.png 480w, https://blog2.michael.gr/post/2020-06-26-domain-oriented-programming/media/DomainOrientedProgramming_hu_80495cb7faae492e.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="160"
data-flex-basis="384px"
&gt;
&lt;/p&gt;
&lt;p&gt;A Software Design Pattern which brings the principles of Inheritance, Encapsulation and Polymorphism one level up from the Class level to the Subsystem level, and offers a way of realizing relationships between classes so as to achieve dependency inversion by means of propagation instead of injection.&lt;/p&gt;
&lt;h3 id="part-1-dependency-inversion"&gt;Part 1: Dependency Inversion
&lt;/h3&gt;&lt;p&gt;The software that we write often invokes other software to get parts of the job done. These are known as &lt;em&gt;&lt;strong&gt;Services&lt;/strong&gt;&lt;/em&gt; or &lt;em&gt;&lt;strong&gt;Dependencies&lt;/strong&gt;&lt;/em&gt;. If Class A is making use of some Class B, then Class A depends on Class B, so Class B is a dependency of Class A.&lt;/p&gt;
&lt;p&gt;The principle of &lt;a class="external"
href="https://en.wikipedia.org/wiki/Dependency_inversion_principle" target="_blank"
&gt;&lt;em&gt;&lt;strong&gt;Dependency Inversion&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt; says that a class should not contain any direct calls to specific instances of any of its dependencies. Instead, it should receive these instances as parameters during initialization.&lt;/p&gt;
&lt;p&gt;That's all very nice, but passing dependencies around can become quite a complicated business, and in large systems it can become a nightmare.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Various mechanisms have been devised for solving this problem. Two that I know of are &lt;a class="external"
href="https://en.wikipedia.org/wiki/Service_locator_pattern" target="_blank"
&gt;&lt;em&gt;&lt;strong&gt;Service Locators&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt;, and &lt;a class="external"
href="https://en.wikipedia.org/wiki/Dependency_injection" target="_blank"
&gt;&lt;strong&gt;Dependency Injection Frameworks&lt;/strong&gt;&lt;/a&gt;. Unfortunately, each of them has some serious disadvantages.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Service Locators&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A service locator is a mandatory global dependency. That's a bad thing to have. At some point you will want to reuse a module in a different system, and that service locator will not be available there, and you will have to start rewriting stuff. Trust me, you will sooner or later regret having it.&lt;/li&gt;
&lt;li&gt;A service locator may defer compile-time errors to run-time errors. These errors occur when a system is being wired together, but tests are usually wired up differently, so these errors cannot be detected with unit testing or integration testing, you have to do end-to-end testing in order to discover them.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Dependency Injection Frameworks&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;They work by magic, and I don't like magic.&lt;/li&gt;
&lt;li&gt;They tend to embrace silent failure, while I mandate hard failure.&lt;/li&gt;
&lt;li&gt;They don't have an API that you can call, so you cannot use code completion, you have to know stuff by heart.&lt;/li&gt;
&lt;li&gt;They tend to make application startup time slow as molasses, while I like application startup to be snappy.&lt;/li&gt;
&lt;li&gt;They are also a mandatory global dependency.&lt;/li&gt;
&lt;li&gt;The individual class is a much too fine-grained unit to be applying dependency injection onto.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In my 35 years of programming I have encountered the problem of dependency injection a lot, and in the last decade or so I have started solving it with a paradigm that I call &lt;em&gt;&lt;strong&gt;Domain Oriented Programming&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Note that Domain Oriented Programming does not have any direct relation to &lt;a class="external"
href="https://en.wikipedia.org/wiki/Domain-driven_design" target="_blank"
&gt;&lt;strong&gt;Domain Driven Design&lt;/strong&gt;&lt;/a&gt;, although it may be a suitable pattern to use when implementing systems designed using the Domain Driven Design paradigm.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Introducing Domain Oriented Programming (DOP)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Domain Oriented Programming Design Pattern can be roughly described as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Classes do not exist in a vacuum; instead, every class has a special relationship with another class by which it is instantiated and from which it obtains its dependencies. The class doing the instantiation and providing dependencies is called &lt;em&gt;&lt;strong&gt;Domain&lt;/strong&gt;&lt;/em&gt;, the instantiated class is called &lt;em&gt;&lt;strong&gt;Subject.&lt;/strong&gt;&lt;/em&gt; Sometimes a class can be Subject to multiple Domains, more on that later.&lt;/li&gt;
&lt;li&gt;Every Subject has specific knowledge of its Domain.&lt;/li&gt;
&lt;li&gt;In some cases Domains also have specific knowledge of their Subjects, and in some cases they do not, more on that later.&lt;/li&gt;
&lt;li&gt;A Domain contains references to all services that are used by itself and by all of its Subjects; so, when a Subject needs to use some service, it obtains the service from its Domain. Therefore, dependencies do not need to be injected into Subjects.&lt;/li&gt;
&lt;li&gt;The Domain-Subject relation is hierarchical, so a Subject of one Domain may in turn be Domain to other Subjects. This way, dependencies are propagated from the root of a system all the way down to the leaf nodes without the need to use any special framework to achieve this.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The domain-subject relation can exist in two forms: &lt;em&gt;&lt;strong&gt;Closed (a.k.a. Realm)&lt;/strong&gt;&lt;/em&gt; and &lt;em&gt;&lt;strong&gt;Open (a.k.a. Free)&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Closed (a.k.a. Realm) Domains
&lt;ul&gt;
&lt;li&gt;The Domain is the one and only Domain for its Subjects. It is passed to each Subject as its first constructor parameter.&lt;/li&gt;
&lt;li&gt;The Domain has complete control over the lifetime of its Subjects. This means that the Domain is the exclusive factory of its Subjects, and can also decide when and if a Subject is destroyed.&lt;/li&gt;
&lt;li&gt;The Domain and its Subjects are &lt;em&gt;&lt;strong&gt;Closely Coupled.&lt;/strong&gt;&lt;/em&gt; This means that not only the Subjects have specific knowledge of their Domain, but also the Domain has specific knowledge of its Subjects. (Close coupling is perfectly okay as long as the Domain limits itself to acting as a factory and the Realm is kept small.)&lt;/li&gt;
&lt;li&gt;Subjects are usually exposed to the outside world as interfaces rather than as objects.&lt;/li&gt;
&lt;li&gt;The Realm forms a coherent, closed group which cannot be extended without modifying the Domain class.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Open (a.k.a. Free) Domains
&lt;ul&gt;
&lt;li&gt;The Domain does not have specific knowledge of any Subjects, it only exists for the purpose of making dependencies available to other Domains.&lt;/li&gt;
&lt;li&gt;Open Domains are usually provided as interfaces rather than as actual objects.&lt;/li&gt;
&lt;li&gt;A Subject of Open Domains can be freely instantiated as long as all the domains necessary for its instantiation are available. It can also be freely disposed.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are a few interesting things to notice here:&lt;/p&gt;
&lt;p&gt;The Domain is to a Subject what the Object is to a Method. Hopefully a DOP oriented language will be introduced one day which realizes the DOP construct in its grammar, making the Domain reference implicit, just as in Object Oriented Programming the Object reference is always the implicit first parameter to every Method.&lt;/p&gt;
&lt;p&gt;(Incidentally, Java and other languages are already doing something along these lines with non-static &lt;a class="external"
href="https://en.wikipedia.org/wiki/Inner_class" target="_blank"
&gt;inner classes&lt;/a&gt;, but we do not want to have to nest the source code of each Subject within the source code of its Domain, especially since a Domain may in turn be Subject of another Domain.)&lt;/p&gt;
&lt;p&gt;Domain Oriented Programming does not require any platform or library: it is just a way of structuring code. So, with DOP, no omnipresent framework is needed for injecting dependencies, and no magic is involved in their propagation; nobody needs to query any service locators for services, (the availability of services is practically guaranteed by the compiler,) and no huge lists of dependencies are passed to constructors, either. Still, at various places where domains are constructed and wired together, all necessary services are supplied, so any one of them can be replaced with a &lt;a class="external"
href="https://en.wikipedia.org/wiki/Test_double" target="_blank"
&gt;&lt;em&gt;&lt;strong&gt;Test Double&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Furthermore, Domain Oriented Programming is interoperable with non-DOP systems: A group of classes making use of DOP among themselves can be introduced into a system which is already using some other mechanism of Dependency Inversion.&lt;/p&gt;
&lt;p&gt;At first glance, Domain Oriented Programming can be thought of as employing something like &lt;em&gt;Half-Way Dependency Injection,&lt;/em&gt; or &lt;em&gt;&lt;strong&gt;Subsystem-level Dependency Injection&lt;/strong&gt;&lt;/em&gt; as opposed to &lt;em&gt;&lt;strong&gt;Class-level Dependency Injection&lt;/strong&gt;&lt;/em&gt;. Dependencies are injected into the Domain, and from that moment on Subjects of the Domain can go ahead and fetch their dependencies from the Domain as needed, instead of having their dependencies injected into them.&lt;/p&gt;
&lt;p&gt;Things become even more interesting when we consider Domains that are in turn Subjects of other Domains, forming a hierarchy of Domains, where at each level we have &lt;em&gt;&lt;strong&gt;SuperDomains&lt;/strong&gt;&lt;/em&gt; and &lt;em&gt;&lt;strong&gt;SubDomains&lt;/strong&gt;&lt;/em&gt;. In this scenario, we do not exactly have Dependency Injection going on anymore, because at each level dependencies are obtained from the level above; however, we still have Dependency Inversion, because dependencies are still not hard-coded in any way, and each Domain has control over each service that it makes available to its subjects, and may, if needed, decide which particular implementation will offer it.&lt;/p&gt;
&lt;p&gt;The lesson to learn from this is that Dependency Injection was never a goal in and of itself; the goal has been Dependency Inversion, (avoiding hard-coded dependencies, &lt;em&gt;Dependency Independence&lt;/em&gt; if you will permit the pun,) and Dependency Injection has been a mechanism for achieving it, but the same goal can be achieved by other means, such as &lt;em&gt;&lt;strong&gt;Dependency Propagation&lt;/strong&gt;&lt;/em&gt;, which is what Domain Oriented Programming offers.&lt;/p&gt;
&lt;h3 id="part-2-object-orientation-at-the-subsystem-level"&gt;Part 2: Object Orientation at the Subsystem Level
&lt;/h3&gt;&lt;p&gt;Domain Oriented Programming is not only about Dependency Propagation. It reflects the realization that Software being created today is immensely more complex than what it used to be back when Object Oriented Programming was invented and the first Object Oriented languages were laid down, about half a century ago.&lt;/p&gt;
&lt;p&gt;It used to be that all we needed was a means of coupling groups of functions with the data that they operate on, and that Inheritance, Encapsulation and Polymorphism were only necessary at the class-and-method level; however, as we build more elaborate software, we find ourselves more and more thinking not so much in terms of classes and methods, but in terms of subsystems and classes, or systems and subsystems. Therefore, there appears to be a need for terminology which brings Inheritance, Encapsulation and Polymorphism one level up, to the subsystem level, and by recursive application, to the entire system.&lt;/p&gt;
&lt;p&gt;Domain Oriented Programming offers the Domain as the unit upon which to apply the principles of Object Oriented Programming.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In DOP the Domain is the principal polymorphic unit, providing an implementation for a complex interface, and instantiating subjects to polymorphically implement smaller scope interfaces.&lt;/li&gt;
&lt;li&gt;In DOP the Domain encapsulates its subjects, hiding their nature and lifetime from the outside world.&lt;/li&gt;
&lt;li&gt;In DOP inheritance is only utilized among Subjects, while the Domain hides from the outside world the fact that it is being utilized.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My first public mention of this concept was in &lt;a class="external"
href="https://softwareengineering.stackexchange.com/a/304041/41811" target="_blank"
&gt;this answer of mine on Software Engineering Stack Exchange.&lt;/a&gt;&lt;/p&gt;</description></item><item><title>The case for software testing</title><link>https://blog2.michael.gr/post/2019-12-on-software-testing/</link><pubDate>Sun, 01 Dec 2019 20:48:53 +0000</pubDate><guid>https://blog2.michael.gr/post/2019-12-on-software-testing/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2019-12-on-software-testing/media/test-pattern.webp"
width="960"
height="600"
srcset="https://blog2.michael.gr/post/2019-12-on-software-testing/media/test-pattern_hu_381d45a688135199.webp 480w, https://blog2.michael.gr/post/2019-12-on-software-testing/media/test-pattern_hu_d0ce67d078ac478f.webp 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="160"
data-flex-basis="384px"
&gt;
&lt;/p&gt;
&lt;h3 id="what-to-reply-to-a-non-programmer-who-thinks-that-testing-is-unnecessary-or-secondary"&gt;What to reply to a non-programmer who thinks that testing is unnecessary or secondary
&lt;/h3&gt;&lt;p&gt;At some point during his or her career, a programmer might come across the following argument, presented by some colleague, partner, or decision maker:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Since we can always test our software by hand, we do not need to implement Automated Software Testing.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Apparently, I reached that point in my career, so now I need to debate this argument. I decided to be a good internet citizen and publish my thoughts. So, in this post I am going to be deconstructing that argument, and demolishing it from every angle that it can be examined. I will be doing so using language that is easy to process by people from outside of our discipline.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;In the particular company where that argument was brought forth, there exist mitigating factors which are specific to the product, the customers, and the type of relationship we have with them, all of which make the argument not as unreasonable as it may sound when taken out of context. Even in light of these factors, the argument still deserves to be blown out of the water, but I will not be bothering the reader with the specific situation of this company, so as to ensure that the discussion is applicable to software development in general.&lt;/p&gt;
&lt;p&gt;In its more complete form, the argument may go like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Automated Software Testing represents a big investment for the company, where all the programmers in the house are spending copious amounts of time doing nothing but writing software tests, but these tests do not yield any visible benefit to the customers. Instead, the programmers should ensure that the software works by spending only a fraction of that time doing manual testing, and then we can take all the time that we save this way and invest it in developing new functionality and fixing existing issues.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To put it more concisely, someone might say something along these lines:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I do not see the business value in Automated Software Testing.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This statement is a bunch of myths rolled up into an admirably terse statement. It is so disarmingly simple, that for a moment you might be at loss of how to respond. Where to begin, really. We need to look at the myths one by one. Here it goes:&lt;/p&gt;
&lt;h3 id="myth-1-software-testing-represents-a-big-investment"&gt;Myth #1: Software testing represents a &lt;em&gt;big&lt;/em&gt; investment.
&lt;/h3&gt;&lt;p&gt;No it doesn't. Or maybe it does, but its ROI is so high that you absolutely don't want to miss it.&lt;/p&gt;
&lt;p&gt;If you do not have software testing in place, then it is an established fact in our industry that you will end up spending an inordinate amount of time researching unexpected application behavior, troubleshooting code to explain the observed behavior, discovering bugs, fixing them, and often repeating this process a few times on each incident because the fix for one bug often creates another bug, or causes pre-existing bugs to manifest, often with the embarrassment of an intervening round-trip to the customer, because the &amp;quot;fixed&amp;quot; software was released before the newly introduced bugs were discovered.&lt;/p&gt;
&lt;p&gt;Really, it works the same way as education. To quote a famous bumper sticker:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You think education is expensive? Try ignorance!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Furthermore, your choice of Manual Software Testing vs. Automated Software Testing has a significant impact on the development effort required after the testing, to fix the issues that the testing discovers. It is a well established fact in the industry that the sooner a bug is discovered, the less it costs to fix it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The earliest time possible for fixing a mistake is when making it. That's why we use strongly typed programming languages, together with Integrated Development Environments that continuously compile our code as we are typing it: this way, any syntax error or type violation is immediately flagged by the IDE with a red underline, so we can see it and fix it before proceeding to type the next line of code. The cost of fixing that bug is near zero. (And one of the main reasons why virtually all scripting languages are absolutely horrible is that in those languages, even a typo can go undetected and become a bug.)&lt;/li&gt;
&lt;li&gt;If you can't catch a bug at the moment you are introducing it, the next best time to catch it is when running automated tests, which is what you are supposed to do before committing your changes to the source code repository. If that doesn't happen, then the bug will be committed, and this already represents a considerable cost that you will have to pay later for fixing it.&lt;/li&gt;
&lt;li&gt;The next best time to catch the bug is by running automated tests as part of the Continuous Build System. This will at least tell you that the most recent commit contained a bug. If there is no Continuous Build with Automated Software Testing in place, then you suffer another steep increase in the price that you will have to pay for eventually fixing the bug.&lt;/li&gt;
&lt;li&gt;By the time a human being gets around to manually testing the software and discovering the bug, many more commits may have been made to the source code repository. This means that by the time the bug is discovered, we will not necessarily know which commits contributed to it, nor which programmers made the relevant commits, and even if we do, they will at that moment be working on something else, which they will have to temporarily drop, and make an often painful mental context switch back to the task that they were working on earlier. Naturally, the more days pass between committing a bug and starting to fix it, the worse it gets.&lt;/li&gt;
&lt;li&gt;At the extreme, consider trying to fix a bug months after it was introduced, when nobody knows anything about the changes that caused it, and the programmer who made those changes is not even with the company anymore. Someone has to become intimately familiar with that module in order to troubleshoot the problem, consider dozens of different commits that may have contributed to the bug, find it, and fix it. The cost of fixing that bug may amount to more than a programmer's monthly salary.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is why the entire software industry today literally swears in the name of testing: it helps to catch bugs as early as possible, and to keep the development workflow uninterrupted, so it ends up saving huge amounts of money.&lt;/p&gt;
&lt;h3 id="myth-2-software-testing-represents-an-investment"&gt;Myth #2: Software testing represents an investment.
&lt;/h3&gt;&lt;p&gt;No, it does not even. Software testing is regarded by our industry as an integral part of software development, so it is meaningless to examine it as an investment separate from the already-recognized-as-necessary investment of developing the software in the first place.&lt;/p&gt;
&lt;p&gt;Beware of the invalid line of reasoning which says that in order to implement a certain piece of functionality all we need is 10 lines of production code which cost 100 bucks, whereas an additional 10 lines, that would only be testing the first 10 lines, and would cost an extra 100 bucks, are optional.&lt;/p&gt;
&lt;p&gt;Instead, the valid reasoning is that in order to implement said functionality we will need 20 lines of code, which will cost 200 bucks. It just so happens that 10 of these lines will reside in a subfolder of the source code tree called &amp;quot;production&amp;quot;, while the other 10 lines will reside in a subfolder of the same tree called &amp;quot;testing&amp;quot;; however, the precise location of each group of lines is a trivial technicality, bearing no relation whatsoever to any notion of &amp;quot;usefulness&amp;quot; of one group of lines versus the other. The fact is that all 20 of those lines of code are essential in order to accomplish the desired result.&lt;/p&gt;
&lt;p&gt;That's because production code without corresponding testing code cannot be said with any certainty to be implementing any functionality at all. The only thing that can be said about testless code is that it has so far been successful at creating the impression to human observers that its behavior sufficiently resembles some desired functionality. Furthermore, it can only be said to be successful to the extent that it has been observed thus far, meaning that a new observation tomorrow might very well find that it is doing something different.&lt;/p&gt;
&lt;p&gt;That's a far cry from saying that &amp;quot;this software does in fact implement that functionality&amp;quot;.&lt;/p&gt;
&lt;h3 id="myth-3-software-testing-is-just-sloppiness-management"&gt;Myth #3: Software testing is just sloppiness management.
&lt;/h3&gt;&lt;p&gt;This is usually not voiced, but implied. So, why can't programmers write correct software the first time around? And why on earth can't software just stay correct once written?&lt;/p&gt;
&lt;p&gt;There is a number of reasons for this, the most important ones have to do with the level of maturity of the software engineering discipline, and the complexity of the software that we are being asked to develop.&lt;/p&gt;
&lt;h4 id="maturity"&gt;Maturity
&lt;/h4&gt;&lt;p&gt;Software development is not a hard science like physics and math. There exist some purely scientific concepts that you learn in the university, but they are rarely applicable to the every day reality of our work. When it comes to developing software, there is not as much help available to us as there is to other disciplines by means of universal laws, fundamental axioms, established common practices and rules, ubiquitous notations, books of formulas and procedures, ready made commercially available standardized components to build with, etc. It is difficult to even find parallels to draw for basic concepts of science and technology such as experimentation, measurement, and reproducibility. That's why software engineering is sometimes characterized as being more of an art than a science, and the fact that anyone can potentially become a programmer without necessarily having studied software engineering does not help to dispel this characterization.&lt;/p&gt;
&lt;p&gt;Automated Software Testing is one of those developments in software engineering that make it more like a science than like an art. With testing we have finally managed to introduce the concepts of experimentation, measurement, and reproducibility in software engineering. Whether testability alone is enough to turn our discipline into a science is debatable, but without testing we can be certain that we are doing nothing but art.&lt;/p&gt;
&lt;h4 id="complexity"&gt;Complexity
&lt;/h4&gt;&lt;p&gt;The software systems that we develop today are immensely complex. A simple application which presents a user with just 4 successive yes/no choices has 16 different execution paths that must be tested. Increase the number of choices to 7, and the number of paths skyrockets to 128. Take a slightly longer but entirely realistic use case sequence of a real world application consisting of 20 steps, and the total number of paths exceeds one million. That's an awful lot of complexity, and so far we have only been considering yes/no choices. Now imagine each step consisting of not just a yes/no choice, but an entire screen full of clickable buttons and editable fields which are interacting with each other. This is not an extreme scenario, it is a rather commonplace situation, and its complexity is of truly astronomical proportions.&lt;/p&gt;
&lt;p&gt;Interestingly enough, hardware engineers like to off-load complexity management to the software. Long gone are the times when machines consisted entirely of hardware, with levers and gears and belts and cams all carefully aligned to work in unison, so that turning a crank at one end would cause printed and folded newspapers to come out the other end. Nowadays, the components of the hardware tend to not interact with each other, because that would be too complex and too difficult to change; instead, every single sensor and every single actuator is connected to a central panel, from which software takes charge and orchestrates the whole thing.&lt;/p&gt;
&lt;p&gt;However, software is not a magical place where complexity just vanishes; you cannot expect to provide software with complex inputs, expect complex outputs, and at the same time expect the insides of it to be nothing but purity and simplicity: a system cannot have less complexity than the complexity inherent in the function that it performs.&lt;/p&gt;
&lt;p&gt;The value of moving the complexity from the hardware to the software is that the system is then easier to change, but when we say &amp;quot;easier&amp;quot; we do not mean &amp;quot;simpler&amp;quot;; all of the complexity is still there and must be dealt with. What we mean when we say &amp;quot;easier to change&amp;quot; is that in order to make a change &lt;em&gt;&lt;strong&gt;we do not have to begin by sending new blueprints to the steel foundry&lt;/strong&gt;&lt;/em&gt;. That's what that you gain by moving complexity from the hardware to the software: being able to change the system without messy, time-consuming, and costly interactions with the physical world.&lt;/p&gt;
&lt;p&gt;So, even though we have eliminated those precisely crafted and carefully arranged levers and gears and belts and cams, their counterparts now exist in the software, you just do not see them, you have no way of seeing them unless you are a programmer, and just as the slightest modification to a physical machine of such complexity would be a strenuous ordeal, so is the slightest modification to a software system of similar complexity a strenuous ordeal.&lt;/p&gt;
&lt;p&gt;Software can only handle complexity if done right. You cannot develop complex software without sophisticated automated software testing in place, and even if you develop it, you cannot make any assumptions whatsoever about its correctness. Furthermore, even if it appears to be working correctly, you cannot make the slightest change to it unless automated software testing is in place to determine that it is still working correctly after the change. That is because you simply cannot test thousands or millions of possible execution paths in any way other than in an automated way.&lt;/p&gt;
&lt;h3 id="myth-4-testing-has-no-visible-benefit-to-the-customers"&gt;Myth #4: Testing has no visible benefit to the customers
&lt;/h3&gt;&lt;p&gt;Yes it does. It is called reliable, consistent, correctly working software. It is also called software which is continuously improving instead of remaining stagnant due to fear of it breaking if sneezed at. It is also called receiving newly introduced features without losing old features that used to work but are now broken. And it is even called receiving an update as soon as it has been introduced instead of having to wait until some poor souls have clicked through the entire application over the course of several days to make sure everything still works as it used to.&lt;/p&gt;
&lt;h3 id="myth-5-manual-testing-can-ensure-that-the-software-works"&gt;Myth #5: Manual testing can ensure that the software works.
&lt;/h3&gt;&lt;p&gt;No it cannot. That's because the complexity of the software is usually far greater than what you could ever possibly hope to test by hand. An interactive application is not like a piece of fabric, which you can visually inspect and have a fair amount of certainty that it has no defects. You are going to need to interact with the software, in a mind-boggling number of different ways, to test for a mind-boggling number of possible failure modes.&lt;/p&gt;
&lt;p&gt;When we do manual testing, in order to save time (and our sanity) we focus only on the subset of the functionality of the software which may have been affected by recent changes that have been made to the source code. However, the choice of which subsets to test is necessarily based on our estimations and assumptions about what parts of the program may have been affected by our modifications, and also on guesses about the ways in which these parts could behave if adversely affected. Alas, these estimations, assumptions, and guesses are notoriously unreliable: it is usually the parts of the software that nobody expected to break that in fact break, and even the suspected parts sometimes break in ways quite different from what anyone had expected and planned to test for.&lt;/p&gt;
&lt;p&gt;And this is by definition so, because all the failure modes that we can easily foresee, based on the modifications that we make, we usually examine ourselves before even calling the modifications complete and committing our code.&lt;/p&gt;
&lt;p&gt;Furthermore, it is widely understood in our industry that persons involved in the development of software are generally unsuitable for testing it. No developer ever uses the software with as much recklessness and capriciousness as a user will. It is as if the programmer's hand has a mind of its own, and avoids sending the mouse pointer in bad areas of the screen, whereas that is precisely where the user's hand is guaranteed to send it. It is as if the programmer's finger will never press that mouse button down as heavily as the user's finger will. Even dedicated testers start behaving like the programmers after a while on the job, because it is only human to employ acquired knowledge about the environment in navigating about the environment, and to re-use established known good paths. It is in our nature. You can ask people to do something which is against their nature, and they may earnestly agree, and they may even try their best, but the results are still guaranteed to suffer.&lt;/p&gt;
&lt;p&gt;Then there is repetitive motion fatigue, both of the physical and the mental kind, that severely limit the scope that any kind of manual testing will ever have.&lt;/p&gt;
&lt;p&gt;Finally, there is the issue of efficiency. When we do manual software testing, we are necessarily doing it in human time, which is excruciatingly slow compared to the speed at which a computer would carry out the same task. A human being testing permutations at the rate of one click per second could theoretically test one million permutations in no less than 2 working months, the computer may do it in a matter of minutes. And the computer will do this perfectly, while the most capable human being will do this quite sloppily in comparison. That's how inefficient manual software testing is.&lt;/p&gt;
&lt;h3 id="myth-6-manual-testing-takes-less-time-than-writing-tests"&gt;Myth #6: Manual testing takes less time than writing tests.
&lt;/h3&gt;&lt;p&gt;No it doesn't. If you want to say that you are actually doing some manual testing worth speaking of, and not a joke of it, then you will have to spend copious amounts of time doing nothing but that, and you will have to keep repeating it all over again every single time the software is modified.&lt;/p&gt;
&lt;p&gt;In contrast, with software testing you are spending some time up-front building some test suites, which you will then be able to re-execute every time you need them, with comparatively small additional effort. So, manual testing for a certain piece of software is an effort that you have to keep repeating, while writing automated test suites for that same piece of software is something that you do once and from that moment on it keeps paying dividends.&lt;/p&gt;
&lt;p&gt;This is why it is a fallacy to say that we will just test the software manually and with the time that we will save we will implement more functionality: as soon as you add a tiny bit of new functionality, you have to repeat the testing all over again. Testing the software manually is a never ending story.&lt;/p&gt;
&lt;p&gt;The situation is a lot like renting vs. buying: with renting, at the end of each month you are at exactly the same situation as you were in the beginning of the month: the home still belongs in its entirety &lt;strong&gt;not&lt;/strong&gt; to you, but to the landlord, and you must now pay a new rent in full, in order to stay for one more month. With buying, you pay a lot of money up front, and some maintenance costs and taxes will always be applicable, but the money that you pay goes into something tangible, it is turned into value in your hands in the form of a home that you now own.&lt;/p&gt;
&lt;p&gt;Furthermore, the relative efficiency of manual testing is usually severely underestimated. In order to do proper manual testing, you have to come up with a meticulous test plan, explaining what the tester is supposed to do, and what the result of each action should be, so that the tester can tell whether the software is behaving according to the requirements or not. However, no test plan will ever be as unambiguous as a piece of code that is actually performing the same test, and the more meticulous you try to be with the test plan, the less you gain, because there comes a point where the effort of writing the test plan starts being comparable to the effort of writing the corresponding automated test instead. So, you might as well write the test plan down in code to begin with.&lt;/p&gt;
&lt;p&gt;Of course one round of writing automated software testing suites will always represent more effort than a few rounds of manually performing the same tests, so the desirability of one approach vs. the other may depend on where you imagine the break-even point to be. If you reckon that the break-even point is fairly soon, then you already see the benefit of implementing automated software testing as soon as possible. If you imagine it will be after the IPO, then you might think it is better to defer it, but actually, even in this case you might not want to go this way, more about that later.&lt;/p&gt;
&lt;p&gt;Well, let me tell you: in the software industry the established understanding is that the break-even point is &lt;strong&gt;extremely&lt;/strong&gt; soon. Like &lt;strong&gt;write-the-tests-before-the-app&lt;/strong&gt; soon. (A practice known as Test-Driven Development.)&lt;/p&gt;
&lt;h3 id="myth-7-you-can-keep-developing-new-functionality-and-fixing-existing-issues-without-software-testing-in-place"&gt;Myth #7: You can keep developing new functionality and fixing existing issues without software testing in place.
&lt;/h3&gt;&lt;p&gt;In theory you could, but in practice you can't. That's because every time you touch the slightest part of the software, everything about the software is now potentially broken. Without automated software testing in place, you just don't know. This is especially true of software which has been written messily, which is in turn especially common in software which has been written without any Automated Software Testing in place from the beginning. Paradoxically enough, automated software testing forces software designs to have some structure, this structure reduces failures, so then the software has lesser testing needs.&lt;/p&gt;
&lt;p&gt;To help lessen change-induced software fragility, we even have a special procedure governing how we fix bugs: when a bug is discovered, we do not always just go ahead and fix it. Instead, what we often do is that we first write a test which checks for the bug according to the requirements, without making any assumptions as to what might be causing it. Of course, since the bug is in the software, the test will initially be observed to fail. Then, we fix the bug according to your theory as to what is causing it, and we should see that test succeeding. If it doesn?t, then we fixed the wrong bug, or more likely, we just broke something which used to be fine. Furthermore, all other tests better also keep succeeding, otherwise in fixing this bug we broke something else. As a bonus, the new test now becomes a permanent part of the suite of tests, so if this particular behavior is broken again in the future, this test will catch it.&lt;/p&gt;
&lt;p&gt;If you go around &amp;quot;fixing bugs&amp;quot; without testing mechanisms such as this in place, you are not really fixing bugs, you are just shuffling bugs around. The same applies to features: if you go around &amp;quot;adding features&amp;quot; without the necessary testing mechanisms in place, then by definition you are not adding features, you are adding bugs.&lt;/p&gt;
&lt;h3 id="myth-8-software-testing-has-no-business-value"&gt;Myth #8: Software testing has no business value
&lt;/h3&gt;&lt;p&gt;Yes it does. The arguments that I have already listed should be making it clear that it does, but let me provide one more argument, which shows how Automated Software Testing directly equates to business value.&lt;/p&gt;
&lt;p&gt;A potentially important factor for virtually any kind of business is investment. When an investor is interested in a software business, and if they have the slightest clue as to what it is that they are doing, they are likely to want to evaluate the source code before committing to the investment. Evaluation is done by sending a copy of the software project to an independent professional software evaluator. The evaluator examines the software and responds with investment advice.&lt;/p&gt;
&lt;p&gt;The evaluator may begin by using the software as a regular user to ensure that it appears to do what it is purported to do, then they may examine the design to make sure it makes sense, then they may examine the source code to make sure things look normal, etc. After spending not too much time on these tasks, the evaluator is likely to proceed to the tests. Software testing is so prevalent in the software industry, that it is unanimously considered to be the single most important factor determining the quality of the software.&lt;/p&gt;
&lt;p&gt;If there are no tests, this is very bad news for the investment advice.&lt;/p&gt;
&lt;p&gt;If the tests do not pass, this is also very bad news.&lt;/p&gt;
&lt;p&gt;If the tests succeed, then the next question is how thorough they are.&lt;/p&gt;
&lt;p&gt;For that, the evaluator is likely to use a tool called &amp;quot;Code Coverage Analyzer&amp;quot;. This tool keeps track of the lines of code that are being executed as the program is running, or, more likely, as the program is being exercised by the tests. By running the tests while the code coverage analysis tool is active, the evaluator will thus obtain the code coverage metric of the software. This is just a single number, from 0 to 100, and it is the percentage of the total number of source code lines that have been exercised by the tests. The more thorough the tests are, the higher this number will be.&lt;/p&gt;
&lt;p&gt;This is a very useful metric, because in a single number it captures an objective, highly important quality metric for the entirety of the software system. It also tends to highly correlate to the actual investment advice that the evaluator will end up giving. The exact numbers may vary depending on the product, the evaluator, the investor, the investment, and other circumstances, but a rough breakdown is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;below 50% means &amp;quot;run in the opposite direction, this is as good as Ebola.&amp;quot;&lt;/li&gt;
&lt;li&gt;50-60% means &amp;quot;poor&amp;quot;,&lt;/li&gt;
&lt;li&gt;60-70% means &amp;quot;decent&amp;quot;,&lt;/li&gt;
&lt;li&gt;70-80% means &amp;quot;good&amp;quot;,&lt;/li&gt;
&lt;li&gt;80-90% means &amp;quot;excellent&amp;quot;,&lt;/li&gt;
&lt;li&gt;90-100% means &amp;quot;exceptional&amp;quot;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course, the graph of programming effort required vs. code coverage achieved is highly non-linear. It is relatively easy to pass the 45% mark; it becomes more and more difficult as you go past the 65% mark; it becomes exceedingly difficult once you cross the 85% mark.&lt;/p&gt;
&lt;p&gt;In my experience and understanding, conscientious software houses in the general commercial software business are striving for the 75% mark. In places where they only achieve about 65% code coverage they consider it acceptable but at the same time they either know that they could be doing better, or they have low self-respect. High criticality software (that human life depends on, or a nation's reputation,) may have 100% coverage, but a tremendous effort is required to achieve this. In any case, what matters is not so much what the developers think, but what the evaluator thinks; and evaluators tend to use the established practices of the industry as the standard by which they judge. The established practices call for extensive software testing, so if you do not do that, then your evaluation is not going to look good.&lt;/p&gt;
&lt;p&gt;So, is there business value in software testing? investment prospects alone say yes, regardless of the technical merits of it. Furthermore, software evaluation may likely be part of the necessary preparations for an IPO to take place, so even if you imagined the break-even point of automated testing vs. manual testing to be after the IPO, there is still ample reason to have them all in perfect working order well before the IPO.&lt;/p&gt;
&lt;p&gt;The above is applicable for businesses that are exclusively into software development. I do not know to what degree parallelisms can be drawn with companies for which software is somewhat secondary, but I suspect it is to no small extent.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Old comments&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;metamaker 2020-11-14 23:03:33 UTC&lt;/p&gt;
&lt;p&gt;| ... in a single number it captures an objective, highly important quality metric for the entirety of the software system.&lt;/p&gt;
&lt;p&gt;I wished to find in an article more about spec tests (BDD, Gherkin). Code lines coverage is not always applicable, and even in the case of unit tests where it is applicable, branch+predicate coverage is as relevant as ever.&lt;/p&gt;
&lt;p&gt;So, devs end up with a need to convert use cases to autotests. I had a great Product Owner (C++ dev in past), who was writing Gherkin scripts inside Jira tickets xD, and team needed to just connect actions to words - then voila! we have autotests for use cases that a user encounters.&lt;/p&gt;
&lt;p&gt;The excuse - it is difficult to setup runner for specs. The solution - fire knaves, hire pros! :D&lt;/p&gt;
&lt;p&gt;| Software testing has no business value&lt;/p&gt;
&lt;p&gt;This is THE PLAGUE of modern software engineering - business decides how programmers should do their work. Moreover there is the BELIEF that writing bug-free code is easy. In the end of the day, software rot trumps all business decisions and team ends up with polluted unsupportable code. This is the one single reason why now I don't even consider job offers to random teams that have already 2-3 years old software - just too high risk to end up with already non-fixable $hitcode (was there, seen undocumented SQL scripts with 5000 LOC and zero documentation - never again).&lt;/p&gt;
&lt;p&gt;I wish everyone to end up sooner or later in a team with good practices and low stress! Stay good!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;metamaker 2020-11-14 23:03:27 UTC&lt;/p&gt;
&lt;p&gt;Yo Mike! Big kudos for the great article!&lt;/p&gt;
&lt;p&gt;(I am sure you know all that I want to mention in the next paragraphs, I just need to vent my thoughts and feelings after reading; hope it is thought-provoking, because thinking === GREATER GOOD)&lt;/p&gt;
&lt;p&gt;| ... so it ends up saving huge amounts of money.&lt;/p&gt;
&lt;p&gt;This is the good reason, but not the BEST (which I will mention below). Be like my old team when one day PM told that single calling code equals single country (+1 CC?), and someone wrote a component relying on this &amp;quot;well-known fact&amp;quot;. After half year we randomly found why some phone numbers were messed up. Ironically, the harm that was done to our company - zero bucks, we haven't lost anything due to this bug. We were b2b company that signed up other companies on board and thus really cared about having more sales and signed contracts rather than a good product.&lt;/p&gt;
&lt;p&gt;Tests are useless waste of time for company that is sales driven. Am I right? Or not so?&lt;/p&gt;
&lt;p&gt;The BEST thing for writing tests is that it documents expectations on code level (not biz, but for us, devs). If you ever need to fix something done by some random dude who now moved to Arctica, test is a good guidance (ofc, if that person wrote a good test and not some mocked up from top to bottom monster).&lt;/p&gt;
&lt;p&gt;A quick thought about code reviews. There is the BELIEF that reviews prevent bad code (poorly written tests including). In fact, I have never seen in my career teams where code reviews were helpful (but I was in a great team without no code reviews and permit to fix random places during the development - we trusted each other and cared about well being). If you have a good tech lead, but unsure about the rest of the team, for the God's sake, let tech lead be the only person who reviews code. By not doing so, if there is less than 51% of team are competent developers, you end up with political circus (been there, seen it, friends get LGTM for $hitcode, foes get comments like &amp;quot;change space, change quote, move comment to next line&amp;quot;; so... you end up making situational friends ;) - needless to say, what happens to code base).&lt;/p&gt;
&lt;p&gt;| ... every time you touch the slightest part of the software, everything about the software is now potentially broken.&lt;/p&gt;
&lt;p&gt;Not mentioning that since you are not a solo developer, you end up with merge conflicts due to other people work (even logical, e.g. Country class starts using 2-letter codes instead of 3-letter and uses same old good String for input of constructor - well, hope that your buddy added invariant to the class constructor). Tests synchronize decision making process, they autofix logical bugs between you and buddy.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>What is wrong with Full Stack Development</title><link>https://blog2.michael.gr/post/2021-12-full-stack-development/</link><pubDate>Sun, 01 Apr 2018 14:37:37 +0000</pubDate><guid>https://blog2.michael.gr/post/2021-12-full-stack-development/</guid><description>&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;img src="https://blog2.michael.gr/post/2021-12-full-stack-development/media/tag-blogger.com,1999-blog-3494795920779884230.post-79094073589883987961.jpg"
width="408"
height="639"
srcset="https://blog2.michael.gr/post/2021-12-full-stack-development/media/tag-blogger.com,1999-blog-3494795920779884230.post-79094073589883987961_hu_755c7da92bba20ac.jpg 480w, https://blog2.michael.gr/post/2021-12-full-stack-development/media/tag-blogger.com,1999-blog-3494795920779884230.post-79094073589883987961_hu_ac4b783d13bec49.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="63"
data-flex-basis="153px"
&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;Inntel Hotel at Amsterdam, Zaandam&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id="table-of-contents"&gt;Table of Contents
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;What is full-stack development&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Why is full-stack development necessary today&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What is wrong with full-stack development&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Conclusion&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(Useful pre-reading:
&lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h4 id="what-is-full-stack-development"&gt;What is full-stack development
&lt;/h4&gt;&lt;p&gt;The predominant web application development model today requires splitting
application logic in two parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The front-end, running on the browser.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The back-end, running on the server.&lt;/p&gt;
&lt;p&gt;The front-end is typically written in JavaScript, while the back-end is
typically written in Java, Scala, C#, or some other programming language. The
two ends invariably communicate with each other via REST. The choice of
JavaScript and REST is not due to any technical merit inherent in these
technologies, (there is none,) but purely due to historical accident; see
&lt;a
href="https://blog2.michael.gr/post/2020-10-19-the-wild-wild-web/"
&gt;The Wild, Wild Web&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A web application developer can either focus on one part of the stack, or work
on both parts. Due to reasons that will be explained further down, more often
than not, web developers are asked to work on both parts simultaneously. When
this happens, it is known as full-stack development.&lt;/p&gt;
&lt;p&gt;For the purposes of this paper, we will call full-stack development not just
this mode of work, but also this architectural style as a whole: full-stack
development is when application logic must be written both on the server and
on the client.&lt;/p&gt;
&lt;p&gt;Full-Stack Development is a paradox, since it suggests a way of work which is
contrary to what common sense dictates. Common sense calls for specialists
each working on their own area of specialization, so one would expect to see
different developers focusing on different layers of the stack, and nobody
ever attempting something as preposterous as working on all layers
simultaneously. However, there is a technological hurdle which renders this
necessary today.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="why-is-full-stack-development-necessary-today"&gt;Why is full-stack development necessary today
&lt;/h4&gt;&lt;p&gt;Normally, (outside of web application development,) in a system that consists
of multiple layers, only one of the layers tends to be application-specific,
while all other layers tend to be general purpose infrastructure layers that
are agnostic of any application that might put them to use. Under such an
arrangement, the functionality offered by each layer is dictated by what makes
sense for that layer to be doing, so the work to be done at each layer tends
to be rather self-contained and straightforward. In this scenario, each
specialist can indeed work on the layer that they specialize in.&lt;/p&gt;
&lt;p&gt;However, in web development we have a server, and we have a client, and so far
we have been unable to find a solution that would allow us to confine all of
our application logic to only one of them. (There have been some attempts in
that direction, but they were only moderately successful, and virtually none
of them survived the transition from monolithic architectures to microservices
architectures.) As a result, in modern web applications, both layers are
application-specific.&lt;/p&gt;
&lt;p&gt;In the early days people did try to apply specialization and division of labor
to web application development, and they found that when all the layers are
application-specific, collaboration between teams working on different layers
suffers, resulting in low productivity. There are too many details that have
to be agreed upon by people working on different layers; too much waiting for
the guys working on the layer below to finish their part before the guys
working on layer above can do their job; too much disagreement as to whose
fault it is when the system is not working as expected; in general, too much
back and forth, too much friction.&lt;/p&gt;
&lt;p&gt;For this reason, full-stack development was invented: instead of dividing the
workforce horizontally, it ends up being less inefficient to divide them
vertically: when each developer works on a different feature of the product
from top to bottom, they do not have to interact too intensively with other
developers, and this represents a gain which seems to offset the loss of not
having specialists working on their respective areas of specialization.&lt;/p&gt;
&lt;h4 id="what-is-wrong-with-full-stack-development"&gt;What is wrong with full-stack development
&lt;/h4&gt;&lt;p&gt;In brief, full-stack development has the following disadvantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The front-end:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Has limited capabilities.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Is confined within the sand-boxed execution environment of the browser.&lt;/li&gt;
&lt;li&gt;Admittedly, browsers today are pretty feature-rich, (actually,
monstrously so,) but still, you are writing code which is running out
there, on browsers, and is therefore out of your control, instead of
here, on the server, where you do have control.&lt;/li&gt;
&lt;li&gt;So, there are always things that you would like to accomplish, but you
cannot on the client, so you have to suffer the additional bureaucracy
of having the client communicate what you are trying to accomplish to
the server, having the server do it for you, and receiving the results
back on the client. That?s an awful lot of work for something as simple
as, say, obtaining the current date and time regardless of client
configuration or misconfiguration.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Suffers from incidental complexity.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Peculiarities of the browser environment such as URLs, HTML, the DOM,
HTTP, REST, Ajax, etc.&lt;/li&gt;
&lt;li&gt;Cross-browser incompatibilities and cross-browser-version
incompatibilities.&lt;/li&gt;
&lt;li&gt;Security hazards.
&lt;ul&gt;
&lt;li&gt;Code on the client must not only accomplish application goals, but it
must do so while avoiding various commonly known and not-so-commonly
known security pitfalls.&lt;/li&gt;
&lt;li&gt;Each time a new security hazard is discovered by the security
community, vast amounts of application code must be meticulously
audited and painstakingly fixed.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Must be re-written on each targeted format (web, mobile, desktop.)&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;When targeting a new format besides the web (e.g. desktop, mobile) we
have to re-engineer not only the presentation markup, but also all of
the application logic which is inextricably mangled with it.&lt;/li&gt;
&lt;li&gt;This necessitates the creation and maintenance of multiple separate code
bases that largely duplicate the functionality of each other.&lt;/li&gt;
&lt;li&gt;These code bases are liable to diverge, thus causing user workflows and
overall user experience to unwantedly differ across formats.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Is usually written in a scripting language.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;The code is error-prone due to scripting languages being untyped.&lt;/li&gt;
&lt;li&gt;The code is hard to maintain due to untyped languages being impervious
to refactoring.&lt;/li&gt;
&lt;li&gt;The code is messy due to scripting languages invariably being inferior
to real programming languages.&lt;/li&gt;
&lt;li&gt;The code is transmitted in source code form to the browser, thus
exposing potentially sensitive intellectual property.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Is usually written in JavaScript in particular.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;JavaScript was originally intended for no more than a few, tiny, and
isolated snippets of code per HTML page. The haphazardness of the
language design reflects this intention. However, modern web
applications tend to contain tens of thousands of lines of
application-specific JavaScript. That is an awful lot of code in a
language which is defective by design.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Excludes artists.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Artists are prevented from actively participating in the creation and
maintenance of web pages, because HTML is inextricably mangled with
JavaScript, so they cannot touch it.&lt;/li&gt;
&lt;li&gt;Thus, artists are resigned to creating mock-ups showing how they want
web pages to look like, and programmers are then tasked with making the
web pages look like the mockups. (As if the programmers did not already
have enough in their hands.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The back-end:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Is inextricably tied to REST&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;This is because REST is impervious to abstraction.&lt;/li&gt;
&lt;li&gt;REST forces reliance on binding-by-name, which undermines the coherence
of the entire system and prevents static code analysis, invariably
resulting in a big unknown chaos.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Duplicates part of the client-side application logic.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;This is necessary in order to perform validation on the server-side too,
because from a security standpoint the client must always be considered
compromised.&lt;/li&gt;
&lt;li&gt;This translates to additional development and maintenance cost.&lt;/li&gt;
&lt;li&gt;Inevitable discrepancies between the validation done on the client and
the validation done on the server are a continuous source of bugs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The application as a whole:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Is split in two parts.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Usually having each part written in a different programming language.&lt;/li&gt;
&lt;li&gt;Having &lt;em&gt;The Internet&lt;/em&gt; interjected between the two parts.&lt;/li&gt;
&lt;li&gt;Having the point of split dictated not by business considerations, but
by technological limitations instead.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mixes application with presentation.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;A fundamental principle of graphical user interface application
development is that application logic should be kept completely separate
from presentation logic. This principle warns against inadvertently
allowing application logic to bleed into the presentation layer;
however, with full-stack development we have application logic not just
&lt;em&gt;bleeding&lt;/em&gt; to the presentation layer, but actually
&lt;em&gt;embarking on a massive deliberate large-scale exodus&lt;/em&gt; to the
presentation layer.&lt;/li&gt;
&lt;li&gt;One might naively think that full-stack development accomplishes
separation by keeping application logic on the server and presentation
logic on the client, but this is demonstrably not so:
&lt;ul&gt;
&lt;li&gt;The server is largely reduced to a bunch of dumb REST endpoints that
perform not much more than Create, Read, Update, Delete, List (CRUDL)
operations with validation. That is not application logic; that's
mostly just querying and updating the data store.&lt;/li&gt;
&lt;li&gt;The client not only decides how things should look, but it also
decides what options should be available to the user at any moment,
and what new options will become available to the user as a result of
user actions. Essentially, all application workflows are implemented
on the client. That's application logic
&lt;em&gt;par excellence&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Is hard to test.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;The front-end is not functional without the back-end, so the two ends
usually have to be tested in integration, necessitating such
monstrosities as Selenium.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prevents specialization and division of labor.&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Full-stack development necessitates &lt;em&gt;The Full-stack Developer&lt;/em&gt;, who
is:
&lt;ul&gt;
&lt;li&gt;a front-end programmer,&lt;/li&gt;
&lt;li&gt;a back-end programmer,&lt;/li&gt;
&lt;li&gt;a network programmer,&lt;/li&gt;
&lt;li&gt;a security expert,&lt;/li&gt;
&lt;li&gt;a user experience expert,&lt;/li&gt;
&lt;li&gt;an accessibility expert, and&lt;/li&gt;
&lt;li&gt;a graphic artist&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt; ? all rolled into one, thus running the risk of being a
*jack of all trades, master of none*.
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;h4 id="conclusion"&gt;Conclusion
&lt;/h4&gt;&lt;p&gt;By its nature, web application development requires systems that consist of
multiple layers; the current state of affairs is such that
application-specific code must be running on each of these layers, and this is
called full-stack development. However, as I have shown, full-stack
development has a list of disadvantages which is rather extensive, and each of
these disadvantages is rather severe.&lt;/p&gt;
&lt;p&gt;Essentially, we are suffering the consequences of a technological limitation:
we currently have no means of confining all application logic to the server,
so we have to be placing application logic on the client too, so we have no
option but to be engaging in full-stack development.&lt;/p&gt;
&lt;p&gt;Technological limitations require technological solutions, but companies with
commercial goals do not usually take it upon themselves to solve the world's
technological problems. Instead, they tend to make do with the existing
problems, providing non-technological workarounds to them, such as throwing
more manpower into the development effort. This might make sense for each
individual company, but from a global perspective, we have collectively been
&lt;em&gt;too busy mopping the floor to turn off the faucet.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A solution that would confine all application logic to the server and thus
eliminate full-stack development has the potential of being very beneficial to
the industry as a whole.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog2.michael.gr/images/images/blog.michael.gr/content/post/generated/2021/2021-12-full-stack-development/images/grumpy-cat-full-stack-development-i-hate-it.jpg"
loading="lazy"
&gt;
&lt;/p&gt;</description></item><item><title>On Code Craftsmanship</title><link>https://blog2.michael.gr/post/2018-02-code-craftsmanship/</link><pubDate>Mon, 05 Feb 2018 15:55:42 +0000</pubDate><guid>https://blog2.michael.gr/post/2018-02-code-craftsmanship/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2018-02-code-craftsmanship/media/craftsmanship-guitar.jpg"
width="2048"
height="1365"
srcset="https://blog2.michael.gr/post/2018-02-code-craftsmanship/media/craftsmanship-guitar_hu_8f8fb8bbba0d0d17.jpg 480w, https://blog2.michael.gr/post/2018-02-code-craftsmanship/media/craftsmanship-guitar_hu_14d10496d9352bee.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
&gt;
&lt;/p&gt;
&lt;p&gt;I will try to make a list of items here, but I could probably write a book on this.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id="assert-everything"&gt;Assert everything
&lt;/h3&gt;&lt;p&gt;Assertions take care of white-box testing your code, so that automated software testing can be confined to the realm of strictly black-box testing, as it should. Assertions do not execute on release builds / production runs, so they essentially cost nothing. This means that you can go wild with them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Go ahead and assert that your array is sorted before performing binary search on it.&lt;/li&gt;
&lt;li&gt;Verify that your binary search worked correctly by comparing its result against the result of a linear search for the same item.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Yes, the time complexity of these assertions is far greater than the time complexity of the operation that they guard, and this is perfectly fine, because:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Remember, assertions do not execute on release runs, so they cost nothing.&lt;/li&gt;
&lt;li&gt;On test runs, you are not supposed to be using large amounts of data anyway. When N is small, then O(N) and even O(N&lt;sup&gt;2&lt;/sup&gt;) are not very different from O(log&lt;sub&gt;2&lt;/sub&gt;(N)), which means that even when assertions do execute, they do not matter.&lt;/li&gt;
&lt;li&gt;To the small extent that assertions might nonetheless slow you down during development, you can see it as one more reason why you, as a developer, should have a computer which is much more powerful than the computers of mere mortals --er, I mean, users.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When I look at code, I don't ask myself &amp;quot;should I assert that?&amp;quot; Instead, I ask myself &amp;quot;is there anything that I forgot to assert?&amp;quot; The idea is to assert everything that could possibly be asserted, leave nothing assertable unasserted. I call this &lt;em&gt;The Maximalistic Approach to Error Checking&lt;/em&gt;, in contrast to the predominant minimalistic approach, where programmers decide on a case by case basis whether to assert something or not, based on completely-oblivious-of-Murphy's-law assumptions about how likely it is to go wrong, inappropriately mixed with misguided performance considerations.&lt;/p&gt;
&lt;p&gt;For more information, see &lt;a
href="https://blog2.michael.gr/post/2014-09-assertions-and-testing/"
&gt;Assertions and Testing&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Also note that the attention horizon of code is the function, so if function &lt;code&gt;f1()&lt;/code&gt; asserts some condition and then invokes function &lt;code&gt;f2()&lt;/code&gt;, it is perfectly fine for &lt;code&gt;f2()&lt;/code&gt; to also assert the same condition. In other words, whether something has already been asserted or not by some other function is irrelevant: each function must assert every condition that pertains to it.&lt;/p&gt;
&lt;h3 id="do-black-box-testing-avoid-white-box-testing"&gt;Do black-box testing, avoid white-box testing
&lt;/h3&gt;&lt;p&gt;Heed the advice that says &lt;em&gt;test against the interface, not the implementation&lt;/em&gt;. Unit Testing is testing against the implementation, so despite the entire software industry's addiction to it, it should be avoided. Incidentally, this means that mocking, despite being an admirably nifty trick, should never be used: if you are using mocks then you are doing white-box testing, so you are doing it wrong.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For more on why Unit Testing is white-box testing, and why white-box testing is bad, read this: &lt;a
href="https://blog2.michael.gr/post/2021-12-white-box-vs-black-box-testing/"
&gt;White-Box vs. Black-Box Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;For more on why mocks in particular are especially bad, read this: &lt;a
href="https://blog2.michael.gr/post/2023-01-14-mocking/"
&gt;If you are using mock objects you are doing it wrong&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For what to use instead of mocks, read this: &lt;a
href="https://blog2.michael.gr/post/2022-10-testing-with-fakes/"
&gt;Testing with Fakes instead of Mocks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;For what to do instead of unit testing, read this: &lt;a
href="https://blog2.michael.gr/post/2022-10-incremental-integration-testing/"
&gt;Incremental Integration Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;If for some reason you &lt;em&gt;must&lt;/em&gt; do white-box testing, then you can at least avoid having to do it in code; read this: &lt;a
href="https://blog2.michael.gr/post/2024-04-audit-testing/"
&gt;Audit Testing&lt;/a&gt; and this: &lt;a
href="https://blog2.michael.gr/post/2023-01-06-collaboration-monitoring/"
&gt;Collaboration Monitoring&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="avoid-non-determinism-in-tests"&gt;Avoid non-determinism in tests
&lt;/h3&gt;&lt;p&gt;Testing must be completely free from non-determinism under all circumstances. Since testing code exercises production code, this means that production code must also be free from non-determinism, or at the very least any source of non-determinism in production code must be replaceable during testing with a fake which is completely deterministic. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Never rely on the garbage-collector doing anything other than reclaiming memory; specifically, never rely on any cleanup operations being initiated by the garbage-collector. Perform all cleanup explicitly. For more information, see &lt;a
href="https://blog2.michael.gr/post/2020-12-27-object-lifetime-awareness/"
&gt;Object Lifetime Awareness&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Never allow any external factors such as file creation times, IP addresses resolved from DNS, etc. to enter into the tests. Fake your file-system; fake The Internet if necessary.&lt;/li&gt;
&lt;li&gt;Never use wall-clock time; always fake the clock, making it start from some arbitrary fixed origin and incrementing by a fixed amount each time it is queried.&lt;/li&gt;
&lt;li&gt;Never use random numbers; if randomness is necessary in some scenario, then fake it using a pseudo-random number generator seeded with a known fixed value. This includes all constructs that utilize randomness, for example GUIDs/UUIDs.&lt;/li&gt;
&lt;li&gt;Never allow any concurrency during testing; all components must be tested while running strictly single-threaded, or at the very least multi-threaded but in lock-step fashion.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="minimize-state-maximize-immutability"&gt;Minimize state, maximize immutability
&lt;/h3&gt;&lt;p&gt;Design so that as much code as possible is dealing with data that is immutable. Re-examine every single class which contains mutable members, and many chances are you will find that it could be replaced with an immutable class. Even if not, you might discover that many of its members could be immutable.&lt;/p&gt;
&lt;p&gt;Eschew frameworks, technologies, and techniques that prevent or hinder immutability. For example, if you are using some dependency-injection (DI) facility that provides you with auto-wiring, use constructor injection &lt;strong&gt;only,&lt;/strong&gt; so that you can always store in final/readonly members. If your DI facility does not support constructor injection, throw away everything and start from scratch with one that does.&lt;/p&gt;
&lt;p&gt;Note, however, that immutability is not important in function-local variables. There is absolutely nothing wrong with function-local mutation if it serves the slightest purpose. Which brings us to the next point:&lt;/p&gt;
&lt;h3 id="do-overwrite-function-parameters"&gt;Do overwrite function parameters
&lt;/h3&gt;&lt;p&gt;There exists a widespread cargo cult habit among programmers, of never overwriting the value of a parameter to a function within the function. This habit is so unquestioned that it enjoys &amp;quot;best practice&amp;quot; status, despite being completely misguided. Some languages (e.g. Scala) even prohibit it, which is deplorable. Go ahead and overwrite function parameters (if your language allows it) when the original parameter value should not be used in the remainder of the function. In doing so you are minimizing the number of variables that are in scope, and preventing accidental use of the original value.&lt;/p&gt;
&lt;p&gt;The historical origins of the practice of never overwriting function parameters are actually quite funny: some early versions of Fortran (the first programming language) used to pass everything by reference, including constants. So, if you had function F(X) which was invoked with 3 for X, and within F(X) you assigned 5 to x, then from that moment on the constant 3 would actually have the value 5 in your entire program. As a result, early computer scientists decreed that function parameters should never be reassigned. Fortran was soon fixed to correct this problem, but the advise kept being passed from generation to generation of programmers, who have been accepting it without rethinking it. This is cargo cult programming at its finest.&lt;/p&gt;
&lt;h3 id="avoid-hail-mary-initializations"&gt;Avoid &lt;em&gt;Hail-Mary Initializations&lt;/em&gt;
&lt;/h3&gt;&lt;p&gt;Contrary to what many people falsely think of as &amp;quot;common knowledge&amp;quot; and &amp;quot;best practice&amp;quot;, you should never initialize a variable before you have a meaningful value to assign to it. For more information, see &lt;a
href="https://blog2.michael.gr/post/2012-01-03-hail-mary-initialization/"
&gt;Hail-Mary Initialization&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="avoid-b-to-a-style-conversions-use-a-from-b-style-instead"&gt;Avoid &amp;quot;b-to-a&amp;quot; style conversions, use &amp;quot;a-from-b&amp;quot; style instead
&lt;/h3&gt;&lt;p&gt;When I see &lt;code&gt;A = AfromB( B )&lt;/code&gt; I can immediately tell that it looks correct, since A is on the side of A and B is on the side of B. However, when I see &lt;code&gt;B = AtoB( A )&lt;/code&gt; I have to stare at it for a few milliseconds longer before I can tell whether it is correct or not. Of course, this is a trivial example: in real-world situations, the identifiers, as well as the call chain, could be much longer and much more complicated. This is related to Joel Spolsky's notion that &lt;a class="external"
href="https://www.joelonsoftware.com/2005/05/11/making-wrong-code-look-wrong/" target="_blank"
&gt;wrong code should look wrong&lt;/a&gt;, and it is especially important since the entire industry has traditionally been doing it in precisely the wrong way with B-to-A style conversions.&lt;/p&gt;
&lt;h3 id="avoid-yoda-conditionals"&gt;Avoid &lt;em&gt;Yoda conditionals&lt;/em&gt;
&lt;/h3&gt;&lt;p&gt;This is the practice of reversing the terms around the equality operator when one of the terms is a constant. You might have seen it the following forms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;if( 5 == a )&lt;/code&gt; instead of the normal &lt;code&gt;if ( a == 5 )&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;if( &amp;quot;x&amp;quot;.equals( b ) )&lt;/code&gt; instead of the normal &lt;code&gt;if( b.equals( &amp;quot;x&amp;quot; ) )&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Don't do this. The Principle of Least Surprise is not just violated by this construct, it is gang-raped. Plus, in doing this you are most probably engaging in the cardinal sin of &lt;em&gt;&lt;strong&gt;silent failure&lt;/strong&gt;&lt;/em&gt;. Here are the reasons often cited for using Yoda conditionals, and their rebuttals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Alleged reason #1&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Statement: It will catch accidental use of the assignment operator where the equality operator was intended.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rebuttal: Such accidental use should be impossible because your compiler or your IDE should be issuing a warning if you try to do this. If you are not receiving a warning, then you have other, much bigger problems in need of solving, i.e. using the wrong programming language, using the wrong IDE, or trying to write code without first having figured out how to enable all warnings.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Alleged reason #2&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Statement: It works even if the variable accidentally happens to be null.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rebuttal: No, it does not work; it silently fails. If you follow &lt;em&gt;offensive programming&lt;/em&gt;, the definition of &amp;quot;it works&amp;quot; is that &lt;em&gt;&lt;strong&gt;it produces correct results when given valid input, and it decisively fails when given invalid input.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So, there are two possibilities: either the variable may legitimately be null, or it may not.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if the variable may legitimately be null, then make it evident by explicitly checking against null.&lt;/li&gt;
&lt;li&gt;if the variable may not legitimately be null, then write the code so that it will &lt;em&gt;&lt;strong&gt;not fail to fail&lt;/strong&gt;&lt;/em&gt; if the variable ever turns out to be null.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="avoid-unnecessary-braces"&gt;Avoid unnecessary braces
&lt;/h3&gt;&lt;p&gt;Doing so keeps the code more compact, making more statements fit within the screen. The cargo-cult programming convention of enclosing even single-statement blocks within curly braces allegedly avoids bugs caused by trying to add a second statement to the block while forgetting to introduce curly braces.&lt;/p&gt;
&lt;p&gt;This has actually happened to me once, and the programmer who introduced the bug in my code did not even apologize, because he considered it my fault for not having provided the curly braces for him to insert his second statement in.&lt;/p&gt;
&lt;p&gt;The fact of the matter is that a decent IDE will point out such a mistake as a formatting violation, so this is not a problem today. Of course, in order to enable the IDE to point out formatting violations you must be keeping a consistent indentation style everywhere, right? &lt;em&gt;&lt;strong&gt;Right?&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h3 id="avoid-egyptian-style-curly-braces"&gt;Avoid Egyptian-style curly braces
&lt;/h3&gt;&lt;p&gt;People who use Egyptian-style curly braces essentially treat them as noise. I would very much favor a programming language where nesting is based on indentation alone, thus requiring no curly braces; unfortunately, the only such language that I know of is Python, which is a scripting language, and therefore out of the question; so, for as long as we are using programming languages that require curly braces, we have to pay attention to them and we cannot just treat them as noise; therefore, absolutely all curly braces must absolutely always be perfectly aligned; period, end of story, discussion is locked and comments are closed.&lt;/p&gt;
&lt;h3 id="minimize-flow-control-statements"&gt;Minimize flow control statements
&lt;/h3&gt;&lt;p&gt;Especially the &lt;code&gt;if&lt;/code&gt; statement. If there is any opportunity to structure a piece of code so as to eliminate an &lt;code&gt;if&lt;/code&gt; statement, the opportunity should be pursued &lt;em&gt;tenaciously&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Of course, by this I do not mean replacing &lt;code&gt;if&lt;/code&gt; statements with the conditional operator ( &lt;code&gt;a ? x : y&lt;/code&gt; ); the conditional operator is nice, because it makes code more expressive and compact, but it is equivalent to an &lt;code&gt;if&lt;/code&gt; statement, so it too should be eliminated when possible.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;if&lt;/code&gt; statement can be avoided in many cases with the use of calculations, with lookup tables, with the judicious application of inheritance and polymorphism, etc.&lt;/p&gt;
&lt;h3 id="favor-one-and-only-one-way-of-doing-any-given-thing"&gt;Favor one and only one way of doing any given thing
&lt;/h3&gt;&lt;p&gt;If you ask a hundred programmers to write some code that accomplishes a certain simple task, you will get a hundred different solutions. These solutions will reflect different ways of thinking, which is inevitable, but they will also reflect different coding conventions, which is entirely unnecessary. Establish conventions that minimize unnecessary differences. One easy way to achieve this is to stipulate that any construct which is optional must be omitted. For example:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Disallow extra parentheses in expressions.&lt;/p&gt;
&lt;p&gt;Unfortunately, compilers by default allow superfluous parentheses without complaining. This has fostered the development of some truly bizarre habits among programmers, such as the construct &lt;code&gt;return (x);&lt;/code&gt; which is so common that some folks are under the impression that this is the correct syntax, and that &lt;code&gt;return x;&lt;/code&gt; would constitute a syntax error. Well, guess what: &lt;code&gt;return x;&lt;/code&gt; is the correct syntax, whereas &lt;code&gt;return (x);&lt;/code&gt; contains a pair of superfluous parentheses. Configure your compiler or your code analysis tool-set to disallow unnecessary parentheses, so that all code that accomplishes the same thing looks the same.&lt;/p&gt;
&lt;p&gt;If you do this, then the tooling will also complain about parentheses that you might be using elsewhere to clarify the order in which calculations are to be performed when you are unsure about the operator precedence rules of the language. Here is what I have to say about that:&lt;/p&gt;
&lt;p&gt;Your programming language has a very specific, very well documented, and rather small set of rules that govern operator precedence; these rules are fundamental, and this programming language is your bread and butter; so, learn them. Learn them all by heart, so that you are never unsure about operator precedence, so that you never need extra parentheses for clarification.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Disallow optional keywords.&lt;/p&gt;
&lt;p&gt;In many languages, certain keywords are implied by default and can be omitted. Unfortunately, in virtually all example code out there, such keywords tend to always be included, which leads people to form the impression that they must be mandatory.&lt;/p&gt;
&lt;p&gt;For example, did you know that in C# every class is &lt;code&gt;internal&lt;/code&gt; by default? This means that you never have to say &lt;code&gt;internal class Foo { ... }&lt;/code&gt;, you can simply say &lt;code&gt;class Foo { ... }&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Furthermore, did you know that in C# every class member is &lt;code&gt;private&lt;/code&gt; by default? This means that you never have to say &lt;code&gt;private int foo() { ... }&lt;/code&gt;, you can simply say &lt;code&gt;int foo() { ... }&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Again, it is fundamental rules of the language that govern these things, which means that every programmer should know them by heart, which in turn means that nobody should be surprised to see &lt;code&gt;int foo() { ... }&lt;/code&gt;, and nobody should be wondering what the visibility of &lt;code&gt;foo()&lt;/code&gt; is.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Disallow the &lt;code&gt;var&lt;/code&gt; keyword.&lt;/p&gt;
&lt;p&gt;If we were to mandate that two lines of code should look identical if they accomplish the same thing, we have two options: either always require the &lt;code&gt;var&lt;/code&gt; keyword, or completely disallow it.&lt;/p&gt;
&lt;p&gt;Always requiring the &lt;code&gt;var&lt;/code&gt; keyword is not an option, because in many cases the type cannot be inferred from the right hand side, so it must be specified. Thus, we are only left with the option of completely disallowing it, and that is the way to go.&lt;/p&gt;
&lt;p&gt;Furthermore, as I explain elsewhere, &amp;quot;absolutely any choice that makes code easier to read is absolutely always preferable over absolutely any choice that makes code easier to write&amp;quot;, and the &lt;code&gt;var&lt;/code&gt; keyword is a prime example of a choice which is easy to write but makes code harder to read, so we should not even be debating this.&lt;/p&gt;
&lt;p&gt;If you are not sure about the exact type of the right-hand side of an assignment, or if you do not want to be bothered with having to type it, is perfectly okay to begin with &lt;code&gt;var x = ...&lt;/code&gt;, and once you have written your entire statement you go back to the &lt;code&gt;var&lt;/code&gt; keyword, and ask your IDE to refactor it and replace it with the actual type.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;var&lt;/code&gt; keyword is only useful in type casts; I would rather say &lt;code&gt;var x = (int)y;&lt;/code&gt; than &lt;code&gt;int x = (int)y;&lt;/code&gt; however, the benefits of being able to disallow &lt;code&gt;var&lt;/code&gt; with a rule outweigh the convenience of being able to use it in type casts.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="put-the-complexity-in-the-design-not-in-the-code"&gt;Put the complexity in the design, not in the code
&lt;/h3&gt;&lt;p&gt;If the code does not look so simple that even an idiot can understand it, then the code is too complex. When this happens, it usually means that shortcuts were taken in the design, which had to be compensated for with overly complex code. Make the design as elaborate as necessary so that the code can be as simple as possible. Overly complex code is usually the result of violations of the &lt;em&gt;Single Responsibility Principle.&lt;/em&gt; Which brings us to the next point:&lt;/p&gt;
&lt;h3 id="adhere-to-the-single-responsibility-principle-like-your-life-depends-on-it"&gt;Adhere to the Single Responsibility Principle like your life depends on it
&lt;/h3&gt;&lt;p&gt;Often, what you &lt;em&gt;think&lt;/em&gt; of as a single responsibility can in fact be further sub-divided into a number of more fundamental responsibilities. Almost all of the code that we write performs, or can be thought of as performing, some kind of transformation, involving a certain number of participants. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;At the lowest level, an assignment operation transforms each bit of the destination variable into the corresponding bit of the source variable. Obviously it involves two participants: the source and the destination.&lt;/li&gt;
&lt;li&gt;At the highest level, a shopping web site transforms relational data and user input into pixels on the user's browser window and purchase orders in the logistics department. In this simplified view we have four participants, realistically we have many more.
&lt;ul&gt;
&lt;li&gt;Most transformations are of the simplest kind, involving only two participants, transforming one into the other. That's great, that's a single responsibility: convert A to B.&lt;/li&gt;
&lt;li&gt;Many transformations involve three participants, A, B and C, and they tend to be appreciably complex.
&lt;ul&gt;
&lt;li&gt;In some cases they can be simplified into successive operations, one to go from A to B and another to go from B to C, meaning that there were in fact two different responsibilities which were identified and realized as separate steps.&lt;/li&gt;
&lt;li&gt;However, quite often they cannot be simplified, as for example when we are converting A to C by consulting B. That's a single responsibility which cannot be further broken down.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;All to often, people manage to involve four or more participants in a single transformation. These tend to be grotesquely complex, and they invariably constitute violations of the single responsibility principle. It goes without saying that they must be avoided at all costs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Luckily, operations that involve more than 3 participants can always be refactored into multiple successive transformations of no more than 3 participants each, by introducing intermediate participant types if necessary. (I have never heard of this being suggested by anyone before, so this could perhaps be &lt;em&gt;The Mike Nakis Postulate for Simplification&lt;/em&gt;.)&lt;/p&gt;
&lt;h3 id="refactor-at-the-slightest-indication-that-refactoring-is-due"&gt;Refactor at the slightest indication that refactoring is due
&lt;/h3&gt;&lt;p&gt;Do not allow technical debt to accumulate. Avoid the situation of being &lt;em&gt;too busy mopping the floor to turn off the faucet.&lt;/em&gt; Allow a percentage of sprints to explicitly handle nothing but technical debt elimination. Do not try to spread the task of refactoring over feature development sprints, because:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The refactoring effort will not magically disappear.&lt;/li&gt;
&lt;li&gt;Focus will be diluted.&lt;/li&gt;
&lt;li&gt;Time estimations will suffer.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Managers who feel that every sprint must involve some feature development or else it does not look good on their report should be removed from their positions and be given jobs milking goats.&lt;/p&gt;
&lt;h3 id="strive-for-abstraction-and-generalization"&gt;Strive for abstraction and generalization
&lt;/h3&gt;&lt;p&gt;The urge to abstract and generalize is often mistaken as having reusability as its sole aim, so it is often met with the YAGNI objection: &amp;quot;You Ain't Gonna Need It&amp;quot;. The objection is useful to keep in mind so as to avoid over-engineering, but it should not be followed blindly, because abstraction and generalization have important inherent benefits, regardless of the promise of reusability.&lt;/p&gt;
&lt;p&gt;Every problem of a certain complexity and above, no matter how application-specific it might seem to be, can benefit from being divided into a specialized, application-specific part, and an abstract, general-purpose part. Strive to look for such divisions and realize them in the design.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The application-specific part will be simpler to write and to understand, because it will be free from the &lt;em&gt;incidental complexity&lt;/em&gt; represented by the general-purpose part.&lt;/li&gt;
&lt;li&gt;The general-purpose part will be simpler to write and to understand, because it will be implementing a self-contained abstraction that can be independently reasoned about.&lt;/li&gt;
&lt;li&gt;Also, the general-purpose part will be fully testable on its own, so you will have assurances that it works, regardless of how the application-specific part uses it, and regardless of how the application-specific part evolves over time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that the above benefits come in addition to the potential benefit of reusability.&lt;/p&gt;
&lt;p&gt;In other words, if you can choose between the following two:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;adding 5 lines of application code, vs.&lt;/li&gt;
&lt;li&gt;adding only 2 lines of application code but a whole 10 lines of infrastructure code&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;then opt for the latter, even if these 10 lines of infrastructure code are unlikely to ever be reused. Saving 3 lines of application code is worth writing an extra 10 lines of infrastructure code.&lt;/p&gt;
&lt;h3 id="use-abstraction-even-in-the-spoken-language"&gt;Use abstraction even in the spoken language
&lt;/h3&gt;&lt;p&gt;People have the unfortunate tendency of using the most specific term for any given thing, rather than the most abstract term. I am not sure why people do this, perhaps it is addiction to technicality, perhaps it is trying to sound smart, but it often ends up causing miscommunication. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if your application has a settings file, and this file happens to be a json file, people are likely to form a habit of calling it &amp;quot;the json file&amp;quot; instead of &amp;quot;the settings file&amp;quot;.&lt;/li&gt;
&lt;li&gt;if your application stores session state information in a key-value store, and that store happens to be a Redis instance, people are likely to say &amp;quot;send it to Redis&amp;quot; instead of &amp;quot;send it to the session state store&amp;quot;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Identify such unwarranted technicalisms and encourage people to switch to using the abstract terms instead. Tell them that the json file was replaced with a yaml file today, and when they all start calling it the yaml file, tell them that it is now an xml file. When they start complaining, tell them that the particular file format of the settings file is none of their business, and they should be calling it by its proper name, which is &amp;quot;the settings file&amp;quot;.&lt;/p&gt;
&lt;h3 id="avoid-false-abstractions"&gt;Avoid false abstractions
&lt;/h3&gt;&lt;p&gt;Sometimes programmers give abstract names to things that are not really abstract. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;so-called serialization frameworks which expose details of the underlying file format, meaning that they are only capable of serializing to and from that specific file format. A serialization framework which exposes XML-specific details should not be called a &amp;quot;Serialization Framework&amp;quot;; it should be called an &amp;quot;XML Serialization Framework&amp;quot;.&lt;/li&gt;
&lt;li&gt;in NuGet (the predominant package manager in DotNet) a version is said to consist of a version prefix and a version suffix, however the toolset interprets the two in a very specific way: the version prefix is not really a prefix, it is the actual version, and the version suffix is not really a suffix, it is a pre-release version identifier.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are examples of pretending that things are more abstract than they really are, which causes misinformation and suffering.&lt;/p&gt;
&lt;h3 id="use-domain-specific-interfaces"&gt;Use domain-specific interfaces
&lt;/h3&gt;&lt;p&gt;Encapsulate third party libraries behind interfaces of your own devise, tailored to your specific application domain. Strive to make it so that any third-party library can be swapped with another product without you having to rewrite application logic.&lt;/p&gt;
&lt;p&gt;Conventional wisdom says the opposite: we have all heard arguments like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;quot;The best code is the code you don't write&amp;quot; (makes me want to invest in the business of &lt;em&gt;not writing software&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;&amp;quot;A third-party library will be better documented than your stuff&amp;quot; (presumably because documentation is a skill your developers have not mastered)&lt;/li&gt;
&lt;li&gt;&amp;quot;If you run into trouble with a library, you can ask for help on Stack Overflow, whereas with something you have developed in-house, you are stuck&amp;quot; (presumably because your developers know nothing of it, despite working with it every day.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The truth with application development is that the more you isolate the application logic from peripheral technologies, the more resilient your application logic becomes to the ever changing technological landscape, a considerable part of which is nothing but ephemeral fashions, the use of which is dictated not by actual technological merit, but by &lt;em&gt;C.V. Driven Development&lt;/em&gt;&lt;sup id="fnref:1"&gt;&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref"&gt;1&lt;/a&gt;&lt;/sup&gt; instead.&lt;/p&gt;
&lt;p&gt;Incidentally, this also means one more thing:&lt;/p&gt;
&lt;h3 id="favor-libraries-over-frameworks"&gt;Favor libraries over frameworks
&lt;/h3&gt;&lt;p&gt;The difference between a framework and a library is, simply speaking, that a library is something that your code invokes, whereas a framework is something that invokes your code. The problem with frameworks is that it is impossible to abstract them away behind custom interfaces; therefore, any code you write using a particular framework will forever be a prisoner of that framework: it will be extremely difficult to replace that framework with a different one without rewriting all your code.&lt;/p&gt;
&lt;h3 id="strive-for-what-is-simple-not-for-what-looks-easy"&gt;Strive for what is simple, not for what looks easy
&lt;/h3&gt;&lt;p&gt;The simple often coincides with the easy, but sometimes the two are at odds with each other. Eschew languages and frameworks that provide the illusion of easiness at the expense of simplicity. The fact that a particular toolset makes &amp;quot;hello, world!&amp;quot; an easy one-liner probably means that the hundred-thousand liner that you are actually aiming for will be unnecessarily complicated and hard to write.&lt;/p&gt;
&lt;p&gt;Watch this: &lt;a class="external"
href="https://www.infoq.com/presentations/Simple-Made-Easy" target="_blank"
&gt;https://www.infoq.com/presentations/Simple-Made-Easy&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="avoid-binding-by-name-like-the-plague"&gt;Avoid binding by name like the plague
&lt;/h3&gt;&lt;p&gt;Avoid as much as possible mechanisms whose modus operandi is binding by name: use them only for interfacing with external entities, never for communication between your own modules. REST enthusiasts can cry me a river.&lt;/p&gt;
&lt;p&gt;Note that binding by name must be avoided even in comments. If you need to refer to an identifier from within a comment, use whatever special notation is offered by the language at hand (&lt;code&gt;{@link ...}&lt;/code&gt; in java, &lt;code&gt;&amp;lt;see cref=&amp;quot;...&amp;quot;&amp;gt;&lt;/code&gt; in C#) so that when you later refactor the name of that identifier, the IDE will also update any comments that mention that identifier.&lt;/p&gt;
&lt;h3 id="always-use-strong-typing"&gt;Always use strong typing
&lt;/h3&gt;&lt;p&gt;Avoid any kind of weak typing (euphemistically called &lt;em&gt;dynamic&lt;/em&gt; typing) and avoid languages and frameworks that require it or even just sympathize with it. Yes, this includes all scripting languages. Scripting language enthusiasts can cry me a river. (And yes, this includes Typescript too, because it &lt;em&gt;sympathizes&lt;/em&gt; with JavaScript.)&lt;/p&gt;
&lt;p&gt;Read this: &lt;a
href="https://blog2.michael.gr/post/2017-05-on-scripting-languages/"
&gt;On Scripting Languages&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="strive-for-debuggability"&gt;Strive for debuggability
&lt;/h3&gt;&lt;p&gt;For example, do not overdo it with the so-called &amp;quot;fluent&amp;quot; style of invocations, because they are not particularly debuggable. Do not hurry to adopt this or that cool new programming language before you have made sure that debugger support for it is complete and working properly.&lt;/p&gt;
&lt;h3 id="resist-the-idiomatic-craze"&gt;Resist the idiomatic craze
&lt;/h3&gt;&lt;p&gt;Contrary to popular belief, doing things in whatever way is considered idiomatic for the programming language at hand is never an end in and of itself; Avoid the use of idiomatic ways of doing things unless you are convinced they are superior. Many of them are, but some of them are not.&lt;/p&gt;
&lt;h3 id="strive-for-testability"&gt;Strive for testability
&lt;/h3&gt;&lt;p&gt;Design interfaces that expose all functionality that makes sense to expose, not only functionality that is known to be needed by the code that will invoke them. For example, the application may only need an interface to expose a &lt;code&gt;register()&lt;/code&gt; and &lt;code&gt;unregister()&lt;/code&gt; pair of methods, but &lt;code&gt;isRegistered()&lt;/code&gt; also makes sense to expose, and it will incidentally facilitate black-box testing.&lt;/p&gt;
&lt;h3 id="enable-all-warnings-that-can-be-enabled"&gt;Enable all warnings that can be enabled
&lt;/h3&gt;&lt;p&gt;The fact that a certain warning may on occasion be issued on legitimate code is no reason to disable the warning: the warning must be enabled, and each occurrence of the warning must be dealt with on a case-by-case basis.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The best way to deal with a warning is to resolve it. For example:
&lt;ul&gt;
&lt;li&gt;If your compiler is warning you that a certain cast is redundant, remove that redundant cast. (Duh!)&lt;/li&gt;
&lt;li&gt;If the compiler is warning you that you are dereferencing a pointer which might be null at that point, then add a null check before dereferencing it. (Duh!)&lt;/li&gt;
&lt;li&gt;If your compiler is warning you that you are invoking an overridable method from within the constructor of a base class, then do whatever restructuring is needed, throw it all away and rewrite it from scratch if necessary, so that no such thing is happening.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Another way of dealing with warnings is by suppressing them. Of course, this approach should only be used on perfectly legitimate code that would become less perfect if it was to be restructured so as to resolve the warning. Suppression should always be as localized as possible, meaning that it should be done on the individual statement where the warning is issued, instead of the entire function or the entire class. Note, however, that there are certain warnings that should always be properly resolved and never suppressed; take the invocation of an overridable method from within the constructor of a base class for example.
&lt;ul&gt;
&lt;li&gt;Some warnings, like &amp;quot;unused identifier&amp;quot;, occur on legitimate code too often for selective suppression to be practical. For those warnings, consider using an IDE that supports a &amp;quot;weak warning&amp;quot; or &amp;quot;suggestion&amp;quot; level, which is highlighted inconspicuously, so it can be easily filtered out by your eyes, but the visual clue is still there in case it points to something unexpected. Also consider using a better programming language, which supports a construct known as a &amp;quot;discard variable&amp;quot;, allowing the programmer to explicitly state their intention to let a variable go unused, so that the warning can remain a warning.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course some silly warnings occur on legitimate code all the time, so it goes without saying that they need to be disabled, but in my experience they are far fewer than the average programmer thinks they are.&lt;/p&gt;
&lt;h3 id="thou-shalt-not-suffer-a-warning-to-live"&gt;Thou shalt not suffer a warning to live
&lt;/h3&gt;&lt;p&gt;Every single warning must always be resolved immediately upon being introduced. Nobody should ever commit code that contains warnings, and therefore nobody should ever check out code that already contains warnings.&lt;/p&gt;
&lt;p&gt;This is because a warning always is (or ought to always be) a cause of alarm; however, long-standing warnings constitute long-standing false alarms, so their continued existence causes two things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;All programmers in the house start becoming insensitive to the alarms, so the alarms start going unnoticed. (The &amp;quot;cry wolf&amp;quot; effect.)&lt;/li&gt;
&lt;li&gt;Those programmers who are perfectionists (and those are the best kind of programmers) start becoming mighty annoyed.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Which brings us to the next point:&lt;/p&gt;
&lt;h3 id="treat-warnings-as-errors"&gt;Treat Warnings as Errors
&lt;/h3&gt;&lt;p&gt;Always use the &amp;quot;treat warnings as errors&amp;quot; option of your compiler. If your compiler does not have such an option, throw away everything and start from scratch with a compiler that has it.&lt;/p&gt;
&lt;p&gt;The conventional understanding of what the difference is between warnings and errors is that with an error, you have to fix it before you can proceed, whereas with a warning, you can just ignore it and proceed.&lt;/p&gt;
&lt;p&gt;This understanding is technically correct, in the sense that this is in fact how compilers tend to behave by default, and this is in turn what most programmers expect, since dumb defaults seem to always suit mindless majorities. However, this conventional understanding, and therefore this default behavior of compilers, is wrong. It has been wrong since the dawn of our discipline, and it continues to be wrong today. The magnitude of the wrongness, multiplied by the pervasiveness of the wrongness, is truly staggering.&lt;/p&gt;
&lt;p&gt;The difference between warnings and errors &lt;em&gt;&lt;strong&gt;should be&lt;/strong&gt;&lt;/em&gt; that you can suppress a warning if you must, whereas you cannot suppress an error; however, you should absolutely have to address and eliminate both, meaning that you should have to either explicitly suppress or otherwise resolve every single warning before being allowed to proceed.&lt;/p&gt;
&lt;p&gt;The &amp;quot;treat warnings as errors&amp;quot; option corrects the wrong behavior of compilers, and exists precisely for the benefit of those (apparently very few) people in our discipline who happen to have their reasoning right on this issue.&lt;/p&gt;
&lt;p&gt;Be one of those people. Use that option.&lt;/p&gt;
&lt;h3 id="strive-for-readability"&gt;Strive for readability
&lt;/h3&gt;&lt;p&gt;Readability is one of the most important qualities of code, second only to correctness. Code is generally read far more often that it is written. We tend to read code several times as we write it, at least once more as we review it, and then many more times throughout its lifetime as we extend it, refactor it, or tweak it; as we write nearby code; as we browse through code to understand how things work; as we perform troubleshooting; etc. In other words, over time, the reads-to-writes ratio of any piece of code approaches infinity. Therefore:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Absolutely any&lt;/strong&gt;&lt;/em&gt; choice that makes code easier to read is &lt;em&gt;&lt;strong&gt;absolutely always&lt;/strong&gt;&lt;/em&gt; preferable over &lt;em&gt;&lt;strong&gt;absolutely any&lt;/strong&gt;&lt;/em&gt; choice that makes code easier to write.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This means that languages that achieve great terseness of code are not really delivering anything of value by this alone, (I am looking at you, Scala,) because verbosity of code is not one of the major problems that our profession is faced with; unreadable code is. This also means that certain languages whose grotesquely arcane syntax has earned them the &amp;quot;write-only language&amp;quot; designation are not to be touched with a 10 ft. pole. Perl enthusiasts can cry me a river.&lt;/p&gt;
&lt;h3 id="avoid-using-elements-of-prose-in-code"&gt;Avoid using elements of prose in code
&lt;/h3&gt;&lt;p&gt;Identifiers should be pedantic, not creative, and unless they pertain to the problem domain, they should come from the realm of engineering, not from the realm of literature. Think twice before using a term like &amp;quot;drop&amp;quot; instead of &amp;quot;delete&amp;quot;, &amp;quot;payload&amp;quot; instead of &amp;quot;content&amp;quot;, etc. because &amp;quot;drop&amp;quot; and &amp;quot;payload&amp;quot; are metaphors. Metaphor should be avoided unless it helps to express something that would otherwise require an entire sentence to express, for example &amp;quot;Factory&amp;quot; instead of &amp;quot;Object-that-creates-other-objects&amp;quot;.&lt;/p&gt;
&lt;h3 id="use-an-ide-with-a-spell-checker"&gt;Use an IDE with a spell checker
&lt;/h3&gt;&lt;p&gt;Avoid anything that fails to pass the spell check.&lt;/p&gt;
&lt;p&gt;Add the spell-checking dictionary of the IDE to source control and review any commits to it just as you review any other code.&lt;/p&gt;
&lt;p&gt;This specifically means abandoning certain old habits; all of the following are wrong:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;nrPoints; pointsNr; nPoints; pointsN; noPoints; pointsNo; lenPoints; pointsLen&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Only the following are right:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;numberOfPoints; pointCount; pointsLength&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="avoid-acronyms-and-abbreviations"&gt;Avoid acronyms and abbreviations
&lt;/h3&gt;&lt;p&gt;Use fully spelled-out words of the English language instead.&lt;/p&gt;
&lt;p&gt;Acronyms and abbreviations are cryptic for the uninitiated, and even if they are not, they make the code look unnecessarily technical. Modern IDEs have formidable auto-completion features, so fully spelling out every word does not necessarily mean that you will have to type more, but even if it did, typing is not one of the major problems that our profession is faced with; unreadable code is.&lt;/p&gt;
&lt;p&gt;This means that a huge number of abbreviations which have traditionally been staple terms in programming, should never be used, or their use should be seriously reconsidered. This includes all of the following: abs, addr, alloc, alt, app, arg, async, attr, auth, avg, bg, bat, bin, bool, buf, buff, btn, calc, cert, char, cls, clr, col, coll, cmd, com, cmp, comp, cfg, conf, config, const, ctx, ctrl, conv, coord, cos, cnt, cur, curr, db, dbg, dec, decl, def, deg, del, desc, dest, dev, diff, dim, dir, disp, div, doc, drv, dyn, env, eq, err, exe, exp, expr, ext, fac, fig, fg, fmt, frac, freq, fn, fun, func, gen, geom, hdr, hex, img, imp, impl, inc, idx, info, init, ins, inst, int, iter, lang, len, lib, lnk, max, mem, msg, mid, min, misc, mod, mul, mut, nav, net, num, obj, org, pkg, param, perf, pic, ptr, pos, pow, pwr, pred, pref, prev, priv, proc, prof, pub, rand, rnd, recv, rec, rect, ref, regex, rel, rem, rm, repo, req, res, ret, rev, sel, seq, svc, sess, sin, sln, src, spec, sqrt, std, stmt, stat, str, sub, sync, tan, tmp, temp, txt, usr, util, var, val, vec, ver, win, wiz.&lt;/p&gt;
&lt;p&gt;If a particular acronym is understood by every programmer, then it might be okay to use it in code, but if it is only understood by domain experts, then it is &lt;em&gt;not okay&lt;/em&gt;. This is because programmers often work on software for domains on which they are not experts, and even if they do eventually become domain experts, in the beginning they are not, but the beginning is when everything is difficult, so that is precisely the time that you do not want to be adding any extra difficulty to them. This means that very few acronyms are actually okay.&lt;/p&gt;
&lt;p&gt;Let me stress this to make sure it is understood: Domain Experts may protest that it is awkward to see a particular term fully spelled out in the code, because the term is so well known, that it appears as an acronym in the entirety of the literature in their field; let them find it awkward, and let them protest. Your code is not part of the literature in their field.&lt;/p&gt;
&lt;p&gt;If the choice is made to keep a certain acronym in the code, then the acronym must be turned into a word, meaning that only the first letter may be written in upper-case, while all subsequent letters must always be written in lower-case. For example, if you have decided that you are not going to replace &lt;code&gt;GUID&lt;/code&gt; with &lt;code&gt;GloballyUniqueIdentifier&lt;/code&gt;, I am totally with you, but then you must replace it with &lt;code&gt;Guid&lt;/code&gt;, so that the spell-checker can recognize it as a word and spell-check it. Otherwise, the spell-checker will consider each capital letter individually, and each individual letter passes spell-checking, so anything written in all-capitals essentially circumvents the spell-checker. If &amp;quot;Guid&amp;quot; as a word violates your English-language sensitivities, then please remember that you are writing code, not prose. There is a reason it is called code: it is specifically &lt;em&gt;not&lt;/em&gt; prose.&lt;/p&gt;
&lt;p&gt;Also beware of abbreviations that do not look like abbreviations. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The word &amp;quot;out&amp;quot; can be a word on its own, but more often than not, it is used as an abbreviation of &amp;quot;output&amp;quot;. Spell out the full word.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the methods &lt;code&gt;ToUpper()&lt;/code&gt; and &lt;code&gt;ToLower()&lt;/code&gt;, the terms &amp;quot;Upper&amp;quot; and &amp;quot;Lower&amp;quot; have no inherent meaning of their own; the proper terms that these abbreviations stand for are &amp;quot;UpperCase&amp;quot; and &amp;quot;LowerCase&amp;quot;. Use the proper terms.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="pay-attention-to-naming"&gt;Pay attention to naming
&lt;/h3&gt;&lt;p&gt;Every single concept must have the best name that it could possibly have. Not just a good name, but an excellent name. Unfortunately, finding the right name for things is hard. It is not a coincidence that naming things is &lt;em&gt;One of the Two Hard Problems in Computer Science.&lt;/em&gt; (&lt;a class="external"
href="https://martinfowler.com/bliki/TwoHardThings.html" target="_blank"
&gt;https://martinfowler.com/bliki/TwoHardThings.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Strive for a variety of names that uniquely and accurately reflect each concept that you are dealing with. A Thesaurus is an indispensable programming tool.&lt;/p&gt;
&lt;p&gt;(I once worked in a metrology environment where both the main entity of interest was called a &amp;quot;Measurement&amp;quot;, and the main thing that you could do with it was to perform a &amp;quot;Measurement&amp;quot;; that's deplorable.)&lt;/p&gt;
&lt;p&gt;If a certain domain-specific term is problematic in code, then do not use that term in code. Completely ignore the domain experts who will protest that the original term is the established term in the field and it is awkward to see it replaced with something else.&lt;/p&gt;
&lt;p&gt;(In that same metrology environment, the goal of the software was to measure and report how something differs from its ideal form; the term used in that field for this kind of difference was &amp;quot;error&amp;quot;, so the software was full of identifiers called &amp;quot;error&amp;quot; that did not stand for error as we know it in software; that's deplorable.)&lt;/p&gt;
&lt;p&gt;Avoid zero-information names; invest the necessary amount of thinking so that each name gives at least some hint as to what it is about to someone who sees it for the first time. A good rule of thumb for deciding whether a name is good is to ask yourself the following question:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Could the same name conceivably also stand for some unrelated entity in my code base?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(A co-worker of mine once created a namespace called &amp;quot;DataInfo&amp;quot;; that's deplorable.)&lt;/p&gt;
&lt;p&gt;In special cases, dare to use names that you may have never heard anyone using before. For example, if you need a Factory of Factories, why not call it &lt;em&gt;Industry&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;Read Chapter 2: &lt;em&gt;Meaningful Names&lt;/em&gt; of the book &lt;em&gt;Clean Code&lt;/em&gt; by Robert C. Martin.&lt;/p&gt;
&lt;p&gt;Also read this: &lt;a
href="https://blog2.michael.gr/post/2018-05-confucius-on-naming/"
&gt;Confucius On Naming Things&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Any code written by a programmer whose English language skills are poor should be reviewed by a programmer whose English language skills are good.&lt;/p&gt;
&lt;p&gt;When words need to be combined to form an identifier, the combination must follow general English grammar rules, except for English grammar special cases.&lt;/p&gt;
&lt;p&gt;Read this: &lt;a class="external"
href="https://softwareengineering.stackexchange.com/q/409455/41811" target="_blank"
&gt;Software Engineering Stack Exchange: Clean Code: long names instead of comments&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the following discussion when we speak of a noun or an adjective or a verb we actually mean a sequence of various parts of speech that effectively constitute a noun or an adjective or a verb. For example, &lt;code&gt;reticulated_spline&lt;/code&gt; is a noun (spline), &lt;code&gt;reticulated_before_dive&lt;/code&gt; is an adjective (reticulated), and &lt;code&gt;dive_for_moog&lt;/code&gt; is a verb (dive).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Types:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Classes:&lt;/strong&gt; The name of a class must always be a noun; it must never be an adjective or a verb; no exceptions. Also, the name of a class must always be in singular form; no exceptions. If you need to signify plurality, do not use plural! Instead, append a plurality-signifying term which is in turn a singular noun. For example, if you have a class that stands for a group of entities, do not call it 'Entities', call it 'EntityGroup' instead. (Duh!)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interfaces:&lt;/strong&gt; The name of an interface must be either an adjective, (e.g. Comparable,) or a noun, (e.g. Serializer,) no exceptions. Singular form goes without saying.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enums:&lt;/strong&gt; The name of an enum type must always be a noun in singular form, no exceptions. (E.g. WeekDay.Monday instead of WeekDays.Monday.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Variables:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Single-value:&lt;/strong&gt; The name of a single-value variable must always be a noun in singular form, unless it is of boolean type, in which case it may signify a condition, such as isEmpty.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Collection:&lt;/strong&gt; The name of a collection variable must always be a noun in plural form, no exceptions.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Functions:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pure:&lt;/strong&gt; The name of a function that returns a result without mutating anything must always be a noun unless it returns boolean, in which case it may signify a condition, such as hasChildren(). The name must be in singular form, unless a collection is returned, in which case the name must be in plural form.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Impure:&lt;/strong&gt; The name of a function that performs an operation (has side effects) must be a verb, no exceptions. If the impure function returns a result indicating success or failure, the name must begin with 'try' followed by the actual verb, for example 'tryAdd()'. If the name does not begin with &lt;code&gt;try&lt;/code&gt; then the rule is that the function will signal failure by throwing an exception.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When multiple words are combined to form an identifier, they must still make sense. As an example of what to avoid, take the &lt;code&gt;INotifyPropertyChanged&lt;/code&gt; interface of WPF. This name is deplorable because notify is a verb, not a noun or an adjective, and because an object implementing this interface is not a property-changed notification, it is an object which may issue property-changed notifications. Admittedly, it is difficult to come up with a good name to describe such objects; a decent choice might be &lt;code&gt;PropertyChangedNotificationIssuer&lt;/code&gt;, but this might be a bit too long for some people's taste. An alternative is to use a familiar term of broader scope if there is no possibility of confusion. So, another decent choice here might simply be &lt;code&gt;Mutable&lt;/code&gt;. It is true that all kinds of different classes are mutable without issuing property-changed notifications, but then again the only thing that different mutable classes could have in common simply by virtue of being mutable, so as to warrant a common interface for all of them, is issuing notifications about their mutations. The point to take home from all this is that although it is difficult to come up with good names, the application of some actual thinking should produce a name which is at least a bit better than nonsense.&lt;/p&gt;
&lt;p&gt;As mentioned earlier, special cases of the English grammar can, and should, be ignored. An example of this is the simplification of plurals: choose &amp;quot;indexes&amp;quot; instead of &amp;quot;indices&amp;quot;, &amp;quot;schemas&amp;quot; instead of &amp;quot;schemata&amp;quot;, and, even though I know this is a tough proposition for some, &amp;quot;companys&amp;quot; instead of &amp;quot;companies&amp;quot;. See &lt;a class="external"
href="https://softwareengineering.stackexchange.com/q/290951/41811" target="_blank"
&gt;Software Engineering Stack Exchange: Does it make sense to use &amp;quot;ys&amp;quot; instead of &amp;quot;ies&amp;quot; in identifiers to ease find-and-replace functionality?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Never begin a function name with the prefix 'check'. Doing so is a typical example of a developer choosing names according to fleeting notions in their head, without the slightest concern as to how these names will be understood by others. The word &lt;code&gt;check&lt;/code&gt; means nothing; a function that only checks something and then does nothing about it would serve absolutely no purpose; presumably, whatever checking the function does culminates in taking some kind of action, or returning some kind of result; this is an extremely important piece of information that the name of the function should not fail to convey; therefore, the name of the function should indicate what kind of action is performed, or what kind of result is returned.&lt;/p&gt;
&lt;h3 id="avoid-conventions-that-make-code-look-unnecessarily-technical"&gt;Avoid conventions that make code look unnecessarily technical
&lt;/h3&gt;&lt;p&gt;Code is, by definition, already quite technical; we do not need to be making it look even more technical than it already is. Abandon the abhorrent practice of prefixing static variables with &amp;quot;s_&amp;quot;, prefixing member variables with &amp;quot;m_&amp;quot;, and prefixing private member variables with &amp;quot;_&amp;quot;. Modern IDEs can be configured to provide sufficient visual clues about these things via syntax highlighting. If your IDE does not support this, throw it away and find one that does. If you are not using an IDE, then please switch to the arts and humanities.&lt;/p&gt;
&lt;h3 id="avoid-hungarian-notation"&gt;Avoid Hungarian Notation.
&lt;/h3&gt;&lt;p&gt;(&lt;a class="external"
href="https://en.wikipedia.org/wiki/Hungarian_notation" target="_blank"
&gt;https://en.wikipedia.org/wiki/Hungarian_notation&lt;/a&gt;.) For example, no matter how popular it is in the DotNet world, the practice of prefixing interface names with &lt;code&gt;I&lt;/code&gt; is ill-conceived. What also helps in order to avoid Hungarian Notation is &lt;em&gt;The Maximalistic Approach to Typing&lt;/em&gt;, where the nature of a variable is fully determined from its data type without the need for name adornments.&lt;/p&gt;
&lt;p&gt;Which brings us to the next item:&lt;/p&gt;
&lt;h3 id="use-the-type-system-to-the-fullest"&gt;Use the type system to the fullest
&lt;/h3&gt;&lt;p&gt;Avoid using general purpose data types; try as much as possible to use data types that are specific for the job. A classic example of this is the use of a &lt;code&gt;Duration&lt;/code&gt; data type instead of an &lt;code&gt;int&lt;/code&gt; number of milliseconds, but it goes a lot further than that.&lt;/p&gt;
&lt;p&gt;So, no, your height is not of type &lt;code&gt;double&lt;/code&gt;, it is of type &lt;code&gt;Length&lt;/code&gt;; your married status is not a boolean, it is an instance of &lt;code&gt;MarriedStatus&lt;/code&gt;; a customer id and a product id are not both of type &lt;code&gt;int&lt;/code&gt;; one is of type &lt;code&gt;CustomerId&lt;/code&gt;, while the other is of type &lt;code&gt;ProductId&lt;/code&gt;; and so on. I call this &lt;em&gt;&lt;strong&gt;The Maximalistic Approach To Typing&lt;/strong&gt;&lt;/em&gt;. Untyped programming language aficionados can cry me a river.&lt;/p&gt;
&lt;h3 id="avoid-defensive-programming-engage-in-offensive-programming-instead"&gt;Avoid defensive programming; engage in &lt;em&gt;offensive&lt;/em&gt; programming instead
&lt;/h3&gt;&lt;p&gt;Defensive programming is summarized by &lt;em&gt;Postel's law&lt;/em&gt;, otherwise known as the &lt;em&gt;Robustness Principle&lt;/em&gt;, which says:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Be conservative in what you do, be liberal in what you accept from others.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(See &lt;a class="external"
href="https://en.wikipedia.org/wiki/Robustness_principle" target="_blank"
&gt;https://en.wikipedia.org/wiki/Robustness_principle&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;This principle suggests that besides producing output which adheres to the spec, our software should, as much as possible, be capable of coping with input that is off-spec. In other words, it should be tolerant to error. People imagine that when software behaves like that, it is more robust.&lt;/p&gt;
&lt;p&gt;If there is one thing that I have learned in several decades of programming, both from my own code and from code written by others, it is that tolerance towards error leads to anything but bug-free software; it invariably results in chaos; and guess what chaotic software tends to be: &lt;em&gt;&lt;strong&gt;buggy.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Read this: &lt;a class="external"
href="https://trevorjim.com/postels-law-is-not-for-you" target="_blank"
&gt;http://trevorjim.com/postels-law-is-not-for-you&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;So, instead of defensive programming, I advocate &lt;em&gt;offensive&lt;/em&gt; programming, which means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Never allow any slack or leeway, require everything to be exactly as expected.&lt;/li&gt;
&lt;li&gt;Require strict adherence to the spec even if you have no use for the full precision mandated by the spec.&lt;/li&gt;
&lt;li&gt;Keep tolerances not just down to a minimum, but at &lt;em&gt;absolute zero&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Never fail silently; fail &lt;em&gt;loudly&lt;/em&gt; instead. Fail fast; fail hard; fail eagerly, and enthusiastically.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples of offensive programming:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Avoid conversion functions that return &lt;code&gt;null&lt;/code&gt; if given &lt;code&gt;null&lt;/code&gt;; always assert that the parameter is non-null. Better yet, avoid nullability altogether, or use a type system with explicit nullability, so as to restrict it via strong typing to only those places where it is meaningful. The same applies to empty strings: if an empty string is not meaningful somewhere, do not simply cope with it; explicitly and categorically disallow it.&lt;/li&gt;
&lt;li&gt;Avoid things like a &lt;code&gt;Map.put()&lt;/code&gt; method which either adds or replaces, and instead design for an &lt;code&gt;add()&lt;/code&gt; method which asserts that the item being added does not already exist, and a &lt;code&gt;replace()&lt;/code&gt; method which asserts that the item being replaced does in fact already exist.&lt;/li&gt;
&lt;li&gt;In scenarios where an add-or-replace operation seems useful to have, (and in my experience, such scenarios are exceedingly rare,) add such a function but give it a name that clearly indicates the weirdness in what it does: call it &lt;code&gt;addOrReplace()&lt;/code&gt;. (Duh!)&lt;/li&gt;
&lt;li&gt;Avoid things like a &lt;code&gt;close()&lt;/code&gt; method which is allowed to be invoked more than once with no penalty: assert that your &lt;code&gt;close()&lt;/code&gt; methods are invoked exactly once.&lt;/li&gt;
&lt;li&gt;Never use the garbage collector for cleanup; always perform explicit and deterministic clean-up at the exact moment when it is supposed to happen; the cleanup function invoked by the garbage collector should only be used for producing diagnostic messages in case we forgot to do explicit cleanup. Read this: &lt;a
href="https://blog2.michael.gr/post/2020-12-27-object-lifetime-awareness/"
&gt;Object Lifetime Awareness&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="use-inheritance-when-it-is-clearly-the-right-choice"&gt;Use inheritance when it is clearly the right choice
&lt;/h3&gt;&lt;p&gt;The advice that &lt;em&gt;composition should be favored over inheritance&lt;/em&gt; was very good advice back in the mid-1990s, because back then people were overdoing it with inheritance: the general practice was to not even consider composition unless all attempts to get things to work with inheritance failed. That practice was bad, and the fact that the predominant language at that time (C++) supported not just inheritance but actually &lt;em&gt;multiple inheritance&lt;/em&gt; made things even worse. So the advice against that practice was very much needed back then.&lt;/p&gt;
&lt;p&gt;However, the advice is still being religiously followed to this day, as if inheritance had always been a bad thing. This is leading to unnecessarily convoluted designs and much weeping, and wailing, and gnashing of teeth. Even the original advice suggested favoring one over the other, it did not prescribe the complete abolition of the other. So, today it is about time we reword the advice as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Know when to use inheritance and when to use composition.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For a variety of opinions and a lengthy discussion about this, see &lt;a class="external"
href="https://stackoverflow.com/q/49002/773113" target="_blank"
&gt;https://stackoverflow.com/q/49002/773113&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Also heed the advice by Josh Bloch to &lt;em&gt;design and document for inheritance or else prohibit it&lt;/em&gt;. (See &lt;a class="external"
href="https://blogs.oracle.com/javamagazine/post/java-inheritance-design-document" target="_blank"
&gt;https://blogs.oracle.com/javamagazine/post/java-inheritance-design-document&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id="favor-early-exits-over-deep-nesting"&gt;Favor early exits over deep nesting
&lt;/h3&gt;&lt;p&gt;This means liberal use of the &lt;code&gt;break&lt;/code&gt; and &lt;code&gt;continue&lt;/code&gt; keywords, as well as &lt;code&gt;return&lt;/code&gt; statements in the middle of a method whenever possible. The code ends up being a lot simpler this way. Yes, this directly contradicts the ancient &amp;quot;one return statement per function&amp;quot; dogma. I love contradicting ancient dogma.&lt;/p&gt;
&lt;h3 id="avoid-static-mutable-state-like-anthrax"&gt;Avoid static mutable state like anthrax
&lt;/h3&gt;&lt;p&gt;Yes, this also includes stateful singletons. The fact that it only makes logical sense to have a single instance of a certain object in your world is no reason to design that object, and your world, so that only one instance of them can ever be.&lt;/p&gt;
&lt;p&gt;You see, I guarantee to you that the need will arise in the future, unbeknownst to you today, &lt;em&gt;to multiply instantiate your world&lt;/em&gt;, along with that object in it, which you thought was one-of-a-kind.&lt;/p&gt;
&lt;p&gt;As a matter of fact, it is quite likely that you will have to do that anyway, for the purpose of testing.&lt;/p&gt;
&lt;h3 id="optimize-performance-bottlenecks-not-performance-penalties"&gt;Optimize performance bottlenecks, not performance penalties
&lt;/h3&gt;&lt;p&gt;The ages-old advice to &lt;em&gt;avoid premature optimization&lt;/em&gt; is considered common knowledge, but it is a bit vague, so it does not actually register with many folks, who will not hesitate to optimize any code construct that they consider as representing a performance penalty, under the reasoning that if it represents a performance penalty then its optimization is not premature.&lt;/p&gt;
&lt;p&gt;For this reason, I like to rephrase the advice as &amp;quot;&lt;strong&gt;Optimize performance bottlenecks, not performance penalties&lt;/strong&gt;&amp;quot; to stress the point that just because something represents a performance penalty, it does not mean that it should be optimized.&lt;/p&gt;
&lt;p&gt;You see, all code takes clock cycles to run, so every little piece of code that we write represents a performance penalty; if that was sufficient reason to optimize it, then premature optimization would be the order of the day, every day. For something to be considered worthy of optimization, it should not merely represent a performance penalty; it should be proven to represent a performance bottleneck.&lt;/p&gt;
&lt;p&gt;You do not know whether something is a bottleneck unless you run the completed software system, discover that its performance is unacceptable, and use the profiler to determine exactly where the bottlenecks are. Also, what usually happens in these cases is that you tend to find some nice and formal algorithmic optimizations to apply in just a few places, and make your software meet its performance requirements, without having to go all over the entire source code base and tweak and hack things to squeeze clock cycles here and there.&lt;/p&gt;
&lt;h3 id="put-the-tools-of-the-trade-into-use"&gt;Put the tools of the trade into use
&lt;/h3&gt;&lt;p&gt;Armies of very good developers have worked hard to build these tools, don't you dare make their efforts go in vain.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Use an IDE.&lt;/p&gt;
&lt;p&gt;Programmers who think that they are better off with their favorite text editor should be admitted to rehabilitation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use the &lt;em&gt;build&lt;/em&gt; feature of your IDE, which only compiles modified files.&lt;/p&gt;
&lt;p&gt;Programmers who habitually perform a full &lt;em&gt;rebuild&lt;/em&gt; instead of a plain build should be fired.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use your IDE for running tests.&lt;/p&gt;
&lt;p&gt;Programmers who habitually run tests via separate tools outside of the IDE should be shot.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The continuous build pipeline is your second line of defense, not your primary means of building and testing. Your IDE will always be a lot faster, and it has a built-in debugger.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use the debugger of your IDE as your first choice for troubleshooting anything, not as the last resort after all other options have been exhausted. This means that you should be using the debugger not only when there is trouble, but always, by default, so that it is ready when trouble occurs. This in turn means that when you want to fire up your creation, or to run the tests, you should never hit the &amp;quot;Run&amp;quot; key on your IDE; you should hit the &amp;quot;Debug&amp;quot; key instead. Always the &amp;quot;Debug&amp;quot; key. Only the &amp;quot;Debug&amp;quot; key. You are a programmer; act like it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Having said all that, I should also add that people who are so attached to their IDE that they program by dragging and dropping code snippets around should perhaps consider that some desktop publishing job might suit them better.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do not even think that you are done with testing unless the code coverage tool gives you sufficient reason to believe so.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Have your IDE perform code analysis, and incorporate even more code analysis in the continuous build.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="design-with-reliability-as-a-foundation-not-as-an-afterthought"&gt;Design with reliability as a foundation, not as an afterthought
&lt;/h3&gt;&lt;p&gt;For example, sharing data in a multi-threaded environment by means of traditional locking techniques (&amp;quot;synchronization&amp;quot;) is both error-prone and untestable, because you cannot test for race conditions. Note that &amp;quot;error prone&amp;quot; and &amp;quot;untestable&amp;quot; is a deadly combination; therefore, this way of sharing data should be abandoned. Instead, design for a lock-free, share-nothing approach that works by passing immutable messages, thus eliminating the very possibility of race conditions.&lt;/p&gt;
&lt;h3 id="design-with-security-as-a-foundation-not-as-an-afterthought"&gt;Design with security as a foundation, not as an afterthought
&lt;/h3&gt;&lt;p&gt;Security is not something that you can add on top of an insecure foundation, because there exist no automated tests that can detect security hazards and no amount of carefulness on behalf of programmers that is careful enough. So, what is necessary is architectural choices that eliminate entire classes of security hazards. (Do not worry, there will always be other classes of security hazards to have to worry about.)&lt;/p&gt;
&lt;p&gt;So, if a certain architectural choice is prone to security vulnerabilities, do not make that choice. An example of a vulnerability-prone architectural choice is putting application code on the web browser, otherwise known as full-stack development. Full-stack developers can cry me a river.&lt;/p&gt;
&lt;p&gt;For more on this, read: &lt;a
href="https://blog2.michael.gr/post/2021-12-full-stack-development/"
&gt;What is wrong with Full Stack Development&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="keep-the-log-clean"&gt;Keep the log clean
&lt;/h3&gt;&lt;p&gt;Do not vex your colleagues, and do not make your own life harder, with torrential info-level or debug-level spam in the log. Keep the info-level messages down to an absolute minimum, and once debugging is done, completely remove all the debug-level log statements. Utilize commit hooks that deliberately fail a commit if it contains debug-level logging statements. Regularly use the &amp;quot;blame&amp;quot; feature of the version control system to remind developers of info-level logging statements that they should remove. Never use the log for capturing metrics or any other kind of structured information; use some separate, specialized instrumentation facility for that.&lt;/p&gt;
&lt;h3 id="make-the-best-out-of-the-log"&gt;Make the best out of the log
&lt;/h3&gt;&lt;p&gt;You should at all times be able to click on a log line in the output window of the IDE and be taken to the source line that generated that log entry, and you should also at all times be able to click on any line of a logged exception stack trace and be taken to the corresponding line of source code. I am appalled by how many programming environments do not offer this as the default mode of operation under all circumstances.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the Microsoft Visual Studio world, for a line to be clickable in the output window it must start with a source pathname, followed by an opening parenthesis, a line number, a closing parenthesis, and a colon. It can optionally be prefixed with whitespace.
&lt;ul&gt;
&lt;li&gt;Fortunately, both C++ and C# support efficient means of obtaining source file name and line number information: In C++ it is the &lt;code&gt;__FILE__&lt;/code&gt; and &lt;code&gt;__LINE__&lt;/code&gt; built-in pre-processor macros, while in C# it is the &lt;code&gt;CallerFilePath&lt;/code&gt; and &lt;code&gt;CallerLineNumber&lt;/code&gt; attributes.&lt;/li&gt;
&lt;li&gt;Unfortunately, the pathnames generated by these mechanisms are absolute, meaning that they start from the drive letter and include the kitchen sink, so you might want to programmatically convert them to pathnames relative to the solution folder before logging them. Visual studio also recognizes those, though this is undocumented.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;In the Jetbrains IntellijIdea world, for a line to be clickable in the output window it needs to contain an identifier, followed by an opening parenthesis, a source filename-plus-extension, (but no path,) a colon, a line number, and a closing parenthesis.
&lt;ul&gt;
&lt;li&gt;The identifier is meant to be a package name, but Idea does not interpret it in any way, so it can be anything.&lt;/li&gt;
&lt;li&gt;Due to a long-standing bug (which JetBrains refuses to acknowledge or fix) if the word &amp;quot;at&amp;quot; appears in the log line, and if it is in any place other than immediately before the package name, then this mechanism breaks. (Note that this is all entirely undocumented.)&lt;/li&gt;
&lt;li&gt;Note that this mechanism suffers from ambiguity in the case of multiple source files with the same filename. An alternative mechanism is to include a &amp;quot;file://&amp;quot; URI in the log entry, but in order to produce such a URL you would have to figure out the path from the package name, which is doable, but not easy.&lt;/li&gt;
&lt;li&gt;Unfortunately, Java does not provide any efficient means of obtaining source file name and line number information, so one has to generate a stack trace in order to extract this information from it.&lt;/li&gt;
&lt;li&gt;Fortunately, generating a stack trace in the java world is not anywhere near as expensive as in the Microsoft world.&lt;/li&gt;
&lt;li&gt;Unfortunately, it is still unreasonably expensive. You can see this performance penalty as one more reason to keep logging to a minimum.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="take-maxims-with-a-grain-of-salt"&gt;Take maxims with a grain of salt
&lt;/h3&gt;&lt;p&gt;(Especially quantitative maxims, which offer specific numerical limits for things.)&lt;/p&gt;
&lt;p&gt;When someone says &amp;quot;no function should accept more than 4 parameters&amp;quot; or &amp;quot;no class should be longer than 250 lines&amp;quot; they are usually talking nonsense.&lt;/p&gt;
&lt;p&gt;A class should be as long as necessary to do its job, and if that is 2000 lines, so be it. I would much rather keep some ugly code confined in a single class than split it into multiple classes and thus propagate the ugliness in the design.&lt;/p&gt;
&lt;p&gt;A function should accept as many parameters as necessary to do its job, and if that is 15 parameters, so be it. I would much rather have a long constructor than a mutable object.&lt;/p&gt;
&lt;p&gt;Breaking things down to smaller units should be done because there is some actual tangible merit in doing so, not because some prophecy said so.&lt;/p&gt;
&lt;h3 id="private-static-methods-are-fine-really"&gt;Private static methods are fine. Really
&lt;/h3&gt;&lt;p&gt;An instance method has the entire object state at its disposal to read and manipulate, and this state may be altered by any other instance method, including instance methods that this method may invoke. The complexity of this is mind-boggling. A static method on the other hand is obviously not in a position to read nor alter any of the object's state, and it is unable to invoke any instance methods that would do that. By its nature, a static method has to rely exclusively on parameters, which are all clearly visible at each call site. Thus, a static method is an &lt;em&gt;&lt;strong&gt;immensely less complex&lt;/strong&gt;&lt;/em&gt; beast than an instance method. What this means is that private static methods are not the slightest bit evil as some folks believe they are, and we should have more of them.&lt;/p&gt;
&lt;p&gt;Personally, when I have a class that has both complex logic and mutable state, I tend to move the complex logic into private static methods, reducing the instance methods to doing nothing but invoking private static methods, passing instance fields to them and storing results into instance fields as necessary.&lt;/p&gt;
&lt;h3 id="do-not-fix-it-unless-there-is-a-test-for-it"&gt;Do not fix it unless there is a test for it
&lt;/h3&gt;&lt;p&gt;I do not yet have an opinion about test-driven development, but what I have found to be immensely useful, is &lt;em&gt;test-driven maintenance&lt;/em&gt;. So, when a bug is discovered, which obviously passed whatever automated tests you already had in place, do not hurry to figure out what causes it and fix it. First, write a test that tests for the bug, being completely agnostic of any theory that you might already have as to what is causing the bug. This test should initially fail; if it does not fail, then the bug is not what you think it is, so you have more research to do. If the test fails as it should, then fix the bug according to your theory as to what is causing it. If the test now passes, then your theory was correct. If not, then not only you have not fixed the bug, but you have probably broken something else which used to be fine.&lt;/p&gt;
&lt;h3 id="avoid-death-by-ten-thousand-little-methods"&gt;Avoid death by ten thousand little methods
&lt;/h3&gt;&lt;p&gt;Again and again I see code bases with multitudes of tiny methods having cryptic names, each containing just one or two lines of trivial code, aiming to ensure that not a single line of code is duplicated anywhere. The downside of this is that it increases the complexity of the call tree and therefore the amount of mental effort required to make sense out of it. A new function is worth introducing if it has a well-defined, meaningful role to play. Difficulty in coming up with a name for a function, or having many functions with names that differ only slightly and fail to readily convey the difference between them, are both good indicators that these functions have no role to play other than to avoid code duplication. Of course there is merit in reducing code duplication, but not when the code in question is trivial. And when you see the possibility to de-duplicate non-trivial code, then the well-defined, meaningful role of the function tends to be immediately obvious, as well as the appropriate name for it.&lt;/p&gt;
&lt;h3 id="make-the-best-out-of-break-on-exception"&gt;Make the best out of break-on-exception
&lt;/h3&gt;&lt;p&gt;Set up your development tooling, and use whatever runtime mechanisms are necessary, so that the debugger always stops at any statement that throws an unexpected exception.&lt;/p&gt;
&lt;p&gt;Many programmers have the bad habit of doing all their troubleshooting by examining logs and postmortem stack traces and theorizing as to what went wrong, instead of having the debugger break on exception and actually seeing what went wrong. This is extremely counter-productive.&lt;/p&gt;
&lt;p&gt;Unfortunately, exceptions are a somewhat complex topic, programming languages and their run-times behave in complex ways when exceptions are thrown, and debuggers have complex mechanisms for dealing with them, none of which helps. As if that was not enough, it is not always easy to tell when a certain exception should be expected and when it should not be expected.&lt;/p&gt;
&lt;p&gt;Thus, there exist several obstacles to accomplishing proper, usable, break-on-exception:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Our code throws and catches expected exceptions all the time, or uses external libraries that do so, internally, all the time; clearly, we do not want the debugger to stop on any of those.&lt;/li&gt;
&lt;li&gt;One might think that the solution to this problem would be to configure the debugger to ignore caught exceptions and only stop on uncaught exceptions; unfortunately, that will not work either, because quite often we have exceptions that we consider as uncaught, but technically they are caught; for example:
&lt;ul&gt;
&lt;li&gt;An external library invokes our code, and our code throws an exception, which is uncaught as far as our code is concerned, but it is caught by the external library. A typical example of this is event-driven frameworks, i.e. virtually all GUI frameworks, which invoke our code to handle events, and almost always do so from within a try-catch block. Thus, any exception thrown by our event handlers is actually a caught exception, and the debugger will not stop on it.&lt;/li&gt;
&lt;li&gt;In many languages, the &lt;code&gt;try-finally&lt;/code&gt; clause internally catches exceptions and re-throws them at the end of &lt;code&gt;finally&lt;/code&gt;, meaning that any exception thrown within the &lt;code&gt;try&lt;/code&gt; block is technically a caught exception. Thus, a debugger configured to stop on uncaught exceptions will break at the end of the &lt;code&gt;finally&lt;/code&gt; block, which is completely useless and counter-productive. The same problem is encountered with other constructs which are internally implemented using &lt;code&gt;try-finally&lt;/code&gt;, such as the synchronization clause, the automatic disposal clause, etc.&lt;/li&gt;
&lt;li&gt;To complicate matters even further, an exception which is unexpected and unhandled under normal circumstances may temporarily become expected and handled during testing. This happens when a test deliberately causes malfunction to ensure that the component-under-test detects it and responds by throwing an exception, which is then caught by the test and examined to ensure that it is the correct exception and it has been correctly filled-in; when this happens, we do not want the debugger to stop, because we do not want our tests to be interrupted by the debugger while everything is proceeding according to plan.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is a StackOverflow question and answer which simplifies things a lot: &lt;a class="external"
href="https://stackoverflow.com/q/71115356/773113" target="_blank"
&gt;https://stackoverflow.com/q/71115356/773113&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="write-code-as-if-it-will-be-reviewed-by-someone-even-if-it-never-will"&gt;Write code as if it will be reviewed by someone, even if it never will
&lt;/h3&gt;&lt;p&gt;Always try to take one more look at the code from a completely agnostic point of view, supposing that you know nothing about what it does, why it does it, how it does it. Does the code still make sense? Is everything obvious? If not, refactor it until it is as plain as daylight. If comments are necessary to explain what is going on, can the code be refactored so that the comments become unnecessary?&lt;/p&gt;
&lt;p&gt;Which brings us to the next point.&lt;/p&gt;
&lt;h3 id="avoid-writing-code-comments"&gt;Avoid writing code comments
&lt;/h3&gt;&lt;p&gt;Never add a comment in the code unless absolutely necessary. (Note that this applies to code comments, not to
public interface comments, which can be nice to have.)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The purpose of a code comment should be to alert the reader that something special is happening here, which is not obvious, and cannot be explained by any means other than written prose. This should only be necessary in exceptional situations, while the norm should be that the code is always so simple, and so self-explanatory, that no comments are necessary.&lt;/li&gt;
&lt;li&gt;An example of an exceptional situation is provenance comments, see related section.&lt;/li&gt;
&lt;li&gt;Code comments that simply state what the code does are unwarranted causes of alert, and if you repeat them enough they will force the reader to start treating your comments as noise, and may thus cause the reader to miss that rare comment which was actually important to note.
- Comments tend to be necessary when a piece of code does something unexpected, which is usually code that takes special measures to circumvent some anomalous behavior of some other code. In these cases, explaining what the code does is not even the goal; the goal is to explain &lt;em&gt;why&lt;/em&gt; it does it, and in order to explain that you have to describe the anomalous behavior, which may even necessitate listing various usage scenarios that have been tried and results that have been observed. This in turn means that comments worth writing tend to be entire multi-paragraph-long essays explaining strange and complicated situations. In my experience, one-liners are usually of no value.
- Note that when documenting code that circumvents anomalous behavior it is a good idea to assert, if possible, that the anomalous behavior is in fact still present, so that if it gets fixed in the future, you will take notice so you can remove the code that circumvents it.
- If you find yourself adding a code comment, first ask yourself whether there is anything you can do to avoid that.
&lt;ul&gt;
&lt;li&gt;Instead of adding a comment to some piece of code explaining what it does, extract that code into a separate function that has a self-explanatory name.
&lt;ul&gt;
&lt;li&gt;However, it is even better to restructure the code, if possible, so that even the explanatory name becomes unnecessary. For example, in old C code you might come across a pointer-returning function whose documentation says that the caller is responsible for freeing the pointer. This is deplorable. Do whatever it takes to avoid this; use a callback, use an allocator parameter, have the caller supply the memory, throw it all away and rewrite it in Java, anything but requiring people to read comments or else they get punished with memory leaks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Instead of adding a comment to a hard-coded value, extract that value into a constant that has a self-explanatory name.
&lt;ul&gt;
&lt;li&gt;When performing a calculation which involves a certain fixed value, it goes without saying that you will &lt;em&gt;&lt;strong&gt;not&lt;/strong&gt;&lt;/em&gt; hard-code some magic number in the calculation; instead, you will declare a constant with a nice descriptive name for that value, and use the constant in the calculation. Note that this must be done even
in fairly trivial cases, for example &lt;code&gt;const int BitsPerByte = 8;&lt;/code&gt; and can only be skipped in an exceedingly small number of special cases, for example when directly multiplying something by 2 in order to double it, or by -1 in order to negate it.
- If a comment can be coded as an assertion statement, that's all the better. Comments saying &amp;quot;x must be greater than y here&amp;quot; are retarded. Assert the darn thing, and spare us from the comment, or perhaps use a comment to explain the &lt;em&gt;why&lt;/em&gt;, but not the &lt;em&gt;what&lt;/em&gt;. The assertion takes care of the &lt;em&gt;what&lt;/em&gt;, and it does so unambiguously and definitively, because it compiles and passes the tests, which is something that no comment will ever do.
- If you modify some code, and there is a comment attached to that code, do not forget to do something about the comment: Ideally, your modifications should make the comment redundant, so you should remove it. If not, then at least make sure that the comment is still valid after the modifications. Unfortunately, programmers often leave comments unchanged while changing the code around them, thus making every single comment in the entire code base liable to devolving into being inaccurate, or even misleading, and thus constituting an instance of sabotage. This is happening because:&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Programmers treat comments as noise, and therefore do not even notice their presence. (This is why comments should be used very rarely, in exceptional situations only.)&lt;/li&gt;
&lt;li&gt;Comments are poorly written, so programmers do not understand them. When a programmer does not understand a comment, they obviously cannot modify it, but it gets even worse: they do not dare to remove it either, because they assume that it must have some special meaning to some other programmer. Thus, poorly written comments are very similar to &lt;a class="external"
href="https://en.wikipedia.org/wiki/Persistent_organic_pollutant" target="_blank"
&gt;Persistent Organic Pollutants (POPs) a.k.a. &lt;em&gt;&lt;strong&gt;forever chemicals&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt;: once created, they stay in the environment, causing harm for all eternity.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If a comment does not make sense to you, then find the author, ask them what it means, and update it accordingly. If the author is not around anymore, then ask any other experienced programmer in the shop. If they cannot tell what it means either, then trust me, this comment will never make sense to anyone, so go ahead and remove it.&lt;/p&gt;
&lt;h3 id="if-you-must-write-doc-comments-make-them-good"&gt;If you must write doc-comments, make them good
&lt;/h3&gt;&lt;p&gt;Ideally, an entity (class or method) should have a well-chosen name and a very simple and straightforward interface or prototype, so that everything is clear at a glance, and therefore no doc-comment is needed. If things are not so simple, then it may be necessary to clarify them with a doc-comment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A doc-comment must be as simple and as brief as possible.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do not try to follow templates, or if you do, then treat all template fields as optional: skip any information that is not strictly speaking necessary.&lt;/li&gt;
&lt;li&gt;Some bureaucratic documentation guidelines require the doc-comment of a function to follow a specific template which begins with a summary line, is followed by one line for each parameter, and includes one line for the return value. If your function really needs all this information to be explained in a doc comment, then your function must be doing something extremely bizarre. If your function is not doing anything bizarre, then a single summary line might suffice to explain what it does; if so, then skip the extra lines explaining each parameter, as well as the extra line explaining the return value.&lt;/li&gt;
&lt;li&gt;As an example of what to avoid, see the &lt;code&gt;IEnumerable&amp;lt;T&amp;gt;.GetEnumerator()&lt;/code&gt; method of C#/dotnet. The doc comment says:
Description: Returns an enumerator that iterates through the collection.
Returns: An enumerator that can be used to iterate through the collection.
As you can see, the documentation is repeating itself. This is wasting the time of anyone attempting to read this documentation. This is annoying. Do not do this.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A doc-comment is a public interface comment, not an implementation comment. As such, a doc-comment on an entity should explain, in the most brief and abstract terms possible, the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What task it accomplishes.&lt;/li&gt;
&lt;li&gt;What input it accepts.&lt;/li&gt;
&lt;li&gt;What output it produces.
Note that it does not need to address each one of those items separately; a doc-comment on a method which simply says that it &amp;quot;sorts a file in-place&amp;quot; explains all three items in one go.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A documentation comment should not make the slightest attempt to explain any of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;How&lt;/em&gt; the task is accomplished.&lt;/li&gt;
&lt;li&gt;Which entities are expected to invoke the entity.&lt;/li&gt;
&lt;li&gt;Which entities are invoked by the entity.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The above points are important to state because many misguided practices from the infancy of our discipline have it all wrong by stipulating that documentation comments should include preposterous things such as who invokes whom, completely missing the whole point behind the notion of &lt;em&gt;general-purpose, reusable software&lt;/em&gt; and even the fundamental notion of &lt;em&gt;abstraction&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;If you are asking &amp;quot;but shouldn't documentation describe the how?&amp;quot; the answer is no, that's what we write code for. By definition, the only authoritative source of information as to how something is done is the code that does it. As I have already explained, the code must be so simple and so easy to read that English-language prose on top of it should be bringing no added value. As a matter of fact, the presence of prose is dangerous, because quite often people modify the code without bothering to also modify the documentation, which leads to situations where the documentation is misleading.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If, after looking at the code, something is still unclear, then place a breakpoint and launch the tests; the debugger will make things pretty clear to you.&lt;/li&gt;
&lt;li&gt;If you are wondering how the code works under a case which is not covered by the tests, then fix this by adding a test for that case! (Duh!) Also note that even if there was a &amp;quot;how&amp;quot; section in the doc-comment, it probably would not have covered that special case anyway.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="always-maintain-provenance"&gt;Always maintain provenance
&lt;/h3&gt;&lt;p&gt;When you copy some code from the interwebz, always add a comment containing a link to the original source. Of course this is not necessary if the code that you copied is something fairly standard, like reversing a string; but if the code is anything but standard, (do you have any idea what it takes in Microsoft Windows to have a progress dialog shown while copying files?) then citing your sources is an absolute must.&lt;/p&gt;
&lt;p&gt;Sources can include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Examples from the official documentation (provide a link to the example page)&lt;/li&gt;
&lt;li&gt;Stack Overflow (provide a link to the answer)&lt;/li&gt;
&lt;li&gt;GitHub (provide a link to the source file(s))&lt;/li&gt;
&lt;li&gt;ChatGPT (give the exact prompt which yielded the code)&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This applies not only to code, but also to any piece of information, including individual values. Why did you choose this particular value and not some other value? Unless the value in question is a &lt;a class="external"
href="https://en.wikipedia.org/wiki/Fundamental_constant" target="_blank"
&gt;Fundamental Constant&lt;/a&gt; (e.g. &lt;code&gt;static readonly Velocity SpeedOfLight = 299792458.0&lt;/code&gt;) you should add a comment to it explaining exactly why this particular value was chosen, or where it came from. For example, if you need to use the population of Mexico City in code, then &lt;code&gt;const int MexicoCityPopulation = 9209944;&lt;/code&gt; is not enough; it must be followed by a comment saying &lt;code&gt;//2020 data from https://en.wikipedia.org/wiki/Mexico_City&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id="stick-with-utc-everywhere"&gt;Stick with UTC everywhere
&lt;/h3&gt;&lt;p&gt;Use UTC and only UTC for any purpose that involves storing, retrieving, communicating, converting, calculating, and doing really anything whatsoever with time, except for the following two cases, and only the following two cases:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Parsing a string that was entered by the user into a UTC time variable.&lt;/li&gt;
&lt;li&gt;Converting a UTC time variable to a string to be shown to the user.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;However:&lt;/strong&gt; When dealing with events that happen in the future, make sure to also store the targeted time-zone along with the UTC coordinate, because every few years various countries around the world decide to change their daylight savings policy, which means that the mapping from UTC to local time may change in the future, and you have no way of knowing that in advance.&lt;/p&gt;
&lt;h3 id="keep-technical-implementation-concerns-separate-from-application-concerns"&gt;Keep technical implementation concerns separate from application concerns
&lt;/h3&gt;&lt;p&gt;Application code should not be making assumptions about the technical details of the system, so that the technical details are free to change with minimal changes to application code, and vice versa.&lt;/p&gt;
&lt;p&gt;For example, the multi-threading regime under which a system operates (whether the system utilizes a single thread, or multiple discrete threads, or a thread-pool,) is a technical implementation concern. As such, all knowledge of how multi-threading is done should be isolated in the relatively small body of code which wires up (realizes) the system, and all application code should be capable of operating regardless of the multi-threading regime. Incidentally, this facilitates running tests under a strictly single-threaded regime, to ease debugging. Async/await aficionados can cry me a river.&lt;/p&gt;
&lt;h3 id="maximize-the-consistency-of-code-formatting"&gt;Maximize the consistency of code formatting
&lt;/h3&gt;&lt;p&gt;I would be tempted to say &amp;quot;format code with absolute consistency&amp;quot;, but I cannot, because we usually lack the tools to achieve this, so the goal is to strive to get as close as possible to achieving absolute formatting consistency.&lt;/p&gt;
&lt;p&gt;In the preface of the highly acclaimed book &amp;quot;Clean Code&amp;quot; by Robert C. Martin, the author mentions some experimental findings indicating that &amp;quot;consistent indentation style was one of the most statistically significant indicators of low bug density.&amp;quot; The author also states that &amp;quot;style distinguishes excellence from mere competence&amp;quot;, which I think is a very good observation; however, the conclusion at which the author arrives is unwarranted, because correlation does not imply causation: it is probably not the consistent indentation style that causes fewer bugs, it is the kind of mindset of programmers who strive for a consistent indentation style which also happens to be the kind of mindset that produces fewer bugs. Be the programmer who has that mindset.&lt;/p&gt;
&lt;p&gt;If you are one of those programmers who do not particularly care for consistent formatting, I know what you are thinking right now: you are thinking that you are the rare exception to the rule, and that your code is of course awesome and bug-free despite looking sloppy; well, you have every right to think in any way you like about yourself, but I hope you understand that nobody else will be particularly willing to give you the benefit of the doubt.&lt;/p&gt;
&lt;p&gt;Note that this does not mean that every programmer must be forced to follow a specific set of formatting guidelines; on the contrary, by using tools to do the formatting for us, we do not have to worry about formatting. The corollary to this is that as an employer, the only kind of code formatting that you have the right to require from programmers is that which can be achieved by means of automatic code reformatting tools that you already have in place.&lt;/p&gt;
&lt;p&gt;The point to take home from all this is that the formatting style must be specified in the highest detail possible, the tools must be painstakingly configured to reformat code according to that style, and the guidelines of how to work around limitations of the tools must be laid down and agreed upon before any work is done on a software project, no matter how much effort all of this represents.&lt;/p&gt;
&lt;h3 id="use-tight-abstractions"&gt;Use tight abstractions
&lt;/h3&gt;&lt;p&gt;In other words, avoid leaky abstractions.&lt;/p&gt;
&lt;p&gt;Joel Spolsky's &lt;a class="external"
href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/" target="_blank"
&gt;original 2002 article formulating the &lt;em&gt;Law of Leaky Abstractions&lt;/em&gt;&lt;/a&gt; stated that &amp;quot;All non-trivial abstractions, to some degree, are leaky&amp;quot;. The article focused on examples where implementation details of the underlying layer are exposed not by the interface itself, but by observing the performance characteristics of the underlying layer. For example, the interface of two-dimensional arrays is generic enough to allow us to iterate over them either row-first or column-first without having to know their internal memory layout; however, which way we choose can have drastic performance implications, due to memory cache utilization. This means that we do of course have to keep in mind the technicalities of the layer which implements the abstraction; it does not, however, mean that the interface should be compromised in any way.&lt;/p&gt;
&lt;p&gt;More often than not, in our daily jobs we have the misfortune of dealing with abstractions that are leaky at the interface level. A glaring example of this, in languages like C# and Java, is &lt;code&gt;class Object&lt;/code&gt;, whose public interface contains a hash-code function, which is entirely out-of-place and unwarranted, because it has to do with an implementation detail of hash-maps.&lt;/p&gt;
&lt;p&gt;This mishap could have been avoided in a number of different ways, for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Require the programmer to supply, upon hash-map construction, the hashing function to use.&lt;/li&gt;
&lt;li&gt;Require objects intended to be used as keys in a hash-map to implement a &lt;code&gt;Hashable&lt;/code&gt; interface which defines a hash-function.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unfortunately, neither of these approaches was chosen, either by Java or by C#, due to some misguided notion of convenience. Instead, the implementation detail of hash-maps that they need a hash function to work with has leaked into &lt;code&gt;Object&lt;/code&gt;, requiring every single class to have a hash-code method, even if the class will never be used as a key in a hash-map, and even if the class is mutable, and should therefore &lt;strong&gt;never&lt;/strong&gt; be used as a key in a hash-map.&lt;/p&gt;
&lt;p&gt;Another example is serialization frameworks that leak details about the underlying file format that they work with: every single XML or JSON serialization framework that I have come across exposes XML-specific functionality or JSON-specific functionality; therefore, it is an XML serialization framework, or a JSON serialization framework, but not a general-purpose serialization framework.&lt;/p&gt;
&lt;p&gt;A proper general-purpose serialization framework would expose no file format details in its interface, thus being replaceable with a different implementation which serializes to and from some other file format, without any changes necessary to the code that uses the framework. I have written such a framework, and I assure you it was not easy, but here is the thing: &lt;em&gt;Doing it right&lt;/em&gt; ‚Ñ¢ is never easy.&lt;/p&gt;
&lt;p&gt;Leaky abstractions are the source of untold suffering in software development, and they must be avoided at all costs. Creating air-tight abstractions is often omitted in the interest of saving time, and people make do with leaky abstractions instead, but this invariably results in orders of magnitude more time wasted over the long run in dealing with the disastrous consequences of the leaky abstractions.&lt;/p&gt;
&lt;p&gt;I would dare to propose that the term abstraction has (or ought to have) an inherent notion of absoluteness; just as one can be either pregnant or non-pregnant but not slightly pregnant or almost pregnant, so can an interface either be an abstraction or not an abstraction; it cannot be somewhere in-between. Thus, an incomplete or leaky abstraction should, for all practical purposes, be regarded as not an abstraction. (Because that's what the &lt;em&gt;almost absolute&lt;/em&gt; is: &lt;em&gt;non-absolute&lt;/em&gt;.)&lt;/p&gt;
&lt;h3 id="thoroughly-emulate-any-and-all-hardware"&gt;Thoroughly emulate any and all hardware
&lt;/h3&gt;&lt;p&gt;Hardware emulation is a special case of abstraction, where instead of abstracting software we are abstracting hardware. Incomplete hardware emulations are a curse for the same reasons that leaky abstractions are a curse. Hardware emulations must be 100% complete so that any software performing high level operations with the hardware can make use of all of the functionality of the hardware while remaining completely agnostic of whether it is connected to the real hardware or to an emulation thereof.&lt;/p&gt;
&lt;h3 id="only-use-absolute-file-system-paths"&gt;Only use absolute file-system paths
&lt;/h3&gt;&lt;p&gt;All file-system paths must be absolute. It is fine to provide the user with the convenience of entering a relative path, but the relative path must be converted to absolute immediately upon entering the system. Relative paths are based on the notion of a &amp;quot;current directory&amp;quot;, which is one of the most ill-conceived, misused, and treacherous notions in the history of programming, because it is a global mutable variable. (I hope I do not need to explain why a global mutable variable is evil, right?) Note that the &amp;quot;current directory&amp;quot; is global not only across all classes of your application, but also across all threads of your application, and, in DotNet, even global across all AppDomains of your application, which were supposed to be completely isolated. Duh!? What were they thinking?&lt;/p&gt;
&lt;h3 id="avoid-guids-also-known-as-uuids"&gt;Avoid GUIDs (also known as UUIDs)
&lt;/h3&gt;&lt;p&gt;Never use GUIDs if you can avoid them. If you must use them, then make sure they are an implementation detail and that they constitute a side-note of your design, not a predominant feature of your design. Read this: &lt;a
href="https://blog2.michael.gr/post/2017-06-on-uuids-and-guids/"
&gt;What is wrong with UUIDs and GUIDs&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="do-it-right-"&gt;Do It Right ‚Ñ¢
&lt;/h3&gt;&lt;p&gt;Avoid taking shortcuts in the name of immediate savings now but at the expense of headaches later, because the later headaches invariably end-up costing orders of magnitude more than the immediate savings. When some colleague, manager, or decision-maker suggests to &amp;quot;make it simple now, and worry about making it right later&amp;quot; they are imagining that they are being smart and they are helping optimize things, while in fact they are being a smart-ass, and they are suggesting that a technical crime be committed.&lt;/p&gt;
&lt;p&gt;An example of this, which has already been mentioned, is finding proper names for identifiers. If you want to introduce a new identifier, finding a proper name for it may require opening up the thesaurus, spending a considerable amount of time creating a list of candidate words, opening up the dictionary, looking up the exact meaning of each candidate word, applying the process of elimination, etc. So, you can save lots of time right now by skipping all this and simply calling it something meaningless, or worse yet, something inaccurate and therefore misleading. It is a fact that you will indeed experience immediate time savings right now if you do this. However, it is also a fact that the time you save now by performing this act of sabotage against yourself will invariably be paid a hundredfold later, when you and your coworkers will be wondering what on earth was meant by this meaningless name, or struggling with the realization that it is being used in the code in ways that are in conflict with its meaning.&lt;/p&gt;
&lt;p&gt;Of course, &lt;em&gt;Do It Right&lt;/em&gt; ‚Ñ¢ does not apply only to naming, it applies to everything. And when I say everything, I mean &lt;strong&gt;E V E R Y T H I N G&lt;/strong&gt;. The practice of &lt;em&gt;Do It Right&lt;/em&gt; ‚Ñ¢ must be a conditioned reflex; it must be the default, reliable, fail-safe, look-no-further choice that we always make, without spending time calculating the costs vs. savings of &lt;em&gt;Do it Right&lt;/em&gt; ‚Ñ¢, debating whether we should &lt;em&gt;Do It Right&lt;/em&gt; ‚Ñ¢ or not &lt;em&gt;Do It Right&lt;/em&gt; ‚Ñ¢, etc. The term &lt;em&gt;Do It Right&lt;/em&gt; ‚Ñ¢ contains in it the reason why we should &lt;em&gt;Do It Right&lt;/em&gt; ‚Ñ¢.&lt;/p&gt;
&lt;div class="footnotes" role="doc-endnotes"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;C.V. Driven Development&lt;/strong&gt;&lt;/em&gt;: See &lt;a class="external"
href="https://martinjeeblog.com/2015/03/11/cv-driven-development-cdd/" target="_blank"
&gt;Martin Jee's blog - CV Driven Development (CDD)&lt;/a&gt;&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink"&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description></item><item><title>What is wrong with UUIDs and GUIDs</title><link>https://blog2.michael.gr/post/2017-06-on-uuids-and-guids/</link><pubDate>Mon, 12 Jun 2017 17:47:55 +0000</pubDate><guid>https://blog2.michael.gr/post/2017-06-on-uuids-and-guids/</guid><description>&lt;h4 id="introduction"&gt;Introduction
&lt;/h4&gt;&lt;p&gt;Universally Unique Identifiers (UUIDs) otherwise known as Globally Unique Identifiers (GUIDs) are 128-bit numbers that are often used to identify information. In its canonical representation, a UUID looks like this: 2205cf3e-139c-4abc-be2d-e29b692934b0.&lt;/p&gt;
&lt;p&gt;The Wikipedia entry for Universally Unique Identifier (&lt;a class="external"
href="https://en.wikipedia.org/wiki/Universally_unique_identifier" target="_blank"
&gt;?&lt;/a&gt;) says that they are &lt;em&gt;for practical purposes unique&lt;/em&gt; and that &lt;em&gt;while the probability that a UUID will be duplicated is not zero, it is so close to zero as to be negligible.&lt;/em&gt; Wikipedia then does the math and shows that if 103 trillion UUIDs are generated, the chance of duplication among them is one in a billion.&lt;/p&gt;
&lt;p&gt;Despite the infinitesimally small chances of receiving a duplicate UUID, there exist programmers out there who are afraid of this actually happening, and who will not hesitate to suspect duplicate UUIDs as being responsible for an observed malfunction rather than first look for a bug in their code. Clearly, these folks do not understand the meaning of &lt;em&gt;infinitesimally small chance&lt;/em&gt;, so let me try to explain it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Infinitessimally small chance&lt;/em&gt; means &lt;em&gt;practically impossible to happen&lt;/em&gt;, and the &lt;em&gt;practically&lt;/em&gt; part is only mentioned for scientific correctness: practically, you can disregard the word &lt;em&gt;practically&lt;/em&gt; and consider it as simply &lt;em&gt;impossible to happen&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Great. Now, let me tell you why I hate UUIDs.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;h4 id="known-disadvantages"&gt;Known disadvantages
&lt;/h4&gt;&lt;p&gt;Disadvantages of UUIDs that are unanimously recognized are the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A UUID is 4 times larger than a regular 32-bit integer. This undeniably affects the performance and storage demands of a system. Apparently, the industry has decided that the benefits of UUIDs are so great that they are worth the sacrifice.&lt;/li&gt;
&lt;li&gt;The randomness of UUIDs is technically unsuitable in certain scenarios, for example in database clustered indexes, where the record ids must be sequential. When a UUID is needed in such applications, a special kind of UUID is used which contains a sequential part, but its uniqueness guarantees are severely limited. (Remember that one-in-a-billion chance of duplication mentioned earlier? Well, you may forget it now.)&lt;/li&gt;
&lt;li&gt;UUIDs are cumbersome to debug with, because they are unreadable, non-sequential, and non-repeatable. Debugging is a notoriously difficult process, so we do not need anything that makes it harder than it already is, but the use of UUIDs imposes an additional burden on debugging.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the paragraphs that follow I will address some of those disadvantages in greater detail, and I will also address some disadvantages that I have personally identified with UUIDs.&lt;/p&gt;
&lt;h4 id="the-entropy"&gt;The entropy
&lt;/h4&gt;&lt;p&gt;When looking at a table of columns, I find that the UUID column is always the angry column. This is because the 32 hexadecimal digits that make up a UUID have a higher concentration of entropy than anything else that I deal with during a regular working day. (It helps that IntelliJ IDEA spares me from having to see git commit hashes.) This is to say that the overwhelming majority of all the entropy that I am exposed to nowadays is due to seeing UUIDs. This was not happening in the days before the UUID; entire weeks could pass without seeing something as hopelessly nonsensical as a UUID, requiring me to coerce my brain to ignore it because &lt;em&gt;there is no sense to be made there&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The higher the entropy of the visual stimulus we are exposed to, the higher the cognitive effort required to process it, even if just to dismiss it as un-processable. This makes UUIDs very tiresome to work with.&lt;/p&gt;
&lt;h4 id="the-undebuggability"&gt;The Undebuggability
&lt;/h4&gt;&lt;p&gt;Ben Morris says in &lt;em&gt;The Problem with GUIDs&lt;/em&gt; (&lt;a class="external"
href="https://www.ben-morris.com/the-problem-with-guids/" target="_blank"
&gt;http://www.ben-morris.com/the-problem-with-guids/&lt;/a&gt;) :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This readability issue is often dismissed as mere inconvenience, but it's a real problem for anybody who has to support applications or trouble-shoot data. GUIDs are often a lazy solution selected by developers who will not have to deal with the support consequences.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you're going to replicate or combine disparate data sources then you really will need some globally unique identifiers. However, this is an implementation detail that does not have to be baked into data design. There's nothing to stop you from adding separate identifiers onto your data rows in response to replication requirements.&lt;/p&gt;
&lt;p&gt;Let me explain in a bit more detail what the problem is with troubleshooting in a system that identifies entities using UUIDs instead of regular sequentially issued integers.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;With sequentially issued integers you can take a mental note of the id of the entity that you are troubleshooting, and then see when and where it pops up. This means noting say, the number 1015, and then looking for a 1015 to appear again. With UUIDs you cannot do that, because a UUID is impossible to memorize. You literally cannot tell that the UUID that you are seeing now is the same as a UUID that you saw a few seconds earlier. Even if you write down the UUID that you are looking for, there is still considerable difficulty in visually comparing a UUID on the screen with a copy you made earlier.&lt;/li&gt;
&lt;li&gt;While you are looking for that 1015, if you see 1010, you know you are close. When you see 1020, you know you passed it. With UUIDs, you cannot do that, because they do not form a sequence. Even when UUIDs are of the special sequentially issued kind, the sequential part is hidden among random digits, making extraction difficult, and even if you detect the subset of the digits that make up the counter, it is in hexadecimal instead of decimal, so it is hard to make sense out of it.&lt;/li&gt;
&lt;li&gt;In the mean time, when the ids of some other entity increment from 2100 to 2200, you know that for every entity of the kind you are troubleshooting, 10 entities of the other kind are being generated. So, if you suddenly see a newly issued id of the other kind in the 3000 range, you know that something for some reason generated more of that kind of entity than expected. No such hint is available when using UUIDs, because they are just random numbers.&lt;/li&gt;
&lt;li&gt;Most importantly, on a subsequent test run, starting with the same initial database state, you can expect the exact same sequential ids to be issued, so you have the exact same ids to troubleshoot. Not so with UUIDs, which are entirely different from run to run.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, what it boils down to is that none of the most common lines of reasoning are applicable when troubleshooting UUIDs: you are constantly in the dark about most aspects that have to do with the identifiers of the entities that you are dealing with.&lt;/p&gt;
&lt;p&gt;Let that sink in for a moment:&lt;/p&gt;
&lt;p&gt;The identifier of an entity is what you use to identify the entity with.&lt;/p&gt;
&lt;p&gt;It is a very important piece of information.&lt;/p&gt;
&lt;p&gt;Arguably, in most scenarios, it is the most important piece of information about an entity.&lt;/p&gt;
&lt;p&gt;UUIDs invalidate all previously known methods of reasoning about identifiers.&lt;/p&gt;
&lt;p&gt;They are essentially useless to humans.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We don't want that.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As a matter of fact, let me put it in blunt terms to drive home a point:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What kind of idiot thought that this would be a good idea?&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id="the-needlessness"&gt;The Needlessness
&lt;/h4&gt;&lt;p&gt;I agree that UUIDs have certain usages, but quite often I see them being used in situations where they are not needed, or they are rather unwanted. Here is a stackoverflow question where some genius is assigning names to his threads, and he is using UUIDs as names: &lt;a class="external"
href="https://stackoverflow.com/questions/44198702/writing-a-custom-threadpool" target="_blank"
&gt;Stack Overflow - Writing a custom ThreadPool&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The only scenario where you really need UUIDs is when you have a decentralized system (consisting of &amp;quot;nodes&amp;quot;) in which all of the following conditions hold true:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You want to have no single point of failure and therefore no single node issuing unique identifiers.&lt;/li&gt;
&lt;li&gt;You have such high performance requirements that you do not want the nodes to have to coordinate with each other in order to issue unique identifiers.&lt;/li&gt;
&lt;li&gt;You are for some reason unable to issue a guaranteed unique node id to each node, so as to trivially solve the problem of unique keys by making each key consist of node id + node-local sequential number.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you do not have a situation that meets all of the above criteria, then you are only using GUIDs because you heard of some really smart and successful guys using them on some really monstrous systems, and you want to be like them.&lt;/p&gt;
&lt;p&gt;The only kind of scenario that I can think of that would actually meet the above criteria would be a system with such a large number of nodes, and such a high new node join rate, that negotiation for a unique node id for each new node would be impractical. There are probably not very many systems in existence on the planet with such requirements, which in turn means that every single one of them is a special case. There is really no point in imposing a worldwide curse on computing just because a few special cases benefit from it.&lt;/p&gt;
&lt;p&gt;If you are using a database, then you probably already have a single point of failure. So, go ahead and use an SQL SEQUENCE, which is very efficient because it caches thousands of ids at a time, and has been available in RDBMS products since the eighties, and part of the standard since SQL2003.&lt;/p&gt;
&lt;p&gt;Many people appear to be under the impression that UUIDs are necessary for replication, but that is not true. What is necessary for replication is row identifiers that are unique over all nodes that participate in the replication of a specific table. That is &amp;quot;system-wide per-table unique identifiers&amp;quot;, which not even system-unique identifiers, and certainly a far cry from &amp;quot;globally-unique&amp;quot; identifiers. A unique row identifier could be created by concatenating a unique node identifier with a node-local, table-specific, sequential row number. It is an arbitrary choice of Microsoft SQL Server to require a ROWGUIDCOL of the xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx format for merge replication, (and transactional replication with queued updating subscriptions,) and if we are to believe the documentation, this requirement can be circumvented by creating your own GUIDs instead of using Microsoft's newid() function.&lt;/p&gt;
&lt;p&gt;Another thing that is sometimes cited as a benefit of UUIDs is their alleged ability to be issued off-line. &amp;quot;Off line&amp;quot; was a condition that computing systems could suffer from in the old times. It is generally not an issue today, and the vast majority of those who cite this as a benefit of UUIDs do not really have an application at hand which really needs to be able to issue ids off-line. However, even in the extremely rare case where being &amp;quot;off-line&amp;quot; is an issue today, it can be taken care of with special handling. We really do not need to pollute everything everywhere with nonsensical entity identifiers just because some exceedingly rare special cases might benefit from them.&lt;/p&gt;
&lt;h4 id="the-paradigm-shift"&gt;The paradigm shift
&lt;/h4&gt;&lt;p&gt;When sequentially incrementing integers are used as identifiers, they represent an absolute guarantee that every identifier will be unique. When UUIDs are used, they represent an almost-absolute guarantee.&lt;/p&gt;
&lt;p&gt;Thus, UUIDs have introduced a fundamental and completely unwanted paradigm shift in programming: we have gone from systematic absolute determinism (never leaving anything to chance) to systematic non-absolute determinism (regularly leaving something to, a however minuscule, chance.)&lt;/p&gt;
&lt;p&gt;You see, that's what the almost-absolute is: non-absolute. I am not sure all these people who are so happily using UUIDs realize this. I find it sacrilegious, like picking a buffer size which is not a power of two.&lt;/p&gt;
&lt;h4 id="the-technological-compromise"&gt;The technological compromise
&lt;/h4&gt;&lt;p&gt;Furthermore, I am not sure people realize that UUIDs represent a technological compromise. Why are UUIDs only 128 bits instead of 256 bits? 256 bits would give even more guarantees of uniqueness, right? How about 512 bits to really make sure no duplicate ever gets issued in this universe and in all parallel universes that we might one day somehow come in contact with? Wouldn't that be the ultimate? Well, obviously, there will always be an even higher number of bits that will always be better, so what it boils down to is that a compromise has been made.&lt;/p&gt;
&lt;p&gt;The thing with GUIDs is that we don't want them to be huge, because then they would be wasteful, so someone had to come up with a number of bits that is small enough to not be too wasteful and yet large enough to give a reasonable guarantee against collisions. And so, 128 bits it is.&lt;/p&gt;
&lt;p&gt;However, if history has taught us anything, it is that technological compromises always seem very reasonable at the time that they are made, and invariably turn out to be unreasonable at a later point in time. There is really no difference between saying &amp;quot;128 bits should be enough for everyone&amp;quot; and saying &amp;quot;640K should be enough for everyone&amp;quot;. At the time that the decision was made to make 640K the absolute upper limit for the amount of memory that the IBM PC could be equipped with, this amount was considered so astronomically large, that nobody was expected to ever have a use for it. Similarly, in our century 128-bit UUIDs seem to be a good compromise, but with almost mathematical certainty there will be another century when this compromise will not be so good anymore.&lt;/p&gt;
&lt;h4 id="epilogue"&gt;Epilogue
&lt;/h4&gt;&lt;p&gt;I do believe that there will be a time, maybe in a couple of thousand years from now, maybe sooner, when we will be colonizing the galaxy, our population will be in the trillions, the individual devices embedded everywhere will number in the quadrillions, and every single one of those devices will be generating UUIDs at rates that are unthinkable today. When that time comes, we will inevitably start running into trouble with duplicate UUIDs popping up every once in a while in distant areas of the galaxy, and then it will be like 640k of memory all over again, two-digit-year millennium bug all over again, DLL hell all over again, all of them combined.&lt;/p&gt;
&lt;p&gt;When that time comes, I hope that we as a species still have some sufficiently low-level understanding of how our computers work, so as to be able to fix them. I fear we might not.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2017-06-on-uuids-and-guids/media/grumpy-cat-guids.jpg"
width="600"
height="400"
srcset="https://blog2.michael.gr/post/2017-06-on-uuids-and-guids/media/grumpy-cat-guids_hu_113e75b0e444c92f.jpg 480w, https://blog2.michael.gr/post/2017-06-on-uuids-and-guids/media/grumpy-cat-guids_hu_6da3ebde98bc76da.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
&gt;
&lt;/p&gt;
&lt;p&gt;This post was inspired by a Stack Overflow answer that I wrote, here:
&lt;a class="external"
href="https://stackoverflow.com/a/8642874/773113" target="_blank"
&gt;https://stackoverflow.com/a/8642874/773113&lt;/a&gt;&lt;/p&gt;</description></item><item><title>On Scripting Languages</title><link>https://blog2.michael.gr/post/2017-05-on-scripting-languages/</link><pubDate>Fri, 19 May 2017 19:46:34 +0000</pubDate><guid>https://blog2.michael.gr/post/2017-05-on-scripting-languages/</guid><description>&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2017-05-on-scripting-languages/images/pacifiers.jpg"
width="1023"
height="575"
srcset="https://blog2.michael.gr/post/2017-05-on-scripting-languages/images/pacifiers_hu_6f30f1f417e0fba0.jpg 480w, https://blog2.michael.gr/post/2017-05-on-scripting-languages/images/pacifiers_hu_ac31a6389070d9d4.jpg 1024w"
loading="lazy"
alt="Teething rings (pacifiers) found on the great interwebz."
class="gallery-image"
data-flex-grow="177"
data-flex-basis="426px"
&gt;
&lt;/p&gt;
&lt;h3 id="foreword"&gt;Foreword
&lt;/h3&gt;&lt;p&gt;Historically, the difference between scripting languages and real programming languages has been understood as the presence or absence of a compilation step. However, in recent decades the distinction has blurred; from time to time we have seen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interpreters for languages that were originally meant to be compiled.&lt;/li&gt;
&lt;li&gt;Compilers for languages that were originally meant to be interpreted.&lt;/li&gt;
&lt;li&gt;Scripting engines internally converting source code to bytecode before
interpreting it.&lt;/li&gt;
&lt;li&gt;Real languages compiling to bytecode which is then mostly interpreted and
rarely converted to machine code.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, compiled vs. interpreted does not seem to be the real differentiating factor; nonetheless, we can usually tell a scripting language when we see one. So, what is it that we see?&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;First, let us identify the three different kinds of error that can potentially occur in program code:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Syntax Error:&lt;/strong&gt; this represents a violation of fundamental rules governing the &lt;em&gt;form&lt;/em&gt; of the language; for example, in most programming languages the statement &lt;code&gt;a = ;&lt;/code&gt; is a syntax error, because something is obviously missing between the equals sign and the semicolon.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Semantic Error:&lt;/strong&gt; this represents failure to respect the &lt;em&gt;meaning&lt;/em&gt; of things; for example, in most languages the statement &lt;code&gt;a = &amp;quot;x&amp;quot; / 5;&lt;/code&gt; is syntactically correct but semantically incorrect, because dividing a string by a number does not make sense. As another example, the statement &lt;code&gt;a.increment();&lt;/code&gt; may represent a semantic error if object &lt;code&gt;a&lt;/code&gt; has no method called &lt;code&gt;increment&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Logic Error:&lt;/strong&gt; this corresponds to a mistake in our &lt;em&gt;reasoning&lt;/em&gt;. For example, the statement &lt;code&gt;circumference = radius * œÄ&lt;/code&gt; can be correct both syntactically and semantically, but it is nonetheless flawed, because this is not how you calculate a circumference given a radius; the correct formula also involves a multiplication by 2.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;From the three types of error that we have identified, the first and the last are unaffected by our choice of programming language:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Syntax error will be detected by any halfway decent IDE regardless of whether we are using a scripting language or a real programming language.&lt;/li&gt;
&lt;li&gt;Logic error is just as easy to make in any programming language, and the way we protect ourselves against it is by writing copious amounts of automated software tests.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Semantic Error is where different kinds of languages take vastly different approaches. This type of error is closely associated with the concept of data types:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The expression &lt;code&gt;&amp;quot;x&amp;quot; / 5&lt;/code&gt; is flawed because the left operand is of type string, while the right operand is of a numeric type.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The validity of the statement &lt;code&gt;a.increment()&lt;/code&gt; depends upon the type of &lt;code&gt;a&lt;/code&gt;, and whether that type defines an &lt;code&gt;increment()&lt;/code&gt; method or not.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If the programming language is strongly typed, then semantic error will always be detected during compilation, so there is never any danger of attempting to run (or ship to the customer) a program containing this kind of error; however, if the programming language is weakly typed, then all semantic error will go undetected until an attempt is made to execute code containing such error, at which point the software will severely malfunction.&lt;/p&gt;
&lt;p&gt;In light of the above, I would suggest that the actual differentiating factor between real programming and scripting languages is nothing but the presence or absence of semantic checking, in other words the use of strong vs. weak typing.&lt;/p&gt;
&lt;p&gt;TypeScript is the odd exception to the rule, and this is to be expected, because the impetus for the creation of TypeScript was vastly different from that of other scripting languages, which tend to be one-man efforts, and usually come into existence as nothing more than toy projects. In contrast, TypeScript was the result of a deliberate group effort backed by a big company (Microsoft) starting with the realization that JavaScript is unfortunately here to stay, and setting out specifically to correct one of its major deficiencies, namely the lack of strong typing.&lt;/p&gt;
&lt;p&gt;The trend of real programming languages to be compiled and of scripting languages to be interpreted can be explained &lt;em&gt;in full&lt;/em&gt; as a consequence of the primary choice of strong vs. weak typing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If a language is strongly typed, then a compilation step is very useful to
have, because it will unfailingly locate all errors that are detectable via
static semantic analysis before attempting to run.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If a language is weakly typed, then semantic errors are undetectable, so
there is no need to parse code in advance. A compilation step would only
reveal syntactic errors, which can also be detected by any halfway decent
IDE.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, allowing for the exception of TypeScript, this leaves us with the following soft rule:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Real languages are strongly typed, employ semantic checking, and are therefore usually compiled.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Scripting languages are weakly typed, lack semantic checking, and are therefore usually interpreted.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And yet, many people like scripting languages, and write lots of code in them, supposedly because they are &amp;quot;easier&amp;quot;. This brings to mind the famous quote by Edsger W. Dijkstra:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;{...} some people found error messages they couldn't ignore more annoying than wrong results, and, when judging the relative merits of programming languages, some still seem to equate &amp;quot;the ease of programming&amp;quot; with the ease of making undetected mistakes.&lt;/p&gt;
&lt;p&gt;(Edsger W. Dijkstra, &lt;em&gt;&lt;a class="external"
href="https://www.cs.utexas.edu/users/EWD/transcriptions/EWD06xx/EWD667.html" target="_blank"
&gt;On the foolishness of &amp;quot;natural language programming&amp;quot;&lt;/a&gt;.&lt;/em&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note that the above quote is from a paper about Natural Language Programming (NLP) but the particular passage containing the quote pertains to programming languages in general. Dijkstra wrote against NLP back in the 1980s because at that time it was being considered by some fools as a viable prospect; luckily, it failed to catch on, (or &lt;em&gt;naturally&lt;/em&gt;, if you would permit the pun,) but little did ol' Edsger know that in the decades that would follow his nightmares would come true, because scripting languages &lt;em&gt;did&lt;/em&gt; catch on. Apparently, people &lt;em&gt;love&lt;/em&gt; making undetected mistakes.&lt;/p&gt;
&lt;h3 id="arguments-in-favor-of-scripting-languages"&gt;Arguments in favor of scripting languages
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Argument:&lt;/strong&gt; It is easy to write code in it; look, the &amp;quot;hello, world!&amp;quot; program is a one-liner.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rebuttal:&lt;/strong&gt; What this means is that this scripting language is a very good choice, possibly even the ideal choice, for writing the &amp;quot;hello, world!&amp;quot; program.&lt;/p&gt;
&lt;p&gt;The ease with which you may write &amp;quot;hello, world!&amp;quot; is no indication whatsoever about the ease with which a non-trivial system may be collaboratively developed, tested, debugged, maintained, and extended.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Argument:&lt;/strong&gt; No, I mean it is really terse. There are many things besides &amp;quot;hello, world!&amp;quot; that I can write in one line.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rebuttal:&lt;/strong&gt; Sure, you can write them in one line; but can you read them?&lt;/p&gt;
&lt;p&gt;One of the most important aspects of code is readability, (second only to correctness,) but terse code is not necessarily easy to read; if that was the case, then Perl would be the most readable language ever, but instead it enjoys the dubious distinction of being the least readable among all programming languages in general use.&lt;/p&gt;
&lt;p&gt;Terseness usually represents a tradeoff between verbosity and understandability: the more terse the code, the less of it you have to read, but also the harder it is to untangle its complexity. Thus, it is debatable whether terseness correlates with readability. Terseness appears to be the modern trend, so as real programming languages keep evolving they are also receiving features that make them more and more terse, for example tuples, lambdas, the fluent style of invocations, etc. So, terseness is not the exclusive domain of scripting languages, and to the extent that scripting languages go further in this regard it is debatable whether it is an advantage or a disadvantage.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Argument:&lt;/strong&gt; There are lots of libraries for it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rebuttal:&lt;/strong&gt; Seriously? There are more libraries for your scripting language than there are for Java?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Argument:&lt;/strong&gt; I don't have to compile it; I just write my code and run it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rebuttal:&lt;/strong&gt; I also just write my code and run it. When I hit the &amp;quot;launch&amp;quot; button, my IDE compiles my code in the blink of an eye and runs it. The difference between you and me is that if I have made any semantic mistakes in my code, I will be told so before wasting my time trying to run it. But what am I saying, being told that there are semantic mistakes in your code probably counts as a disadvantage for you, right?&lt;/p&gt;
&lt;p&gt;The ability to just write your code and run it without any semantic checking is causing real harm in scripting languages because it prevents them from evolving. This is, for example, a reason why Python version 2.x is still enjoying widespread use despite the language having moved on to version 3.x by now: people are afraid to make the transition to version 3.x in existing projects, even though it is mostly backwards compatible with version 2.x, because it is not 100% compatible, and lack of semantic checking means that there is no way of knowing which lines of code will break unless these lines get executed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Argument:&lt;/strong&gt; I can modify my program as it runs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rebuttal:&lt;/strong&gt; I can also modify my program as it runs; the ability to do this is available in most real programming languages, and it is called &amp;quot;edit and continue&amp;quot; or &amp;quot;hot reload&amp;quot; depending on the language; look it up.&lt;/p&gt;
&lt;p&gt;Modification of running code is not always applicable in real programming languages, and it does not always work, but then again nor does it always work when you modify running code in a scripting language, because usually, you already have data structures in memory that were created by the code before it was modified. In real programming languages, you are prevented from making edits to running code that would seriously foul things up; in scripting languages, you are allowed to do whatever you please, and the catastrophic consequences of doing so are your own problem.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Argument:&lt;/strong&gt; I do not like to have to declare the type of every single variable because it is a pain.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rebuttal:&lt;/strong&gt; This is akin to arguing against seat belts because putting them on and taking them off is a pain. Do you have any idea of what kind of pain you are looking at if you get in a traffic accident without a seat belt?&lt;/p&gt;
&lt;p&gt;Furthermore, the ability to not have to declare the type of every single variable is not the exclusive privilege of scripting languages, because in recent years type inference has been gaining ground in real programming languages, allowing us to omit declaring the type of many of the variables that we use. The difference is that in real programming languages this is done right, by means of type inference instead of type ostrichism:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Type inference is deterministic extra work that the compiler does for us,
and it relies on having already assigned specific types to other variables,
so that we do not have to repeat things that are already known to, or can be
inferred by, the compiler.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Type ostrichism is scripting language programmers preferring to not see
types and to not deal with types, as if that will make the types go away.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It might be worth taking a look at PEP 483 (&lt;a class="external"
href="https://peps.python.org/pep-0483/" target="_blank"
&gt;https://peps.python.org/pep-0483/&lt;/a&gt;) where the people responsible for the advancement of Python are acknowledging that behind the scenes every variable is of course of a specific type, and discussing the potential benefits of adding a type annotation system to the language which will allow programmers to make their intentions about types explicit, so as to be able to at least partially, and at least as an afterthought, enjoy some of the benefits of strong typing. I quote:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;These annotations can be used to avoid many kind of bugs, for documentation purposes, or maybe even to increase speed of program execution.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Argument:&lt;/strong&gt; I am not worried about errors, because I use testing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rebuttal:&lt;/strong&gt; Oh really? Are your tests achieving even a mere 60% code coverage as we speak? And supposing that they do, how do you feel about the fact that in the remaining 40%, every single line is liable to break due to reasons as trivial and yet as common as a typo?&lt;/p&gt;
&lt;p&gt;Testing is an indispensable quality assurance mechanism for software, but it does not, in and by itself, guarantee correctness. You can easily forget to test something, and you can easily test &amp;quot;around&amp;quot; a bug, essentially creating tests that pretty much require the bug to be in place in order to pass. Despite these deficiencies, testing is still very important, but it is nothing more than a weapon in our arsenal against bugs. This arsenal also happens to include another weapon, which is closer to the forefront in the battle against bugs, and it is 100% objective, and &lt;em&gt;definitive&lt;/em&gt;. This weapon is called &lt;em&gt;strong typing&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Argument:&lt;/strong&gt; It has lots and lots of built-in features.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rebuttal:&lt;/strong&gt; Sure, and that's why scripting languages are not entirely useless. If the only thing that matters is to accomplish a certain highly self-contained goal of severely limited scope in as little time as possible, then please, by all means, do go ahead and use your favorite scripting language with its awesome built-in features. However, if the project is bound to take a life of its own, you are far better off investing a couple of minutes to create a project in a real programming language, and to include the external libraries that will give you any extra features that you might need.&lt;/p&gt;
&lt;p&gt;Built-in features do not only come with benefits; in contrast to libraries, they are much more difficult to evolve, because even a minute change in them may break existing code, resulting in people being reluctant to migrate to the latest version of the language. (Take the Python 2.x vs. 3.x conundrum for example.)&lt;/p&gt;
&lt;p&gt;Furthermore, built-in features usually have to be supported forever, even after better alternatives have been invented, or after they simply go out of style and fall out of grace, so over time scripting languages tend to gather lots of unnecessary baggage. We have tried feature-bloated programming languages before, (with ADA for example,) and the consensus is that they are not the way to go.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Argument:&lt;/strong&gt; But really, it is so much easier! Look here, in one statement I obtain a list and assign its elements to individual variables!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rebuttal:&lt;/strong&gt; That's great, I bet this has slashed your time-to-market by half. What happens if the number of elements in the list differs from the number of variables that you decompose it into? I bet there is no error, because you do not like being bothered with errors, right?&lt;/p&gt;
&lt;p&gt;In any case, my compiled language of choice has its own unique, arcane syntax quirks that I could, if I wanted to, claim that they make things so much easier for me.&lt;/p&gt;
&lt;p&gt;Some of them are not even that arcane; for example, instead of using clunky annotations to hint to the IDE the types of my variables, so that it can then provide me with some rudimentary type checking, I get to simply declare the type of each variable as part of the actual syntax of the language! Imagine that!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Argument:&lt;/strong&gt; I like dynamic typing. It gives me freedom.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rebuttal:&lt;/strong&gt; Yes, freedom to shoot yourself in the foot. Also please note that there is no such thing as &amp;quot;dynamic&amp;quot; typing; this term is just a euphemism invented by scripting language aficionados to down-play the detrimental nature of this practice. The proper term is &lt;em&gt;&lt;strong&gt;weak&lt;/strong&gt;&lt;/em&gt; typing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Argument:&lt;/strong&gt; I do not need type safety. I am better off without it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rebuttal:&lt;/strong&gt; Right. So, you are the technological equivalent of an anti-vaxxer. (Credit: &lt;a class="external"
href="https://danluu.com/empirical-pl/" target="_blank"
&gt;danluu&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Argument:&lt;/strong&gt; I do not have to use an IDE, I can just use my favorite text editor.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rebuttal:&lt;/strong&gt; Oh sure. You are also the technological equivalent of an Amish farmer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Argument:&lt;/strong&gt; My scripting language is trendy. It is hip.&lt;/p&gt;
&lt;p&gt;No contest here. I can't argue with hipsters.&lt;/p&gt;
&lt;h3 id="the-problems-with-scripting-languages"&gt;The problems with scripting languages
&lt;/h3&gt;&lt;h4 id="the-nonsense"&gt;The nonsense
&lt;/h4&gt;&lt;p&gt;I don't need to say much here, just watch the legendary &amp;quot;Wat&amp;quot; video by Gary Bernhardt from CodeMash 2012, it is only 4 minutes long:&lt;/p&gt;
&lt;video width="97%" poster="https://www.destroyallsoftware.com/assets/posters/talks/wat.poster-4f5425901c10ffeaceb61f82e25dc40b9212aadf078cead0dc6ffe40696e2bec.png" preload="none"&gt;
&lt;source src="https://destroyallsoftware-talks.s3.amazonaws.com/wat.mp4?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=AKIAIKRVCECXBC4ZGHIQ%2F20241128%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20241128T124514Z&amp;amp;X-Amz-Expires=14400&amp;amp;X-Amz-SignedHeaders=host&amp;amp;X-Amz-Signature=866f87a9e2a988029db034ad51f846818c5a2e4415da80559bb334e602fd6bad" /&gt;
&lt;track label="English" kind="captions" srclang="en" src="https://blog2.michael.gr/captions/talks/wat.vtt"&gt;&lt;/track&gt;
&lt;/video&gt;
&lt;p&gt;Source: &lt;a class="external"
href="https://www.destroyallsoftware.com/talks/wat" target="_blank"
&gt;https://www.destroyallsoftware.com/talks/wat&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The reason for all this nonsense is that all these languages are hacks.&lt;/p&gt;
&lt;p&gt;When the foundation that you are working on is a hack, then either anything you will build on top of it will in turn be a hack, or you are going to be putting an enormous effort to circumvent the hackiness of the foundation and build something reasonable over it. Why handicap yourself?&lt;/p&gt;
&lt;h4 id="the-errors"&gt;The errors
&lt;/h4&gt;&lt;p&gt;Lack of semantic checking means that the mistakes that will inevitably be made will not be caught by a compilation step. Therefore, lack of semantic checking necessarily means that there will be more errors.&lt;/p&gt;
&lt;p&gt;It is an established fact that a certain percentage of errors will always pass testing and make it to production, which in turn inescapably means that there will be a somewhat increased number of bugs in production.&lt;/p&gt;
&lt;p&gt;This alone is enough to classify scripting languages as unsuitable for anything but tinkering, and the debate should be over right there.&lt;/p&gt;
&lt;h4 id="the-crippled-ide"&gt;The crippled IDE
&lt;/h4&gt;&lt;p&gt;Lack of semantic checking means that your IDE cannot provide you with many useful features that you get with strongly typed languages. Specifically, you either have limited functionality, or you do not have at all, some or all of the following features:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Context-sensitive argument auto-completion.&lt;/strong&gt; Since any parameter to any function can be of any type, the IDE usually has no clue as to which of the variables in scope may be passed to a certain parameter of a certain function. Therefore, it has to suggest everything that happens to be in scope. Most of these suggestions are preposterous, some are even treacherous.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Member Auto-completion.&lt;/strong&gt; Since a variable does not have a specific type, the IDE usually has no clue as to what member fields and functions are exposed by that variable. Therefore, either it cannot give any suggestions, or it has to suggest every single member of every single known type and the kitchen sink.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Listing all usages of a type.&lt;/strong&gt; Since any variable can be of any type, the IDE usually has no clue as to where a given type is used, or if it is used at all. Contrast this with strongly typed languages where the IDE can very accurately list all usages of any given type and even provide you with visual clues about unused types.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Type sensitive search.&lt;/strong&gt; If you have multiple different types where each one of them contains, say, a &lt;code&gt;Name&lt;/code&gt; member, you cannot search for all references of the &lt;code&gt;Name&lt;/code&gt; member of only one of those types. You have to use text search, which will yield all irrelevant synonyms in the results. This can be okay in tiny projects, but it very quickly becomes non-viable as the project size increases.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Refactoring.&lt;/strong&gt; When the IDE has no knowledge of the semantics of your code, it is incapable of performing various useful refactoring operations on it. IDEs that nonetheless offer some limited set of refactoring features on untyped languages are actually faking it; they should not be calling it refactoring, they should be calling it &lt;em&gt;Cunning Search and Replace&lt;/em&gt;. Needless to say, it does not always work as intended, and it does sometimes severely mess up the code. (When this happens, it is called &lt;em&gt;&lt;a class="external"
href="https://www.catb.org/jargon/html/S/search-and-destroy-mode.html" target="_blank"
&gt;Search and Destroy&lt;/a&gt;.&lt;/em&gt;) Furthermore, since there is no compiler, you have no way of knowing that a line of code has been messed up until that line of code gets executed, which is something that may happen very rarely for some lines of code.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id="that-little-performance-issue"&gt;That little performance issue
&lt;/h4&gt;&lt;p&gt;Performance is generally not an issue for scripting languages, because they tend to be used in situations where performance is not required.&lt;/p&gt;
&lt;p&gt;(There are of course some situations where people opt to use a scripting language despite the fact that performance matters, and in those situations people do in fact suffer the consequences of poor performance, take web servers written in node.js for example.)&lt;/p&gt;
&lt;p&gt;In today's world where the majority of personal computers are running on precious battery power, it can be argued that even the tiniest bit of performance matters, but we can let that one slide, since battery technology is constantly improving.&lt;/p&gt;
&lt;p&gt;In cases where performance matters but the task at hand is well-defined and relatively isolated, performance is again not an issue for scripting languages because external libraries tend to be quickly developed to handle those tasks. (These external libraries are written in guess what: &lt;em&gt;real&lt;/em&gt; programming languages.)&lt;/p&gt;
&lt;p&gt;Having explained that performance is usually not an issue, let us also quickly mention before moving on that on computationally expensive tasks, such as iterating over all pixels of an image to manipulate each one of them, and assuming a competent programmer in each language, the following statements hold true:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;there is no way that a scripting language will perform as well as Java, just as:&lt;/li&gt;
&lt;li&gt;there is no way that Java will perform as well as C++, just as:&lt;/li&gt;
&lt;li&gt;there is no way that C++ will perform as well as Assembly.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Stop arguing about this.&lt;/p&gt;
&lt;h4 id="the-horrendous-syntax"&gt;The horrendous syntax
&lt;/h4&gt;&lt;p&gt;Most scripting languages suffer from a severe case of capriciously arcane and miserably grotesque syntax. No, beauty is not in the eye of the beholder, and there is only a certain extent up to which aesthetics are subjective.&lt;/p&gt;
&lt;p&gt;The syntax of scripting languages tends to suffer due to various reasons, the most common being:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Their priorities are all wrong to begin with.&lt;/li&gt;
&lt;li&gt;They were hastily hacked together in a very short amount of time.&lt;/li&gt;
&lt;li&gt;Plain incompetence on behalf of their creators.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Scripting languages that have their priorities wrong are, for example, all the shell scripting languages. These languages aim to make strings (filenames) look and feel as if they are identifiers, so that you can type commands without having to enclose them in quotes, as if the convenience of not having to use quotes was the most important thing ever. If all we want to do in a shell script is to list a sequence of commands to execute, then this convenience is perhaps all we care for, but the moment we try to use any actual programming construct, like variables and flow control statements, what we have in our hands is a string-escaping nightmare of epic proportions.&lt;/p&gt;
&lt;p&gt;Obligatory XKCD comic:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://blog2.michael.gr/post/2017-05-on-scripting-languages/images/xkcd-backslash.png"
width="571"
height="207"
srcset="https://blog2.michael.gr/post/2017-05-on-scripting-languages/images/xkcd-backslash_hu_a3b55ba8a827aa03.png 480w, https://blog2.michael.gr/post/2017-05-on-scripting-languages/images/xkcd-backslash_hu_1eec207eb5351c55.png 1024w"
loading="lazy"
alt="Backslashes"
class="gallery-image"
data-flex-grow="275"
data-flex-basis="662px"
&gt;
&lt;/p&gt;
&lt;p&gt;(Source: &amp;quot;Backslashes&amp;quot; &lt;a class="external"
href="https://www.xkcd.com/1638/" target="_blank"
&gt;https://www.xkcd.com/1638/&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;This totally ill-conceived prioritization extends to other scripting languages that try to pull similar tricks, for example YAML, where:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For the sake of convenience, tokens like &lt;code&gt;yes&lt;/code&gt; and &lt;code&gt;no&lt;/code&gt; are (case-insensitively) recognized as Boolean literals besides &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;false&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Also for the sake of convenience, strings &lt;em&gt;do not have to&lt;/em&gt; be enclosed in quotes
...which famously leads to the infamous &lt;a class="external"
href="https://langdev.stackexchange.com/questions/1123/what-design-trade-offs-led-to-the-norway-problem-in-yaml-and-when-are-they-wo" target="_blank"
&gt;Norway Problem&lt;/a&gt;, where the two-letter country code for Norway is interpreted as the Boolean value &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A scripting language that owes its bad syntax to being hastily hacked together is JavaScript. Brendan Eich, its creator, has admitted that JavaScript was developed within a couple of weeks, and that the language was not meant for anything but short isolated snippets of code. He is honest enough to speak of his own creation in derogatory terms, and to accept blame. (See &lt;a class="external"
href="https://www.youtube.com/watch?v=zlcnOr81lPc" target="_blank"
&gt;TEDxVienna 2016&lt;/a&gt;, opening statement, &amp;quot;Hello, I am to blame for JavaScript&amp;quot;.) Also, pretty much anyone deeply involved with JavaScript will admit that it has serious problems. One of the most highly acclaimed books on the language is &lt;em&gt;JavaScript: The Good Parts&lt;/em&gt;, authored by Douglas Crockford and published by O'Reilly; you can take the title of the book as a hint.&lt;/p&gt;
&lt;p&gt;A scripting language that owes its horrific syntax to lack of competence is PHP. Its creator, Rasmus Lerdorf, is quoted &lt;a class="external"
href="https://en.wikipedia.org/wiki/PHP#Early_history" target="_blank"
&gt;on the Wikipedia article about PHP&lt;/a&gt; as saying &amp;quot;I don't know how to stop it, there was never any intent to write a programming language {...} I have absolutely no idea how to write a programming language, I just kept adding the next logical step on the way.&amp;quot;&lt;/p&gt;
&lt;p&gt;So, from the above it should be obvious that most scripting languages are little toy projects that were created by individuals who simply wanted to prove that they could build something like that, without actually intending it to be used outside of their own workbench.&lt;/p&gt;
&lt;h4 id="the-cheapness"&gt;The cheapness
&lt;/h4&gt;&lt;p&gt;The lack of semantic checking in scripting languages is usually not a deliberate design choice, but instead a consequence of the very limited effort that has gone into creating them. In many cases the creators of scripting languages would not know how to add semantic checking to the language even if they wanted to. In all cases, the amount of work required to add semantic checking would have been several orders of magnitude greater than the total amount of work that went into the creation of the language in the first place.&lt;/p&gt;
&lt;p&gt;In this sense, the comparison between scripting languages and real programming languages is a lot like comparing children's tinker toy tools with tools for professionals: sure, a plastic screwdriver is inexpensive, lightweight and easy to use, but try screwing anything but plastic screws with it.&lt;/p&gt;
&lt;p&gt;(I was going to also add &amp;quot;you cannot hurt yourself with it&amp;quot;, but this analogy does not transfer to programming: you can very easily hurt yourself with a scripting language.)&lt;/p&gt;
&lt;h3 id="what-scripting-languages-are-good-for"&gt;What scripting languages are good for
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Scripting languages used to be an easy way to write cross-platform software. This does not hold true anymore, since most major real programming languages are pretty much cross-platform nowadays.&lt;/li&gt;
&lt;li&gt;Scripting languages are useful when embedded within applications, (applications written in &lt;em&gt;real&lt;/em&gt; programming languages,) as evaluators of user-supplied expressions. (E.g. spreadsheet cell formulas.)&lt;/li&gt;
&lt;li&gt;Scripting languages are useful when shortening the time from the moment you fire up the code editor to the moment you first run your program is more important than everything else. By &amp;quot;everything else&amp;quot; we really mean everything: understandability, maintainability, performance, even correctness.&lt;/li&gt;
&lt;li&gt;Scripting languages are useful when the program to be written is so trivial, and its expected lifetime is so short, that it is hardly worth the effort of creating a new folder with a new project file in it. The corollary to this is that if it is worth creating a project for it, then it is worth using a real programming language.&lt;/li&gt;
&lt;li&gt;Scripting languages are useful when the code to be written is so small and simple that bugs can be detected by simply skimming through the code. The corollary to this is that if the program is to be even slightly complex, it should be written in a real programming language. (Adding insult to injury, many scripting languages tend to have such a cryptic write-only syntax that it is very hard to grasp what any piece of code does, let alone skim through it and vouch for it being bug-free.)&lt;/li&gt;
&lt;li&gt;The most important thing about scripting languages (and the main reason why they have become so wildly popular in recent years) is that they are useful in getting non-programmers into programming as quickly as possible.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Most of us programmers have had a friend, who was not a programmer, and who one day asked us how to get into programming. The thought process should be familiar: you think about it for a moment, you start making a mental list of things they would need in order to get started with a real programming language, and you quickly change your mind and suggest that they try Python, because this answer stands some chance of fitting within our friend's attention span. However, the truth of the matter is that this recommendation will only save our friend from maybe a few hours of preparatory work, and it would be a crime if it condemns them to thousands of hours wasted over the course of a several year long career due to the use of an inferior programming language. This brings us to the following realization:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Scripting languages are a lot like teething rings (pacifiers):&lt;/p&gt;
&lt;p&gt;It is okay to start with one; you must get rid of it as soon as you grow some teeth.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="conclusion"&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;The fact that some scripting languages catch on and spread like wildfire simply shows how eager the industry is to adopt any contemptible piece of nonsense without any critical thinking whatsoever, as long as it helps optimize some short-sighted concern, such as how to get non-programmers into programming as quickly as possible. It is a truly deplorable situation that kids nowadays learn JavaScript as their first programming language due to it being so accessible to them: all you need is a web browser, and one day instead of F11 for full-screen you accidentally hit F12 which opens up the developer tools, and you realize that you have an entire integrated development environment for JavaScript sitting right there, ready to use. The availability of JavaScript to small children is frightening.&lt;/p&gt;
&lt;p&gt;Usually, once a language becomes extremely popular, tools are created to lessen the impact of its deficiencies. Thanks to the herculean efforts of teams that develop scripting engines, and through all kinds of sorcery being done under the hood in these engines, the most popular scripting languages are considerably faster today than they used to be. However, the sorcery is not always applicable, even when it is applicable it is imperfect, and besides, it incurs a penalty of its own, so scripting languages will never match the performance of real programming languages. Also, modern IDEs have evolved to provide some resemblance of semantic checking in some scripting languages, but since this checking has been added as an afterthought, it is always partial, unreliable, hacky, and generally an uphill battle.&lt;/p&gt;
&lt;p&gt;So, you might ask, what about the hundreds of thousands of successful projects written in scripting languages? Are they all junk? And what about the hundreds of thousands of programmers all over the world who are making extensive use of scripting languages every day and are happy with them? Are they all misguided? Can't they see all these problems? Are they all ensnared in a monstrous collective delusion?&lt;/p&gt;
&lt;p&gt;Yep, that's exactly it. You took the words from my mouth.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center"&gt;&lt;img src="https://blog2.michael.gr/post/2017-05-on-scripting-languages/images/grumpy-cat-scripting-languages.jpg"
width="600"
height="400"
srcset="https://blog2.michael.gr/post/2017-05-on-scripting-languages/images/grumpy-cat-scripting-languages_hu_5be306c65a008b9c.jpg 480w, https://blog2.michael.gr/post/2017-05-on-scripting-languages/images/grumpy-cat-scripting-languages_hu_8081d0eb266ea027.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center"&gt;mandatory grumpy cat meme: &amp;quot;Scripting Languages - I Hate Them.&amp;quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Also read: &lt;a
href="https://blog2.michael.gr/post/2018-01-tablecloth/"
&gt;Tablecloth&lt;/a&gt; (A high-tech, sci-fi horror short-story)&lt;/p&gt;
&lt;p&gt;Note: This is a draft. It may contain inaccuracies or mistakes. There are bound to be corrections after I receive some feedback.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Scratch&lt;/p&gt;
&lt;p&gt;See:&lt;/p&gt;
&lt;p&gt;&lt;a class="external"
href="http://stackoverflow.com/questions/397418/when-to-use-a-scripting-language" target="_blank"
&gt;http://stackoverflow.com/questions/397418/when-to-use-a-scripting-language&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;From &lt;a class="external"
href="http://wiki.c2.com/?SeriousVersusScriptingLanguages" target="_blank"
&gt;http://wiki.c2.com/?SeriousVersusScriptingLanguages&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Scripting Languages emphasize quickly writing one-off programs&lt;/p&gt;
&lt;p&gt;Serious languages emphasize writing long-lived, maintainable, fast-running programs.&lt;/p&gt;
&lt;p&gt;light-duty &amp;quot;gluing&amp;quot; of components and languages.&lt;/p&gt;
&lt;p&gt;From &lt;a class="external"
href="https://danluu.com/empirical-pl/" target="_blank"
&gt;https://danluu.com/empirical-pl/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&amp;quot;I think programmers who doubt that type systems help are basically the tech equivalent of an anti-vaxxer&amp;quot;&lt;/p&gt;
&lt;p&gt;The effect isn't quantifiable by a controlled experiment.&lt;/p&gt;
&lt;p&gt;Misinformation people want to believe spreads faster than information people don't want to believe.&lt;/p&gt;
&lt;p&gt;&lt;a class="external"
href="https://stackoverflow.blog/2023/01/19/adding-structure-to-dynamic-languages" target="_blank"
&gt;The Stack Overflow Blog: Minimizing the downsides of dynamic programming languages&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Mandatory disposal vs. the 'Dispose-disposing' abomination</title><link>https://blog2.michael.gr/post/2015-03-on-dispose-bool-disposing-abomination/</link><pubDate>Fri, 20 Mar 2015 09:54:20 +0000</pubDate><guid>https://blog2.michael.gr/post/2015-03-on-dispose-bool-disposing-abomination/</guid><description>&lt;p&gt;This article started as a &lt;a class="external"
href="https://programmers.stackexchange.com/a/276792/41811" target="_blank"
&gt;stackoverflow answer&lt;/a&gt;, and then I copied it over here to expand on it.&lt;/p&gt;
&lt;p&gt;For a discussion of the same issue but in java-oriented terms, see this Stack Overflow answer of mine: &lt;em&gt;Is overriding Object.finalize() really bad?&lt;/em&gt; &lt;a class="external"
href="https://programmers.stackexchange.com/a/288724/41811" target="_blank"
&gt;http://programmers.stackexchange.com/a/288724/41811&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There is this practice which is unfortunately very prevalent in the C# world, of implementing object disposal using the ugly, clunky, inelegant, ill-conceived, and error prone idiom known as &lt;strong&gt;IDisposable-disposing&lt;/strong&gt;. MSDN &lt;a class="external"
href="https://msdn.microsoft.com/en-us/library/fs2xkftw%28v=vs.110%29.aspx" target="_blank"
&gt;describes it in length&lt;/a&gt;, and lots of people swear by it, follow it religiously, write walls of text discussing &lt;a class="external"
href="https://stackoverflow.com/q/538060/773113" target="_blank"
&gt;&lt;em&gt;precisely&lt;/em&gt; how it should be done and &lt;em&gt;precisely&lt;/em&gt; how it works&lt;/a&gt;, and &lt;a class="external"
href="https://joeduffyblog.com/2005/04/08/dg-update-dispose-finalization-and-resource-management/" target="_blank"
&gt;precisely how they arrived at this particular way of doing it&lt;/a&gt;, etc.&lt;/p&gt;
&lt;p&gt;(Please note that what I am calling ugly here is not the object disposal pattern itself; what I am calling ugly is the particular idiom of implementing an extra &lt;code&gt;Dispose&lt;/code&gt; method with a &lt;code&gt;bool disposing&lt;/code&gt; parameter.)&lt;/p&gt;
&lt;p&gt;This idiom was invented under the assumption that the invocation of &lt;code&gt;IDisposable.Dispose()&lt;/code&gt; is something optional, or in any case something which might be OK to forget, in combination with the fact that it is impossible to guarantee that our objects' destructor will always be invoked by the garbage collector to clean up resources. So, people tend to make their best effort to invoke their &lt;code&gt;IDisposable.Dispose()&lt;/code&gt; methods, and in case they forget, they also give it one more try from within the destructor. You know, just in case.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;But then your &lt;code&gt;IDisposable.Dispose()&lt;/code&gt; might have both managed and unmanaged objects to clean up, but the managed ones cannot be cleaned up when &lt;code&gt;IDisposable.Dispose()&lt;/code&gt; is invoked from within the destructor, because they have already been taken care of by the garbage collector at that point in time, so there is this need for a separate &lt;code&gt;Dispose()&lt;/code&gt; method that accepts a &lt;code&gt;bool disposing&lt;/code&gt; flag to know if both managed and unmanaged objects should be cleaned up, or only unmanaged ones. In addition to that, you have to guard against disposing your unmanaged resources twice, so you have to either have a &lt;code&gt;disposed&lt;/code&gt; member variable to keep track of whether &lt;code&gt;IDisposable.Dispose()&lt;/code&gt; has been invoked, or, better yet, invoke &lt;code&gt;GC.SuppressFinalize()&lt;/code&gt; from within &lt;code&gt;IDisposable.Dispose()&lt;/code&gt; so that finalization can be skipped if the object is known to have been properly disposed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Excuse me, but this is just insane.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I go by Einstein's axiom, which says that &lt;em&gt;things should be as simple as possible, but not simpler.&lt;/em&gt; Clearly, we cannot omit the cleaning up of resources, so the simplest possible solution has to include at least that. The next simplest solution involves always disposing everything at the precise point in time that it is supposed to be disposed, without complicating things by bringing into the picture the destructor as an alternative fall back. So, that has to be it, according to my line of thinking. I call it &lt;strong&gt;&lt;em&gt;Mandatory Disposal&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Now, strictly speaking, it is of course impossible to guarantee that every single programmer out there will always remember to make sure that &lt;code&gt;IDisposable.Dispose()&lt;/code&gt; will be invoked, but what &lt;em&gt;can&lt;/em&gt; be done, is that the destructor can be used to detect such omissions. The crux of the matter is what we do once we have detected such an omission: &lt;strong&gt;we do not attempt to correct it; instead, we generate an error message.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It is very simple, really. (Duh!) All the destructor has to do is generate a log entry if it detects that the &lt;code&gt;disposed&lt;/code&gt; flag of the &lt;code&gt;IDisposable&lt;/code&gt; object was never set to true. So, the use of the destructor is not an integral part of our disposal strategy, but it is our quality assurance mechanism. And since this is a debug-mode only test, we can place our entire destructor inside an &lt;code&gt;#if DEBUG&lt;/code&gt; block, so we never incur any destruction penalty in a production environment. The IDisposable-disposing idiom prescribes that &lt;code&gt;GC.SuppressFinalize()&lt;/code&gt; should be invoked precisely in order to lessen the overhead of finalization, but with Mandatory Disposal it is possible to &lt;strong&gt;completely avoid all finalization in our production build.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;What it boils down to is the eternal &lt;strong&gt;hard error doctrine vs. soft error doctrine&lt;/strong&gt; argument:&lt;/p&gt;
&lt;p&gt;The IDisposable-disposing idiom of object disposal is a soft error doctrine approach, allowing the programmer to forget to invoke &lt;code&gt;IDisposable.Dispose()&lt;/code&gt; and attempting to somehow (magically) make things right in the end. My Mandatory Disposal idiom is a hard error doctrine approach, requiring that the programmer must always make sure that &lt;code&gt;IDisposable.Dispose()&lt;/code&gt; gets invoked, under penalty of error.&lt;/p&gt;
&lt;p&gt;The error is mitigated in this special case, from the standard assertion failure exception that the hard error doctrine usually calls for, to a mere error-level message in the debug log, since the error is detected during finalization, and by that time it is too late for fail-fast measures anyway.&lt;/p&gt;
&lt;p&gt;The Mandatory Disposal mechanism works best if the &lt;code&gt;DEBUG&lt;/code&gt; build of our application performs a full garbage disposal before quitting, so as to guarantee that all destructors will be invoked, and thus detect any &lt;code&gt;IDisposable&lt;/code&gt; objects that we forgot to dispose. Also, the Mandatory Disposal mechanism works best if we avoid using static references to objects, because such references prevent objects from being garbage-collected.&lt;/p&gt;
&lt;p&gt;Once you start using Mandatory Disposal, one issue you inevitably encounter is that you discover objects which you forgot to dispose of, but you do not know how to fix them because you have no idea where they were allocated. There is a nice way of solving this problem without considerable complications, but this will be the subject of another post.&lt;/p&gt;
&lt;p&gt;More on this issue, but in java-oriented terms, in this Stack Overflow answer of mine: &lt;em&gt;Is overriding Object.finalize() really bad?&lt;/em&gt;&lt;a class="external"
href="https://programmers.stackexchange.com/a/288724/41811" target="_blank"
&gt;http://programmers.stackexchange.com/a/288724/41811&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A whole new paper on this issue is here: &lt;a
href="https://blog2.michael.gr/post/2020-12-27-object-lifetime-awareness/"
&gt;Object Lifetime Awareness&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Assertions and Testing</title><link>https://blog2.michael.gr/post/2014-09-assertions-and-testing/</link><pubDate>Fri, 19 Sep 2014 15:27:57 +0000</pubDate><guid>https://blog2.michael.gr/post/2014-09-assertions-and-testing/</guid><description>&lt;p&gt;So, since we do software testing, we should quit placing &lt;code&gt;assert&lt;/code&gt; statements in production code, right? Let me count the ways in which this is wrong:&lt;/p&gt;
&lt;p&gt;(TL;DR: skip to the paragraph containing a red sentence and read only that.)&lt;/p&gt;
&lt;h3 id="1-assertions-are-optional"&gt;1. Assertions are optional.
&lt;/h3&gt;&lt;p&gt;Each programming language has its own mechanism for enabling or disabling assertions. In languages like C++ and C# there is a distinction between a release build and a debug build, and assertions are generally only enabled in the debug build. Java has a simpler mechanism: there is only one build, but assertions do not execute unless the &lt;code&gt;-enableassertions&lt;/code&gt; (&lt;code&gt;-ea&lt;/code&gt; for short) option is specified in the command line which started the virtual machine. Therefore, if someone absolutely cannot stand the idea that assertions may be executing in a production environment, they can simply refrain from supplying the &lt;code&gt;-ea&lt;/code&gt; option; problem solved.&lt;/p&gt;
&lt;p&gt;(Useful pre-reading: &lt;a
href="https://blog2.michael.gr/post/2022-11-about-these-papers/"
&gt;About these papers&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;The mere fact that assertions are optional and not even enabled by default should be enough to quench any objections to their use. Now, in order to convince people to start actively using assertions instead of merely not minding if others do, I need to explain why assertions are awesome. This is what the rest of this document sets out to do.&lt;/p&gt;
&lt;h3 id="2-assertions-check-things-that-testing-cannot-and-should-not"&gt;2. Assertions check things that testing cannot (and should not.)
&lt;/h3&gt;&lt;p&gt;Testing treats (or should be treating) the production code as a black box, ensuring that given specific input, it produces expected results. Assertions, on the other hand, have a white box view of the code, (of course, since they live in it,) so they perform internal checks to make sure that everything is working as expected under the hood. Therefore, the domain of assertions is different from the domain of software testing, so there is a clear need for both.&lt;/p&gt;
&lt;p&gt;If there is any uncertainty as to whether software testing should be taking a black box or a white box approach, let me briefly open up a parenthesis to clarify this one:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;When tests are tied to implementation details of the production code, situations arise where the production code gets refactored or bugs are fixed in it, and as a result the tests break and have to be modified in order to continue passing. I would call this &lt;em&gt;The Fragile Test Problem&lt;/em&gt;. To avoid this, tests should be written having in mind nothing but the operational requirements of the software system, so that they only need to be revised in the event of a change in the requirements. (Also see footnote 1.)&lt;/li&gt;
&lt;li&gt;Testing against implementation details of the production code renders the tests non-reusable:
&lt;ol&gt;
&lt;li&gt;It should be possible to completely rewrite a piece of production code and then reuse the old tests to make sure that the new code works exactly as the old one did.&lt;/li&gt;
&lt;li&gt;It should be possible to write a test once and have it test multiple different implementations of a system, created by independently working development teams taking different approaches to solving the same problem.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Just as users tend to test software in ways that the developer never thought of, (the well known &amp;quot;works for me but always breaks in the hands of the user&amp;quot; paradox,) software tests written by developers who maintain an agnostic stance about the inner workings of the production code are likely to test for things that were never considered by those who wrote the production code.&lt;/li&gt;
&lt;li&gt;Yes, of course, black box testing cannot claim that it leaves nothing to chance, and that's precisely why you need assertions!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Close parenthesis.&lt;/p&gt;
&lt;p&gt;So, each assertion can be seen as a little software test embedded within the software.&lt;/p&gt;
&lt;p&gt;Various techniques that are applicable to software testing are also applicable to assertions. An example of such a technique is the &amp;quot;do not fix it unless there is a test for it&amp;quot; advice. When a malfunction is observed in production, which has obviously passed all existing tests, instead of theorizing as to what went wrong and implementing a fix according to the theory, we add a theory-agnostic test against that malfunction, and we observe it failing. Then, we fix the malfunction according to our theory, and we observe the test passing. If the test still does not pass, then our theory was wrong.&lt;/p&gt;
&lt;p&gt;The exact same approach is valid with assertions, with the added benefit that the assertion is a one-liner instead of an entire test. The savings here can be huge, both in terms of work to be done by the programmer, and in terms of total tests execution time, because a test may have to do a lot of work to set up the right conditions for the malfunction to be observed.&lt;/p&gt;
&lt;h3 id="3-assertions-are-an-excellent-documentation-tool"&gt;3. Assertions are an excellent documentation tool.
&lt;/h3&gt;&lt;p&gt;Unfortunately there is a very prevalent bad habit among software engineers worldwide, the habit of documenting assumptions within comments. This is very bad because:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Every time the code gets revised, amended or refactored, someone must remember to also update the comments, but this does not always happen. As a result, comments tend to become out of date as the code evolves, their accuracy and relevance eventually deteriorating so much that they come in conflict with what the code actually does.&lt;/li&gt;
&lt;li&gt;No comment ever was, or will ever be, as precise and unambiguous as a piece of code stipulating the same thing.&lt;/li&gt;
&lt;li&gt;Even the most precisely and unambiguously expressed comment is, by its very nature of being a comment, not enforceable in any way.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So, if you require a certain condition to be met, or if you have a certain assumption which you believe to be true, put your code where your mouth is and back up your claim with an assertion statement. Since assertions are optional, there is no performance penalty, and even if the code is not even once run with assertions enabled, the assertion is still better documentation than a comment, because at the very least, it compiles.&lt;/p&gt;
&lt;h3 id="4-assertions-can-catch-errors-in-the-testing-code"&gt;4. Assertions can catch errors in the testing code.
&lt;/h3&gt;&lt;p&gt;Sometimes the person coding or maintaining the test code and the person coding or maintaining the production code might have a different understanding of what the operational requirements actually mean. Assertions within the production code help catch any such discrepancies at the earliest point possible, and they show that the production code is the way it is on purpose, and not by accident.&lt;/p&gt;
&lt;h3 id="5-assertions-can-be-more-pertinent-than-testing"&gt;5. Assertions can be more pertinent than testing.
&lt;/h3&gt;&lt;p&gt;Sometimes the operational requirements are vague on issues on which the software design needs to make specific decisions. If the preferred way of solving a certain problem involves a division by something, then obviously, that something must not be zero, but if the operational requirements say nothing about zero, then the tests might not test for zero, and in any case they cannot be expected to test for zero. The implementation, however, knowing its own limitations, should assert against a zero. Ideally, such an issue of vagueness in the specification would be submitted back to the people responsible for it, and it should receive a definitive answer in the operational requirements document, which should then be translated into an additional test, but these things do not always happen in the real world.&lt;/p&gt;
&lt;h3 id="6-assertions-pinpoint-errors-that-testing-only-broadly-hints-at"&gt;6. Assertions pinpoint errors that testing only broadly hints at.
&lt;/h3&gt;&lt;p&gt;Consider this scenario: you have a TimeTable object which contains WorkShift objects. The shifts are stored in an array which is sorted by start time, and binary search is used to answer queries such as which employee is working at a certain time. Now, suppose that you have forgotten to sort the array after an insertion, so the binary search fails.&lt;/p&gt;
&lt;p&gt;All that the failed test will tell you is that it scheduled John to work from 10:00 to 11:00, but a query for who works at 10:30 did not yield anyone. This is not very useful; the bug could be anywhere.&lt;/p&gt;
&lt;p&gt;Proper use of assertions mandates that at the very least, immediately prior to performing a binary search on your array, you should ensure that it meets the requirement for it to be searchable via binary search, that is, to be sorted. So, voila! the assertion immediately discovers the nature of the bug.&lt;/p&gt;
&lt;p&gt;Even better, at the end of each operation on your TimeTable object you can assert that the operation is leaving the object in a valid state, which includes the requirement that this array must be at all times sorted. Thus, you will have an assertion failure at the end of the method which inserted an item to the array but forgot to sort it, pinpointing the bug with great accuracy.&lt;/p&gt;
&lt;p&gt;Now imagine the same happening in an immensely more complicated software system, where a maintenance programmer attempts to make a few small changes without comprehending exactly how the entire system works, and as a result the tests of this system start to fail without any indication as to where the problem might be. Sure, those few altered lines of code broke it, but how? What is wrong? Would it not be nice if the system could tell us what is wrong with it? Well, assertions help you achieve precisely that: software systems that can very often tell what is wrong with themselves.&lt;/p&gt;
&lt;h3 id="7-assertions-reduce-program-complexity"&gt;7. Assertions reduce program complexity.
&lt;/h3&gt;&lt;p&gt;The &lt;a class="external"
href="https://en.wikipedia.org/wiki/Time_complexity" target="_blank"
&gt;time complexity&lt;/a&gt; and &lt;a class="external"
href="https://en.wikipedia.org/wiki/Computational_complexity_theory" target="_blank"
&gt;computational complexity&lt;/a&gt; of algorithms are subjects which have received extensive study, but most of the code being written on a daily basis all over the planet is not algorithms in an academic sense, so these notions are inapplicable to it. What is pertinent to most code that we regularly write is &lt;em&gt;state complexity&lt;/em&gt;, which is a subject that has not received much study yet. I hope that an analytical state complexity algebra will be invented one day, allowing us to accurately calculate the state complexity of any given piece of code, but until then, nothing prevents us from theorizing about it in coarse terms. I hold it as self evident that if you add a variable to a system, the total state complexity of the system is compounded by something akin to the number of bits of that variable multiplied by the total number of statements throughout the system that make use of the value of that variable. If you add an &lt;code&gt;if&lt;/code&gt; statement, total system state complexity is compounded by the number of bits of state altered by the body of the &lt;code&gt;if&lt;/code&gt; statement, times two for the case that the body of the &lt;code&gt;if&lt;/code&gt; statement does not get executed, and therefore the bits do not get altered. From this it should be evident that each time we add the tiniest little something to our program, we are exponentially increasing its state complexity.&lt;/p&gt;
&lt;p&gt;There are only two constructs that I know of which actually reduce program state complexity instead of increasing it. One is the &lt;code&gt;final&lt;/code&gt; keyword, and the other is the &lt;code&gt;assert&lt;/code&gt; statement. The &lt;code&gt;final&lt;/code&gt; keyword makes bits unalterable, thus excluding them from program state. The &lt;code&gt;assert&lt;/code&gt; keyword limits the ranges of values that variables may have, thus also reducing the number of bits that participate in program state, and it even goes one step further, eliminating &lt;code&gt;if&lt;/code&gt; statements and guaranteeing that certain paths of execution will never be followed.&lt;/p&gt;
&lt;p&gt;So, think about it: every time you code an assertion statement you are actually making your program more simple instead of more complicated. I believe that this realization alone should be enough to convince anyone that &lt;code&gt;assert&lt;/code&gt;, along with &lt;code&gt;final&lt;/code&gt;, are literally the most useful constructs that any programmer could ever use.&lt;/p&gt;
&lt;h3 id="8-assertions-help-the-compiler-make-better-sense-of-your-code"&gt;8. Assertions help the compiler make better sense of your code.
&lt;/h3&gt;&lt;p&gt;Please do try this at home:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-Java" data-lang="Java"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;foo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Object&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;assert&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;If you have a reasonable number of warnings enabled, (as any decent programmer would,) your compiler should issue a warning telling you that the condition &lt;code&gt;x == null&lt;/code&gt; is always false. What this demonstrates is that the preceding assertion gave the compiler knowledge of the fact that &lt;code&gt;x&lt;/code&gt; cannot be null, and the compiler is now making use of this knowledge as it compiles the rest of your method, pointing out to you potential flaws in your reasoning. Furthermore, some compilers perform useful optimizations based on knowledge that they gather from assertion statements. (I do not know to what extent java compilers do that, but I know for a fact that the Microsoft Visual C++ compiler does it; see footnote 2.)&lt;/p&gt;
&lt;h3 id="conclusion"&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;Test code should always be treating production code as a black box, and knowledge of the inner workings of the production code should be used at most as a hint for testing, never as an instrument for testing. Consequently, assertions are necessary for performing white box tests within the production code so as to ensure that absolutely nothing is left to chance.&lt;/p&gt;
&lt;p&gt;Additionally, assertions help document the code, reduce its complexity, strengthen it against assumptions made by the testing code, and help build systems that, in the event of an error, can tell you what is wrong with themselves.&lt;/p&gt;
&lt;p&gt;The fact that assertions are usually disabled on deployed systems means that their use can be thought of as incurring a zero performance penalty, which &lt;strong&gt;allows programmers to develop a maximalistic error-checking culture&lt;/strong&gt; of having every single assumption always checked, never leaving anything to chance. By contrast, runtime checks always incur a performance penalty, and for this reason programmers tend to use them on a minimalistic, &amp;quot;only if necessary&amp;quot; basis. &lt;strong&gt;So, with runtime checks, programmers tend to constantly ask &amp;quot;should I check this?&amp;quot; while with assertions, they can develop the habit of asking &amp;quot;is there anything I forgot to check?&amp;quot;&lt;/strong&gt; (If there is only one paragraph that you should take home from this paper, that was it.)&lt;/p&gt;
&lt;h3 id="addendum-how-to-use-assertions"&gt;Addendum: How to use assertions
&lt;/h3&gt;&lt;p&gt;Assertions can be used in every single place where an unexpected exception would otherwise be thrown. This includes all instances of contract violations such as a null pointer exception or an illegal argument exception, and in general, all instances of errors which a) indicate a bug, (should never happen,) and b) cannot be handled in any meaningful way.&lt;/p&gt;
&lt;p&gt;In java the &lt;code&gt;assert&lt;/code&gt; keyword cannot throw any exception that you might wish it to throw; it only throws the &lt;code&gt;AssertionError&lt;/code&gt; exception. Usually this is not a problem, because no piece of production code should ever try to catch an unexpected exception. (That is, after all, precisely why it is called unexpected; it is not that the guest may arrive unannounced, it is that he is not supposed to arrive at all.) Therefore, since it is never meant to be caught, &lt;code&gt;AssertionError&lt;/code&gt; is, generally speaking, a suitable one-class-fits-all replacement of all unexpected exceptions.&lt;/p&gt;
&lt;p&gt;However, when developing a library, which will be used with assertions presumably enabled at times, you will of course need to have tests which attempt to use your library in various wrong ways, ascertaining that every single one of those attempts gets asserted against, and the problem then with all errors being reported as &lt;code&gt;AssertionError&lt;/code&gt;s is that your tests cannot tell whether the error that was caught was the specific error that you were testing for, and not some unrelated coincidental error. For this reason, when developing libraries, a different approach is needed. One approach is the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-Java" data-lang="Java"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;assert&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;IllegalArgumentException&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;#34;n&amp;#34;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;This works nicely because according to the java language specification, the expression at the right hand side of the colon of an assertion statement does not have to be of any particular type, but if it happens to be of an exception type, then it will be treated as the 'cause' of the &lt;code&gt;AssertionError&lt;/code&gt; exception. (In all other cases, its &lt;code&gt;toString()&lt;/code&gt; will be used as the 'message' of the &lt;code&gt;AssertionError&lt;/code&gt; exception.) Thus, your testing code can catch the assertion exception and examine its cause to ensure that it is indeed the expected exception.&lt;/p&gt;
&lt;p&gt;So, your test suite might contain a utility method like the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt; 1
&lt;/span&gt;&lt;span class="lnt"&gt; 2
&lt;/span&gt;&lt;span class="lnt"&gt; 3
&lt;/span&gt;&lt;span class="lnt"&gt; 4
&lt;/span&gt;&lt;span class="lnt"&gt; 5
&lt;/span&gt;&lt;span class="lnt"&gt; 6
&lt;/span&gt;&lt;span class="lnt"&gt; 7
&lt;/span&gt;&lt;span class="lnt"&gt; 8
&lt;/span&gt;&lt;span class="lnt"&gt; 9
&lt;/span&gt;&lt;span class="lnt"&gt;10
&lt;/span&gt;&lt;span class="lnt"&gt;11
&lt;/span&gt;&lt;span class="lnt"&gt;12
&lt;/span&gt;&lt;span class="lnt"&gt;13
&lt;/span&gt;&lt;span class="lnt"&gt;14
&lt;/span&gt;&lt;span class="lnt"&gt;15
&lt;/span&gt;&lt;span class="lnt"&gt;16
&lt;/span&gt;&lt;span class="lnt"&gt;17
&lt;/span&gt;&lt;span class="lnt"&gt;18
&lt;/span&gt;&lt;span class="lnt"&gt;19
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="n"&gt;final&lt;/span&gt; &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="n"&gt;extends&lt;/span&gt; &lt;span class="n"&gt;Throwable&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="n"&gt;expectException&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;Class&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;exceptionClass&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Runnable&lt;/span&gt; &lt;span class="n"&gt;runnable&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;try&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;runnable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;catch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;Throwable&lt;/span&gt; &lt;span class="n"&gt;throwable&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;throwable&lt;/span&gt; &lt;span class="n"&gt;instanceof&lt;/span&gt; &lt;span class="n"&gt;AssertionError&lt;/span&gt; &lt;span class="p"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;throwable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getCause&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;!=&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;throwable&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;throwable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getCause&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;exceptionClass&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isInstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;throwable&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;throwable&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;//exception of the wrong kind was thrown.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;throwable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getClass&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;==&lt;/span&gt; &lt;span class="n"&gt;exceptionClass&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;throwable&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;//exception thrown was a subclass, but not the exact class, expected.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;@SuppressWarnings&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="s"&gt;&amp;#34;unchecked&amp;#34;&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;throwable&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;assert&lt;/span&gt; &lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;//expected exception was not thrown.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;//to keep the compiler happy.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Which might be used as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;IllegalArgumentException&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;expectException&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;IllegalArgumentException&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;myObject&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="n"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getMessage&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="k"&gt;equals&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="s"&gt;&amp;#34;n&amp;#34;&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;There are times when you have the need to check whether assertions are enabled. For example, in the first thing I always do in my test suites is to make sure that assertions are enabled, because if someone forgot to pass the -ea switch, all tests may pass without checking for a single defect in the code. Here is how to test whether assertions are enabled in java:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt;1
&lt;/span&gt;&lt;span class="lnt"&gt;2
&lt;/span&gt;&lt;span class="lnt"&gt;3
&lt;/span&gt;&lt;span class="lnt"&gt;4
&lt;/span&gt;&lt;span class="lnt"&gt;5
&lt;/span&gt;&lt;span class="lnt"&gt;6
&lt;/span&gt;&lt;span class="lnt"&gt;7
&lt;/span&gt;&lt;span class="lnt"&gt;8
&lt;/span&gt;&lt;span class="lnt"&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-CSharp" data-lang="CSharp"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="n"&gt;boolean&lt;/span&gt; &lt;span class="n"&gt;isAssertEnabled&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;//noinspection UnusedAssignment&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;boolean&lt;/span&gt; &lt;span class="n"&gt;assertEnabled&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;//noinspection AssertWithSideEffects,NestedAssignment,ConstantConditions&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="n"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;assertEnabled&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="c1"&gt;//noinspection ConstantConditions&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;assertEnabled&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Note: the &lt;code&gt;//noinspection&lt;/code&gt; comments are understood by IntelliJ IDEA; if the misfortune hath befallen thee of having to use some other IDE such as Eclipse, you will have to use some different warning suppression notation.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="footnote-1"&gt;Footnote 1
&lt;/h3&gt;&lt;p&gt;What makes the Fragile Test Problem especially bad is that the process of fixing tests to make them pass is often carried out under unfavorable conditions, resulting in a sloppy job:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The programmer needs to switch his frame of mind back and forth between his core work and the somewhat unrelated and usually less exciting context of tests;&lt;/li&gt;
&lt;li&gt;The need for these fixes is usually unforeseen, so time for the fixes is rarely allocated in the schedule, which means that the programmer fixing broken tests is usually in a hurry;&lt;/li&gt;
&lt;li&gt;It is not always clear whether the production code is right and the test is wrong, or whether the test is right and a dormant bug in the production code has been exposed; etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, what tends to happen is that tests are quite often fixed sloppily, so over time they tend to evolve to &amp;quot;test around&amp;quot; (specifically pass) long-standing bugs.&lt;/p&gt;
&lt;p&gt;In the preface of Roy Osherove's &lt;em&gt;The Art of Unit Testing&lt;/em&gt; (Manning, 2009) the author admits to having participated in a project which failed to a large part due to the tremendous development burden imposed by badly designed unit tests which had to be maintained throughout the duration of the development effort.&lt;/p&gt;
&lt;h3 id="footnote-2"&gt;Footnote 2
&lt;/h3&gt;&lt;p&gt;In Microsoft Visual C++ the &lt;code&gt;ASSERT(x)&lt;/code&gt; macro does not expand to nothing when _DEBUG is undefined; instead, it expands to an &lt;code&gt;assume(x)&lt;/code&gt; intrinsic directive which, even though it does not cause any code to be emitted, it allows the asserted expression to survive the preprocessing step and to be considered by the compiler, so that the corresponding optimizations can take place in the release build, too.&lt;/p&gt;
&lt;h3 id="further-reading"&gt;Further reading
&lt;/h3&gt;&lt;p&gt;Stackoverflow answer by Jo√£o Manuel Rodrigues
&lt;a class="external"
href="https://stackoverflow.com/a/49131673/773113" target="_blank"
&gt;https://stackoverflow.com/a/49131673/773113&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Stackoverflow answer by me
&lt;a class="external"
href="https://stackoverflow.com/a/27622328/773113" target="_blank"
&gt;https://stackoverflow.com/a/27622328/773113&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Benchmarking code written in Java or C# (or any GCed, JITted, VM-based language)</title><link>https://blog2.michael.gr/post/2014-07-benchmarking-code-written-in-java-or-c/</link><pubDate>Fri, 18 Jul 2014 15:45:12 +0000</pubDate><guid>https://blog2.michael.gr/post/2014-07-benchmarking-code-written-in-java-or-c/</guid><description>&lt;p&gt;NOTE: This paper contains various inaccuracies.&lt;/p&gt;
&lt;p&gt;Sometimes we need to measure the time it takes for various pieces of code to execute in order to determine whether a certain construct takes significantly less time to execute than another. It sounds like a pretty simple task, but anyone who has ever attempted to do it knows that simplistic approaches are highly inaccurate, and achieving any accuracy at all is not trivial.&lt;/p&gt;
&lt;p&gt;Back in the days of C and MS-DOS things were pretty straightforward: you would read the value of the system clock, run your code, read the value of the clock again, subtract the two, and that was how much time it took to run your code. The rather coarse resolution of the system clock would skew things a bit, so one trick you would at the very least employ was to loop waiting for the value of the system clock to change, then start running your code, and stop running at another transition of the value of the system clock. Another popular hack was to run benchmarks with interrupts disabled. Yes, back in those days the entire machine was yours, so you could actually do such a thing.&lt;/p&gt;
&lt;p&gt;Nowadays, things are far more complicated. For one thing, the entire machine tends to never be yours, so you cannot disable interrupts. Other threads will pre-empt your thread, and there is nothing you can do about it, you just have to accept some inaccuracy from it. Luckily, with modern multi-core CPUs this is not so much an issue as it used to be, but in modern VM-based languages like Java and C# we have additional and far more severe inaccuracies introduced by the garbage collection and the jitting. Luckily, their impact can be reduced.&lt;/p&gt;
&lt;p&gt;In order to avoid inaccuracies due to jitting, we always perform one run of the code under measurement before the measurements begin. This gives the JIT compiler a chance to do its job, so it will not be getting in the way later, during the actual benchmark.&lt;/p&gt;
&lt;p&gt;In order to avoid inaccuracies due to garbage collection, we always perform one full garbage collection before starting the benchmark, and we try to keep the benchmark short, so as to reduce the chances of another garbage collection happening before it completes. The garbage collection APIs of most VMs tend to be somewhat snobbish, and they do not really guarantee that a full garbage collection will actually take place when requested, so we need an additional trick: we allocate an object keeping only a weak reference to it, then we keep calling the VM to garbage collect and run finalizers until that object disappears. This still does not guarantee that a full garbage collection will take place, but it gives us the closest we can have to a guarantee by using only conventional means.&lt;/p&gt;
&lt;p&gt;So, here is the class that I use for benchmarking, employing all of the above tricks:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt; 1
&lt;/span&gt;&lt;span class="lnt"&gt; 2
&lt;/span&gt;&lt;span class="lnt"&gt; 3
&lt;/span&gt;&lt;span class="lnt"&gt; 4
&lt;/span&gt;&lt;span class="lnt"&gt; 5
&lt;/span&gt;&lt;span class="lnt"&gt; 6
&lt;/span&gt;&lt;span class="lnt"&gt; 7
&lt;/span&gt;&lt;span class="lnt"&gt; 8
&lt;/span&gt;&lt;span class="lnt"&gt; 9
&lt;/span&gt;&lt;span class="lnt"&gt; 10
&lt;/span&gt;&lt;span class="lnt"&gt; 11
&lt;/span&gt;&lt;span class="lnt"&gt; 12
&lt;/span&gt;&lt;span class="lnt"&gt; 13
&lt;/span&gt;&lt;span class="lnt"&gt; 14
&lt;/span&gt;&lt;span class="lnt"&gt; 15
&lt;/span&gt;&lt;span class="lnt"&gt; 16
&lt;/span&gt;&lt;span class="lnt"&gt; 17
&lt;/span&gt;&lt;span class="lnt"&gt; 18
&lt;/span&gt;&lt;span class="lnt"&gt; 19
&lt;/span&gt;&lt;span class="lnt"&gt; 20
&lt;/span&gt;&lt;span class="lnt"&gt; 21
&lt;/span&gt;&lt;span class="lnt"&gt; 22
&lt;/span&gt;&lt;span class="lnt"&gt; 23
&lt;/span&gt;&lt;span class="lnt"&gt; 24
&lt;/span&gt;&lt;span class="lnt"&gt; 25
&lt;/span&gt;&lt;span class="lnt"&gt; 26
&lt;/span&gt;&lt;span class="lnt"&gt; 27
&lt;/span&gt;&lt;span class="lnt"&gt; 28
&lt;/span&gt;&lt;span class="lnt"&gt; 29
&lt;/span&gt;&lt;span class="lnt"&gt; 30
&lt;/span&gt;&lt;span class="lnt"&gt; 31
&lt;/span&gt;&lt;span class="lnt"&gt; 32
&lt;/span&gt;&lt;span class="lnt"&gt; 33
&lt;/span&gt;&lt;span class="lnt"&gt; 34
&lt;/span&gt;&lt;span class="lnt"&gt; 35
&lt;/span&gt;&lt;span class="lnt"&gt; 36
&lt;/span&gt;&lt;span class="lnt"&gt; 37
&lt;/span&gt;&lt;span class="lnt"&gt; 38
&lt;/span&gt;&lt;span class="lnt"&gt; 39
&lt;/span&gt;&lt;span class="lnt"&gt; 40
&lt;/span&gt;&lt;span class="lnt"&gt; 41
&lt;/span&gt;&lt;span class="lnt"&gt; 42
&lt;/span&gt;&lt;span class="lnt"&gt; 43
&lt;/span&gt;&lt;span class="lnt"&gt; 44
&lt;/span&gt;&lt;span class="lnt"&gt; 45
&lt;/span&gt;&lt;span class="lnt"&gt; 46
&lt;/span&gt;&lt;span class="lnt"&gt; 47
&lt;/span&gt;&lt;span class="lnt"&gt; 48
&lt;/span&gt;&lt;span class="lnt"&gt; 49
&lt;/span&gt;&lt;span class="lnt"&gt; 50
&lt;/span&gt;&lt;span class="lnt"&gt; 51
&lt;/span&gt;&lt;span class="lnt"&gt; 52
&lt;/span&gt;&lt;span class="lnt"&gt; 53
&lt;/span&gt;&lt;span class="lnt"&gt; 54
&lt;/span&gt;&lt;span class="lnt"&gt; 55
&lt;/span&gt;&lt;span class="lnt"&gt; 56
&lt;/span&gt;&lt;span class="lnt"&gt; 57
&lt;/span&gt;&lt;span class="lnt"&gt; 58
&lt;/span&gt;&lt;span class="lnt"&gt; 59
&lt;/span&gt;&lt;span class="lnt"&gt; 60
&lt;/span&gt;&lt;span class="lnt"&gt; 61
&lt;/span&gt;&lt;span class="lnt"&gt; 62
&lt;/span&gt;&lt;span class="lnt"&gt; 63
&lt;/span&gt;&lt;span class="lnt"&gt; 64
&lt;/span&gt;&lt;span class="lnt"&gt; 65
&lt;/span&gt;&lt;span class="lnt"&gt; 66
&lt;/span&gt;&lt;span class="lnt"&gt; 67
&lt;/span&gt;&lt;span class="lnt"&gt; 68
&lt;/span&gt;&lt;span class="lnt"&gt; 69
&lt;/span&gt;&lt;span class="lnt"&gt; 70
&lt;/span&gt;&lt;span class="lnt"&gt; 71
&lt;/span&gt;&lt;span class="lnt"&gt; 72
&lt;/span&gt;&lt;span class="lnt"&gt; 73
&lt;/span&gt;&lt;span class="lnt"&gt; 74
&lt;/span&gt;&lt;span class="lnt"&gt; 75
&lt;/span&gt;&lt;span class="lnt"&gt; 76
&lt;/span&gt;&lt;span class="lnt"&gt; 77
&lt;/span&gt;&lt;span class="lnt"&gt; 78
&lt;/span&gt;&lt;span class="lnt"&gt; 79
&lt;/span&gt;&lt;span class="lnt"&gt; 80
&lt;/span&gt;&lt;span class="lnt"&gt; 81
&lt;/span&gt;&lt;span class="lnt"&gt; 82
&lt;/span&gt;&lt;span class="lnt"&gt; 83
&lt;/span&gt;&lt;span class="lnt"&gt; 84
&lt;/span&gt;&lt;span class="lnt"&gt; 85
&lt;/span&gt;&lt;span class="lnt"&gt; 86
&lt;/span&gt;&lt;span class="lnt"&gt; 87
&lt;/span&gt;&lt;span class="lnt"&gt; 88
&lt;/span&gt;&lt;span class="lnt"&gt; 89
&lt;/span&gt;&lt;span class="lnt"&gt; 90
&lt;/span&gt;&lt;span class="lnt"&gt; 91
&lt;/span&gt;&lt;span class="lnt"&gt; 92
&lt;/span&gt;&lt;span class="lnt"&gt; 93
&lt;/span&gt;&lt;span class="lnt"&gt; 94
&lt;/span&gt;&lt;span class="lnt"&gt; 95
&lt;/span&gt;&lt;span class="lnt"&gt; 96
&lt;/span&gt;&lt;span class="lnt"&gt; 97
&lt;/span&gt;&lt;span class="lnt"&gt; 98
&lt;/span&gt;&lt;span class="lnt"&gt; 99
&lt;/span&gt;&lt;span class="lnt"&gt;100
&lt;/span&gt;&lt;span class="lnt"&gt;101
&lt;/span&gt;&lt;span class="lnt"&gt;102
&lt;/span&gt;&lt;span class="lnt"&gt;103
&lt;/span&gt;&lt;span class="lnt"&gt;104
&lt;/span&gt;&lt;span class="lnt"&gt;105
&lt;/span&gt;&lt;span class="lnt"&gt;106
&lt;/span&gt;&lt;span class="lnt"&gt;107
&lt;/span&gt;&lt;span class="lnt"&gt;108
&lt;/span&gt;&lt;span class="lnt"&gt;109
&lt;/span&gt;&lt;span class="lnt"&gt;110
&lt;/span&gt;&lt;span class="lnt"&gt;111
&lt;/span&gt;&lt;span class="lnt"&gt;112
&lt;/span&gt;&lt;span class="lnt"&gt;113
&lt;/span&gt;&lt;span class="lnt"&gt;114
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-Java" data-lang="Java"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kn"&gt;package&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;saganaki&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;java.lang.ref.WeakReference&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;&lt;/span&gt;&lt;span class="cm"&gt;/**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * Measures the time it takes to run a piece of code.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; *
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * @author Michael Belivanakis (michael.gr)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; */&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;&lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Benchmark&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;private&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;final&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;long&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;NANOSECONDS_PER_MILLISECOND&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;1000_000L&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;private&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;final&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;long&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;durationInMilliseconds&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="cm"&gt;/**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * Initializes a new instance of {@link Benchmark}.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; *
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * @param durationInMilliseconds for how long to run the benchmark.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; */&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;Benchmark&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;long&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;durationInMilliseconds&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;durationInMilliseconds&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;durationInMilliseconds&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="cm"&gt;/**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * Runs the benchmark, printing the results to {@link System#out}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; *
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * @param prefix text to print before the results.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * @param runnable the code to benchmark.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; */&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;runAndPrint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;prefix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Runnable&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;runnable&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;iterationsPerMillisecond&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;runnable&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;iterationsPerMillisecond&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;roundToSignificantFigures&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;iterationsPerMillisecond&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;6&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;prefix&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;#34; &amp;#34;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;iterationsPerMillisecond&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;#34; iterations per millisecond&amp;#34;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="cm"&gt;/**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * Runs the benchmark
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; *
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * @param runnable the code to benchmark.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; *
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * @return number of iterations per millisecond.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; */&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;public&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Runnable&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;runnable&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;//run the benchmarked code once, so that it gets JITted&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;runnable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;run&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;//perform a full garbage collection to bring the VM to an as clean as possible state&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;runGarbageCollection&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;//wait for a system clock transition&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;long&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;currentNanos&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;nanoTime&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;long&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;startNanos&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;currentNanos&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;currentNanos&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;startNanos&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;currentNanos&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;nanoTime&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;startNanos&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;currentNanos&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;//run the benchmarked code for the given number of milliseconds&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;long&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;endNanos&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;startNanos&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;durationInMilliseconds&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;NANOSECONDS_PER_MILLISECOND&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;long&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;iterations&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;iterations&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;currentNanos&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;endNanos&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;iterations&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;runnable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;run&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;currentNanos&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;nanoTime&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;//calculate and return number of iterations per millisecond.&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;iterations&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;currentNanos&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;startNanos&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;NANOSECONDS_PER_MILLISECOND&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="cm"&gt;/**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * Runs a full garbage collection.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; *
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * See Stack Overflow: Forcing Garbage Collection in Java?
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; */&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;private&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;runGarbageCollection&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;WeakReference&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Object&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ref&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;WeakReference&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Object&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;gc&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Runtime&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getRuntime&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="na"&gt;runFinalization&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ref&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Thread&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;yield&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="cm"&gt;/**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * Rounds a number to a given number of significant digits.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; *
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * See Stack Overflow: rounding to an arbitrary number of significant digits
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; *
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * @param number the number to round
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * @param digits the number of significant digits to round to.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; *
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; * @return the number rounded to the given number of significant digits.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="cm"&gt; */&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;private&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;roundToSignificantFigures&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;digits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nd"&gt;@SuppressWarnings&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;#34;NonReproducibleMathCall&amp;#34;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;final&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Math&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;ceil&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Math&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;log10&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nd"&gt;@SuppressWarnings&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;#34;NumericCastThatLosesPrecision&amp;#34;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;final&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;power&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;digits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nd"&gt;@SuppressWarnings&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;#34;NonReproducibleMathCall&amp;#34;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;final&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;magnitude&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Math&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;pow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;power&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;final&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;long&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;shifted&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Math&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;magnitude&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;shifted&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;magnitude&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;For an application of the above class, see my next post: &lt;a
href="https://blog2.michael.gr/post/2014-07-benchmarking-java-8-lambdas/"
&gt;Benchmarking Java 8 lambdas&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Intertwine: Normalizing Interface Invocations</title><link>https://blog2.michael.gr/post/2011-10-16-intertwine-normalizing-interface/</link><pubDate>Sun, 16 Oct 2011 18:42:25 +0000</pubDate><guid>https://blog2.michael.gr/post/2011-10-16-intertwine-normalizing-interface/</guid><description>&lt;p&gt;Note: This post has been superseded by a new post in 2022. See &lt;a
href="https://blog2.michael.gr/post/2022-12-intertwine/"
&gt;Intertwine&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is a C# project that I did back in 2011. It consists of a (rather informal) white paper which describes the project, and a zip file containing the source code in the form of a Microsoft Visual Studio solution.&lt;/p&gt;
&lt;p&gt;Here is the abstract:&lt;/p&gt;
&lt;p&gt;A mechanism is proposed for converting (entwining) method call invocations of any interface to a general purpose single-method normal form, and converting back (untwining) from the normal form to interface invocations, so that operations can be performed on the normal form in a way agnostic to the interface being invoked. The normal form is a delegate in C# or a functional interface in Java, realized as &lt;code&gt;object AnyCall( int selector, object[] parameters )&lt;/code&gt;. A DotNet implementation is provided in C#, though the discussion also applies to Java.&lt;/p&gt;
&lt;p&gt;And here is the table of contents:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Abstract&lt;/strong&gt; (page 1)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The Problem&lt;/strong&gt; (page 1)
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Why messages are bad&lt;/strong&gt; (page 2)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What is missing&lt;/strong&gt; (page 2)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The Solution&lt;/strong&gt; (page 2)
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;A hand-crafted solution&lt;/strong&gt; (page 3)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Automating with Intertwine&lt;/strong&gt; (page 6)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Appendix 1: A note about Dynamic Proxies&lt;/strong&gt; (page 6)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Appendix 2: An example: Interface multicasts (events)&lt;/strong&gt; (page 7)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Appendix 3: Things to fix&lt;/strong&gt; (page 8)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Download the white paper: &lt;a class="external"
href="https://www.dropbox.com/s/yjnkog3taradwz1/Intertwine%20v2.1.pdf?dl=0" target="_blank"
&gt;Intertwine v2.1.pdf&lt;/a&gt;&lt;/strong&gt;
&lt;strong&gt;Download the source code: &lt;a class="external"
href="https://www.dropbox.com/s/4cw2os83hv4iq91/Intertwine%20v2.0.zip" target="_blank"
&gt;Intertwine v2.0.zip&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;</description></item></channel></rss>